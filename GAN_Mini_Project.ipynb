{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_Mini_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m8AGwZZpG1V",
        "colab_type": "code",
        "outputId": "c4584d5a-9164-44e5-9912-85822f80cd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoQLxUZwpSrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/drive/My\\ Drive/indian-pines-hyperspectral-dataset.zip .\n",
        "!cp /content/drive/My\\ Drive/models/model_0698.h5 ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtjtRntmKnLp",
        "colab_type": "code",
        "outputId": "3b18f4c9-e331-428e-d84e-3e119ea03277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!unzip indian-pines-hyperspectral-dataset.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  indian-pines-hyperspectral-dataset.zip\n",
            "  inflating: indianpinearray.npy     \n",
            "  inflating: IPgt.npy                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26QNI_AedlsN",
        "colab_type": "code",
        "outputId": "f68e0641-3f61-4e9b-c136-b1408eaede24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnbX6wfZzFEC",
        "colab_type": "code",
        "outputId": "d75f2687-4476-404e-b560-1c2c9cf9ef15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import keras.backend as K\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPElY_I20pEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications, layers\n",
        "\n",
        "class FrozenBatchNormalization(layers.BatchNormalization):\n",
        "    def call(self, inputs, training=None):\n",
        "        return super().call(inputs=inputs, training=False)\n",
        "\n",
        "# Keep a copy of the original class\n",
        "BatchNormalization = layers.BatchNormalization\n",
        "\n",
        "# Patch the class temporarily\n",
        "layers.BatchNormalization = FrozenBatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhOKnBCkLmxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "data = np.load('indianpinearray.npy')\n",
        "gt = np.load('IPgt.npy')\n",
        "gt = gt.flatten()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPZefS5U3gjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import expand_dims\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.fashion_mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D,Conv1D,multiply\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D, UpSampling1D\n",
        "from keras.initializers import RandomNormal\n",
        "from matplotlib import pyplot\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from skimage.color import label2rgb\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77RdXF9E4fV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_discriminator(in_shape=(10,1), n_classes=17):\n",
        "\tmodel = Sequential()\n",
        "\n",
        "\tmodel.add(Conv1D(256, kernel_size=4, strides=1, input_shape=in_shape, padding=\"same\"))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "\tmodel.add(Conv1D(512, kernel_size=4, strides=1, padding=\"same\"))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "\tmodel.add(Conv1D(128, kernel_size=4, strides=1, padding=\"same\"))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.summary()\n",
        "\n",
        "\timg = Input(shape=in_shape)\n",
        "\tfeatures = model(img)\n",
        "\tvalidity = Dense(1, activation=\"sigmoid\")(features)\n",
        "\tlabel = Dense(n_classes, activation=\"softmax\")(features)\n",
        "\tmodel = Model(img, [validity, label])\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.summary()\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt, metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDTE3a3n4gmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_generator(latent_dim, n_classes=17):\n",
        "\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(512, activation=\"relu\", input_dim=latent_dim))\n",
        "\tmodel.add(Reshape((1, 512)))\n",
        "\tmodel.add(BatchNormalization(momentum=0.8))\n",
        "\tmodel.add(UpSampling1D())\n",
        "\tmodel.add(Conv1D(512, kernel_size=4, padding=\"same\"))\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tmodel.add(BatchNormalization(momentum=0.8))\n",
        "\tmodel.add(UpSampling1D(size=5))\n",
        "\tmodel.add(Conv1D(128, kernel_size=4, padding=\"same\"))\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tmodel.add(BatchNormalization(momentum=0.8))\n",
        "\tmodel.add(Conv1D(1, kernel_size=4, padding='same'))\n",
        "\tmodel.add(Activation(\"tanh\"))\n",
        "\tmodel.summary()\n",
        "\n",
        "\tnoise = Input(shape=(latent_dim,))\n",
        "\tlabel = Input(shape=(1,), dtype='int32')\n",
        "\tlabel_embedding = Flatten()(Embedding(n_classes, latent_dim)(label))\n",
        "\n",
        "\tmodel_input = multiply([noise, label_embedding])\n",
        "\timg = model(model_input)\n",
        "\n",
        "\treturn Model([noise, label], img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW6TRvQz4tNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "\td_model.trainable = False\n",
        "\tgan_output = d_model(g_model.output)\n",
        "\tmodel = Model(g_model.input, gan_output)\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt)\n",
        "\treturn model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fo9EEAJ-4tYS",
        "colab_type": "code",
        "outputId": "aad36499-cba2-448b-c5e3-23c2bec7ad00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "voxel = data.reshape(-1,data.shape[2])\n",
        "scaler = StandardScaler()\n",
        "voxel = scaler.fit_transform(voxel)\n",
        "pca = PCA(n_components=10)\n",
        "principalComponents = pca.fit_transform(voxel)\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['pc'+str(x) for x in range(10)])\n",
        "fullDataX = principalDf\n",
        "fullDataY = pd.DataFrame(data=gt)\n",
        "X_train, X_test, y_train, y_test = train_test_split(principalDf, pd.DataFrame(data=gt), test_size=0.20)\n",
        "ax = sns.barplot( x=[\"pc\"+str(i) for i in range(10)],y=pca.explained_variance_)\n",
        "ax.set_title(\"PCA\")\n",
        "\n",
        "\n",
        "def generate_real_test_samples(n_samples):\n",
        "\timages, labels =  X_test,y_test\n",
        "\tix = randint(0, images.shape[0], n_samples)\n",
        "\tX, labels = images.iloc[ix], labels.iloc[ix]\n",
        "\tX = X.to_numpy().reshape(n_samples,10,1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn [X, labels], y\n",
        "\n",
        "def generate_real_samples(n_samples):\n",
        "\timages, labels =  X_train, y_train\n",
        "\tix = randint(0, images.shape[0], n_samples)\n",
        "\tX, labels = images.iloc[ix], labels.iloc[ix]\n",
        "\tX = X.to_numpy().reshape(n_samples,10,1)\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn [X, labels], y\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=17):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
        "\tlabels = randint(0, n_classes, n_samples)\n",
        "\treturn [z_input, labels]\n",
        "\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\tz_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "\timages = generator.predict([z_input, labels_input])\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn [images, labels_input], y\n",
        "\n",
        "def summarize_performance(step, g_model, latent_dim):\n",
        "\tfilename = 'model_%04d.h5' % (step+1)\n",
        "\tg_model.save_weights(filename)\n",
        "\t\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4eUlSBQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA1FxBeYoneO",
        "colab_type": "code",
        "outputId": "c76b1839-5358-4de4-8cb8-8c626216512b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        }
      },
      "source": [
        "def biplot(score,coeff,labels=None):\n",
        "    xs = score[:,0]\n",
        "    ys = score[:,1]\n",
        "    n = coeff.shape[0]\n",
        "    scalex = 1.0/(xs.max() - xs.min())\n",
        "    scaley = 1.0/(ys.max() - ys.min())\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    plt.scatter(xs * scalex,ys * scaley,c=fullDataY.to_numpy().reshape(-1,),cmap=\"jet\")\n",
        "    for i in range(n):\n",
        "        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'r',alpha = 0.5)\n",
        "        if labels is None:\n",
        "            plt.text(coeff[i,0]* 1.75, coeff[i,1] * 1.75, \"Var\"+str(i+1), color = 'g', ha = 'center', va = 'center')\n",
        "        else:\n",
        "            plt.text(coeff[i,0]* 1.75, coeff[i,1] * 1.75, labels[i], color = 'g', ha = 'center', va = 'center')\n",
        "    plt.xlim(-1,1)\n",
        "    plt.ylim(-1,1)\n",
        "    plt.xlabel(\"PC{}\".format(1))\n",
        "    plt.ylabel(\"PC{}\".format(2))\n",
        "    plt.grid()\n",
        "  \n",
        "biplot(principalComponents[:,0:2],np.transpose(pca.components_[0:2, :]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAJRCAYAAAA9A3HHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDwvP3r9ybYx",
        "colab_type": "code",
        "outputId": "3f1a70ef-2ce5-407c-cf4c-6aa28c930e0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
        "clf.fit(X_train, y_train) \n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "macro = f1_score(y_test, y_pred, average='macro')\n",
        "micro = f1_score(y_test, y_pred, average='micro')\n",
        "weighted = f1_score(y_test, y_pred, average='weighted')\n",
        "print(\"Micro: \", micro)\n",
        "print(\"Macro: \", macro)\n",
        "print(\"Weighted: \", weighted)\n",
        "print(\"Accuracy: \", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Micro:  0.6913198573127229\n",
            "Macro:  0.3950280731180826\n",
            "Weighted:  0.6363955822185554\n",
            "Accuracy:  0.6913198573127229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdCuft4IzLBS",
        "colab_type": "code",
        "outputId": "fa9d6ed7-7206-4353-b658-cd5492e76517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm = cm/1000\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(cm, annot=True, ax = ax)\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Confusion Matrix')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAJcCAYAAAAb0rWEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCQr/R+rIpTCU+lXdAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hJLrl5c425k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(g_model, d_model, gan_model, latent_dim, n_epochs=400, n_batch=2048):\n",
        "\timport warnings\n",
        "\twarnings.filterwarnings(\"ignore\")\n",
        "\tbat_per_epo = int(15000 / n_batch)\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\tprev_acc1 = 0.20\n",
        "\tprev_acc2 = 0.20\n",
        "\tfor i in range(n_steps):\n",
        "\t\t[X_real, labels_real], y_real = generate_real_samples( half_batch)\n",
        "\t\tprint(labels_real.shape)\n",
        "\t\td_loss_real = d_model.train_on_batch(X_real, [y_real, labels_real])\n",
        "\t\t[X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\td_loss_fake = d_model.train_on_batch(X_fake, [y_fake, labels_fake])\n",
        "\t\td_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\t\t[z_input, z_labels] = generate_latent_points(latent_dim, n_batch)\n",
        "\t\ty_gan = ones((n_batch, 1))\n",
        "\t\tg_loss = gan_model.train_on_batch([z_input, z_labels], [y_gan, z_labels])\n",
        "\t\top_acc = d_loss[4]\n",
        "\t\tprint (\"Training Metrics: %d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (i, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]))\n",
        "\t\tprint ( \"Validating on test set\" )\n",
        "\n",
        "\t\t# [X_treal, labels_treal], y_treal = generate_real_test_samples(half_batch)\n",
        "\t\t# d_loss_real = d_model.test_on_batch(X_treal, [y_treal, labels_treal])\n",
        "\t\n",
        "\t\t[X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\td_loss = d_model.test_on_batch(X_fake, [y_fake, labels_fake])\n",
        "\t\t#d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\t\n",
        "\t\t[z_input, z_labels] = generate_latent_points(latent_dim, n_batch)\n",
        "\t\ty_gan = ones((n_batch, 1))\n",
        "\t\tg_loss = gan_model.test_on_batch([z_input, z_labels], [y_gan, z_labels])\n",
        "\t\n",
        "\t\tprint (\"Validation Metrics: %d [D loss: %f, acc.: %.2f%%, op_acc: %.2f%%] [G loss: %f]\" % (i, d_loss[0], 100*d_loss[3], 100*d_loss[4], g_loss[0]))\n",
        "\t\n",
        "\t\t# if (op_acc > prev_acc1 and d_loss[4]>prev_acc2):\n",
        "\t\t# \tprev_acc1 = op_acc\n",
        "\t\t# \tprev_acc2 = d_loss[4]\n",
        "\t\t# \tsummarize_performance(i, d_model, latent_dim)\n",
        "\t\tif (i+1) % (bat_per_epo * 10) == 0:\n",
        "\t\t\tsummarize_performance(i, d_model, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ma4lfyn46Cb",
        "colab_type": "code",
        "outputId": "de727e1e-758e-4419-9742-f5965d699729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "latent_dim = 100\n",
        "discriminator = define_discriminator()\n",
        "generator = define_generator(latent_dim)\n",
        "\n",
        "discriminator.trainable = False\n",
        "gan_output = discriminator(generator.output)\n",
        "gan_model = Model(generator.input, gan_output)\n",
        "opt = Adam(lr=0.002, beta_1=0.5)\n",
        "gan_model.compile(loss=['binary_crossentropy', 'sparse_categorical_crossentropy'], optimizer=opt)\n",
        "  \n",
        "#dataset = load_data()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_10 (Conv1D)           (None, 10, 256)           1280      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_11 (Conv1D)           (None, 10, 512)           524800    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "frozen_batch_normalization_6 (None, 10, 512)           2048      \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 10, 128)           262272    \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1280)              0         \n",
            "=================================================================\n",
            "Total params: 790,400\n",
            "Trainable params: 789,376\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 10, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 1280)         790400      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            1281        sequential_4[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 17)           21777       sequential_4[1][0]               \n",
            "==================================================================================================\n",
            "Total params: 813,458\n",
            "Trainable params: 812,434\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 512)               51712     \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 1, 512)            0         \n",
            "_________________________________________________________________\n",
            "frozen_batch_normalization_7 (None, 1, 512)            2048      \n",
            "_________________________________________________________________\n",
            "up_sampling1d_3 (UpSampling1 (None, 2, 512)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 2, 512)            1049088   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 512)            0         \n",
            "_________________________________________________________________\n",
            "frozen_batch_normalization_8 (None, 2, 512)            2048      \n",
            "_________________________________________________________________\n",
            "up_sampling1d_4 (UpSampling1 (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 10, 128)           262272    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10, 128)           0         \n",
            "_________________________________________________________________\n",
            "frozen_batch_normalization_9 (None, 10, 128)           512       \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 10, 1)             513       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10, 1)             0         \n",
            "=================================================================\n",
            "Total params: 1,368,193\n",
            "Trainable params: 1,365,889\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC8HpHPK-6fO",
        "colab_type": "code",
        "outputId": "1828d5bd-0ef6-47e4-f4f1-2ac847b67e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(generator, discriminator, gan_model, latent_dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Training Metrics: 0 [D loss: 3.525901, acc.: 31.93%, op_acc: 7.03%] [G loss: 3.523215]\n",
            "Validating on test set\n",
            "Validation Metrics: 0 [D loss: 3.549351, acc.: 0.00%, op_acc: 6.54%] [G loss: 3.503699]\n",
            "(1024, 1)\n",
            "Training Metrics: 1 [D loss: 3.290110, acc.: 50.00%, op_acc: 27.83%] [G loss: 3.506094]\n",
            "Validating on test set\n",
            "Validation Metrics: 1 [D loss: 3.607728, acc.: 0.00%, op_acc: 7.23%] [G loss: 3.455691]\n",
            "(1024, 1)\n",
            "Training Metrics: 2 [D loss: 3.121123, acc.: 50.00%, op_acc: 30.32%] [G loss: 3.534095]\n",
            "Validating on test set\n",
            "Validation Metrics: 2 [D loss: 3.532652, acc.: 5.47%, op_acc: 5.96%] [G loss: 3.534230]\n",
            "(1024, 1)\n",
            "Training Metrics: 3 [D loss: 2.914962, acc.: 100.00%, op_acc: 30.37%] [G loss: 3.687427]\n",
            "Validating on test set\n",
            "Validation Metrics: 3 [D loss: 3.436670, acc.: 100.00%, op_acc: 4.98%] [G loss: 3.633785]\n",
            "(1024, 1)\n",
            "Training Metrics: 4 [D loss: 2.729887, acc.: 100.00%, op_acc: 32.52%] [G loss: 3.742366]\n",
            "Validating on test set\n",
            "Validation Metrics: 4 [D loss: 3.494133, acc.: 100.00%, op_acc: 6.45%] [G loss: 3.556338]\n",
            "(1024, 1)\n",
            "Training Metrics: 5 [D loss: 2.689628, acc.: 100.00%, op_acc: 32.37%] [G loss: 3.565303]\n",
            "Validating on test set\n",
            "Validation Metrics: 5 [D loss: 3.571606, acc.: 0.00%, op_acc: 6.54%] [G loss: 3.480392]\n",
            "(1024, 1)\n",
            "Training Metrics: 6 [D loss: 2.679237, acc.: 50.00%, op_acc: 32.03%] [G loss: 3.485134]\n",
            "Validating on test set\n",
            "Validation Metrics: 6 [D loss: 3.901593, acc.: 0.00%, op_acc: 5.47%] [G loss: 3.274329]\n",
            "(1024, 1)\n",
            "Training Metrics: 7 [D loss: 2.788166, acc.: 50.00%, op_acc: 32.18%] [G loss: 3.330314]\n",
            "Validating on test set\n",
            "Validation Metrics: 7 [D loss: 4.268769, acc.: 0.00%, op_acc: 5.76%] [G loss: 3.216900]\n",
            "(1024, 1)\n",
            "Training Metrics: 8 [D loss: 2.881421, acc.: 50.00%, op_acc: 31.59%] [G loss: 3.399556]\n",
            "Validating on test set\n",
            "Validation Metrics: 8 [D loss: 3.836282, acc.: 0.00%, op_acc: 6.05%] [G loss: 3.380969]\n",
            "(1024, 1)\n",
            "Training Metrics: 9 [D loss: 2.631427, acc.: 50.00%, op_acc: 32.67%] [G loss: 3.674096]\n",
            "Validating on test set\n",
            "Validation Metrics: 9 [D loss: 3.497741, acc.: 100.00%, op_acc: 5.37%] [G loss: 3.669096]\n",
            "(1024, 1)\n",
            "Training Metrics: 10 [D loss: 2.507293, acc.: 100.00%, op_acc: 31.10%] [G loss: 3.950094]\n",
            "Validating on test set\n",
            "Validation Metrics: 10 [D loss: 3.304693, acc.: 100.00%, op_acc: 4.30%] [G loss: 3.944788]\n",
            "(1024, 1)\n",
            "Training Metrics: 11 [D loss: 2.388790, acc.: 98.88%, op_acc: 33.30%] [G loss: 4.188025]\n",
            "Validating on test set\n",
            "Validation Metrics: 11 [D loss: 3.187349, acc.: 100.00%, op_acc: 5.76%] [G loss: 4.181051]\n",
            "(1024, 1)\n",
            "Training Metrics: 12 [D loss: 2.366642, acc.: 98.63%, op_acc: 31.59%] [G loss: 4.392080]\n",
            "Validating on test set\n",
            "Validation Metrics: 12 [D loss: 3.128602, acc.: 100.00%, op_acc: 6.64%] [G loss: 4.324214]\n",
            "(1024, 1)\n",
            "Training Metrics: 13 [D loss: 2.342816, acc.: 98.29%, op_acc: 30.27%] [G loss: 4.511144]\n",
            "Validating on test set\n",
            "Validation Metrics: 13 [D loss: 3.167885, acc.: 100.00%, op_acc: 5.18%] [G loss: 4.181880]\n",
            "(1024, 1)\n",
            "Training Metrics: 14 [D loss: 2.314883, acc.: 98.49%, op_acc: 32.13%] [G loss: 4.351549]\n",
            "Validating on test set\n",
            "Validation Metrics: 14 [D loss: 3.385150, acc.: 100.00%, op_acc: 5.96%] [G loss: 3.685588]\n",
            "(1024, 1)\n",
            "Training Metrics: 15 [D loss: 2.414782, acc.: 98.14%, op_acc: 32.18%] [G loss: 3.708607]\n",
            "Validating on test set\n",
            "Validation Metrics: 15 [D loss: 3.499574, acc.: 100.00%, op_acc: 4.98%] [G loss: 3.578537]\n",
            "(1024, 1)\n",
            "Training Metrics: 16 [D loss: 2.465692, acc.: 98.54%, op_acc: 31.59%] [G loss: 3.610367]\n",
            "Validating on test set\n",
            "Validation Metrics: 16 [D loss: 3.838976, acc.: 0.00%, op_acc: 5.37%] [G loss: 3.384851]\n",
            "(1024, 1)\n",
            "Training Metrics: 17 [D loss: 2.593835, acc.: 48.58%, op_acc: 33.35%] [G loss: 3.713563]\n",
            "Validating on test set\n",
            "Validation Metrics: 17 [D loss: 3.437077, acc.: 100.00%, op_acc: 6.25%] [G loss: 3.691710]\n",
            "(1024, 1)\n",
            "Training Metrics: 18 [D loss: 2.352186, acc.: 98.97%, op_acc: 33.50%] [G loss: 4.139491]\n",
            "Validating on test set\n",
            "Validation Metrics: 18 [D loss: 3.214527, acc.: 100.00%, op_acc: 6.64%] [G loss: 4.039275]\n",
            "(1024, 1)\n",
            "Training Metrics: 19 [D loss: 2.242957, acc.: 99.37%, op_acc: 33.45%] [G loss: 4.343942]\n",
            "Validating on test set\n",
            "Validation Metrics: 19 [D loss: 3.308419, acc.: 100.00%, op_acc: 6.05%] [G loss: 3.908489]\n",
            "(1024, 1)\n",
            "Training Metrics: 20 [D loss: 2.339059, acc.: 99.76%, op_acc: 31.40%] [G loss: 3.946901]\n",
            "Validating on test set\n",
            "Validation Metrics: 20 [D loss: 3.257479, acc.: 100.00%, op_acc: 5.86%] [G loss: 3.919123]\n",
            "(1024, 1)\n",
            "Training Metrics: 21 [D loss: 2.287565, acc.: 99.51%, op_acc: 32.52%] [G loss: 3.964993]\n",
            "Validating on test set\n",
            "Validation Metrics: 21 [D loss: 3.420133, acc.: 100.00%, op_acc: 5.57%] [G loss: 3.693563]\n",
            "(1024, 1)\n",
            "Training Metrics: 22 [D loss: 2.381730, acc.: 99.95%, op_acc: 32.08%] [G loss: 3.717663]\n",
            "Validating on test set\n",
            "Validation Metrics: 22 [D loss: 3.495711, acc.: 100.00%, op_acc: 5.96%] [G loss: 3.659390]\n",
            "(1024, 1)\n",
            "Training Metrics: 23 [D loss: 2.404128, acc.: 99.95%, op_acc: 32.81%] [G loss: 3.739602]\n",
            "Validating on test set\n",
            "Validation Metrics: 23 [D loss: 3.485596, acc.: 100.00%, op_acc: 5.57%] [G loss: 3.693483]\n",
            "(1024, 1)\n",
            "Training Metrics: 24 [D loss: 2.388181, acc.: 99.90%, op_acc: 32.42%] [G loss: 3.798610]\n",
            "Validating on test set\n",
            "Validation Metrics: 24 [D loss: 3.366148, acc.: 100.00%, op_acc: 5.47%] [G loss: 3.806929]\n",
            "(1024, 1)\n",
            "Training Metrics: 25 [D loss: 2.335269, acc.: 99.41%, op_acc: 31.88%] [G loss: 3.908805]\n",
            "Validating on test set\n",
            "Validation Metrics: 25 [D loss: 3.342713, acc.: 100.00%, op_acc: 5.96%] [G loss: 3.848484]\n",
            "(1024, 1)\n",
            "Training Metrics: 26 [D loss: 2.337261, acc.: 98.83%, op_acc: 33.11%] [G loss: 3.932109]\n",
            "Validating on test set\n",
            "Validation Metrics: 26 [D loss: 3.357860, acc.: 100.00%, op_acc: 5.96%] [G loss: 3.806172]\n",
            "(1024, 1)\n",
            "Training Metrics: 27 [D loss: 2.345476, acc.: 98.68%, op_acc: 33.11%] [G loss: 3.849834]\n",
            "Validating on test set\n",
            "Validation Metrics: 27 [D loss: 3.373055, acc.: 100.00%, op_acc: 5.96%] [G loss: 3.771024]\n",
            "(1024, 1)\n",
            "Training Metrics: 28 [D loss: 2.353567, acc.: 98.97%, op_acc: 32.42%] [G loss: 3.842618]\n",
            "Validating on test set\n",
            "Validation Metrics: 28 [D loss: 3.400173, acc.: 100.00%, op_acc: 7.32%] [G loss: 3.751061]\n",
            "(1024, 1)\n",
            "Training Metrics: 29 [D loss: 2.368560, acc.: 99.27%, op_acc: 32.23%] [G loss: 3.914029]\n",
            "Validating on test set\n",
            "Validation Metrics: 29 [D loss: 3.372578, acc.: 100.00%, op_acc: 4.49%] [G loss: 3.854623]\n",
            "(1024, 1)\n",
            "Training Metrics: 30 [D loss: 2.342105, acc.: 99.02%, op_acc: 31.54%] [G loss: 4.116650]\n",
            "Validating on test set\n",
            "Validation Metrics: 30 [D loss: 3.293964, acc.: 100.00%, op_acc: 5.18%] [G loss: 3.982606]\n",
            "(1024, 1)\n",
            "Training Metrics: 31 [D loss: 2.268050, acc.: 98.49%, op_acc: 33.45%] [G loss: 4.256056]\n",
            "Validating on test set\n",
            "Validation Metrics: 31 [D loss: 3.207295, acc.: 100.00%, op_acc: 5.47%] [G loss: 4.131667]\n",
            "(1024, 1)\n",
            "Training Metrics: 32 [D loss: 2.236255, acc.: 98.24%, op_acc: 32.91%] [G loss: 4.392216]\n",
            "Validating on test set\n",
            "Validation Metrics: 32 [D loss: 3.176301, acc.: 100.00%, op_acc: 5.86%] [G loss: 4.243318]\n",
            "(1024, 1)\n",
            "Training Metrics: 33 [D loss: 2.263977, acc.: 97.27%, op_acc: 32.23%] [G loss: 4.418676]\n",
            "Validating on test set\n",
            "Validation Metrics: 33 [D loss: 3.259779, acc.: 100.00%, op_acc: 6.54%] [G loss: 4.047957]\n",
            "(1024, 1)\n",
            "Training Metrics: 34 [D loss: 2.273681, acc.: 97.51%, op_acc: 33.89%] [G loss: 4.213211]\n",
            "Validating on test set\n",
            "Validation Metrics: 34 [D loss: 3.357970, acc.: 100.00%, op_acc: 6.05%] [G loss: 4.019654]\n",
            "(1024, 1)\n",
            "Training Metrics: 35 [D loss: 2.300694, acc.: 98.29%, op_acc: 32.91%] [G loss: 4.248725]\n",
            "Validating on test set\n",
            "Validation Metrics: 35 [D loss: 3.295449, acc.: 100.00%, op_acc: 6.84%] [G loss: 4.084215]\n",
            "(1024, 1)\n",
            "Training Metrics: 36 [D loss: 2.307473, acc.: 97.22%, op_acc: 33.79%] [G loss: 4.349792]\n",
            "Validating on test set\n",
            "Validation Metrics: 36 [D loss: 3.247295, acc.: 100.00%, op_acc: 4.88%] [G loss: 4.222540]\n",
            "(1024, 1)\n",
            "Training Metrics: 37 [D loss: 2.264092, acc.: 97.22%, op_acc: 33.35%] [G loss: 4.509756]\n",
            "Validating on test set\n",
            "Validation Metrics: 37 [D loss: 3.131836, acc.: 100.00%, op_acc: 7.13%] [G loss: 4.346639]\n",
            "(1024, 1)\n",
            "Training Metrics: 38 [D loss: 2.260882, acc.: 96.04%, op_acc: 32.96%] [G loss: 4.506022]\n",
            "Validating on test set\n",
            "Validation Metrics: 38 [D loss: 3.179899, acc.: 100.00%, op_acc: 7.71%] [G loss: 4.239537]\n",
            "(1024, 1)\n",
            "Training Metrics: 39 [D loss: 2.265860, acc.: 96.29%, op_acc: 33.98%] [G loss: 4.329705]\n",
            "Validating on test set\n",
            "Validation Metrics: 39 [D loss: 3.218894, acc.: 100.00%, op_acc: 7.32%] [G loss: 4.182520]\n",
            "(1024, 1)\n",
            "Training Metrics: 40 [D loss: 2.258592, acc.: 96.88%, op_acc: 32.42%] [G loss: 4.410705]\n",
            "Validating on test set\n",
            "Validation Metrics: 40 [D loss: 3.154688, acc.: 100.00%, op_acc: 5.66%] [G loss: 4.312010]\n",
            "(1024, 1)\n",
            "Training Metrics: 41 [D loss: 2.236138, acc.: 98.10%, op_acc: 31.74%] [G loss: 4.624113]\n",
            "Validating on test set\n",
            "Validation Metrics: 41 [D loss: 3.109501, acc.: 100.00%, op_acc: 5.27%] [G loss: 4.463882]\n",
            "(1024, 1)\n",
            "Training Metrics: 42 [D loss: 2.174040, acc.: 97.85%, op_acc: 33.94%] [G loss: 4.732393]\n",
            "Validating on test set\n",
            "Validation Metrics: 42 [D loss: 3.041226, acc.: 100.00%, op_acc: 6.05%] [G loss: 4.633683]\n",
            "(1024, 1)\n",
            "Training Metrics: 43 [D loss: 2.172774, acc.: 97.07%, op_acc: 32.96%] [G loss: 4.766297]\n",
            "Validating on test set\n",
            "Validation Metrics: 43 [D loss: 3.102824, acc.: 100.00%, op_acc: 6.64%] [G loss: 4.479721]\n",
            "(1024, 1)\n",
            "Training Metrics: 44 [D loss: 2.186986, acc.: 98.34%, op_acc: 32.42%] [G loss: 4.668489]\n",
            "Validating on test set\n",
            "Validation Metrics: 44 [D loss: 3.099451, acc.: 100.00%, op_acc: 7.03%] [G loss: 4.365094]\n",
            "(1024, 1)\n",
            "Training Metrics: 45 [D loss: 2.192961, acc.: 97.56%, op_acc: 32.52%] [G loss: 4.603941]\n",
            "Validating on test set\n",
            "Validation Metrics: 45 [D loss: 3.179266, acc.: 100.00%, op_acc: 5.86%] [G loss: 4.394498]\n",
            "(1024, 1)\n",
            "Training Metrics: 46 [D loss: 2.231364, acc.: 97.95%, op_acc: 32.57%] [G loss: 4.840265]\n",
            "Validating on test set\n",
            "Validation Metrics: 46 [D loss: 3.084267, acc.: 100.00%, op_acc: 6.05%] [G loss: 4.773329]\n",
            "(1024, 1)\n",
            "Training Metrics: 47 [D loss: 2.165360, acc.: 97.36%, op_acc: 34.77%] [G loss: 5.226234]\n",
            "Validating on test set\n",
            "Validation Metrics: 47 [D loss: 2.999137, acc.: 100.00%, op_acc: 4.88%] [G loss: 5.128898]\n",
            "(1024, 1)\n",
            "Training Metrics: 48 [D loss: 2.170997, acc.: 96.63%, op_acc: 31.40%] [G loss: 5.282264]\n",
            "Validating on test set\n",
            "Validation Metrics: 48 [D loss: 3.010627, acc.: 100.00%, op_acc: 5.18%] [G loss: 5.114126]\n",
            "(1024, 1)\n",
            "Training Metrics: 49 [D loss: 2.136299, acc.: 96.88%, op_acc: 34.42%] [G loss: 5.275834]\n",
            "Validating on test set\n",
            "Validation Metrics: 49 [D loss: 2.960979, acc.: 100.00%, op_acc: 5.18%] [G loss: 5.258502]\n",
            "(1024, 1)\n",
            "Training Metrics: 50 [D loss: 2.120539, acc.: 97.51%, op_acc: 32.57%] [G loss: 5.458379]\n",
            "Validating on test set\n",
            "Validation Metrics: 50 [D loss: 2.941025, acc.: 100.00%, op_acc: 5.08%] [G loss: 5.414121]\n",
            "(1024, 1)\n",
            "Training Metrics: 51 [D loss: 2.069089, acc.: 98.10%, op_acc: 32.62%] [G loss: 5.605167]\n",
            "Validating on test set\n",
            "Validation Metrics: 51 [D loss: 2.963242, acc.: 100.00%, op_acc: 6.35%] [G loss: 5.164045]\n",
            "(1024, 1)\n",
            "Training Metrics: 52 [D loss: 2.110188, acc.: 98.00%, op_acc: 32.42%] [G loss: 5.284060]\n",
            "Validating on test set\n",
            "Validation Metrics: 52 [D loss: 3.011115, acc.: 100.00%, op_acc: 6.74%] [G loss: 5.185972]\n",
            "(1024, 1)\n",
            "Training Metrics: 53 [D loss: 2.172501, acc.: 97.17%, op_acc: 32.71%] [G loss: 5.354862]\n",
            "Validating on test set\n",
            "Validation Metrics: 53 [D loss: 3.046926, acc.: 100.00%, op_acc: 11.43%] [G loss: 4.962066]\n",
            "(1024, 1)\n",
            "Training Metrics: 54 [D loss: 2.121391, acc.: 97.95%, op_acc: 37.26%] [G loss: 5.240891]\n",
            "Validating on test set\n",
            "Validation Metrics: 54 [D loss: 2.975223, acc.: 100.00%, op_acc: 11.23%] [G loss: 4.799920]\n",
            "(1024, 1)\n",
            "Training Metrics: 55 [D loss: 2.115550, acc.: 97.90%, op_acc: 34.81%] [G loss: 4.974267]\n",
            "Validating on test set\n",
            "Validation Metrics: 55 [D loss: 2.994284, acc.: 100.00%, op_acc: 10.94%] [G loss: 4.701658]\n",
            "(1024, 1)\n",
            "Training Metrics: 56 [D loss: 2.141718, acc.: 97.51%, op_acc: 37.94%] [G loss: 5.003757]\n",
            "Validating on test set\n",
            "Validation Metrics: 56 [D loss: 2.950577, acc.: 100.00%, op_acc: 11.72%] [G loss: 4.806155]\n",
            "(1024, 1)\n",
            "Training Metrics: 57 [D loss: 2.175742, acc.: 97.02%, op_acc: 33.69%] [G loss: 5.015556]\n",
            "Validating on test set\n",
            "Validation Metrics: 57 [D loss: 2.908977, acc.: 100.00%, op_acc: 11.13%] [G loss: 4.950012]\n",
            "(1024, 1)\n",
            "Training Metrics: 58 [D loss: 2.074223, acc.: 97.85%, op_acc: 35.35%] [G loss: 5.291220]\n",
            "Validating on test set\n",
            "Validation Metrics: 58 [D loss: 2.807523, acc.: 100.00%, op_acc: 10.55%] [G loss: 5.235589]\n",
            "(1024, 1)\n",
            "Training Metrics: 59 [D loss: 2.062889, acc.: 96.97%, op_acc: 34.96%] [G loss: 5.277352]\n",
            "Validating on test set\n",
            "Validation Metrics: 59 [D loss: 2.790168, acc.: 100.00%, op_acc: 12.01%] [G loss: 5.231454]\n",
            "(1024, 1)\n",
            "Training Metrics: 60 [D loss: 2.002596, acc.: 97.95%, op_acc: 36.96%] [G loss: 5.374352]\n",
            "Validating on test set\n",
            "Validation Metrics: 60 [D loss: 2.735320, acc.: 100.00%, op_acc: 18.26%] [G loss: 5.302666]\n",
            "(1024, 1)\n",
            "Training Metrics: 61 [D loss: 1.999622, acc.: 97.90%, op_acc: 37.84%] [G loss: 5.237278]\n",
            "Validating on test set\n",
            "Validation Metrics: 61 [D loss: 2.752867, acc.: 100.00%, op_acc: 12.99%] [G loss: 5.138088]\n",
            "(1024, 1)\n",
            "Training Metrics: 62 [D loss: 2.013100, acc.: 98.63%, op_acc: 36.23%] [G loss: 5.277617]\n",
            "Validating on test set\n",
            "Validation Metrics: 62 [D loss: 2.773520, acc.: 100.00%, op_acc: 12.50%] [G loss: 5.104096]\n",
            "(1024, 1)\n",
            "Training Metrics: 63 [D loss: 2.004140, acc.: 98.34%, op_acc: 35.60%] [G loss: 5.118880]\n",
            "Validating on test set\n",
            "Validation Metrics: 63 [D loss: 2.820951, acc.: 100.00%, op_acc: 11.52%] [G loss: 4.821904]\n",
            "(1024, 1)\n",
            "Training Metrics: 64 [D loss: 2.026421, acc.: 98.63%, op_acc: 35.99%] [G loss: 5.245540]\n",
            "Validating on test set\n",
            "Validation Metrics: 64 [D loss: 2.801447, acc.: 100.00%, op_acc: 7.71%] [G loss: 5.113065]\n",
            "(1024, 1)\n",
            "Training Metrics: 65 [D loss: 2.040811, acc.: 97.90%, op_acc: 32.37%] [G loss: 5.370731]\n",
            "Validating on test set\n",
            "Validation Metrics: 65 [D loss: 2.881524, acc.: 100.00%, op_acc: 9.47%] [G loss: 5.509431]\n",
            "(1024, 1)\n",
            "Training Metrics: 66 [D loss: 2.065941, acc.: 98.39%, op_acc: 34.77%] [G loss: 5.847671]\n",
            "Validating on test set\n",
            "Validation Metrics: 66 [D loss: 2.827351, acc.: 100.00%, op_acc: 12.70%] [G loss: 5.797474]\n",
            "(1024, 1)\n",
            "Training Metrics: 67 [D loss: 1.999965, acc.: 98.34%, op_acc: 36.87%] [G loss: 6.176495]\n",
            "Validating on test set\n",
            "Validation Metrics: 67 [D loss: 2.716820, acc.: 100.00%, op_acc: 12.30%] [G loss: 6.123962]\n",
            "(1024, 1)\n",
            "Training Metrics: 68 [D loss: 2.007080, acc.: 97.71%, op_acc: 35.64%] [G loss: 5.913067]\n",
            "Validating on test set\n",
            "Validation Metrics: 68 [D loss: 2.727318, acc.: 100.00%, op_acc: 11.72%] [G loss: 5.957128]\n",
            "(1024, 1)\n",
            "Training Metrics: 69 [D loss: 1.968709, acc.: 98.34%, op_acc: 36.13%] [G loss: 6.040966]\n",
            "Validating on test set\n",
            "Validation Metrics: 69 [D loss: 2.655216, acc.: 100.00%, op_acc: 11.91%] [G loss: 5.958103]\n",
            "(1024, 1)\n",
            "Training Metrics: 70 [D loss: 1.955525, acc.: 98.34%, op_acc: 35.35%] [G loss: 5.763771]\n",
            "Validating on test set\n",
            "Validation Metrics: 70 [D loss: 2.649343, acc.: 100.00%, op_acc: 11.91%] [G loss: 5.709931]\n",
            "(1024, 1)\n",
            "Training Metrics: 71 [D loss: 1.906836, acc.: 98.88%, op_acc: 36.18%] [G loss: 5.843072]\n",
            "Validating on test set\n",
            "Validation Metrics: 71 [D loss: 2.575777, acc.: 100.00%, op_acc: 11.91%] [G loss: 5.749496]\n",
            "(1024, 1)\n",
            "Training Metrics: 72 [D loss: 1.882739, acc.: 98.88%, op_acc: 35.50%] [G loss: 5.783589]\n",
            "Validating on test set\n",
            "Validation Metrics: 72 [D loss: 2.510753, acc.: 100.00%, op_acc: 9.67%] [G loss: 5.693913]\n",
            "(1024, 1)\n",
            "Training Metrics: 73 [D loss: 1.829793, acc.: 98.83%, op_acc: 33.89%] [G loss: 5.698089]\n",
            "Validating on test set\n",
            "Validation Metrics: 73 [D loss: 2.462281, acc.: 100.00%, op_acc: 18.46%] [G loss: 5.652074]\n",
            "(1024, 1)\n",
            "Training Metrics: 74 [D loss: 1.832287, acc.: 99.12%, op_acc: 34.86%] [G loss: 5.719445]\n",
            "Validating on test set\n",
            "Validation Metrics: 74 [D loss: 2.683170, acc.: 100.00%, op_acc: 9.77%] [G loss: 5.702586]\n",
            "(1024, 1)\n",
            "Training Metrics: 75 [D loss: 1.933363, acc.: 99.22%, op_acc: 34.77%] [G loss: 5.487698]\n",
            "Validating on test set\n",
            "Validation Metrics: 75 [D loss: 2.478482, acc.: 100.00%, op_acc: 17.38%] [G loss: 5.307091]\n",
            "(1024, 1)\n",
            "Training Metrics: 76 [D loss: 1.779906, acc.: 99.32%, op_acc: 38.33%] [G loss: 5.466044]\n",
            "Validating on test set\n",
            "Validation Metrics: 76 [D loss: 2.578413, acc.: 100.00%, op_acc: 15.72%] [G loss: 5.297048]\n",
            "(1024, 1)\n",
            "Training Metrics: 77 [D loss: 1.865581, acc.: 99.61%, op_acc: 38.43%] [G loss: 5.608879]\n",
            "Validating on test set\n",
            "Validation Metrics: 77 [D loss: 2.573781, acc.: 100.00%, op_acc: 12.11%] [G loss: 5.580557]\n",
            "(1024, 1)\n",
            "Training Metrics: 78 [D loss: 1.835864, acc.: 99.22%, op_acc: 37.11%] [G loss: 5.686398]\n",
            "Validating on test set\n",
            "Validation Metrics: 78 [D loss: 2.399286, acc.: 100.00%, op_acc: 17.97%] [G loss: 5.545842]\n",
            "(1024, 1)\n",
            "Training Metrics: 79 [D loss: 1.795445, acc.: 98.68%, op_acc: 36.82%] [G loss: 5.537758]\n",
            "Validating on test set\n",
            "Validation Metrics: 79 [D loss: 2.492544, acc.: 100.00%, op_acc: 8.50%] [G loss: 5.538146]\n",
            "(1024, 1)\n",
            "Training Metrics: 80 [D loss: 1.821119, acc.: 99.46%, op_acc: 35.45%] [G loss: 5.830729]\n",
            "Validating on test set\n",
            "Validation Metrics: 80 [D loss: 2.472293, acc.: 100.00%, op_acc: 16.21%] [G loss: 5.823232]\n",
            "(1024, 1)\n",
            "Training Metrics: 81 [D loss: 1.869265, acc.: 99.17%, op_acc: 36.28%] [G loss: 5.865321]\n",
            "Validating on test set\n",
            "Validation Metrics: 81 [D loss: 2.538918, acc.: 100.00%, op_acc: 11.23%] [G loss: 5.652002]\n",
            "(1024, 1)\n",
            "Training Metrics: 82 [D loss: 1.851685, acc.: 99.37%, op_acc: 35.35%] [G loss: 5.983461]\n",
            "Validating on test set\n",
            "Validation Metrics: 82 [D loss: 2.513937, acc.: 100.00%, op_acc: 11.72%] [G loss: 5.880732]\n",
            "(1024, 1)\n",
            "Training Metrics: 83 [D loss: 1.872502, acc.: 98.73%, op_acc: 34.33%] [G loss: 5.844098]\n",
            "Validating on test set\n",
            "Validation Metrics: 83 [D loss: 2.405373, acc.: 100.00%, op_acc: 17.19%] [G loss: 5.818567]\n",
            "(1024, 1)\n",
            "Training Metrics: 84 [D loss: 1.798659, acc.: 98.78%, op_acc: 36.96%] [G loss: 6.019616]\n",
            "Validating on test set\n",
            "Validation Metrics: 84 [D loss: 2.506404, acc.: 100.00%, op_acc: 12.99%] [G loss: 6.033843]\n",
            "(1024, 1)\n",
            "Training Metrics: 85 [D loss: 1.859222, acc.: 98.39%, op_acc: 36.72%] [G loss: 5.944294]\n",
            "Validating on test set\n",
            "Validation Metrics: 85 [D loss: 2.397360, acc.: 100.00%, op_acc: 17.77%] [G loss: 5.887104]\n",
            "(1024, 1)\n",
            "Training Metrics: 86 [D loss: 1.813162, acc.: 98.93%, op_acc: 37.99%] [G loss: 5.902071]\n",
            "Validating on test set\n",
            "Validation Metrics: 86 [D loss: 2.350100, acc.: 100.00%, op_acc: 17.29%] [G loss: 5.867338]\n",
            "(1024, 1)\n",
            "Training Metrics: 87 [D loss: 1.755933, acc.: 98.73%, op_acc: 36.33%] [G loss: 5.939246]\n",
            "Validating on test set\n",
            "Validation Metrics: 87 [D loss: 2.298513, acc.: 100.00%, op_acc: 17.77%] [G loss: 5.899941]\n",
            "(1024, 1)\n",
            "Training Metrics: 88 [D loss: 1.747330, acc.: 98.78%, op_acc: 33.94%] [G loss: 5.722154]\n",
            "Validating on test set\n",
            "Validation Metrics: 88 [D loss: 2.264885, acc.: 100.00%, op_acc: 13.67%] [G loss: 5.673482]\n",
            "(1024, 1)\n",
            "Training Metrics: 89 [D loss: 1.740060, acc.: 99.02%, op_acc: 37.89%] [G loss: 5.755848]\n",
            "Validating on test set\n",
            "Validation Metrics: 89 [D loss: 2.232629, acc.: 100.00%, op_acc: 20.41%] [G loss: 5.671948]\n",
            "(1024, 1)\n",
            "Training Metrics: 90 [D loss: 1.706393, acc.: 99.12%, op_acc: 38.67%] [G loss: 5.610551]\n",
            "Validating on test set\n",
            "Validation Metrics: 90 [D loss: 2.239356, acc.: 100.00%, op_acc: 13.67%] [G loss: 5.480236]\n",
            "(1024, 1)\n",
            "Training Metrics: 91 [D loss: 1.696402, acc.: 99.17%, op_acc: 36.18%] [G loss: 5.625956]\n",
            "Validating on test set\n",
            "Validation Metrics: 91 [D loss: 2.181383, acc.: 100.00%, op_acc: 20.41%] [G loss: 5.536821]\n",
            "(1024, 1)\n",
            "Training Metrics: 92 [D loss: 1.700760, acc.: 99.27%, op_acc: 39.06%] [G loss: 5.710071]\n",
            "Validating on test set\n",
            "Validation Metrics: 92 [D loss: 2.133733, acc.: 100.00%, op_acc: 24.32%] [G loss: 5.499528]\n",
            "(1024, 1)\n",
            "Training Metrics: 93 [D loss: 1.714864, acc.: 98.58%, op_acc: 39.31%] [G loss: 5.272376]\n",
            "Validating on test set\n",
            "Validation Metrics: 93 [D loss: 2.259843, acc.: 100.00%, op_acc: 17.77%] [G loss: 5.182557]\n",
            "(1024, 1)\n",
            "Training Metrics: 94 [D loss: 1.656162, acc.: 99.02%, op_acc: 40.04%] [G loss: 5.521890]\n",
            "Validating on test set\n",
            "Validation Metrics: 94 [D loss: 2.315606, acc.: 100.00%, op_acc: 5.86%] [G loss: 5.242241]\n",
            "(1024, 1)\n",
            "Training Metrics: 95 [D loss: 1.809691, acc.: 99.27%, op_acc: 34.91%] [G loss: 5.537552]\n",
            "Validating on test set\n",
            "Validation Metrics: 95 [D loss: 2.236511, acc.: 100.00%, op_acc: 16.70%] [G loss: 5.550169]\n",
            "(1024, 1)\n",
            "Training Metrics: 96 [D loss: 1.730493, acc.: 98.29%, op_acc: 38.33%] [G loss: 6.025730]\n",
            "Validating on test set\n",
            "Validation Metrics: 96 [D loss: 2.610947, acc.: 100.00%, op_acc: 6.54%] [G loss: 5.842650]\n",
            "(1024, 1)\n",
            "Training Metrics: 97 [D loss: 2.033035, acc.: 97.85%, op_acc: 29.93%] [G loss: 5.993798]\n",
            "Validating on test set\n",
            "Validation Metrics: 97 [D loss: 2.408513, acc.: 100.00%, op_acc: 13.28%] [G loss: 5.512091]\n",
            "(1024, 1)\n",
            "Training Metrics: 98 [D loss: 1.910220, acc.: 98.19%, op_acc: 35.21%] [G loss: 5.810431]\n",
            "Validating on test set\n",
            "Validation Metrics: 98 [D loss: 2.601997, acc.: 100.00%, op_acc: 10.94%] [G loss: 5.464887]\n",
            "(1024, 1)\n",
            "Training Metrics: 99 [D loss: 2.034057, acc.: 96.88%, op_acc: 33.94%] [G loss: 5.494652]\n",
            "Validating on test set\n",
            "Validation Metrics: 99 [D loss: 2.754233, acc.: 100.00%, op_acc: 6.64%] [G loss: 5.441701]\n",
            "(1024, 1)\n",
            "Training Metrics: 100 [D loss: 2.007695, acc.: 98.58%, op_acc: 31.88%] [G loss: 5.794788]\n",
            "Validating on test set\n",
            "Validation Metrics: 100 [D loss: 2.617979, acc.: 100.00%, op_acc: 12.21%] [G loss: 5.609434]\n",
            "(1024, 1)\n",
            "Training Metrics: 101 [D loss: 1.984207, acc.: 97.80%, op_acc: 37.21%] [G loss: 5.926891]\n",
            "Validating on test set\n",
            "Validation Metrics: 101 [D loss: 2.456831, acc.: 100.00%, op_acc: 10.35%] [G loss: 5.752169]\n",
            "(1024, 1)\n",
            "Training Metrics: 102 [D loss: 1.861215, acc.: 97.80%, op_acc: 33.20%] [G loss: 6.065481]\n",
            "Validating on test set\n",
            "Validation Metrics: 102 [D loss: 2.331660, acc.: 100.00%, op_acc: 22.17%] [G loss: 5.755957]\n",
            "(1024, 1)\n",
            "Training Metrics: 103 [D loss: 1.908589, acc.: 97.61%, op_acc: 31.30%] [G loss: 5.365039]\n",
            "Validating on test set\n",
            "Validation Metrics: 103 [D loss: 2.423558, acc.: 100.00%, op_acc: 10.06%] [G loss: 5.302523]\n",
            "(1024, 1)\n",
            "Training Metrics: 104 [D loss: 1.828598, acc.: 98.83%, op_acc: 35.64%] [G loss: 5.806720]\n",
            "Validating on test set\n",
            "Validation Metrics: 104 [D loss: 2.334215, acc.: 100.00%, op_acc: 20.51%] [G loss: 5.686434]\n",
            "(1024, 1)\n",
            "Training Metrics: 105 [D loss: 1.797484, acc.: 98.05%, op_acc: 40.33%] [G loss: 5.463059]\n",
            "Validating on test set\n",
            "Validation Metrics: 105 [D loss: 2.248477, acc.: 100.00%, op_acc: 25.39%] [G loss: 5.450182]\n",
            "(1024, 1)\n",
            "Training Metrics: 106 [D loss: 1.795976, acc.: 98.24%, op_acc: 39.75%] [G loss: 5.580977]\n",
            "Validating on test set\n",
            "Validation Metrics: 106 [D loss: 2.246190, acc.: 100.00%, op_acc: 18.16%] [G loss: 5.538661]\n",
            "(1024, 1)\n",
            "Training Metrics: 107 [D loss: 1.754688, acc.: 98.29%, op_acc: 37.45%] [G loss: 5.379842]\n",
            "Validating on test set\n",
            "Validation Metrics: 107 [D loss: 2.241242, acc.: 100.00%, op_acc: 21.58%] [G loss: 5.333941]\n",
            "(1024, 1)\n",
            "Training Metrics: 108 [D loss: 1.759066, acc.: 98.93%, op_acc: 37.84%] [G loss: 5.658230]\n",
            "Validating on test set\n",
            "Validation Metrics: 108 [D loss: 2.223948, acc.: 100.00%, op_acc: 22.56%] [G loss: 5.635950]\n",
            "(1024, 1)\n",
            "Training Metrics: 109 [D loss: 1.765145, acc.: 98.00%, op_acc: 38.28%] [G loss: 5.245426]\n",
            "Validating on test set\n",
            "Validation Metrics: 109 [D loss: 2.235230, acc.: 100.00%, op_acc: 17.58%] [G loss: 5.235211]\n",
            "(1024, 1)\n",
            "Training Metrics: 110 [D loss: 1.705114, acc.: 98.97%, op_acc: 38.87%] [G loss: 5.537204]\n",
            "Validating on test set\n",
            "Validation Metrics: 110 [D loss: 2.193837, acc.: 100.00%, op_acc: 22.56%] [G loss: 5.529293]\n",
            "(1024, 1)\n",
            "Training Metrics: 111 [D loss: 1.711158, acc.: 98.44%, op_acc: 38.57%] [G loss: 5.396303]\n",
            "Validating on test set\n",
            "Validation Metrics: 111 [D loss: 2.170381, acc.: 100.00%, op_acc: 23.14%] [G loss: 5.384678]\n",
            "(1024, 1)\n",
            "Training Metrics: 112 [D loss: 1.661798, acc.: 98.93%, op_acc: 42.38%] [G loss: 5.713433]\n",
            "Validating on test set\n",
            "Validation Metrics: 112 [D loss: 2.127450, acc.: 100.00%, op_acc: 26.17%] [G loss: 5.701872]\n",
            "(1024, 1)\n",
            "Training Metrics: 113 [D loss: 1.682727, acc.: 98.78%, op_acc: 42.77%] [G loss: 5.472301]\n",
            "Validating on test set\n",
            "Validation Metrics: 113 [D loss: 2.121160, acc.: 100.00%, op_acc: 24.51%] [G loss: 5.465196]\n",
            "(1024, 1)\n",
            "Training Metrics: 114 [D loss: 1.658725, acc.: 98.49%, op_acc: 41.89%] [G loss: 5.489785]\n",
            "Validating on test set\n",
            "Validation Metrics: 114 [D loss: 2.095132, acc.: 100.00%, op_acc: 25.88%] [G loss: 5.464799]\n",
            "(1024, 1)\n",
            "Training Metrics: 115 [D loss: 1.637322, acc.: 98.68%, op_acc: 41.06%] [G loss: 5.540469]\n",
            "Validating on test set\n",
            "Validation Metrics: 115 [D loss: 2.070005, acc.: 100.00%, op_acc: 27.54%] [G loss: 5.526797]\n",
            "(1024, 1)\n",
            "Training Metrics: 116 [D loss: 1.617375, acc.: 98.88%, op_acc: 43.55%] [G loss: 5.482229]\n",
            "Validating on test set\n",
            "Validation Metrics: 116 [D loss: 2.059644, acc.: 100.00%, op_acc: 24.80%] [G loss: 5.460923]\n",
            "(1024, 1)\n",
            "Training Metrics: 117 [D loss: 1.598796, acc.: 98.83%, op_acc: 44.29%] [G loss: 5.570611]\n",
            "Validating on test set\n",
            "Validation Metrics: 117 [D loss: 2.049335, acc.: 100.00%, op_acc: 18.16%] [G loss: 5.469413]\n",
            "(1024, 1)\n",
            "Training Metrics: 118 [D loss: 1.623840, acc.: 99.17%, op_acc: 42.04%] [G loss: 5.248317]\n",
            "Validating on test set\n",
            "Validation Metrics: 118 [D loss: 2.069785, acc.: 100.00%, op_acc: 23.63%] [G loss: 5.223056]\n",
            "(1024, 1)\n",
            "Training Metrics: 119 [D loss: 1.680183, acc.: 99.17%, op_acc: 40.23%] [G loss: 5.701414]\n",
            "Validating on test set\n",
            "Validation Metrics: 119 [D loss: 1.998656, acc.: 100.00%, op_acc: 25.59%] [G loss: 5.529821]\n",
            "(1024, 1)\n",
            "Training Metrics: 120 [D loss: 1.692822, acc.: 98.93%, op_acc: 41.16%] [G loss: 5.116766]\n",
            "Validating on test set\n",
            "Validation Metrics: 120 [D loss: 1.984841, acc.: 100.00%, op_acc: 27.34%] [G loss: 5.103187]\n",
            "(1024, 1)\n",
            "Training Metrics: 121 [D loss: 1.626801, acc.: 99.41%, op_acc: 42.77%] [G loss: 5.448565]\n",
            "Validating on test set\n",
            "Validation Metrics: 121 [D loss: 1.938156, acc.: 100.00%, op_acc: 29.79%] [G loss: 5.427816]\n",
            "(1024, 1)\n",
            "Training Metrics: 122 [D loss: 1.565032, acc.: 98.93%, op_acc: 45.56%] [G loss: 5.599516]\n",
            "Validating on test set\n",
            "Validation Metrics: 122 [D loss: 1.933498, acc.: 100.00%, op_acc: 28.91%] [G loss: 5.558370]\n",
            "(1024, 1)\n",
            "Training Metrics: 123 [D loss: 1.616960, acc.: 98.63%, op_acc: 44.58%] [G loss: 5.272880]\n",
            "Validating on test set\n",
            "Validation Metrics: 123 [D loss: 1.987080, acc.: 100.00%, op_acc: 30.57%] [G loss: 5.249052]\n",
            "(1024, 1)\n",
            "Training Metrics: 124 [D loss: 1.563577, acc.: 99.27%, op_acc: 45.75%] [G loss: 5.429989]\n",
            "Validating on test set\n",
            "Validation Metrics: 124 [D loss: 1.936607, acc.: 100.00%, op_acc: 30.18%] [G loss: 5.446652]\n",
            "(1024, 1)\n",
            "Training Metrics: 125 [D loss: 1.536861, acc.: 99.07%, op_acc: 44.78%] [G loss: 5.373452]\n",
            "Validating on test set\n",
            "Validation Metrics: 125 [D loss: 1.967909, acc.: 100.00%, op_acc: 24.61%] [G loss: 5.362028]\n",
            "(1024, 1)\n",
            "Training Metrics: 126 [D loss: 1.546629, acc.: 99.12%, op_acc: 44.34%] [G loss: 5.530067]\n",
            "Validating on test set\n",
            "Validation Metrics: 126 [D loss: 1.918864, acc.: 100.00%, op_acc: 23.73%] [G loss: 5.484403]\n",
            "(1024, 1)\n",
            "Training Metrics: 127 [D loss: 1.540604, acc.: 99.07%, op_acc: 44.87%] [G loss: 5.286249]\n",
            "Validating on test set\n",
            "Validation Metrics: 127 [D loss: 1.874390, acc.: 100.00%, op_acc: 24.71%] [G loss: 5.268299]\n",
            "(1024, 1)\n",
            "Training Metrics: 128 [D loss: 1.573622, acc.: 99.27%, op_acc: 43.70%] [G loss: 5.584294]\n",
            "Validating on test set\n",
            "Validation Metrics: 128 [D loss: 1.870077, acc.: 100.00%, op_acc: 28.12%] [G loss: 5.553899]\n",
            "(1024, 1)\n",
            "Training Metrics: 129 [D loss: 1.654784, acc.: 98.73%, op_acc: 40.09%] [G loss: 5.262119]\n",
            "Validating on test set\n",
            "Validation Metrics: 129 [D loss: 1.861970, acc.: 100.00%, op_acc: 26.07%] [G loss: 5.249956]\n",
            "(1024, 1)\n",
            "Training Metrics: 130 [D loss: 1.543741, acc.: 99.17%, op_acc: 46.14%] [G loss: 5.599655]\n",
            "Validating on test set\n",
            "Validation Metrics: 130 [D loss: 1.818426, acc.: 100.00%, op_acc: 37.40%] [G loss: 5.561058]\n",
            "(1024, 1)\n",
            "Training Metrics: 131 [D loss: 1.553552, acc.: 98.93%, op_acc: 45.80%] [G loss: 5.088301]\n",
            "Validating on test set\n",
            "Validation Metrics: 131 [D loss: 1.784642, acc.: 100.00%, op_acc: 29.69%] [G loss: 5.082103]\n",
            "(1024, 1)\n",
            "Training Metrics: 132 [D loss: 1.538209, acc.: 99.46%, op_acc: 44.43%] [G loss: 5.677249]\n",
            "Validating on test set\n",
            "Validation Metrics: 132 [D loss: 1.807065, acc.: 100.00%, op_acc: 30.08%] [G loss: 5.686247]\n",
            "(1024, 1)\n",
            "Training Metrics: 133 [D loss: 1.549484, acc.: 98.49%, op_acc: 45.26%] [G loss: 5.304396]\n",
            "Validating on test set\n",
            "Validation Metrics: 133 [D loss: 1.951270, acc.: 100.00%, op_acc: 19.82%] [G loss: 5.507350]\n",
            "(1024, 1)\n",
            "Training Metrics: 134 [D loss: 1.542878, acc.: 99.27%, op_acc: 42.09%] [G loss: 5.593435]\n",
            "Validating on test set\n",
            "Validation Metrics: 134 [D loss: 2.330349, acc.: 100.00%, op_acc: 13.57%] [G loss: 5.949830]\n",
            "(1024, 1)\n",
            "Training Metrics: 135 [D loss: 1.763181, acc.: 99.17%, op_acc: 36.08%] [G loss: 6.055323]\n",
            "Validating on test set\n",
            "Validation Metrics: 135 [D loss: 2.111235, acc.: 100.00%, op_acc: 15.43%] [G loss: 6.003165]\n",
            "(1024, 1)\n",
            "Training Metrics: 136 [D loss: 1.670413, acc.: 98.73%, op_acc: 40.33%] [G loss: 5.993949]\n",
            "Validating on test set\n",
            "Validation Metrics: 136 [D loss: 1.938633, acc.: 100.00%, op_acc: 22.66%] [G loss: 5.747640]\n",
            "(1024, 1)\n",
            "Training Metrics: 137 [D loss: 1.511255, acc.: 99.27%, op_acc: 42.82%] [G loss: 5.314948]\n",
            "Validating on test set\n",
            "Validation Metrics: 137 [D loss: 1.804364, acc.: 100.00%, op_acc: 31.54%] [G loss: 5.259682]\n",
            "(1024, 1)\n",
            "Training Metrics: 138 [D loss: 1.476773, acc.: 99.56%, op_acc: 46.68%] [G loss: 5.716331]\n",
            "Validating on test set\n",
            "Validation Metrics: 138 [D loss: 1.723115, acc.: 100.00%, op_acc: 27.15%] [G loss: 5.681444]\n",
            "(1024, 1)\n",
            "Training Metrics: 139 [D loss: 1.542398, acc.: 98.88%, op_acc: 42.58%] [G loss: 5.176506]\n",
            "Validating on test set\n",
            "Validation Metrics: 139 [D loss: 1.685358, acc.: 100.00%, op_acc: 29.39%] [G loss: 5.152620]\n",
            "(1024, 1)\n",
            "Training Metrics: 140 [D loss: 1.505924, acc.: 99.41%, op_acc: 43.36%] [G loss: 5.700740]\n",
            "Validating on test set\n",
            "Validation Metrics: 140 [D loss: 1.660842, acc.: 100.00%, op_acc: 36.43%] [G loss: 5.659649]\n",
            "(1024, 1)\n",
            "Training Metrics: 141 [D loss: 1.499871, acc.: 98.83%, op_acc: 44.34%] [G loss: 5.335006]\n",
            "Validating on test set\n",
            "Validation Metrics: 141 [D loss: 1.615229, acc.: 100.00%, op_acc: 44.34%] [G loss: 5.328020]\n",
            "(1024, 1)\n",
            "Training Metrics: 142 [D loss: 1.387095, acc.: 98.93%, op_acc: 51.42%] [G loss: 5.551919]\n",
            "Validating on test set\n",
            "Validation Metrics: 142 [D loss: 1.618193, acc.: 100.00%, op_acc: 33.30%] [G loss: 5.533820]\n",
            "(1024, 1)\n",
            "Training Metrics: 143 [D loss: 1.416794, acc.: 99.07%, op_acc: 46.53%] [G loss: 5.328919]\n",
            "Validating on test set\n",
            "Validation Metrics: 143 [D loss: 1.568058, acc.: 100.00%, op_acc: 47.85%] [G loss: 5.304949]\n",
            "(1024, 1)\n",
            "Training Metrics: 144 [D loss: 1.377861, acc.: 99.17%, op_acc: 51.71%] [G loss: 5.361633]\n",
            "Validating on test set\n",
            "Validation Metrics: 144 [D loss: 1.537950, acc.: 100.00%, op_acc: 39.26%] [G loss: 5.345533]\n",
            "(1024, 1)\n",
            "Training Metrics: 145 [D loss: 1.356620, acc.: 99.51%, op_acc: 49.66%] [G loss: 5.395147]\n",
            "Validating on test set\n",
            "Validation Metrics: 145 [D loss: 1.527470, acc.: 100.00%, op_acc: 46.09%] [G loss: 5.393948]\n",
            "(1024, 1)\n",
            "Training Metrics: 146 [D loss: 1.362226, acc.: 99.02%, op_acc: 49.56%] [G loss: 5.323884]\n",
            "Validating on test set\n",
            "Validation Metrics: 146 [D loss: 1.495459, acc.: 100.00%, op_acc: 45.80%] [G loss: 5.309221]\n",
            "(1024, 1)\n",
            "Training Metrics: 147 [D loss: 1.340676, acc.: 98.93%, op_acc: 51.90%] [G loss: 5.307314]\n",
            "Validating on test set\n",
            "Validation Metrics: 147 [D loss: 1.457195, acc.: 100.00%, op_acc: 50.39%] [G loss: 5.295391]\n",
            "(1024, 1)\n",
            "Training Metrics: 148 [D loss: 1.300843, acc.: 99.41%, op_acc: 55.62%] [G loss: 5.405366]\n",
            "Validating on test set\n",
            "Validation Metrics: 148 [D loss: 1.509815, acc.: 100.00%, op_acc: 39.75%] [G loss: 5.456821]\n",
            "(1024, 1)\n",
            "Training Metrics: 149 [D loss: 1.359516, acc.: 99.27%, op_acc: 49.66%] [G loss: 5.546522]\n",
            "Validating on test set\n",
            "Validation Metrics: 149 [D loss: 1.543462, acc.: 100.00%, op_acc: 36.33%] [G loss: 5.637336]\n",
            "(1024, 1)\n",
            "Training Metrics: 150 [D loss: 1.398520, acc.: 99.51%, op_acc: 45.51%] [G loss: 5.178673]\n",
            "Validating on test set\n",
            "Validation Metrics: 150 [D loss: 2.032088, acc.: 100.00%, op_acc: 14.45%] [G loss: 5.662623]\n",
            "(1024, 1)\n",
            "Training Metrics: 151 [D loss: 1.685899, acc.: 99.22%, op_acc: 35.74%] [G loss: 6.254131]\n",
            "Validating on test set\n",
            "Validation Metrics: 151 [D loss: 1.844303, acc.: 100.00%, op_acc: 17.68%] [G loss: 6.185374]\n",
            "(1024, 1)\n",
            "Training Metrics: 152 [D loss: 1.558766, acc.: 99.37%, op_acc: 39.45%] [G loss: 5.892767]\n",
            "Validating on test set\n",
            "Validation Metrics: 152 [D loss: 1.650856, acc.: 100.00%, op_acc: 25.39%] [G loss: 5.708460]\n",
            "(1024, 1)\n",
            "Training Metrics: 153 [D loss: 1.394627, acc.: 99.12%, op_acc: 42.14%] [G loss: 5.989809]\n",
            "Validating on test set\n",
            "Validation Metrics: 153 [D loss: 1.591044, acc.: 100.00%, op_acc: 32.23%] [G loss: 5.933405]\n",
            "(1024, 1)\n",
            "Training Metrics: 154 [D loss: 1.408544, acc.: 99.02%, op_acc: 48.19%] [G loss: 5.363408]\n",
            "Validating on test set\n",
            "Validation Metrics: 154 [D loss: 1.545899, acc.: 100.00%, op_acc: 32.62%] [G loss: 5.331409]\n",
            "(1024, 1)\n",
            "Training Metrics: 155 [D loss: 1.356154, acc.: 99.76%, op_acc: 48.49%] [G loss: 5.642638]\n",
            "Validating on test set\n",
            "Validation Metrics: 155 [D loss: 1.519598, acc.: 100.00%, op_acc: 38.09%] [G loss: 5.616220]\n",
            "(1024, 1)\n",
            "Training Metrics: 156 [D loss: 1.410363, acc.: 99.27%, op_acc: 46.83%] [G loss: 5.321169]\n",
            "Validating on test set\n",
            "Validation Metrics: 156 [D loss: 1.500867, acc.: 100.00%, op_acc: 44.14%] [G loss: 5.321719]\n",
            "(1024, 1)\n",
            "Training Metrics: 157 [D loss: 1.360882, acc.: 99.22%, op_acc: 51.12%] [G loss: 5.348616]\n",
            "Validating on test set\n",
            "Validation Metrics: 157 [D loss: 1.452572, acc.: 100.00%, op_acc: 43.36%] [G loss: 5.291467]\n",
            "(1024, 1)\n",
            "Training Metrics: 158 [D loss: 1.294238, acc.: 99.56%, op_acc: 54.30%] [G loss: 5.316307]\n",
            "Validating on test set\n",
            "Validation Metrics: 158 [D loss: 1.421719, acc.: 100.00%, op_acc: 44.73%] [G loss: 5.283887]\n",
            "(1024, 1)\n",
            "Training Metrics: 159 [D loss: 1.289503, acc.: 99.17%, op_acc: 53.08%] [G loss: 5.386477]\n",
            "Validating on test set\n",
            "Validation Metrics: 159 [D loss: 1.427941, acc.: 100.00%, op_acc: 44.14%] [G loss: 5.402797]\n",
            "(1024, 1)\n",
            "Training Metrics: 160 [D loss: 1.313564, acc.: 99.37%, op_acc: 52.29%] [G loss: 5.439066]\n",
            "Validating on test set\n",
            "Validation Metrics: 160 [D loss: 1.479852, acc.: 100.00%, op_acc: 35.94%] [G loss: 5.547659]\n",
            "(1024, 1)\n",
            "Training Metrics: 161 [D loss: 1.366007, acc.: 99.51%, op_acc: 47.61%] [G loss: 5.473413]\n",
            "Validating on test set\n",
            "Validation Metrics: 161 [D loss: 1.615623, acc.: 100.00%, op_acc: 27.25%] [G loss: 5.597579]\n",
            "(1024, 1)\n",
            "Training Metrics: 162 [D loss: 1.422349, acc.: 99.41%, op_acc: 43.99%] [G loss: 5.605109]\n",
            "Validating on test set\n",
            "Validation Metrics: 162 [D loss: 1.722277, acc.: 100.00%, op_acc: 23.73%] [G loss: 5.729759]\n",
            "(1024, 1)\n",
            "Training Metrics: 163 [D loss: 1.447732, acc.: 99.51%, op_acc: 41.41%] [G loss: 5.698995]\n",
            "Validating on test set\n",
            "Validation Metrics: 163 [D loss: 1.619901, acc.: 100.00%, op_acc: 21.58%] [G loss: 5.600935]\n",
            "(1024, 1)\n",
            "Training Metrics: 164 [D loss: 1.362469, acc.: 99.56%, op_acc: 43.70%] [G loss: 5.763182]\n",
            "Validating on test set\n",
            "Validation Metrics: 164 [D loss: 1.467958, acc.: 100.00%, op_acc: 36.52%] [G loss: 5.625253]\n",
            "(1024, 1)\n",
            "Training Metrics: 165 [D loss: 1.353105, acc.: 99.37%, op_acc: 46.68%] [G loss: 5.424723]\n",
            "Validating on test set\n",
            "Validation Metrics: 165 [D loss: 1.457630, acc.: 100.00%, op_acc: 37.70%] [G loss: 5.384961]\n",
            "(1024, 1)\n",
            "Training Metrics: 166 [D loss: 1.285918, acc.: 99.37%, op_acc: 50.39%] [G loss: 5.533435]\n",
            "Validating on test set\n",
            "Validation Metrics: 166 [D loss: 1.407556, acc.: 100.00%, op_acc: 41.70%] [G loss: 5.534014]\n",
            "(1024, 1)\n",
            "Training Metrics: 167 [D loss: 1.260885, acc.: 99.22%, op_acc: 52.34%] [G loss: 5.523499]\n",
            "Validating on test set\n",
            "Validation Metrics: 167 [D loss: 1.385027, acc.: 100.00%, op_acc: 42.38%] [G loss: 5.508124]\n",
            "(1024, 1)\n",
            "Training Metrics: 168 [D loss: 1.272759, acc.: 99.17%, op_acc: 52.20%] [G loss: 5.182539]\n",
            "Validating on test set\n",
            "Validation Metrics: 168 [D loss: 1.346289, acc.: 100.00%, op_acc: 46.88%] [G loss: 5.176255]\n",
            "(1024, 1)\n",
            "Training Metrics: 169 [D loss: 1.252852, acc.: 99.12%, op_acc: 55.13%] [G loss: 5.361502]\n",
            "Validating on test set\n",
            "Validation Metrics: 169 [D loss: 1.338010, acc.: 100.00%, op_acc: 42.97%] [G loss: 5.337934]\n",
            "(1024, 1)\n",
            "Training Metrics: 170 [D loss: 1.203110, acc.: 99.51%, op_acc: 53.52%] [G loss: 5.514420]\n",
            "Validating on test set\n",
            "Validation Metrics: 170 [D loss: 1.343279, acc.: 100.00%, op_acc: 48.14%] [G loss: 5.514200]\n",
            "(1024, 1)\n",
            "Training Metrics: 171 [D loss: 1.224147, acc.: 99.41%, op_acc: 55.81%] [G loss: 5.188744]\n",
            "Validating on test set\n",
            "Validation Metrics: 171 [D loss: 1.289693, acc.: 100.00%, op_acc: 51.07%] [G loss: 5.203110]\n",
            "(1024, 1)\n",
            "Training Metrics: 172 [D loss: 1.213405, acc.: 99.56%, op_acc: 58.11%] [G loss: 5.511678]\n",
            "Validating on test set\n",
            "Validation Metrics: 172 [D loss: 1.292632, acc.: 100.00%, op_acc: 49.90%] [G loss: 5.495342]\n",
            "(1024, 1)\n",
            "Training Metrics: 173 [D loss: 1.257839, acc.: 99.41%, op_acc: 54.20%] [G loss: 5.352843]\n",
            "Validating on test set\n",
            "Validation Metrics: 173 [D loss: 1.290707, acc.: 100.00%, op_acc: 50.88%] [G loss: 5.370983]\n",
            "(1024, 1)\n",
            "Training Metrics: 174 [D loss: 1.233841, acc.: 99.17%, op_acc: 56.49%] [G loss: 5.337651]\n",
            "Validating on test set\n",
            "Validation Metrics: 174 [D loss: 1.344784, acc.: 100.00%, op_acc: 41.60%] [G loss: 5.453196]\n",
            "(1024, 1)\n",
            "Training Metrics: 175 [D loss: 1.226846, acc.: 99.56%, op_acc: 52.44%] [G loss: 5.437989]\n",
            "Validating on test set\n",
            "Validation Metrics: 175 [D loss: 1.534071, acc.: 100.00%, op_acc: 37.79%] [G loss: 5.628457]\n",
            "(1024, 1)\n",
            "Training Metrics: 176 [D loss: 1.315031, acc.: 99.56%, op_acc: 48.10%] [G loss: 5.614681]\n",
            "Validating on test set\n",
            "Validation Metrics: 176 [D loss: 1.972502, acc.: 100.00%, op_acc: 18.46%] [G loss: 6.094966]\n",
            "(1024, 1)\n",
            "Training Metrics: 177 [D loss: 1.573276, acc.: 99.46%, op_acc: 39.89%] [G loss: 6.119097]\n",
            "Validating on test set\n",
            "Validation Metrics: 177 [D loss: 1.898101, acc.: 100.00%, op_acc: 23.05%] [G loss: 6.126737]\n",
            "(1024, 1)\n",
            "Training Metrics: 178 [D loss: 1.530745, acc.: 99.51%, op_acc: 40.67%] [G loss: 6.212254]\n",
            "Validating on test set\n",
            "Validation Metrics: 178 [D loss: 1.574658, acc.: 100.00%, op_acc: 30.08%] [G loss: 5.784683]\n",
            "(1024, 1)\n",
            "Training Metrics: 179 [D loss: 1.383991, acc.: 99.46%, op_acc: 42.82%] [G loss: 5.911786]\n",
            "Validating on test set\n",
            "Validation Metrics: 179 [D loss: 1.607891, acc.: 100.00%, op_acc: 29.59%] [G loss: 5.892558]\n",
            "(1024, 1)\n",
            "Training Metrics: 180 [D loss: 1.407989, acc.: 99.46%, op_acc: 43.41%] [G loss: 6.015891]\n",
            "Validating on test set\n",
            "Validation Metrics: 180 [D loss: 1.512798, acc.: 100.00%, op_acc: 34.96%] [G loss: 5.980777]\n",
            "(1024, 1)\n",
            "Training Metrics: 181 [D loss: 1.381499, acc.: 99.32%, op_acc: 45.36%] [G loss: 5.746570]\n",
            "Validating on test set\n",
            "Validation Metrics: 181 [D loss: 1.485171, acc.: 100.00%, op_acc: 35.45%] [G loss: 5.731742]\n",
            "(1024, 1)\n",
            "Training Metrics: 182 [D loss: 1.348837, acc.: 99.61%, op_acc: 44.19%] [G loss: 6.126564]\n",
            "Validating on test set\n",
            "Validation Metrics: 182 [D loss: 1.426906, acc.: 100.00%, op_acc: 36.62%] [G loss: 6.108178]\n",
            "(1024, 1)\n",
            "Training Metrics: 183 [D loss: 1.376029, acc.: 99.07%, op_acc: 50.44%] [G loss: 5.346466]\n",
            "Validating on test set\n",
            "Validation Metrics: 183 [D loss: 1.381550, acc.: 100.00%, op_acc: 46.29%] [G loss: 5.329062]\n",
            "(1024, 1)\n",
            "Training Metrics: 184 [D loss: 1.253158, acc.: 99.61%, op_acc: 53.08%] [G loss: 5.723914]\n",
            "Validating on test set\n",
            "Validation Metrics: 184 [D loss: 1.333811, acc.: 100.00%, op_acc: 45.70%] [G loss: 5.734516]\n",
            "(1024, 1)\n",
            "Training Metrics: 185 [D loss: 1.278477, acc.: 99.37%, op_acc: 50.05%] [G loss: 5.394561]\n",
            "Validating on test set\n",
            "Validation Metrics: 185 [D loss: 1.336627, acc.: 100.00%, op_acc: 50.88%] [G loss: 5.386068]\n",
            "(1024, 1)\n",
            "Training Metrics: 186 [D loss: 1.270865, acc.: 99.41%, op_acc: 55.71%] [G loss: 5.693514]\n",
            "Validating on test set\n",
            "Validation Metrics: 186 [D loss: 1.304099, acc.: 100.00%, op_acc: 46.39%] [G loss: 5.701339]\n",
            "(1024, 1)\n",
            "Training Metrics: 187 [D loss: 1.216489, acc.: 99.22%, op_acc: 53.08%] [G loss: 5.340380]\n",
            "Validating on test set\n",
            "Validation Metrics: 187 [D loss: 1.401002, acc.: 100.00%, op_acc: 46.00%] [G loss: 5.434604]\n",
            "(1024, 1)\n",
            "Training Metrics: 188 [D loss: 1.262188, acc.: 99.46%, op_acc: 53.27%] [G loss: 5.915866]\n",
            "Validating on test set\n",
            "Validation Metrics: 188 [D loss: 1.872535, acc.: 100.00%, op_acc: 31.15%] [G loss: 6.529339]\n",
            "(1024, 1)\n",
            "Training Metrics: 189 [D loss: 1.590105, acc.: 99.32%, op_acc: 43.75%] [G loss: 5.999533]\n",
            "Validating on test set\n",
            "Validation Metrics: 189 [D loss: 1.453374, acc.: 100.00%, op_acc: 40.92%] [G loss: 5.558384]\n",
            "(1024, 1)\n",
            "Training Metrics: 190 [D loss: 1.326856, acc.: 99.46%, op_acc: 50.29%] [G loss: 6.071767]\n",
            "Validating on test set\n",
            "Validation Metrics: 190 [D loss: 1.422386, acc.: 100.00%, op_acc: 40.43%] [G loss: 6.031952]\n",
            "(1024, 1)\n",
            "Training Metrics: 191 [D loss: 1.312713, acc.: 99.41%, op_acc: 48.73%] [G loss: 5.323678]\n",
            "Validating on test set\n",
            "Validation Metrics: 191 [D loss: 1.367933, acc.: 100.00%, op_acc: 40.53%] [G loss: 5.254395]\n",
            "(1024, 1)\n",
            "Training Metrics: 192 [D loss: 1.327956, acc.: 99.46%, op_acc: 52.44%] [G loss: 5.899503]\n",
            "Validating on test set\n",
            "Validation Metrics: 192 [D loss: 1.317887, acc.: 100.00%, op_acc: 43.55%] [G loss: 5.906734]\n",
            "(1024, 1)\n",
            "Training Metrics: 193 [D loss: 1.315030, acc.: 99.22%, op_acc: 47.12%] [G loss: 5.369514]\n",
            "Validating on test set\n",
            "Validation Metrics: 193 [D loss: 1.308780, acc.: 100.00%, op_acc: 46.39%] [G loss: 5.352839]\n",
            "(1024, 1)\n",
            "Training Metrics: 194 [D loss: 1.250457, acc.: 99.66%, op_acc: 54.79%] [G loss: 5.917279]\n",
            "Validating on test set\n",
            "Validation Metrics: 194 [D loss: 1.335484, acc.: 100.00%, op_acc: 41.50%] [G loss: 5.909027]\n",
            "(1024, 1)\n",
            "Training Metrics: 195 [D loss: 1.260643, acc.: 99.51%, op_acc: 50.44%] [G loss: 5.349618]\n",
            "Validating on test set\n",
            "Validation Metrics: 195 [D loss: 1.265027, acc.: 100.00%, op_acc: 48.14%] [G loss: 5.312487]\n",
            "(1024, 1)\n",
            "Training Metrics: 196 [D loss: 1.190261, acc.: 99.46%, op_acc: 54.79%] [G loss: 5.510484]\n",
            "Validating on test set\n",
            "Validation Metrics: 196 [D loss: 1.268971, acc.: 100.00%, op_acc: 50.98%] [G loss: 5.522313]\n",
            "(1024, 1)\n",
            "Training Metrics: 197 [D loss: 1.179779, acc.: 99.71%, op_acc: 55.91%] [G loss: 5.662659]\n",
            "Validating on test set\n",
            "Validation Metrics: 197 [D loss: 1.251232, acc.: 100.00%, op_acc: 48.05%] [G loss: 5.678518]\n",
            "(1024, 1)\n",
            "Training Metrics: 198 [D loss: 1.235523, acc.: 99.46%, op_acc: 52.73%] [G loss: 5.564091]\n",
            "Validating on test set\n",
            "Validation Metrics: 198 [D loss: 1.254573, acc.: 100.00%, op_acc: 52.15%] [G loss: 5.559077]\n",
            "(1024, 1)\n",
            "Training Metrics: 199 [D loss: 1.195255, acc.: 99.51%, op_acc: 55.66%] [G loss: 5.546175]\n",
            "Validating on test set\n",
            "Validation Metrics: 199 [D loss: 1.297914, acc.: 100.00%, op_acc: 40.62%] [G loss: 5.661325]\n",
            "(1024, 1)\n",
            "Training Metrics: 200 [D loss: 1.230143, acc.: 99.61%, op_acc: 50.05%] [G loss: 5.781504]\n",
            "Validating on test set\n",
            "Validation Metrics: 200 [D loss: 1.513552, acc.: 100.00%, op_acc: 36.04%] [G loss: 5.956756]\n",
            "(1024, 1)\n",
            "Training Metrics: 201 [D loss: 1.355807, acc.: 99.61%, op_acc: 46.14%] [G loss: 5.695948]\n",
            "Validating on test set\n",
            "Validation Metrics: 201 [D loss: 1.732086, acc.: 100.00%, op_acc: 25.20%] [G loss: 5.979565]\n",
            "(1024, 1)\n",
            "Training Metrics: 202 [D loss: 1.460046, acc.: 99.22%, op_acc: 42.97%] [G loss: 6.634167]\n",
            "Validating on test set\n",
            "Validation Metrics: 202 [D loss: 1.545120, acc.: 100.00%, op_acc: 31.54%] [G loss: 6.517174]\n",
            "(1024, 1)\n",
            "Training Metrics: 203 [D loss: 1.383019, acc.: 99.37%, op_acc: 46.58%] [G loss: 5.851987]\n",
            "Validating on test set\n",
            "Validation Metrics: 203 [D loss: 1.349367, acc.: 100.00%, op_acc: 37.30%] [G loss: 5.614694]\n",
            "(1024, 1)\n",
            "Training Metrics: 204 [D loss: 1.282418, acc.: 99.61%, op_acc: 45.51%] [G loss: 6.036988]\n",
            "Validating on test set\n",
            "Validation Metrics: 204 [D loss: 1.317750, acc.: 100.00%, op_acc: 41.02%] [G loss: 5.984091]\n",
            "(1024, 1)\n",
            "Training Metrics: 205 [D loss: 1.254035, acc.: 99.46%, op_acc: 51.66%] [G loss: 5.504423]\n",
            "Validating on test set\n",
            "Validation Metrics: 205 [D loss: 1.273819, acc.: 100.00%, op_acc: 52.05%] [G loss: 5.489512]\n",
            "(1024, 1)\n",
            "Training Metrics: 206 [D loss: 1.236608, acc.: 99.56%, op_acc: 56.30%] [G loss: 5.837701]\n",
            "Validating on test set\n",
            "Validation Metrics: 206 [D loss: 1.230107, acc.: 100.00%, op_acc: 47.36%] [G loss: 5.814578]\n",
            "(1024, 1)\n",
            "Training Metrics: 207 [D loss: 1.241652, acc.: 99.07%, op_acc: 53.76%] [G loss: 5.324857]\n",
            "Validating on test set\n",
            "Validation Metrics: 207 [D loss: 1.198999, acc.: 100.00%, op_acc: 50.49%] [G loss: 5.313505]\n",
            "(1024, 1)\n",
            "Training Metrics: 208 [D loss: 1.189105, acc.: 99.56%, op_acc: 54.74%] [G loss: 5.610200]\n",
            "Validating on test set\n",
            "Validation Metrics: 208 [D loss: 1.239200, acc.: 100.00%, op_acc: 47.17%] [G loss: 5.652406]\n",
            "(1024, 1)\n",
            "Training Metrics: 209 [D loss: 1.167693, acc.: 99.61%, op_acc: 53.81%] [G loss: 5.295368]\n",
            "Validating on test set\n",
            "Validation Metrics: 209 [D loss: 1.306734, acc.: 100.00%, op_acc: 43.07%] [G loss: 5.491730]\n",
            "(1024, 1)\n",
            "Training Metrics: 210 [D loss: 1.217436, acc.: 99.80%, op_acc: 51.90%] [G loss: 5.977783]\n",
            "Validating on test set\n",
            "Validation Metrics: 210 [D loss: 1.304980, acc.: 100.00%, op_acc: 40.23%] [G loss: 5.955954]\n",
            "(1024, 1)\n",
            "Training Metrics: 211 [D loss: 1.295242, acc.: 99.56%, op_acc: 49.80%] [G loss: 5.605692]\n",
            "Validating on test set\n",
            "Validation Metrics: 211 [D loss: 1.345768, acc.: 100.00%, op_acc: 37.89%] [G loss: 5.659238]\n",
            "(1024, 1)\n",
            "Training Metrics: 212 [D loss: 1.279040, acc.: 99.41%, op_acc: 48.78%] [G loss: 5.847324]\n",
            "Validating on test set\n",
            "Validation Metrics: 212 [D loss: 1.196605, acc.: 100.00%, op_acc: 47.17%] [G loss: 5.715751]\n",
            "(1024, 1)\n",
            "Training Metrics: 213 [D loss: 1.172052, acc.: 99.46%, op_acc: 54.25%] [G loss: 5.585690]\n",
            "Validating on test set\n",
            "Validation Metrics: 213 [D loss: 1.177099, acc.: 100.00%, op_acc: 48.93%] [G loss: 5.596315]\n",
            "(1024, 1)\n",
            "Training Metrics: 214 [D loss: 1.162736, acc.: 99.56%, op_acc: 55.13%] [G loss: 5.651953]\n",
            "Validating on test set\n",
            "Validation Metrics: 214 [D loss: 1.156386, acc.: 100.00%, op_acc: 48.34%] [G loss: 5.650369]\n",
            "(1024, 1)\n",
            "Training Metrics: 215 [D loss: 1.202318, acc.: 99.32%, op_acc: 54.49%] [G loss: 5.419528]\n",
            "Validating on test set\n",
            "Validation Metrics: 215 [D loss: 1.176544, acc.: 100.00%, op_acc: 50.88%] [G loss: 5.442103]\n",
            "(1024, 1)\n",
            "Training Metrics: 216 [D loss: 1.177619, acc.: 99.66%, op_acc: 53.96%] [G loss: 5.780088]\n",
            "Validating on test set\n",
            "Validation Metrics: 216 [D loss: 1.227921, acc.: 100.00%, op_acc: 45.51%] [G loss: 5.896967]\n",
            "(1024, 1)\n",
            "Training Metrics: 217 [D loss: 1.173663, acc.: 99.51%, op_acc: 56.74%] [G loss: 5.577540]\n",
            "Validating on test set\n",
            "Validation Metrics: 217 [D loss: 1.155845, acc.: 100.00%, op_acc: 49.02%] [G loss: 5.506569]\n",
            "(1024, 1)\n",
            "Training Metrics: 218 [D loss: 1.113163, acc.: 99.51%, op_acc: 54.30%] [G loss: 5.773426]\n",
            "Validating on test set\n",
            "Validation Metrics: 218 [D loss: 1.132911, acc.: 100.00%, op_acc: 49.51%] [G loss: 5.723001]\n",
            "(1024, 1)\n",
            "Training Metrics: 219 [D loss: 1.132210, acc.: 99.66%, op_acc: 56.79%] [G loss: 5.384653]\n",
            "Validating on test set\n",
            "Validation Metrics: 219 [D loss: 1.172246, acc.: 100.00%, op_acc: 52.25%] [G loss: 5.440286]\n",
            "(1024, 1)\n",
            "Training Metrics: 220 [D loss: 1.173672, acc.: 99.66%, op_acc: 53.66%] [G loss: 5.812940]\n",
            "Validating on test set\n",
            "Validation Metrics: 220 [D loss: 1.365426, acc.: 100.00%, op_acc: 37.89%] [G loss: 6.129379]\n",
            "(1024, 1)\n",
            "Training Metrics: 221 [D loss: 1.357878, acc.: 99.37%, op_acc: 47.31%] [G loss: 5.672160]\n",
            "Validating on test set\n",
            "Validation Metrics: 221 [D loss: 1.741908, acc.: 100.00%, op_acc: 24.90%] [G loss: 5.954306]\n",
            "(1024, 1)\n",
            "Training Metrics: 222 [D loss: 1.424022, acc.: 99.56%, op_acc: 43.26%] [G loss: 6.575647]\n",
            "Validating on test set\n",
            "Validation Metrics: 222 [D loss: 1.520198, acc.: 100.00%, op_acc: 31.25%] [G loss: 6.445508]\n",
            "(1024, 1)\n",
            "Training Metrics: 223 [D loss: 1.334296, acc.: 99.22%, op_acc: 42.82%] [G loss: 6.151421]\n",
            "Validating on test set\n",
            "Validation Metrics: 223 [D loss: 1.320257, acc.: 100.00%, op_acc: 37.11%] [G loss: 5.928532]\n",
            "(1024, 1)\n",
            "Training Metrics: 224 [D loss: 1.210468, acc.: 99.46%, op_acc: 47.17%] [G loss: 5.978277]\n",
            "Validating on test set\n",
            "Validation Metrics: 224 [D loss: 1.272776, acc.: 100.00%, op_acc: 39.06%] [G loss: 5.899932]\n",
            "(1024, 1)\n",
            "Training Metrics: 225 [D loss: 1.200478, acc.: 99.27%, op_acc: 50.05%] [G loss: 5.753834]\n",
            "Validating on test set\n",
            "Validation Metrics: 225 [D loss: 1.256173, acc.: 100.00%, op_acc: 43.36%] [G loss: 5.755979]\n",
            "(1024, 1)\n",
            "Training Metrics: 226 [D loss: 1.227814, acc.: 99.61%, op_acc: 48.54%] [G loss: 5.407847]\n",
            "Validating on test set\n",
            "Validation Metrics: 226 [D loss: 1.545684, acc.: 100.00%, op_acc: 35.74%] [G loss: 5.594873]\n",
            "(1024, 1)\n",
            "Training Metrics: 227 [D loss: 1.407672, acc.: 99.61%, op_acc: 47.12%] [G loss: 5.831617]\n",
            "Validating on test set\n",
            "Validation Metrics: 227 [D loss: 1.767832, acc.: 100.00%, op_acc: 30.37%] [G loss: 6.359581]\n",
            "(1024, 1)\n",
            "Training Metrics: 228 [D loss: 1.456619, acc.: 99.32%, op_acc: 45.41%] [G loss: 6.243158]\n",
            "Validating on test set\n",
            "Validation Metrics: 228 [D loss: 1.392891, acc.: 100.00%, op_acc: 37.70%] [G loss: 5.903281]\n",
            "(1024, 1)\n",
            "Training Metrics: 229 [D loss: 1.225891, acc.: 99.76%, op_acc: 49.27%] [G loss: 5.942818]\n",
            "Validating on test set\n",
            "Validation Metrics: 229 [D loss: 1.300231, acc.: 100.00%, op_acc: 41.21%] [G loss: 5.881131]\n",
            "(1024, 1)\n",
            "Training Metrics: 230 [D loss: 1.186361, acc.: 99.61%, op_acc: 51.37%] [G loss: 5.601048]\n",
            "Validating on test set\n",
            "Validation Metrics: 230 [D loss: 1.254708, acc.: 100.00%, op_acc: 44.04%] [G loss: 5.582850]\n",
            "(1024, 1)\n",
            "Training Metrics: 231 [D loss: 1.180747, acc.: 99.56%, op_acc: 53.56%] [G loss: 5.739400]\n",
            "Validating on test set\n",
            "Validation Metrics: 231 [D loss: 1.179323, acc.: 100.00%, op_acc: 46.68%] [G loss: 5.624267]\n",
            "(1024, 1)\n",
            "Training Metrics: 232 [D loss: 1.111244, acc.: 99.71%, op_acc: 56.49%] [G loss: 5.304668]\n",
            "Validating on test set\n",
            "Validation Metrics: 232 [D loss: 1.165691, acc.: 100.00%, op_acc: 51.37%] [G loss: 5.276565]\n",
            "(1024, 1)\n",
            "Training Metrics: 233 [D loss: 1.145317, acc.: 99.56%, op_acc: 54.64%] [G loss: 5.576610]\n",
            "Validating on test set\n",
            "Validation Metrics: 233 [D loss: 1.095822, acc.: 100.00%, op_acc: 51.27%] [G loss: 5.576731]\n",
            "(1024, 1)\n",
            "Training Metrics: 234 [D loss: 1.122591, acc.: 99.80%, op_acc: 58.30%] [G loss: 5.412786]\n",
            "Validating on test set\n",
            "Validation Metrics: 234 [D loss: 1.181405, acc.: 100.00%, op_acc: 47.46%] [G loss: 5.466462]\n",
            "(1024, 1)\n",
            "Training Metrics: 235 [D loss: 1.136197, acc.: 99.32%, op_acc: 57.96%] [G loss: 5.612431]\n",
            "Validating on test set\n",
            "Validation Metrics: 235 [D loss: 1.170087, acc.: 100.00%, op_acc: 46.48%] [G loss: 5.690554]\n",
            "(1024, 1)\n",
            "Training Metrics: 236 [D loss: 1.158199, acc.: 99.66%, op_acc: 54.30%] [G loss: 5.478058]\n",
            "Validating on test set\n",
            "Validation Metrics: 236 [D loss: 1.160792, acc.: 100.00%, op_acc: 45.80%] [G loss: 5.405879]\n",
            "(1024, 1)\n",
            "Training Metrics: 237 [D loss: 1.142525, acc.: 99.46%, op_acc: 53.37%] [G loss: 5.380294]\n",
            "Validating on test set\n",
            "Validation Metrics: 237 [D loss: 1.036950, acc.: 100.00%, op_acc: 54.79%] [G loss: 5.313644]\n",
            "(1024, 1)\n",
            "Training Metrics: 238 [D loss: 1.071319, acc.: 99.66%, op_acc: 58.01%] [G loss: 5.282330]\n",
            "Validating on test set\n",
            "Validation Metrics: 238 [D loss: 1.053561, acc.: 100.00%, op_acc: 50.00%] [G loss: 5.289524]\n",
            "(1024, 1)\n",
            "Training Metrics: 239 [D loss: 1.059932, acc.: 99.61%, op_acc: 59.72%] [G loss: 5.285280]\n",
            "Validating on test set\n",
            "Validation Metrics: 239 [D loss: 1.037350, acc.: 100.00%, op_acc: 54.00%] [G loss: 5.320542]\n",
            "(1024, 1)\n",
            "Training Metrics: 240 [D loss: 1.004377, acc.: 99.85%, op_acc: 59.96%] [G loss: 5.538745]\n",
            "Validating on test set\n",
            "Validation Metrics: 240 [D loss: 1.132106, acc.: 100.00%, op_acc: 51.27%] [G loss: 5.617224]\n",
            "(1024, 1)\n",
            "Training Metrics: 241 [D loss: 1.101769, acc.: 99.46%, op_acc: 58.35%] [G loss: 5.623887]\n",
            "Validating on test set\n",
            "Validation Metrics: 241 [D loss: 1.145020, acc.: 100.00%, op_acc: 47.27%] [G loss: 5.713354]\n",
            "(1024, 1)\n",
            "Training Metrics: 242 [D loss: 1.125914, acc.: 99.61%, op_acc: 54.64%] [G loss: 5.670813]\n",
            "Validating on test set\n",
            "Validation Metrics: 242 [D loss: 1.109724, acc.: 100.00%, op_acc: 46.09%] [G loss: 5.661226]\n",
            "(1024, 1)\n",
            "Training Metrics: 243 [D loss: 1.100126, acc.: 99.76%, op_acc: 52.25%] [G loss: 5.709946]\n",
            "Validating on test set\n",
            "Validation Metrics: 243 [D loss: 1.027972, acc.: 100.00%, op_acc: 55.96%] [G loss: 5.649484]\n",
            "(1024, 1)\n",
            "Training Metrics: 244 [D loss: 1.038864, acc.: 99.61%, op_acc: 58.54%] [G loss: 5.514274]\n",
            "Validating on test set\n",
            "Validation Metrics: 244 [D loss: 1.032798, acc.: 100.00%, op_acc: 46.39%] [G loss: 5.459968]\n",
            "(1024, 1)\n",
            "Training Metrics: 245 [D loss: 1.050752, acc.: 99.56%, op_acc: 58.64%] [G loss: 5.553793]\n",
            "Validating on test set\n",
            "Validation Metrics: 245 [D loss: 0.936277, acc.: 100.00%, op_acc: 62.70%] [G loss: 5.515017]\n",
            "(1024, 1)\n",
            "Training Metrics: 246 [D loss: 1.020165, acc.: 99.27%, op_acc: 57.28%] [G loss: 5.281709]\n",
            "Validating on test set\n",
            "Validation Metrics: 246 [D loss: 0.965328, acc.: 100.00%, op_acc: 60.45%] [G loss: 5.294909]\n",
            "(1024, 1)\n",
            "Training Metrics: 247 [D loss: 1.001446, acc.: 99.66%, op_acc: 59.47%] [G loss: 5.360861]\n",
            "Validating on test set\n",
            "Validation Metrics: 247 [D loss: 0.934931, acc.: 100.00%, op_acc: 66.50%] [G loss: 5.329147]\n",
            "(1024, 1)\n",
            "Training Metrics: 248 [D loss: 0.988894, acc.: 99.80%, op_acc: 64.94%] [G loss: 5.377009]\n",
            "Validating on test set\n",
            "Validation Metrics: 248 [D loss: 0.909982, acc.: 100.00%, op_acc: 61.23%] [G loss: 5.380012]\n",
            "(1024, 1)\n",
            "Training Metrics: 249 [D loss: 0.969073, acc.: 99.61%, op_acc: 62.40%] [G loss: 5.657331]\n",
            "Validating on test set\n",
            "Validation Metrics: 249 [D loss: 0.914807, acc.: 100.00%, op_acc: 59.77%] [G loss: 5.664876]\n",
            "(1024, 1)\n",
            "Training Metrics: 250 [D loss: 1.030962, acc.: 99.17%, op_acc: 62.55%] [G loss: 5.439257]\n",
            "Validating on test set\n",
            "Validation Metrics: 250 [D loss: 0.931737, acc.: 100.00%, op_acc: 62.50%] [G loss: 5.480719]\n",
            "(1024, 1)\n",
            "Training Metrics: 251 [D loss: 0.983796, acc.: 99.66%, op_acc: 62.35%] [G loss: 5.499307]\n",
            "Validating on test set\n",
            "Validation Metrics: 251 [D loss: 1.022761, acc.: 100.00%, op_acc: 51.46%] [G loss: 5.603801]\n",
            "(1024, 1)\n",
            "Training Metrics: 252 [D loss: 1.037802, acc.: 99.32%, op_acc: 57.67%] [G loss: 5.362569]\n",
            "Validating on test set\n",
            "Validation Metrics: 252 [D loss: 1.414719, acc.: 100.00%, op_acc: 42.19%] [G loss: 5.766726]\n",
            "(1024, 1)\n",
            "Training Metrics: 253 [D loss: 1.224778, acc.: 99.66%, op_acc: 54.30%] [G loss: 6.023343]\n",
            "Validating on test set\n",
            "Validation Metrics: 253 [D loss: 1.054413, acc.: 100.00%, op_acc: 53.22%] [G loss: 5.760669]\n",
            "(1024, 1)\n",
            "Training Metrics: 254 [D loss: 1.119935, acc.: 99.85%, op_acc: 57.52%] [G loss: 5.581869]\n",
            "Validating on test set\n",
            "Validation Metrics: 254 [D loss: 1.010433, acc.: 100.00%, op_acc: 58.30%] [G loss: 5.506904]\n",
            "(1024, 1)\n",
            "Training Metrics: 255 [D loss: 1.069427, acc.: 99.71%, op_acc: 59.77%] [G loss: 5.876964]\n",
            "Validating on test set\n",
            "Validation Metrics: 255 [D loss: 1.016720, acc.: 100.00%, op_acc: 55.86%] [G loss: 5.943694]\n",
            "(1024, 1)\n",
            "Training Metrics: 256 [D loss: 1.124756, acc.: 99.46%, op_acc: 61.91%] [G loss: 5.434453]\n",
            "Validating on test set\n",
            "Validation Metrics: 256 [D loss: 0.993275, acc.: 100.00%, op_acc: 58.11%] [G loss: 5.430149]\n",
            "(1024, 1)\n",
            "Training Metrics: 257 [D loss: 1.037995, acc.: 99.76%, op_acc: 59.52%] [G loss: 5.690135]\n",
            "Validating on test set\n",
            "Validation Metrics: 257 [D loss: 0.893786, acc.: 100.00%, op_acc: 62.01%] [G loss: 5.588272]\n",
            "(1024, 1)\n",
            "Training Metrics: 258 [D loss: 0.991182, acc.: 99.46%, op_acc: 60.11%] [G loss: 5.508531]\n",
            "Validating on test set\n",
            "Validation Metrics: 258 [D loss: 0.824175, acc.: 100.00%, op_acc: 65.43%] [G loss: 5.470308]\n",
            "(1024, 1)\n",
            "Training Metrics: 259 [D loss: 1.009094, acc.: 99.51%, op_acc: 63.96%] [G loss: 5.424148]\n",
            "Validating on test set\n",
            "Validation Metrics: 259 [D loss: 0.883079, acc.: 100.00%, op_acc: 69.04%] [G loss: 5.424709]\n",
            "(1024, 1)\n",
            "Training Metrics: 260 [D loss: 1.048448, acc.: 99.66%, op_acc: 61.72%] [G loss: 5.593925]\n",
            "Validating on test set\n",
            "Validation Metrics: 260 [D loss: 0.896789, acc.: 100.00%, op_acc: 66.60%] [G loss: 5.611282]\n",
            "(1024, 1)\n",
            "Training Metrics: 261 [D loss: 0.999249, acc.: 99.41%, op_acc: 64.26%] [G loss: 5.379839]\n",
            "Validating on test set\n",
            "Validation Metrics: 261 [D loss: 0.945149, acc.: 100.00%, op_acc: 68.36%] [G loss: 5.369673]\n",
            "(1024, 1)\n",
            "Training Metrics: 262 [D loss: 1.015653, acc.: 99.66%, op_acc: 60.50%] [G loss: 5.930849]\n",
            "Validating on test set\n",
            "Validation Metrics: 262 [D loss: 0.947312, acc.: 100.00%, op_acc: 60.45%] [G loss: 5.937170]\n",
            "(1024, 1)\n",
            "Training Metrics: 263 [D loss: 1.085570, acc.: 99.12%, op_acc: 60.69%] [G loss: 5.162010]\n",
            "Validating on test set\n",
            "Validation Metrics: 263 [D loss: 1.104085, acc.: 100.00%, op_acc: 45.31%] [G loss: 5.286186]\n",
            "(1024, 1)\n",
            "Training Metrics: 264 [D loss: 1.161771, acc.: 99.61%, op_acc: 56.79%] [G loss: 6.124198]\n",
            "Validating on test set\n",
            "Validation Metrics: 264 [D loss: 0.932202, acc.: 100.00%, op_acc: 56.84%] [G loss: 6.023488]\n",
            "(1024, 1)\n",
            "Training Metrics: 265 [D loss: 1.110440, acc.: 99.66%, op_acc: 56.54%] [G loss: 5.443389]\n",
            "Validating on test set\n",
            "Validation Metrics: 265 [D loss: 0.867479, acc.: 100.00%, op_acc: 64.65%] [G loss: 5.353141]\n",
            "(1024, 1)\n",
            "Training Metrics: 266 [D loss: 0.992240, acc.: 99.27%, op_acc: 64.16%] [G loss: 5.594648]\n",
            "Validating on test set\n",
            "Validation Metrics: 266 [D loss: 0.861241, acc.: 100.00%, op_acc: 67.19%] [G loss: 5.603901]\n",
            "(1024, 1)\n",
            "Training Metrics: 267 [D loss: 0.991418, acc.: 99.66%, op_acc: 63.43%] [G loss: 5.642630]\n",
            "Validating on test set\n",
            "Validation Metrics: 267 [D loss: 0.841920, acc.: 100.00%, op_acc: 69.73%] [G loss: 5.635446]\n",
            "(1024, 1)\n",
            "Training Metrics: 268 [D loss: 0.972486, acc.: 99.32%, op_acc: 63.67%] [G loss: 5.379683]\n",
            "Validating on test set\n",
            "Validation Metrics: 268 [D loss: 0.860639, acc.: 100.00%, op_acc: 67.87%] [G loss: 5.362031]\n",
            "(1024, 1)\n",
            "Training Metrics: 269 [D loss: 1.020593, acc.: 99.41%, op_acc: 64.36%] [G loss: 5.436947]\n",
            "Validating on test set\n",
            "Validation Metrics: 269 [D loss: 0.827507, acc.: 100.00%, op_acc: 72.27%] [G loss: 5.429993]\n",
            "(1024, 1)\n",
            "Training Metrics: 270 [D loss: 0.959803, acc.: 99.56%, op_acc: 66.46%] [G loss: 5.615480]\n",
            "Validating on test set\n",
            "Validation Metrics: 270 [D loss: 0.805913, acc.: 100.00%, op_acc: 69.92%] [G loss: 5.585429]\n",
            "(1024, 1)\n",
            "Training Metrics: 271 [D loss: 0.935016, acc.: 99.66%, op_acc: 67.19%] [G loss: 5.378404]\n",
            "Validating on test set\n",
            "Validation Metrics: 271 [D loss: 0.777267, acc.: 100.00%, op_acc: 73.93%] [G loss: 5.366378]\n",
            "(1024, 1)\n",
            "Training Metrics: 272 [D loss: 0.925728, acc.: 99.80%, op_acc: 69.43%] [G loss: 5.597508]\n",
            "Validating on test set\n",
            "Validation Metrics: 272 [D loss: 0.778674, acc.: 100.00%, op_acc: 71.29%] [G loss: 5.602056]\n",
            "(1024, 1)\n",
            "Training Metrics: 273 [D loss: 0.918154, acc.: 99.71%, op_acc: 65.62%] [G loss: 5.504380]\n",
            "Validating on test set\n",
            "Validation Metrics: 273 [D loss: 0.784036, acc.: 100.00%, op_acc: 71.00%] [G loss: 5.511056]\n",
            "(1024, 1)\n",
            "Training Metrics: 274 [D loss: 0.932590, acc.: 99.76%, op_acc: 66.80%] [G loss: 5.731553]\n",
            "Validating on test set\n",
            "Validation Metrics: 274 [D loss: 0.750925, acc.: 100.00%, op_acc: 73.44%] [G loss: 5.762719]\n",
            "(1024, 1)\n",
            "Training Metrics: 275 [D loss: 0.902826, acc.: 99.61%, op_acc: 69.92%] [G loss: 5.747727]\n",
            "Validating on test set\n",
            "Validation Metrics: 275 [D loss: 0.753606, acc.: 100.00%, op_acc: 79.00%] [G loss: 5.774438]\n",
            "(1024, 1)\n",
            "Training Metrics: 276 [D loss: 0.969654, acc.: 99.66%, op_acc: 66.55%] [G loss: 5.666862]\n",
            "Validating on test set\n",
            "Validation Metrics: 276 [D loss: 0.733124, acc.: 100.00%, op_acc: 75.10%] [G loss: 5.685882]\n",
            "(1024, 1)\n",
            "Training Metrics: 277 [D loss: 0.920855, acc.: 99.66%, op_acc: 67.53%] [G loss: 5.530984]\n",
            "Validating on test set\n",
            "Validation Metrics: 277 [D loss: 0.762829, acc.: 100.00%, op_acc: 72.07%] [G loss: 5.524811]\n",
            "(1024, 1)\n",
            "Training Metrics: 278 [D loss: 0.924740, acc.: 99.56%, op_acc: 66.89%] [G loss: 5.772202]\n",
            "Validating on test set\n",
            "Validation Metrics: 278 [D loss: 0.803257, acc.: 100.00%, op_acc: 62.79%] [G loss: 5.826523]\n",
            "(1024, 1)\n",
            "Training Metrics: 279 [D loss: 0.946773, acc.: 99.56%, op_acc: 61.91%] [G loss: 5.511031]\n",
            "Validating on test set\n",
            "Validation Metrics: 279 [D loss: 0.927324, acc.: 100.00%, op_acc: 60.64%] [G loss: 5.660130]\n",
            "(1024, 1)\n",
            "Training Metrics: 280 [D loss: 1.047085, acc.: 99.56%, op_acc: 60.06%] [G loss: 5.939215]\n",
            "Validating on test set\n",
            "Validation Metrics: 280 [D loss: 1.521068, acc.: 100.00%, op_acc: 50.20%] [G loss: 6.399919]\n",
            "(1024, 1)\n",
            "Training Metrics: 281 [D loss: 1.353434, acc.: 99.56%, op_acc: 53.42%] [G loss: 5.809960]\n",
            "Validating on test set\n",
            "Validation Metrics: 281 [D loss: 1.326618, acc.: 100.00%, op_acc: 47.95%] [G loss: 5.909080]\n",
            "(1024, 1)\n",
            "Training Metrics: 282 [D loss: 1.276557, acc.: 99.80%, op_acc: 53.81%] [G loss: 6.560726]\n",
            "Validating on test set\n",
            "Validation Metrics: 282 [D loss: 1.036393, acc.: 100.00%, op_acc: 55.37%] [G loss: 6.249651]\n",
            "(1024, 1)\n",
            "Training Metrics: 283 [D loss: 1.099696, acc.: 99.51%, op_acc: 57.47%] [G loss: 5.454860]\n",
            "Validating on test set\n",
            "Validation Metrics: 283 [D loss: 0.934276, acc.: 100.00%, op_acc: 63.09%] [G loss: 5.429510]\n",
            "(1024, 1)\n",
            "Training Metrics: 284 [D loss: 1.020553, acc.: 99.80%, op_acc: 61.33%] [G loss: 5.669045]\n",
            "Validating on test set\n",
            "Validation Metrics: 284 [D loss: 0.900352, acc.: 100.00%, op_acc: 65.33%] [G loss: 5.678633]\n",
            "(1024, 1)\n",
            "Training Metrics: 285 [D loss: 1.032541, acc.: 99.76%, op_acc: 60.79%] [G loss: 5.887448]\n",
            "Validating on test set\n",
            "Validation Metrics: 285 [D loss: 0.877264, acc.: 100.00%, op_acc: 62.50%] [G loss: 5.838810]\n",
            "(1024, 1)\n",
            "Training Metrics: 286 [D loss: 1.059964, acc.: 99.46%, op_acc: 60.11%] [G loss: 5.351046]\n",
            "Validating on test set\n",
            "Validation Metrics: 286 [D loss: 0.801658, acc.: 100.00%, op_acc: 72.07%] [G loss: 5.311636]\n",
            "(1024, 1)\n",
            "Training Metrics: 287 [D loss: 0.989420, acc.: 99.76%, op_acc: 66.26%] [G loss: 5.808851]\n",
            "Validating on test set\n",
            "Validation Metrics: 287 [D loss: 0.775299, acc.: 100.00%, op_acc: 73.34%] [G loss: 5.807372]\n",
            "(1024, 1)\n",
            "Training Metrics: 288 [D loss: 1.006738, acc.: 99.71%, op_acc: 60.64%] [G loss: 5.328809]\n",
            "Validating on test set\n",
            "Validation Metrics: 288 [D loss: 0.774217, acc.: 100.00%, op_acc: 70.70%] [G loss: 5.294358]\n",
            "(1024, 1)\n",
            "Training Metrics: 289 [D loss: 0.965408, acc.: 99.85%, op_acc: 65.87%] [G loss: 5.850395]\n",
            "Validating on test set\n",
            "Validation Metrics: 289 [D loss: 0.777384, acc.: 100.00%, op_acc: 70.12%] [G loss: 5.894393]\n",
            "(1024, 1)\n",
            "Training Metrics: 290 [D loss: 1.041577, acc.: 99.41%, op_acc: 64.89%] [G loss: 5.554626]\n",
            "Validating on test set\n",
            "Validation Metrics: 290 [D loss: 0.791976, acc.: 100.00%, op_acc: 66.89%] [G loss: 5.571915]\n",
            "(1024, 1)\n",
            "Training Metrics: 291 [D loss: 0.941361, acc.: 99.66%, op_acc: 64.99%] [G loss: 5.450279]\n",
            "Validating on test set\n",
            "Validation Metrics: 291 [D loss: 0.795139, acc.: 100.00%, op_acc: 70.90%] [G loss: 5.420088]\n",
            "(1024, 1)\n",
            "Training Metrics: 292 [D loss: 0.932890, acc.: 99.76%, op_acc: 66.99%] [G loss: 5.529409]\n",
            "Validating on test set\n",
            "Validation Metrics: 292 [D loss: 0.725894, acc.: 100.00%, op_acc: 72.66%] [G loss: 5.527978]\n",
            "(1024, 1)\n",
            "Training Metrics: 293 [D loss: 0.896516, acc.: 99.76%, op_acc: 65.97%] [G loss: 5.592955]\n",
            "Validating on test set\n",
            "Validation Metrics: 293 [D loss: 0.711338, acc.: 100.00%, op_acc: 78.71%] [G loss: 5.608728]\n",
            "(1024, 1)\n",
            "Training Metrics: 294 [D loss: 0.896054, acc.: 99.85%, op_acc: 69.78%] [G loss: 5.714478]\n",
            "Validating on test set\n",
            "Validation Metrics: 294 [D loss: 0.705228, acc.: 100.00%, op_acc: 77.05%] [G loss: 5.688717]\n",
            "(1024, 1)\n",
            "Training Metrics: 295 [D loss: 0.893787, acc.: 99.80%, op_acc: 67.24%] [G loss: 5.732175]\n",
            "Validating on test set\n",
            "Validation Metrics: 295 [D loss: 0.673263, acc.: 100.00%, op_acc: 79.30%] [G loss: 5.738077]\n",
            "(1024, 1)\n",
            "Training Metrics: 296 [D loss: 0.868841, acc.: 99.56%, op_acc: 69.19%] [G loss: 5.469084]\n",
            "Validating on test set\n",
            "Validation Metrics: 296 [D loss: 0.661718, acc.: 100.00%, op_acc: 77.64%] [G loss: 5.442345]\n",
            "(1024, 1)\n",
            "Training Metrics: 297 [D loss: 0.908493, acc.: 99.56%, op_acc: 70.70%] [G loss: 5.591575]\n",
            "Validating on test set\n",
            "Validation Metrics: 297 [D loss: 0.657959, acc.: 100.00%, op_acc: 78.71%] [G loss: 5.571657]\n",
            "(1024, 1)\n",
            "Training Metrics: 298 [D loss: 0.896155, acc.: 99.66%, op_acc: 66.21%] [G loss: 5.541273]\n",
            "Validating on test set\n",
            "Validation Metrics: 298 [D loss: 0.689924, acc.: 100.00%, op_acc: 74.02%] [G loss: 5.527190]\n",
            "(1024, 1)\n",
            "Training Metrics: 299 [D loss: 0.890598, acc.: 99.61%, op_acc: 68.90%] [G loss: 5.604864]\n",
            "Validating on test set\n",
            "Validation Metrics: 299 [D loss: 0.682381, acc.: 100.00%, op_acc: 74.61%] [G loss: 5.652231]\n",
            "(1024, 1)\n",
            "Training Metrics: 300 [D loss: 0.941546, acc.: 99.71%, op_acc: 67.24%] [G loss: 5.363230]\n",
            "Validating on test set\n",
            "Validation Metrics: 300 [D loss: 0.826815, acc.: 100.00%, op_acc: 63.09%] [G loss: 5.550118]\n",
            "(1024, 1)\n",
            "Training Metrics: 301 [D loss: 1.017872, acc.: 99.66%, op_acc: 58.01%] [G loss: 5.801816]\n",
            "Validating on test set\n",
            "Validation Metrics: 301 [D loss: 0.949041, acc.: 100.00%, op_acc: 60.64%] [G loss: 6.106194]\n",
            "(1024, 1)\n",
            "Training Metrics: 302 [D loss: 1.063466, acc.: 99.41%, op_acc: 60.60%] [G loss: 5.736683]\n",
            "Validating on test set\n",
            "Validation Metrics: 302 [D loss: 1.133116, acc.: 100.00%, op_acc: 48.63%] [G loss: 5.823862]\n",
            "(1024, 1)\n",
            "Training Metrics: 303 [D loss: 1.186014, acc.: 99.66%, op_acc: 52.54%] [G loss: 6.041170]\n",
            "Validating on test set\n",
            "Validation Metrics: 303 [D loss: 0.856458, acc.: 100.00%, op_acc: 61.23%] [G loss: 5.820038]\n",
            "(1024, 1)\n",
            "Training Metrics: 304 [D loss: 1.013430, acc.: 99.56%, op_acc: 61.13%] [G loss: 5.594507]\n",
            "Validating on test set\n",
            "Validation Metrics: 304 [D loss: 0.821518, acc.: 100.00%, op_acc: 63.18%] [G loss: 5.518998]\n",
            "(1024, 1)\n",
            "Training Metrics: 305 [D loss: 0.934155, acc.: 99.85%, op_acc: 62.55%] [G loss: 5.737927]\n",
            "Validating on test set\n",
            "Validation Metrics: 305 [D loss: 0.721194, acc.: 100.00%, op_acc: 75.20%] [G loss: 5.657298]\n",
            "(1024, 1)\n",
            "Training Metrics: 306 [D loss: 0.919363, acc.: 99.71%, op_acc: 66.80%] [G loss: 5.537083]\n",
            "Validating on test set\n",
            "Validation Metrics: 306 [D loss: 0.748644, acc.: 100.00%, op_acc: 71.19%] [G loss: 5.575985]\n",
            "(1024, 1)\n",
            "Training Metrics: 307 [D loss: 0.905710, acc.: 99.85%, op_acc: 68.60%] [G loss: 5.704100]\n",
            "Validating on test set\n",
            "Validation Metrics: 307 [D loss: 0.687073, acc.: 100.00%, op_acc: 76.27%] [G loss: 5.746595]\n",
            "(1024, 1)\n",
            "Training Metrics: 308 [D loss: 0.850004, acc.: 99.71%, op_acc: 69.34%] [G loss: 5.923248]\n",
            "Validating on test set\n",
            "Validation Metrics: 308 [D loss: 0.693561, acc.: 100.00%, op_acc: 74.41%] [G loss: 5.867159]\n",
            "(1024, 1)\n",
            "Training Metrics: 309 [D loss: 0.896072, acc.: 99.51%, op_acc: 68.75%] [G loss: 5.484046]\n",
            "Validating on test set\n",
            "Validation Metrics: 309 [D loss: 0.683455, acc.: 100.00%, op_acc: 80.86%] [G loss: 5.513427]\n",
            "(1024, 1)\n",
            "Training Metrics: 310 [D loss: 0.917925, acc.: 99.71%, op_acc: 71.44%] [G loss: 5.829311]\n",
            "Validating on test set\n",
            "Validation Metrics: 310 [D loss: 0.673836, acc.: 100.00%, op_acc: 81.64%] [G loss: 5.823937]\n",
            "(1024, 1)\n",
            "Training Metrics: 311 [D loss: 0.945316, acc.: 99.66%, op_acc: 66.80%] [G loss: 5.455316]\n",
            "Validating on test set\n",
            "Validation Metrics: 311 [D loss: 0.651363, acc.: 100.00%, op_acc: 79.10%] [G loss: 5.430783]\n",
            "(1024, 1)\n",
            "Training Metrics: 312 [D loss: 0.876647, acc.: 99.85%, op_acc: 71.78%] [G loss: 5.514322]\n",
            "Validating on test set\n",
            "Validation Metrics: 312 [D loss: 0.630394, acc.: 100.00%, op_acc: 81.54%] [G loss: 5.484725]\n",
            "(1024, 1)\n",
            "Training Metrics: 313 [D loss: 0.862062, acc.: 99.71%, op_acc: 70.90%] [G loss: 5.728157]\n",
            "Validating on test set\n",
            "Validation Metrics: 313 [D loss: 0.613353, acc.: 100.00%, op_acc: 87.89%] [G loss: 5.702620]\n",
            "(1024, 1)\n",
            "Training Metrics: 314 [D loss: 0.870922, acc.: 99.66%, op_acc: 72.07%] [G loss: 5.584483]\n",
            "Validating on test set\n",
            "Validation Metrics: 314 [D loss: 0.598320, acc.: 100.00%, op_acc: 81.54%] [G loss: 5.605956]\n",
            "(1024, 1)\n",
            "Training Metrics: 315 [D loss: 0.849884, acc.: 99.61%, op_acc: 72.51%] [G loss: 5.708472]\n",
            "Validating on test set\n",
            "Validation Metrics: 315 [D loss: 0.638356, acc.: 100.00%, op_acc: 83.89%] [G loss: 5.715842]\n",
            "(1024, 1)\n",
            "Training Metrics: 316 [D loss: 0.853715, acc.: 99.46%, op_acc: 73.05%] [G loss: 5.647514]\n",
            "Validating on test set\n",
            "Validation Metrics: 316 [D loss: 0.599488, acc.: 100.00%, op_acc: 83.98%] [G loss: 5.661965]\n",
            "(1024, 1)\n",
            "Training Metrics: 317 [D loss: 0.845072, acc.: 99.71%, op_acc: 71.14%] [G loss: 5.399658]\n",
            "Validating on test set\n",
            "Validation Metrics: 317 [D loss: 0.711039, acc.: 100.00%, op_acc: 72.17%] [G loss: 5.492317]\n",
            "(1024, 1)\n",
            "Training Metrics: 318 [D loss: 0.960264, acc.: 99.66%, op_acc: 66.75%] [G loss: 5.882853]\n",
            "Validating on test set\n",
            "Validation Metrics: 318 [D loss: 0.835416, acc.: 100.00%, op_acc: 66.31%] [G loss: 6.071840]\n",
            "(1024, 1)\n",
            "Training Metrics: 319 [D loss: 1.033383, acc.: 99.51%, op_acc: 61.23%] [G loss: 5.448915]\n",
            "Validating on test set\n",
            "Validation Metrics: 319 [D loss: 1.099151, acc.: 100.00%, op_acc: 49.32%] [G loss: 5.577768]\n",
            "(1024, 1)\n",
            "Training Metrics: 320 [D loss: 1.144015, acc.: 99.71%, op_acc: 55.03%] [G loss: 5.883793]\n",
            "Validating on test set\n",
            "Validation Metrics: 320 [D loss: 1.317934, acc.: 100.00%, op_acc: 52.64%] [G loss: 6.186442]\n",
            "(1024, 1)\n",
            "Training Metrics: 321 [D loss: 1.243144, acc.: 99.61%, op_acc: 56.01%] [G loss: 6.521240]\n",
            "Validating on test set\n",
            "Validation Metrics: 321 [D loss: 0.919139, acc.: 100.00%, op_acc: 67.97%] [G loss: 6.185060]\n",
            "(1024, 1)\n",
            "Training Metrics: 322 [D loss: 1.045863, acc.: 99.61%, op_acc: 61.87%] [G loss: 5.881279]\n",
            "Validating on test set\n",
            "Validation Metrics: 322 [D loss: 0.803081, acc.: 100.00%, op_acc: 67.29%] [G loss: 5.770902]\n",
            "(1024, 1)\n",
            "Training Metrics: 323 [D loss: 0.956230, acc.: 99.71%, op_acc: 63.77%] [G loss: 5.944536]\n",
            "Validating on test set\n",
            "Validation Metrics: 323 [D loss: 0.697413, acc.: 100.00%, op_acc: 79.30%] [G loss: 5.878551]\n",
            "(1024, 1)\n",
            "Training Metrics: 324 [D loss: 1.003336, acc.: 99.51%, op_acc: 65.72%] [G loss: 5.487982]\n",
            "Validating on test set\n",
            "Validation Metrics: 324 [D loss: 0.716858, acc.: 100.00%, op_acc: 75.10%] [G loss: 5.464660]\n",
            "(1024, 1)\n",
            "Training Metrics: 325 [D loss: 0.917077, acc.: 99.71%, op_acc: 68.21%] [G loss: 6.230619]\n",
            "Validating on test set\n",
            "Validation Metrics: 325 [D loss: 0.616101, acc.: 100.00%, op_acc: 81.74%] [G loss: 6.219787]\n",
            "(1024, 1)\n",
            "Training Metrics: 326 [D loss: 0.913175, acc.: 99.32%, op_acc: 67.19%] [G loss: 5.324812]\n",
            "Validating on test set\n",
            "Validation Metrics: 326 [D loss: 0.636381, acc.: 100.00%, op_acc: 79.39%] [G loss: 5.334368]\n",
            "(1024, 1)\n",
            "Training Metrics: 327 [D loss: 0.848754, acc.: 99.71%, op_acc: 69.58%] [G loss: 5.566676]\n",
            "Validating on test set\n",
            "Validation Metrics: 327 [D loss: 0.606170, acc.: 100.00%, op_acc: 81.74%] [G loss: 5.593566]\n",
            "(1024, 1)\n",
            "Training Metrics: 328 [D loss: 0.831868, acc.: 99.61%, op_acc: 72.41%] [G loss: 5.336902]\n",
            "Validating on test set\n",
            "Validation Metrics: 328 [D loss: 0.746439, acc.: 100.00%, op_acc: 65.92%] [G loss: 5.442215]\n",
            "(1024, 1)\n",
            "Training Metrics: 329 [D loss: 0.925266, acc.: 99.71%, op_acc: 63.67%] [G loss: 5.827682]\n",
            "Validating on test set\n",
            "Validation Metrics: 329 [D loss: 0.835678, acc.: 100.00%, op_acc: 68.75%] [G loss: 6.033594]\n",
            "(1024, 1)\n",
            "Training Metrics: 330 [D loss: 0.970926, acc.: 99.71%, op_acc: 66.85%] [G loss: 5.557312]\n",
            "Validating on test set\n",
            "Validation Metrics: 330 [D loss: 0.711929, acc.: 100.00%, op_acc: 71.00%] [G loss: 5.379628]\n",
            "(1024, 1)\n",
            "Training Metrics: 331 [D loss: 0.902075, acc.: 99.76%, op_acc: 67.53%] [G loss: 5.742566]\n",
            "Validating on test set\n",
            "Validation Metrics: 331 [D loss: 0.599127, acc.: 100.00%, op_acc: 75.39%] [G loss: 5.599298]\n",
            "(1024, 1)\n",
            "Training Metrics: 332 [D loss: 0.859736, acc.: 99.71%, op_acc: 68.21%] [G loss: 5.409790]\n",
            "Validating on test set\n",
            "Validation Metrics: 332 [D loss: 0.595541, acc.: 100.00%, op_acc: 75.98%] [G loss: 5.365202]\n",
            "(1024, 1)\n",
            "Training Metrics: 333 [D loss: 0.852477, acc.: 99.66%, op_acc: 68.85%] [G loss: 5.936059]\n",
            "Validating on test set\n",
            "Validation Metrics: 333 [D loss: 0.562212, acc.: 100.00%, op_acc: 80.96%] [G loss: 5.918458]\n",
            "(1024, 1)\n",
            "Training Metrics: 334 [D loss: 0.848128, acc.: 99.46%, op_acc: 72.61%] [G loss: 5.289217]\n",
            "Validating on test set\n",
            "Validation Metrics: 334 [D loss: 0.557490, acc.: 100.00%, op_acc: 81.05%] [G loss: 5.285429]\n",
            "(1024, 1)\n",
            "Training Metrics: 335 [D loss: 0.814916, acc.: 99.80%, op_acc: 72.22%] [G loss: 5.407212]\n",
            "Validating on test set\n",
            "Validation Metrics: 335 [D loss: 0.543380, acc.: 100.00%, op_acc: 80.86%] [G loss: 5.418045]\n",
            "(1024, 1)\n",
            "Training Metrics: 336 [D loss: 0.829233, acc.: 99.76%, op_acc: 71.53%] [G loss: 5.412895]\n",
            "Validating on test set\n",
            "Validation Metrics: 336 [D loss: 0.495634, acc.: 100.00%, op_acc: 85.74%] [G loss: 5.422388]\n",
            "(1024, 1)\n",
            "Training Metrics: 337 [D loss: 0.812967, acc.: 99.76%, op_acc: 70.36%] [G loss: 5.597808]\n",
            "Validating on test set\n",
            "Validation Metrics: 337 [D loss: 0.515041, acc.: 100.00%, op_acc: 81.64%] [G loss: 5.575009]\n",
            "(1024, 1)\n",
            "Training Metrics: 338 [D loss: 0.838970, acc.: 99.76%, op_acc: 73.39%] [G loss: 5.556013]\n",
            "Validating on test set\n",
            "Validation Metrics: 338 [D loss: 0.484444, acc.: 100.00%, op_acc: 89.16%] [G loss: 5.521393]\n",
            "(1024, 1)\n",
            "Training Metrics: 339 [D loss: 0.823562, acc.: 99.66%, op_acc: 71.68%] [G loss: 5.736160]\n",
            "Validating on test set\n",
            "Validation Metrics: 339 [D loss: 0.501582, acc.: 100.00%, op_acc: 90.33%] [G loss: 5.747458]\n",
            "(1024, 1)\n",
            "Training Metrics: 340 [D loss: 0.778980, acc.: 99.80%, op_acc: 75.78%] [G loss: 5.507195]\n",
            "Validating on test set\n",
            "Validation Metrics: 340 [D loss: 0.516365, acc.: 100.00%, op_acc: 84.47%] [G loss: 5.516791]\n",
            "(1024, 1)\n",
            "Training Metrics: 341 [D loss: 0.818760, acc.: 99.61%, op_acc: 73.00%] [G loss: 5.640990]\n",
            "Validating on test set\n",
            "Validation Metrics: 341 [D loss: 0.514546, acc.: 100.00%, op_acc: 84.38%] [G loss: 5.650448]\n",
            "(1024, 1)\n",
            "Training Metrics: 342 [D loss: 0.845839, acc.: 99.76%, op_acc: 68.85%] [G loss: 5.540003]\n",
            "Validating on test set\n",
            "Validation Metrics: 342 [D loss: 0.532933, acc.: 100.00%, op_acc: 78.81%] [G loss: 5.626416]\n",
            "(1024, 1)\n",
            "Training Metrics: 343 [D loss: 0.872227, acc.: 99.76%, op_acc: 69.24%] [G loss: 5.568967]\n",
            "Validating on test set\n",
            "Validation Metrics: 343 [D loss: 0.550894, acc.: 100.00%, op_acc: 75.29%] [G loss: 5.590672]\n",
            "(1024, 1)\n",
            "Training Metrics: 344 [D loss: 0.836447, acc.: 99.71%, op_acc: 68.07%] [G loss: 5.601781]\n",
            "Validating on test set\n",
            "Validation Metrics: 344 [D loss: 0.557054, acc.: 100.00%, op_acc: 80.18%] [G loss: 5.646474]\n",
            "(1024, 1)\n",
            "Training Metrics: 345 [D loss: 0.824281, acc.: 99.56%, op_acc: 69.19%] [G loss: 5.884543]\n",
            "Validating on test set\n",
            "Validation Metrics: 345 [D loss: 0.535376, acc.: 100.00%, op_acc: 81.84%] [G loss: 5.824851]\n",
            "(1024, 1)\n",
            "Training Metrics: 346 [D loss: 0.832998, acc.: 99.66%, op_acc: 71.14%] [G loss: 5.065324]\n",
            "Validating on test set\n",
            "Validation Metrics: 346 [D loss: 0.481279, acc.: 100.00%, op_acc: 84.47%] [G loss: 5.026217]\n",
            "(1024, 1)\n",
            "Training Metrics: 347 [D loss: 0.801490, acc.: 99.80%, op_acc: 72.17%] [G loss: 5.692200]\n",
            "Validating on test set\n",
            "Validation Metrics: 347 [D loss: 0.496344, acc.: 100.00%, op_acc: 81.54%] [G loss: 5.681312]\n",
            "(1024, 1)\n",
            "Training Metrics: 348 [D loss: 0.826824, acc.: 99.85%, op_acc: 67.43%] [G loss: 5.560405]\n",
            "Validating on test set\n",
            "Validation Metrics: 348 [D loss: 0.505680, acc.: 100.00%, op_acc: 78.71%] [G loss: 5.601887]\n",
            "(1024, 1)\n",
            "Training Metrics: 349 [D loss: 0.821968, acc.: 99.90%, op_acc: 71.29%] [G loss: 5.599487]\n",
            "Validating on test set\n",
            "Validation Metrics: 349 [D loss: 0.524037, acc.: 100.00%, op_acc: 83.01%] [G loss: 5.600075]\n",
            "(1024, 1)\n",
            "Training Metrics: 350 [D loss: 0.802414, acc.: 99.80%, op_acc: 71.19%] [G loss: 5.900281]\n",
            "Validating on test set\n",
            "Validation Metrics: 350 [D loss: 0.540344, acc.: 100.00%, op_acc: 75.68%] [G loss: 6.013067]\n",
            "(1024, 1)\n",
            "Training Metrics: 351 [D loss: 0.861643, acc.: 99.56%, op_acc: 68.26%] [G loss: 5.678633]\n",
            "Validating on test set\n",
            "Validation Metrics: 351 [D loss: 0.976490, acc.: 100.00%, op_acc: 57.91%] [G loss: 5.998040]\n",
            "(1024, 1)\n",
            "Training Metrics: 352 [D loss: 1.029524, acc.: 99.66%, op_acc: 60.06%] [G loss: 6.407531]\n",
            "Validating on test set\n",
            "Validation Metrics: 352 [D loss: 0.861586, acc.: 100.00%, op_acc: 61.82%] [G loss: 6.508832]\n",
            "(1024, 1)\n",
            "Training Metrics: 353 [D loss: 1.040317, acc.: 99.56%, op_acc: 60.21%] [G loss: 5.976723]\n",
            "Validating on test set\n",
            "Validation Metrics: 353 [D loss: 1.339118, acc.: 100.00%, op_acc: 47.36%] [G loss: 6.375065]\n",
            "(1024, 1)\n",
            "Training Metrics: 354 [D loss: 1.220470, acc.: 99.80%, op_acc: 56.01%] [G loss: 6.469972]\n",
            "Validating on test set\n",
            "Validation Metrics: 354 [D loss: 0.863497, acc.: 100.00%, op_acc: 62.99%] [G loss: 6.238421]\n",
            "(1024, 1)\n",
            "Training Metrics: 355 [D loss: 1.080606, acc.: 99.76%, op_acc: 62.21%] [G loss: 6.077039]\n",
            "Validating on test set\n",
            "Validation Metrics: 355 [D loss: 0.823921, acc.: 100.00%, op_acc: 68.26%] [G loss: 6.078452]\n",
            "(1024, 1)\n",
            "Training Metrics: 356 [D loss: 0.897804, acc.: 99.80%, op_acc: 66.99%] [G loss: 6.207858]\n",
            "Validating on test set\n",
            "Validation Metrics: 356 [D loss: 0.594714, acc.: 100.00%, op_acc: 73.24%] [G loss: 5.991637]\n",
            "(1024, 1)\n",
            "Training Metrics: 357 [D loss: 0.807738, acc.: 99.71%, op_acc: 71.73%] [G loss: 5.520419]\n",
            "Validating on test set\n",
            "Validation Metrics: 357 [D loss: 0.707015, acc.: 100.00%, op_acc: 76.07%] [G loss: 5.245590]\n",
            "(1024, 1)\n",
            "Training Metrics: 358 [D loss: 0.919966, acc.: 99.90%, op_acc: 64.89%] [G loss: 5.728443]\n",
            "Validating on test set\n",
            "Validation Metrics: 358 [D loss: 0.553708, acc.: 100.00%, op_acc: 80.96%] [G loss: 5.509587]\n",
            "(1024, 1)\n",
            "Training Metrics: 359 [D loss: 0.795507, acc.: 99.71%, op_acc: 70.36%] [G loss: 5.549210]\n",
            "Validating on test set\n",
            "Validation Metrics: 359 [D loss: 0.565626, acc.: 100.00%, op_acc: 79.20%] [G loss: 5.472327]\n",
            "(1024, 1)\n",
            "Training Metrics: 360 [D loss: 0.802734, acc.: 99.71%, op_acc: 71.73%] [G loss: 5.571950]\n",
            "Validating on test set\n",
            "Validation Metrics: 360 [D loss: 0.572572, acc.: 100.00%, op_acc: 78.61%] [G loss: 5.533758]\n",
            "(1024, 1)\n",
            "Training Metrics: 361 [D loss: 0.784421, acc.: 99.76%, op_acc: 70.21%] [G loss: 5.875113]\n",
            "Validating on test set\n",
            "Validation Metrics: 361 [D loss: 0.528455, acc.: 100.00%, op_acc: 80.37%] [G loss: 5.825232]\n",
            "(1024, 1)\n",
            "Training Metrics: 362 [D loss: 0.810985, acc.: 99.71%, op_acc: 71.63%] [G loss: 6.003306]\n",
            "Validating on test set\n",
            "Validation Metrics: 362 [D loss: 0.513493, acc.: 100.00%, op_acc: 81.15%] [G loss: 5.935511]\n",
            "(1024, 1)\n",
            "Training Metrics: 363 [D loss: 0.813650, acc.: 99.56%, op_acc: 70.61%] [G loss: 5.614432]\n",
            "Validating on test set\n",
            "Validation Metrics: 363 [D loss: 0.527510, acc.: 100.00%, op_acc: 79.88%] [G loss: 5.623937]\n",
            "(1024, 1)\n",
            "Training Metrics: 364 [D loss: 0.848753, acc.: 99.61%, op_acc: 69.09%] [G loss: 5.815541]\n",
            "Validating on test set\n",
            "Validation Metrics: 364 [D loss: 0.498001, acc.: 100.00%, op_acc: 80.96%] [G loss: 5.776833]\n",
            "(1024, 1)\n",
            "Training Metrics: 365 [D loss: 0.769978, acc.: 99.76%, op_acc: 71.83%] [G loss: 6.079911]\n",
            "Validating on test set\n",
            "Validation Metrics: 365 [D loss: 0.500121, acc.: 100.00%, op_acc: 86.43%] [G loss: 6.106623]\n",
            "(1024, 1)\n",
            "Training Metrics: 366 [D loss: 0.774790, acc.: 99.61%, op_acc: 75.93%] [G loss: 5.693401]\n",
            "Validating on test set\n",
            "Validation Metrics: 366 [D loss: 0.475131, acc.: 100.00%, op_acc: 84.38%] [G loss: 5.676465]\n",
            "(1024, 1)\n",
            "Training Metrics: 367 [D loss: 0.763946, acc.: 99.85%, op_acc: 74.27%] [G loss: 5.496904]\n",
            "Validating on test set\n",
            "Validation Metrics: 367 [D loss: 0.491722, acc.: 100.00%, op_acc: 90.82%] [G loss: 5.482934]\n",
            "(1024, 1)\n",
            "Training Metrics: 368 [D loss: 0.779776, acc.: 99.41%, op_acc: 74.02%] [G loss: 5.510414]\n",
            "Validating on test set\n",
            "Validation Metrics: 368 [D loss: 0.486235, acc.: 100.00%, op_acc: 79.79%] [G loss: 5.454994]\n",
            "(1024, 1)\n",
            "Training Metrics: 369 [D loss: 0.784263, acc.: 99.66%, op_acc: 71.97%] [G loss: 5.410242]\n",
            "Validating on test set\n",
            "Validation Metrics: 369 [D loss: 0.512178, acc.: 100.00%, op_acc: 84.67%] [G loss: 5.385953]\n",
            "(1024, 1)\n",
            "Training Metrics: 370 [D loss: 0.771488, acc.: 99.56%, op_acc: 75.63%] [G loss: 5.464970]\n",
            "Validating on test set\n",
            "Validation Metrics: 370 [D loss: 0.506261, acc.: 100.00%, op_acc: 83.89%] [G loss: 5.426474]\n",
            "(1024, 1)\n",
            "Training Metrics: 371 [D loss: 0.755347, acc.: 99.66%, op_acc: 73.83%] [G loss: 5.346930]\n",
            "Validating on test set\n",
            "Validation Metrics: 371 [D loss: 0.654551, acc.: 100.00%, op_acc: 77.34%] [G loss: 5.329065]\n",
            "(1024, 1)\n",
            "Training Metrics: 372 [D loss: 0.846731, acc.: 99.80%, op_acc: 71.92%] [G loss: 5.924871]\n",
            "Validating on test set\n",
            "Validation Metrics: 372 [D loss: 0.935032, acc.: 100.00%, op_acc: 71.09%] [G loss: 6.274807]\n",
            "(1024, 1)\n",
            "Training Metrics: 373 [D loss: 0.991741, acc.: 99.90%, op_acc: 67.33%] [G loss: 5.846002]\n",
            "Validating on test set\n",
            "Validation Metrics: 373 [D loss: 0.762281, acc.: 100.00%, op_acc: 69.24%] [G loss: 5.891245]\n",
            "(1024, 1)\n",
            "Training Metrics: 374 [D loss: 0.894078, acc.: 99.80%, op_acc: 66.26%] [G loss: 6.258617]\n",
            "Validating on test set\n",
            "Validation Metrics: 374 [D loss: 1.375620, acc.: 100.00%, op_acc: 48.54%] [G loss: 6.854181]\n",
            "(1024, 1)\n",
            "Training Metrics: 375 [D loss: 1.292273, acc.: 99.46%, op_acc: 54.74%] [G loss: 6.623002]\n",
            "Validating on test set\n",
            "Validation Metrics: 375 [D loss: 0.657242, acc.: 100.00%, op_acc: 69.14%] [G loss: 6.145737]\n",
            "(1024, 1)\n",
            "Training Metrics: 376 [D loss: 0.853742, acc.: 99.80%, op_acc: 65.48%] [G loss: 5.811604]\n",
            "Validating on test set\n",
            "Validation Metrics: 376 [D loss: 0.672494, acc.: 100.00%, op_acc: 71.97%] [G loss: 5.769321]\n",
            "(1024, 1)\n",
            "Training Metrics: 377 [D loss: 0.804401, acc.: 99.71%, op_acc: 67.92%] [G loss: 5.811694]\n",
            "Validating on test set\n",
            "Validation Metrics: 377 [D loss: 0.619557, acc.: 100.00%, op_acc: 78.12%] [G loss: 5.742444]\n",
            "(1024, 1)\n",
            "Training Metrics: 378 [D loss: 0.823316, acc.: 99.56%, op_acc: 70.12%] [G loss: 5.864815]\n",
            "Validating on test set\n",
            "Validation Metrics: 378 [D loss: 0.523561, acc.: 100.00%, op_acc: 85.06%] [G loss: 5.813566]\n",
            "(1024, 1)\n",
            "Training Metrics: 379 [D loss: 0.787561, acc.: 99.61%, op_acc: 73.00%] [G loss: 5.527176]\n",
            "Validating on test set\n",
            "Validation Metrics: 379 [D loss: 0.509438, acc.: 100.00%, op_acc: 80.47%] [G loss: 5.551074]\n",
            "(1024, 1)\n",
            "Training Metrics: 380 [D loss: 0.753640, acc.: 99.80%, op_acc: 75.54%] [G loss: 5.663172]\n",
            "Validating on test set\n",
            "Validation Metrics: 380 [D loss: 0.527709, acc.: 100.00%, op_acc: 78.03%] [G loss: 5.652841]\n",
            "(1024, 1)\n",
            "Training Metrics: 381 [D loss: 0.776838, acc.: 99.76%, op_acc: 74.22%] [G loss: 5.975423]\n",
            "Validating on test set\n",
            "Validation Metrics: 381 [D loss: 0.513552, acc.: 100.00%, op_acc: 81.05%] [G loss: 5.985851]\n",
            "(1024, 1)\n",
            "Training Metrics: 382 [D loss: 0.792181, acc.: 99.66%, op_acc: 73.44%] [G loss: 5.423436]\n",
            "Validating on test set\n",
            "Validation Metrics: 382 [D loss: 0.502157, acc.: 100.00%, op_acc: 81.15%] [G loss: 5.417569]\n",
            "(1024, 1)\n",
            "Training Metrics: 383 [D loss: 0.754711, acc.: 99.61%, op_acc: 72.51%] [G loss: 5.527395]\n",
            "Validating on test set\n",
            "Validation Metrics: 383 [D loss: 0.480916, acc.: 100.00%, op_acc: 84.86%] [G loss: 5.499871]\n",
            "(1024, 1)\n",
            "Training Metrics: 384 [D loss: 0.774102, acc.: 99.71%, op_acc: 72.66%] [G loss: 5.593117]\n",
            "Validating on test set\n",
            "Validation Metrics: 384 [D loss: 0.462015, acc.: 100.00%, op_acc: 91.89%] [G loss: 5.577643]\n",
            "(1024, 1)\n",
            "Training Metrics: 385 [D loss: 0.781648, acc.: 99.85%, op_acc: 71.68%] [G loss: 5.864354]\n",
            "Validating on test set\n",
            "Validation Metrics: 385 [D loss: 0.458862, acc.: 100.00%, op_acc: 88.38%] [G loss: 5.871327]\n",
            "(1024, 1)\n",
            "Training Metrics: 386 [D loss: 0.753860, acc.: 99.80%, op_acc: 72.66%] [G loss: 5.563338]\n",
            "Validating on test set\n",
            "Validation Metrics: 386 [D loss: 0.466691, acc.: 100.00%, op_acc: 84.28%] [G loss: 5.599404]\n",
            "(1024, 1)\n",
            "Training Metrics: 387 [D loss: 0.807002, acc.: 99.71%, op_acc: 73.14%] [G loss: 5.811343]\n",
            "Validating on test set\n",
            "Validation Metrics: 387 [D loss: 0.460836, acc.: 100.00%, op_acc: 90.14%] [G loss: 5.812202]\n",
            "(1024, 1)\n",
            "Training Metrics: 388 [D loss: 0.804385, acc.: 99.61%, op_acc: 71.53%] [G loss: 5.424049]\n",
            "Validating on test set\n",
            "Validation Metrics: 388 [D loss: 0.438967, acc.: 100.00%, op_acc: 87.40%] [G loss: 5.410018]\n",
            "(1024, 1)\n",
            "Training Metrics: 389 [D loss: 0.741066, acc.: 99.85%, op_acc: 74.41%] [G loss: 5.793594]\n",
            "Validating on test set\n",
            "Validation Metrics: 389 [D loss: 0.415139, acc.: 100.00%, op_acc: 92.68%] [G loss: 5.780015]\n",
            "(1024, 1)\n",
            "Training Metrics: 390 [D loss: 0.764317, acc.: 99.90%, op_acc: 73.97%] [G loss: 5.930933]\n",
            "Validating on test set\n",
            "Validation Metrics: 390 [D loss: 0.404114, acc.: 100.00%, op_acc: 88.96%] [G loss: 5.918541]\n",
            "(1024, 1)\n",
            "Training Metrics: 391 [D loss: 0.759531, acc.: 99.71%, op_acc: 74.85%] [G loss: 6.183396]\n",
            "Validating on test set\n",
            "Validation Metrics: 391 [D loss: 0.443727, acc.: 100.00%, op_acc: 82.81%] [G loss: 6.198251]\n",
            "(1024, 1)\n",
            "Training Metrics: 392 [D loss: 0.825963, acc.: 99.85%, op_acc: 70.31%] [G loss: 5.395274]\n",
            "Validating on test set\n",
            "Validation Metrics: 392 [D loss: 0.440741, acc.: 100.00%, op_acc: 84.28%] [G loss: 5.418544]\n",
            "(1024, 1)\n",
            "Training Metrics: 393 [D loss: 0.787186, acc.: 99.66%, op_acc: 73.24%] [G loss: 6.043463]\n",
            "Validating on test set\n",
            "Validation Metrics: 393 [D loss: 0.416391, acc.: 100.00%, op_acc: 86.43%] [G loss: 6.038840]\n",
            "(1024, 1)\n",
            "Training Metrics: 394 [D loss: 0.828002, acc.: 99.66%, op_acc: 73.29%] [G loss: 5.196228]\n",
            "Validating on test set\n",
            "Validation Metrics: 394 [D loss: 0.402982, acc.: 100.00%, op_acc: 85.55%] [G loss: 5.191530]\n",
            "(1024, 1)\n",
            "Training Metrics: 395 [D loss: 0.737175, acc.: 99.61%, op_acc: 74.32%] [G loss: 5.644567]\n",
            "Validating on test set\n",
            "Validation Metrics: 395 [D loss: 0.384466, acc.: 100.00%, op_acc: 86.62%] [G loss: 5.651448]\n",
            "(1024, 1)\n",
            "Training Metrics: 396 [D loss: 0.743726, acc.: 99.66%, op_acc: 73.19%] [G loss: 5.716739]\n",
            "Validating on test set\n",
            "Validation Metrics: 396 [D loss: 0.354316, acc.: 100.00%, op_acc: 88.57%] [G loss: 5.677794]\n",
            "(1024, 1)\n",
            "Training Metrics: 397 [D loss: 0.735684, acc.: 99.80%, op_acc: 73.78%] [G loss: 5.604890]\n",
            "Validating on test set\n",
            "Validation Metrics: 397 [D loss: 0.403307, acc.: 100.00%, op_acc: 86.23%] [G loss: 5.592122]\n",
            "(1024, 1)\n",
            "Training Metrics: 398 [D loss: 0.749469, acc.: 99.66%, op_acc: 72.17%] [G loss: 5.690124]\n",
            "Validating on test set\n",
            "Validation Metrics: 398 [D loss: 0.441467, acc.: 100.00%, op_acc: 87.60%] [G loss: 5.757943]\n",
            "(1024, 1)\n",
            "Training Metrics: 399 [D loss: 0.795822, acc.: 99.80%, op_acc: 71.73%] [G loss: 6.100090]\n",
            "Validating on test set\n",
            "Validation Metrics: 399 [D loss: 0.569666, acc.: 100.00%, op_acc: 80.18%] [G loss: 6.147375]\n",
            "(1024, 1)\n",
            "Training Metrics: 400 [D loss: 0.893274, acc.: 99.32%, op_acc: 69.04%] [G loss: 5.148650]\n",
            "Validating on test set\n",
            "Validation Metrics: 400 [D loss: 0.401804, acc.: 100.00%, op_acc: 88.18%] [G loss: 5.033550]\n",
            "(1024, 1)\n",
            "Training Metrics: 401 [D loss: 0.740191, acc.: 99.90%, op_acc: 74.71%] [G loss: 5.800958]\n",
            "Validating on test set\n",
            "Validation Metrics: 401 [D loss: 0.436668, acc.: 100.00%, op_acc: 88.09%] [G loss: 5.652301]\n",
            "(1024, 1)\n",
            "Training Metrics: 402 [D loss: 0.763160, acc.: 99.80%, op_acc: 73.49%] [G loss: 5.668050]\n",
            "Validating on test set\n",
            "Validation Metrics: 402 [D loss: 0.418831, acc.: 100.00%, op_acc: 89.45%] [G loss: 5.668265]\n",
            "(1024, 1)\n",
            "Training Metrics: 403 [D loss: 0.735401, acc.: 99.61%, op_acc: 75.39%] [G loss: 6.145014]\n",
            "Validating on test set\n",
            "Validation Metrics: 403 [D loss: 0.419735, acc.: 100.00%, op_acc: 89.26%] [G loss: 6.124335]\n",
            "(1024, 1)\n",
            "Training Metrics: 404 [D loss: 0.760420, acc.: 99.32%, op_acc: 73.68%] [G loss: 5.357160]\n",
            "Validating on test set\n",
            "Validation Metrics: 404 [D loss: 0.403010, acc.: 100.00%, op_acc: 84.77%] [G loss: 5.355822]\n",
            "(1024, 1)\n",
            "Training Metrics: 405 [D loss: 0.741846, acc.: 99.76%, op_acc: 75.59%] [G loss: 5.934401]\n",
            "Validating on test set\n",
            "Validation Metrics: 405 [D loss: 0.390046, acc.: 100.00%, op_acc: 87.99%] [G loss: 5.991889]\n",
            "(1024, 1)\n",
            "Training Metrics: 406 [D loss: 0.730754, acc.: 99.80%, op_acc: 74.85%] [G loss: 5.804019]\n",
            "Validating on test set\n",
            "Validation Metrics: 406 [D loss: 0.387139, acc.: 100.00%, op_acc: 86.23%] [G loss: 5.765455]\n",
            "(1024, 1)\n",
            "Training Metrics: 407 [D loss: 0.737418, acc.: 99.66%, op_acc: 72.95%] [G loss: 5.593143]\n",
            "Validating on test set\n",
            "Validation Metrics: 407 [D loss: 0.369810, acc.: 100.00%, op_acc: 94.04%] [G loss: 5.586766]\n",
            "(1024, 1)\n",
            "Training Metrics: 408 [D loss: 0.714636, acc.: 99.71%, op_acc: 78.27%] [G loss: 5.612726]\n",
            "Validating on test set\n",
            "Validation Metrics: 408 [D loss: 0.348315, acc.: 100.00%, op_acc: 95.70%] [G loss: 5.607014]\n",
            "(1024, 1)\n",
            "Training Metrics: 409 [D loss: 0.715403, acc.: 99.76%, op_acc: 77.98%] [G loss: 5.441867]\n",
            "Validating on test set\n",
            "Validation Metrics: 409 [D loss: 0.358901, acc.: 100.00%, op_acc: 95.21%] [G loss: 5.442261]\n",
            "(1024, 1)\n",
            "Training Metrics: 410 [D loss: 0.701723, acc.: 99.85%, op_acc: 77.39%] [G loss: 6.121451]\n",
            "Validating on test set\n",
            "Validation Metrics: 410 [D loss: 0.416464, acc.: 100.00%, op_acc: 88.48%] [G loss: 6.137107]\n",
            "(1024, 1)\n",
            "Training Metrics: 411 [D loss: 0.780556, acc.: 99.76%, op_acc: 72.66%] [G loss: 5.673845]\n",
            "Validating on test set\n",
            "Validation Metrics: 411 [D loss: 0.447691, acc.: 100.00%, op_acc: 86.82%] [G loss: 5.760850]\n",
            "(1024, 1)\n",
            "Training Metrics: 412 [D loss: 0.826394, acc.: 99.61%, op_acc: 74.80%] [G loss: 5.812404]\n",
            "Validating on test set\n",
            "Validation Metrics: 412 [D loss: 0.523828, acc.: 100.00%, op_acc: 83.11%] [G loss: 5.856702]\n",
            "(1024, 1)\n",
            "Training Metrics: 413 [D loss: 0.843988, acc.: 99.80%, op_acc: 71.34%] [G loss: 5.636195]\n",
            "Validating on test set\n",
            "Validation Metrics: 413 [D loss: 0.593473, acc.: 100.00%, op_acc: 79.49%] [G loss: 5.809062]\n",
            "(1024, 1)\n",
            "Training Metrics: 414 [D loss: 0.894890, acc.: 99.80%, op_acc: 69.48%] [G loss: 6.128918]\n",
            "Validating on test set\n",
            "Validation Metrics: 414 [D loss: 0.812207, acc.: 100.00%, op_acc: 70.51%] [G loss: 6.288107]\n",
            "(1024, 1)\n",
            "Training Metrics: 415 [D loss: 0.976389, acc.: 99.76%, op_acc: 67.43%] [G loss: 5.982106]\n",
            "Validating on test set\n",
            "Validation Metrics: 415 [D loss: 1.453434, acc.: 100.00%, op_acc: 61.91%] [G loss: 6.930352]\n",
            "(1024, 1)\n",
            "Training Metrics: 416 [D loss: 1.326926, acc.: 99.76%, op_acc: 59.81%] [G loss: 6.378755]\n",
            "Validating on test set\n",
            "Validation Metrics: 416 [D loss: 0.964862, acc.: 100.00%, op_acc: 76.86%] [G loss: 5.913168]\n",
            "(1024, 1)\n",
            "Training Metrics: 417 [D loss: 0.992018, acc.: 99.66%, op_acc: 69.19%] [G loss: 6.257295]\n",
            "Validating on test set\n",
            "Validation Metrics: 417 [D loss: 1.042271, acc.: 100.00%, op_acc: 70.12%] [G loss: 6.532699]\n",
            "(1024, 1)\n",
            "Training Metrics: 418 [D loss: 1.061638, acc.: 99.76%, op_acc: 67.14%] [G loss: 5.965593]\n",
            "Validating on test set\n",
            "Validation Metrics: 418 [D loss: 0.768830, acc.: 100.00%, op_acc: 72.75%] [G loss: 5.874782]\n",
            "(1024, 1)\n",
            "Training Metrics: 419 [D loss: 0.856706, acc.: 99.85%, op_acc: 69.73%] [G loss: 5.830976]\n",
            "Validating on test set\n",
            "Validation Metrics: 419 [D loss: 0.589241, acc.: 100.00%, op_acc: 77.05%] [G loss: 5.715659]\n",
            "(1024, 1)\n",
            "Training Metrics: 420 [D loss: 0.822163, acc.: 99.85%, op_acc: 70.41%] [G loss: 5.627504]\n",
            "Validating on test set\n",
            "Validation Metrics: 420 [D loss: 0.547588, acc.: 100.00%, op_acc: 80.57%] [G loss: 5.577539]\n",
            "(1024, 1)\n",
            "Training Metrics: 421 [D loss: 0.782839, acc.: 99.80%, op_acc: 72.17%] [G loss: 5.603494]\n",
            "Validating on test set\n",
            "Validation Metrics: 421 [D loss: 0.507590, acc.: 100.00%, op_acc: 79.20%] [G loss: 5.539295]\n",
            "(1024, 1)\n",
            "Training Metrics: 422 [D loss: 0.783609, acc.: 99.80%, op_acc: 72.66%] [G loss: 5.831100]\n",
            "Validating on test set\n",
            "Validation Metrics: 422 [D loss: 0.477662, acc.: 100.00%, op_acc: 81.64%] [G loss: 5.844702]\n",
            "(1024, 1)\n",
            "Training Metrics: 423 [D loss: 0.807672, acc.: 99.76%, op_acc: 70.61%] [G loss: 5.624362]\n",
            "Validating on test set\n",
            "Validation Metrics: 423 [D loss: 0.402691, acc.: 100.00%, op_acc: 88.87%] [G loss: 5.591323]\n",
            "(1024, 1)\n",
            "Training Metrics: 424 [D loss: 0.746611, acc.: 99.90%, op_acc: 76.46%] [G loss: 5.782985]\n",
            "Validating on test set\n",
            "Validation Metrics: 424 [D loss: 0.374053, acc.: 100.00%, op_acc: 89.75%] [G loss: 5.756068]\n",
            "(1024, 1)\n",
            "Training Metrics: 425 [D loss: 0.738566, acc.: 99.71%, op_acc: 73.34%] [G loss: 5.696758]\n",
            "Validating on test set\n",
            "Validation Metrics: 425 [D loss: 0.390222, acc.: 100.00%, op_acc: 94.53%] [G loss: 5.677283]\n",
            "(1024, 1)\n",
            "Training Metrics: 426 [D loss: 0.671774, acc.: 99.76%, op_acc: 77.29%] [G loss: 5.579178]\n",
            "Validating on test set\n",
            "Validation Metrics: 426 [D loss: 0.357562, acc.: 100.00%, op_acc: 96.00%] [G loss: 5.593860]\n",
            "(1024, 1)\n",
            "Training Metrics: 427 [D loss: 0.666970, acc.: 99.85%, op_acc: 81.88%] [G loss: 5.718300]\n",
            "Validating on test set\n",
            "Validation Metrics: 427 [D loss: 0.338901, acc.: 100.00%, op_acc: 96.68%] [G loss: 5.722452]\n",
            "(1024, 1)\n",
            "Training Metrics: 428 [D loss: 0.684288, acc.: 99.71%, op_acc: 80.66%] [G loss: 5.442308]\n",
            "Validating on test set\n",
            "Validation Metrics: 428 [D loss: 0.353007, acc.: 100.00%, op_acc: 94.82%] [G loss: 5.426892]\n",
            "(1024, 1)\n",
            "Training Metrics: 429 [D loss: 0.702048, acc.: 99.85%, op_acc: 77.73%] [G loss: 5.744282]\n",
            "Validating on test set\n",
            "Validation Metrics: 429 [D loss: 0.311207, acc.: 100.00%, op_acc: 92.58%] [G loss: 5.774211]\n",
            "(1024, 1)\n",
            "Training Metrics: 430 [D loss: 0.734270, acc.: 99.76%, op_acc: 75.49%] [G loss: 5.075420]\n",
            "Validating on test set\n",
            "Validation Metrics: 430 [D loss: 0.335420, acc.: 100.00%, op_acc: 96.68%] [G loss: 5.086464]\n",
            "(1024, 1)\n",
            "Training Metrics: 431 [D loss: 0.691593, acc.: 99.80%, op_acc: 77.73%] [G loss: 5.832446]\n",
            "Validating on test set\n",
            "Validation Metrics: 431 [D loss: 0.313134, acc.: 100.00%, op_acc: 92.58%] [G loss: 5.847349]\n",
            "(1024, 1)\n",
            "Training Metrics: 432 [D loss: 0.697584, acc.: 99.80%, op_acc: 80.03%] [G loss: 5.572592]\n",
            "Validating on test set\n",
            "Validation Metrics: 432 [D loss: 0.323519, acc.: 100.00%, op_acc: 91.80%] [G loss: 5.549104]\n",
            "(1024, 1)\n",
            "Training Metrics: 433 [D loss: 0.676057, acc.: 99.76%, op_acc: 77.64%] [G loss: 5.661674]\n",
            "Validating on test set\n",
            "Validation Metrics: 433 [D loss: 0.314401, acc.: 100.00%, op_acc: 95.21%] [G loss: 5.656931]\n",
            "(1024, 1)\n",
            "Training Metrics: 434 [D loss: 0.648179, acc.: 99.80%, op_acc: 78.71%] [G loss: 5.685251]\n",
            "Validating on test set\n",
            "Validation Metrics: 434 [D loss: 0.300358, acc.: 100.00%, op_acc: 93.75%] [G loss: 5.701551]\n",
            "(1024, 1)\n",
            "Training Metrics: 435 [D loss: 0.668754, acc.: 99.90%, op_acc: 79.20%] [G loss: 5.584973]\n",
            "Validating on test set\n",
            "Validation Metrics: 435 [D loss: 0.310014, acc.: 100.00%, op_acc: 95.80%] [G loss: 5.601733]\n",
            "(1024, 1)\n",
            "Training Metrics: 436 [D loss: 0.676873, acc.: 99.71%, op_acc: 78.37%] [G loss: 5.623476]\n",
            "Validating on test set\n",
            "Validation Metrics: 436 [D loss: 0.332001, acc.: 100.00%, op_acc: 87.40%] [G loss: 5.680652]\n",
            "(1024, 1)\n",
            "Training Metrics: 437 [D loss: 0.655766, acc.: 99.95%, op_acc: 76.17%] [G loss: 5.679740]\n",
            "Validating on test set\n",
            "Validation Metrics: 437 [D loss: 0.304268, acc.: 100.00%, op_acc: 95.51%] [G loss: 5.677265]\n",
            "(1024, 1)\n",
            "Training Metrics: 438 [D loss: 0.669631, acc.: 99.85%, op_acc: 79.05%] [G loss: 6.169015]\n",
            "Validating on test set\n",
            "Validation Metrics: 438 [D loss: 0.287692, acc.: 100.00%, op_acc: 92.68%] [G loss: 6.147891]\n",
            "(1024, 1)\n",
            "Training Metrics: 439 [D loss: 0.673751, acc.: 99.56%, op_acc: 77.20%] [G loss: 5.323094]\n",
            "Validating on test set\n",
            "Validation Metrics: 439 [D loss: 0.298095, acc.: 100.00%, op_acc: 97.66%] [G loss: 5.317262]\n",
            "(1024, 1)\n",
            "Training Metrics: 440 [D loss: 0.642599, acc.: 99.90%, op_acc: 80.27%] [G loss: 5.718128]\n",
            "Validating on test set\n",
            "Validation Metrics: 440 [D loss: 0.309584, acc.: 100.00%, op_acc: 93.07%] [G loss: 5.704132]\n",
            "(1024, 1)\n",
            "Training Metrics: 441 [D loss: 0.671953, acc.: 99.76%, op_acc: 78.96%] [G loss: 5.819847]\n",
            "Validating on test set\n",
            "Validation Metrics: 441 [D loss: 0.292080, acc.: 100.00%, op_acc: 95.31%] [G loss: 5.818219]\n",
            "(1024, 1)\n",
            "Training Metrics: 442 [D loss: 0.670483, acc.: 99.90%, op_acc: 78.03%] [G loss: 6.274071]\n",
            "Validating on test set\n",
            "Validation Metrics: 442 [D loss: 0.274077, acc.: 100.00%, op_acc: 92.19%] [G loss: 6.288506]\n",
            "(1024, 1)\n",
            "Training Metrics: 443 [D loss: 0.696841, acc.: 99.85%, op_acc: 75.00%] [G loss: 5.479472]\n",
            "Validating on test set\n",
            "Validation Metrics: 443 [D loss: 0.287441, acc.: 100.00%, op_acc: 95.41%] [G loss: 5.486694]\n",
            "(1024, 1)\n",
            "Training Metrics: 444 [D loss: 0.758582, acc.: 99.80%, op_acc: 76.95%] [G loss: 6.102921]\n",
            "Validating on test set\n",
            "Validation Metrics: 444 [D loss: 0.273034, acc.: 100.00%, op_acc: 93.36%] [G loss: 6.113955]\n",
            "(1024, 1)\n",
            "Training Metrics: 445 [D loss: 0.692504, acc.: 99.76%, op_acc: 75.88%] [G loss: 5.568147]\n",
            "Validating on test set\n",
            "Validation Metrics: 445 [D loss: 0.308743, acc.: 100.00%, op_acc: 93.26%] [G loss: 5.604644]\n",
            "(1024, 1)\n",
            "Training Metrics: 446 [D loss: 0.685710, acc.: 99.76%, op_acc: 79.69%] [G loss: 5.897161]\n",
            "Validating on test set\n",
            "Validation Metrics: 446 [D loss: 0.289986, acc.: 100.00%, op_acc: 89.36%] [G loss: 5.898695]\n",
            "(1024, 1)\n",
            "Training Metrics: 447 [D loss: 0.711010, acc.: 99.85%, op_acc: 74.56%] [G loss: 5.318345]\n",
            "Validating on test set\n",
            "Validation Metrics: 447 [D loss: 0.346828, acc.: 100.00%, op_acc: 87.21%] [G loss: 5.337992]\n",
            "(1024, 1)\n",
            "Training Metrics: 448 [D loss: 0.725529, acc.: 99.76%, op_acc: 74.12%] [G loss: 5.991630]\n",
            "Validating on test set\n",
            "Validation Metrics: 448 [D loss: 0.268162, acc.: 100.00%, op_acc: 92.09%] [G loss: 5.980282]\n",
            "(1024, 1)\n",
            "Training Metrics: 449 [D loss: 0.672877, acc.: 99.80%, op_acc: 76.86%] [G loss: 5.313985]\n",
            "Validating on test set\n",
            "Validation Metrics: 449 [D loss: 0.301123, acc.: 100.00%, op_acc: 96.97%] [G loss: 5.316676]\n",
            "(1024, 1)\n",
            "Training Metrics: 450 [D loss: 0.719272, acc.: 99.95%, op_acc: 76.12%] [G loss: 6.157828]\n",
            "Validating on test set\n",
            "Validation Metrics: 450 [D loss: 0.263311, acc.: 100.00%, op_acc: 97.27%] [G loss: 6.126990]\n",
            "(1024, 1)\n",
            "Training Metrics: 451 [D loss: 0.697436, acc.: 99.71%, op_acc: 78.96%] [G loss: 5.560473]\n",
            "Validating on test set\n",
            "Validation Metrics: 451 [D loss: 0.255053, acc.: 100.00%, op_acc: 98.54%] [G loss: 5.545093]\n",
            "(1024, 1)\n",
            "Training Metrics: 452 [D loss: 0.656344, acc.: 99.80%, op_acc: 80.42%] [G loss: 5.771291]\n",
            "Validating on test set\n",
            "Validation Metrics: 452 [D loss: 0.251475, acc.: 100.00%, op_acc: 96.97%] [G loss: 5.799918]\n",
            "(1024, 1)\n",
            "Training Metrics: 453 [D loss: 0.626375, acc.: 99.66%, op_acc: 79.88%] [G loss: 5.418167]\n",
            "Validating on test set\n",
            "Validation Metrics: 453 [D loss: 0.246285, acc.: 100.00%, op_acc: 94.73%] [G loss: 5.428096]\n",
            "(1024, 1)\n",
            "Training Metrics: 454 [D loss: 0.618890, acc.: 99.71%, op_acc: 79.39%] [G loss: 5.386268]\n",
            "Validating on test set\n",
            "Validation Metrics: 454 [D loss: 0.292585, acc.: 100.00%, op_acc: 88.57%] [G loss: 5.399060]\n",
            "(1024, 1)\n",
            "Training Metrics: 455 [D loss: 0.670516, acc.: 99.90%, op_acc: 74.22%] [G loss: 5.714153]\n",
            "Validating on test set\n",
            "Validation Metrics: 455 [D loss: 0.270889, acc.: 100.00%, op_acc: 92.38%] [G loss: 5.714446]\n",
            "(1024, 1)\n",
            "Training Metrics: 456 [D loss: 0.672742, acc.: 99.80%, op_acc: 78.37%] [G loss: 5.746881]\n",
            "Validating on test set\n",
            "Validation Metrics: 456 [D loss: 0.284766, acc.: 100.00%, op_acc: 93.95%] [G loss: 5.743554]\n",
            "(1024, 1)\n",
            "Training Metrics: 457 [D loss: 0.645860, acc.: 99.71%, op_acc: 76.27%] [G loss: 5.739296]\n",
            "Validating on test set\n",
            "Validation Metrics: 457 [D loss: 0.309682, acc.: 100.00%, op_acc: 89.45%] [G loss: 5.754031]\n",
            "(1024, 1)\n",
            "Training Metrics: 458 [D loss: 0.669545, acc.: 99.90%, op_acc: 76.61%] [G loss: 5.664287]\n",
            "Validating on test set\n",
            "Validation Metrics: 458 [D loss: 0.335777, acc.: 100.00%, op_acc: 83.79%] [G loss: 5.656163]\n",
            "(1024, 1)\n",
            "Training Metrics: 459 [D loss: 0.660601, acc.: 99.80%, op_acc: 72.61%] [G loss: 5.914000]\n",
            "Validating on test set\n",
            "Validation Metrics: 459 [D loss: 0.309109, acc.: 100.00%, op_acc: 90.53%] [G loss: 5.940344]\n",
            "(1024, 1)\n",
            "Training Metrics: 460 [D loss: 0.680836, acc.: 99.85%, op_acc: 74.95%] [G loss: 5.736188]\n",
            "Validating on test set\n",
            "Validation Metrics: 460 [D loss: 0.288323, acc.: 100.00%, op_acc: 88.28%] [G loss: 5.757021]\n",
            "(1024, 1)\n",
            "Training Metrics: 461 [D loss: 0.683803, acc.: 99.76%, op_acc: 73.49%] [G loss: 6.007553]\n",
            "Validating on test set\n",
            "Validation Metrics: 461 [D loss: 0.264571, acc.: 100.00%, op_acc: 94.63%] [G loss: 5.974048]\n",
            "(1024, 1)\n",
            "Training Metrics: 462 [D loss: 0.662244, acc.: 99.46%, op_acc: 78.42%] [G loss: 5.359447]\n",
            "Validating on test set\n",
            "Validation Metrics: 462 [D loss: 0.238710, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.358016]\n",
            "(1024, 1)\n",
            "Training Metrics: 463 [D loss: 0.613747, acc.: 99.90%, op_acc: 81.30%] [G loss: 5.759815]\n",
            "Validating on test set\n",
            "Validation Metrics: 463 [D loss: 0.235362, acc.: 100.00%, op_acc: 96.48%] [G loss: 5.747526]\n",
            "(1024, 1)\n",
            "Training Metrics: 464 [D loss: 0.666019, acc.: 99.76%, op_acc: 79.54%] [G loss: 5.620636]\n",
            "Validating on test set\n",
            "Validation Metrics: 464 [D loss: 0.228616, acc.: 100.00%, op_acc: 97.85%] [G loss: 5.598498]\n",
            "(1024, 1)\n",
            "Training Metrics: 465 [D loss: 0.651998, acc.: 99.95%, op_acc: 80.86%] [G loss: 6.121031]\n",
            "Validating on test set\n",
            "Validation Metrics: 465 [D loss: 0.233144, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.121288]\n",
            "(1024, 1)\n",
            "Training Metrics: 466 [D loss: 0.631572, acc.: 99.61%, op_acc: 79.39%] [G loss: 5.331207]\n",
            "Validating on test set\n",
            "Validation Metrics: 466 [D loss: 0.224045, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.340464]\n",
            "(1024, 1)\n",
            "Training Metrics: 467 [D loss: 0.669217, acc.: 99.71%, op_acc: 78.91%] [G loss: 6.012413]\n",
            "Validating on test set\n",
            "Validation Metrics: 467 [D loss: 0.254524, acc.: 100.00%, op_acc: 96.09%] [G loss: 6.043751]\n",
            "(1024, 1)\n",
            "Training Metrics: 468 [D loss: 0.662622, acc.: 99.56%, op_acc: 80.96%] [G loss: 5.491963]\n",
            "Validating on test set\n",
            "Validation Metrics: 468 [D loss: 0.229731, acc.: 100.00%, op_acc: 96.39%] [G loss: 5.515784]\n",
            "(1024, 1)\n",
            "Training Metrics: 469 [D loss: 0.616130, acc.: 99.56%, op_acc: 80.42%] [G loss: 5.272384]\n",
            "Validating on test set\n",
            "Validation Metrics: 469 [D loss: 0.258372, acc.: 100.00%, op_acc: 93.16%] [G loss: 5.276373]\n",
            "(1024, 1)\n",
            "Training Metrics: 470 [D loss: 0.703211, acc.: 99.71%, op_acc: 75.73%] [G loss: 5.500341]\n",
            "Validating on test set\n",
            "Validation Metrics: 470 [D loss: 0.308021, acc.: 100.00%, op_acc: 85.64%] [G loss: 5.537815]\n",
            "(1024, 1)\n",
            "Training Metrics: 471 [D loss: 0.710850, acc.: 99.85%, op_acc: 71.14%] [G loss: 5.681226]\n",
            "Validating on test set\n",
            "Validation Metrics: 471 [D loss: 0.344230, acc.: 100.00%, op_acc: 85.16%] [G loss: 5.760311]\n",
            "(1024, 1)\n",
            "Training Metrics: 472 [D loss: 0.657691, acc.: 99.51%, op_acc: 74.41%] [G loss: 5.308344]\n",
            "Validating on test set\n",
            "Validation Metrics: 472 [D loss: 0.490211, acc.: 100.00%, op_acc: 76.86%] [G loss: 5.465183]\n",
            "(1024, 1)\n",
            "Training Metrics: 473 [D loss: 0.768316, acc.: 99.66%, op_acc: 69.73%] [G loss: 5.777373]\n",
            "Validating on test set\n",
            "Validation Metrics: 473 [D loss: 0.591367, acc.: 100.00%, op_acc: 76.56%] [G loss: 6.033533]\n",
            "(1024, 1)\n",
            "Training Metrics: 474 [D loss: 0.886033, acc.: 99.85%, op_acc: 68.55%] [G loss: 5.949349]\n",
            "Validating on test set\n",
            "Validation Metrics: 474 [D loss: 0.896262, acc.: 100.00%, op_acc: 71.39%] [G loss: 6.162207]\n",
            "(1024, 1)\n",
            "Training Metrics: 475 [D loss: 1.030785, acc.: 99.76%, op_acc: 65.33%] [G loss: 6.383397]\n",
            "Validating on test set\n",
            "Validation Metrics: 475 [D loss: 0.844760, acc.: 100.00%, op_acc: 73.44%] [G loss: 6.337169]\n",
            "(1024, 1)\n",
            "Training Metrics: 476 [D loss: 0.923822, acc.: 99.85%, op_acc: 71.19%] [G loss: 6.769319]\n",
            "Validating on test set\n",
            "Validation Metrics: 476 [D loss: 0.583461, acc.: 100.00%, op_acc: 80.96%] [G loss: 6.611325]\n",
            "(1024, 1)\n",
            "Training Metrics: 477 [D loss: 0.824477, acc.: 99.56%, op_acc: 70.21%] [G loss: 6.238502]\n",
            "Validating on test set\n",
            "Validation Metrics: 477 [D loss: 0.417584, acc.: 100.00%, op_acc: 84.28%] [G loss: 6.131347]\n",
            "(1024, 1)\n",
            "Training Metrics: 478 [D loss: 0.731960, acc.: 99.90%, op_acc: 78.08%] [G loss: 6.264743]\n",
            "Validating on test set\n",
            "Validation Metrics: 478 [D loss: 0.406001, acc.: 100.00%, op_acc: 88.38%] [G loss: 6.253098]\n",
            "(1024, 1)\n",
            "Training Metrics: 479 [D loss: 0.712062, acc.: 99.76%, op_acc: 76.46%] [G loss: 5.881579]\n",
            "Validating on test set\n",
            "Validation Metrics: 479 [D loss: 0.340115, acc.: 100.00%, op_acc: 89.55%] [G loss: 5.836407]\n",
            "(1024, 1)\n",
            "Training Metrics: 480 [D loss: 0.672734, acc.: 99.95%, op_acc: 77.54%] [G loss: 5.726299]\n",
            "Validating on test set\n",
            "Validation Metrics: 480 [D loss: 0.264024, acc.: 100.00%, op_acc: 95.70%] [G loss: 5.715779]\n",
            "(1024, 1)\n",
            "Training Metrics: 481 [D loss: 0.610552, acc.: 99.95%, op_acc: 81.25%] [G loss: 5.386445]\n",
            "Validating on test set\n",
            "Validation Metrics: 481 [D loss: 0.261269, acc.: 100.00%, op_acc: 97.27%] [G loss: 5.388212]\n",
            "(1024, 1)\n",
            "Training Metrics: 482 [D loss: 0.608458, acc.: 99.90%, op_acc: 80.57%] [G loss: 5.718661]\n",
            "Validating on test set\n",
            "Validation Metrics: 482 [D loss: 0.246426, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.699267]\n",
            "(1024, 1)\n",
            "Training Metrics: 483 [D loss: 0.601139, acc.: 99.85%, op_acc: 80.91%] [G loss: 5.547009]\n",
            "Validating on test set\n",
            "Validation Metrics: 483 [D loss: 0.237774, acc.: 100.00%, op_acc: 94.24%] [G loss: 5.565447]\n",
            "(1024, 1)\n",
            "Training Metrics: 484 [D loss: 0.666479, acc.: 99.80%, op_acc: 76.76%] [G loss: 5.766467]\n",
            "Validating on test set\n",
            "Validation Metrics: 484 [D loss: 0.249082, acc.: 100.00%, op_acc: 94.63%] [G loss: 5.757317]\n",
            "(1024, 1)\n",
            "Training Metrics: 485 [D loss: 0.623733, acc.: 99.85%, op_acc: 77.78%] [G loss: 5.673855]\n",
            "Validating on test set\n",
            "Validation Metrics: 485 [D loss: 0.226364, acc.: 100.00%, op_acc: 97.56%] [G loss: 5.677097]\n",
            "(1024, 1)\n",
            "Training Metrics: 486 [D loss: 0.618372, acc.: 99.80%, op_acc: 80.81%] [G loss: 5.668191]\n",
            "Validating on test set\n",
            "Validation Metrics: 486 [D loss: 0.212659, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.643564]\n",
            "(1024, 1)\n",
            "Training Metrics: 487 [D loss: 0.595575, acc.: 99.80%, op_acc: 81.69%] [G loss: 5.779061]\n",
            "Validating on test set\n",
            "Validation Metrics: 487 [D loss: 0.227779, acc.: 100.00%, op_acc: 97.95%] [G loss: 5.819476]\n",
            "(1024, 1)\n",
            "Training Metrics: 488 [D loss: 0.624384, acc.: 99.61%, op_acc: 80.52%] [G loss: 5.510550]\n",
            "Validating on test set\n",
            "Validation Metrics: 488 [D loss: 0.201856, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.495780]\n",
            "(1024, 1)\n",
            "Training Metrics: 489 [D loss: 0.625391, acc.: 99.71%, op_acc: 79.64%] [G loss: 5.776697]\n",
            "Validating on test set\n",
            "Validation Metrics: 489 [D loss: 0.361003, acc.: 100.00%, op_acc: 95.51%] [G loss: 5.355462]\n",
            "(1024, 1)\n",
            "Training Metrics: 490 [D loss: 0.674434, acc.: 99.85%, op_acc: 80.47%] [G loss: 6.651507]\n",
            "Validating on test set\n",
            "Validation Metrics: 490 [D loss: 1.067998, acc.: 100.00%, op_acc: 68.65%] [G loss: 5.581106]\n",
            "(1024, 1)\n",
            "Training Metrics: 491 [D loss: 1.105303, acc.: 99.61%, op_acc: 65.62%] [G loss: 8.076860]\n",
            "Validating on test set\n",
            "Validation Metrics: 491 [D loss: 1.972828, acc.: 100.00%, op_acc: 57.42%] [G loss: 8.945382]\n",
            "(1024, 1)\n",
            "Training Metrics: 492 [D loss: 1.603912, acc.: 99.17%, op_acc: 60.06%] [G loss: 9.783854]\n",
            "Validating on test set\n",
            "Validation Metrics: 492 [D loss: 1.535926, acc.: 100.00%, op_acc: 56.84%] [G loss: 6.743205]\n",
            "(1024, 1)\n",
            "Training Metrics: 493 [D loss: 1.434518, acc.: 98.68%, op_acc: 57.18%] [G loss: 8.502374]\n",
            "Validating on test set\n",
            "Validation Metrics: 493 [D loss: 1.645609, acc.: 100.00%, op_acc: 43.07%] [G loss: 9.017220]\n",
            "(1024, 1)\n",
            "Training Metrics: 494 [D loss: 1.505864, acc.: 97.75%, op_acc: 52.29%] [G loss: 7.152450]\n",
            "Validating on test set\n",
            "Validation Metrics: 494 [D loss: 2.113630, acc.: 100.00%, op_acc: 46.97%] [G loss: 8.114548]\n",
            "(1024, 1)\n",
            "Training Metrics: 495 [D loss: 1.692682, acc.: 98.73%, op_acc: 50.49%] [G loss: 6.763554]\n",
            "Validating on test set\n",
            "Validation Metrics: 495 [D loss: 1.684586, acc.: 100.00%, op_acc: 43.16%] [G loss: 6.710558]\n",
            "(1024, 1)\n",
            "Training Metrics: 496 [D loss: 1.470304, acc.: 98.88%, op_acc: 51.76%] [G loss: 5.726692]\n",
            "Validating on test set\n",
            "Validation Metrics: 496 [D loss: 1.667621, acc.: 100.00%, op_acc: 41.41%] [G loss: 5.710036]\n",
            "(1024, 1)\n",
            "Training Metrics: 497 [D loss: 1.315336, acc.: 99.37%, op_acc: 53.42%] [G loss: 6.576530]\n",
            "Validating on test set\n",
            "Validation Metrics: 497 [D loss: 1.197063, acc.: 100.00%, op_acc: 52.44%] [G loss: 6.546089]\n",
            "(1024, 1)\n",
            "Training Metrics: 498 [D loss: 1.170143, acc.: 99.32%, op_acc: 56.20%] [G loss: 6.263402]\n",
            "Validating on test set\n",
            "Validation Metrics: 498 [D loss: 1.287040, acc.: 100.00%, op_acc: 53.91%] [G loss: 6.307856]\n",
            "(1024, 1)\n",
            "Training Metrics: 499 [D loss: 1.257336, acc.: 99.32%, op_acc: 59.72%] [G loss: 5.802257]\n",
            "Validating on test set\n",
            "Validation Metrics: 499 [D loss: 1.061557, acc.: 100.00%, op_acc: 62.60%] [G loss: 5.778890]\n",
            "(1024, 1)\n",
            "Training Metrics: 500 [D loss: 1.108656, acc.: 99.56%, op_acc: 59.67%] [G loss: 6.243837]\n",
            "Validating on test set\n",
            "Validation Metrics: 500 [D loss: 0.922456, acc.: 100.00%, op_acc: 70.80%] [G loss: 6.178636]\n",
            "(1024, 1)\n",
            "Training Metrics: 501 [D loss: 0.971954, acc.: 99.32%, op_acc: 67.92%] [G loss: 5.741254]\n",
            "Validating on test set\n",
            "Validation Metrics: 501 [D loss: 0.765468, acc.: 100.00%, op_acc: 77.15%] [G loss: 5.620326]\n",
            "(1024, 1)\n",
            "Training Metrics: 502 [D loss: 0.928352, acc.: 99.61%, op_acc: 70.51%] [G loss: 5.945152]\n",
            "Validating on test set\n",
            "Validation Metrics: 502 [D loss: 0.733525, acc.: 100.00%, op_acc: 73.24%] [G loss: 5.957299]\n",
            "(1024, 1)\n",
            "Training Metrics: 503 [D loss: 0.961137, acc.: 99.37%, op_acc: 66.36%] [G loss: 5.744943]\n",
            "Validating on test set\n",
            "Validation Metrics: 503 [D loss: 0.657746, acc.: 100.00%, op_acc: 86.62%] [G loss: 5.702848]\n",
            "(1024, 1)\n",
            "Training Metrics: 504 [D loss: 0.892054, acc.: 99.66%, op_acc: 74.37%] [G loss: 6.055183]\n",
            "Validating on test set\n",
            "Validation Metrics: 504 [D loss: 0.623788, acc.: 100.00%, op_acc: 86.04%] [G loss: 6.018225]\n",
            "(1024, 1)\n",
            "Training Metrics: 505 [D loss: 0.831497, acc.: 99.32%, op_acc: 73.97%] [G loss: 5.659963]\n",
            "Validating on test set\n",
            "Validation Metrics: 505 [D loss: 0.591834, acc.: 100.00%, op_acc: 86.33%] [G loss: 5.652884]\n",
            "(1024, 1)\n",
            "Training Metrics: 506 [D loss: 0.828070, acc.: 99.41%, op_acc: 77.25%] [G loss: 5.605669]\n",
            "Validating on test set\n",
            "Validation Metrics: 506 [D loss: 0.587496, acc.: 100.00%, op_acc: 88.87%] [G loss: 5.606586]\n",
            "(1024, 1)\n",
            "Training Metrics: 507 [D loss: 0.815535, acc.: 99.76%, op_acc: 75.63%] [G loss: 5.905240]\n",
            "Validating on test set\n",
            "Validation Metrics: 507 [D loss: 0.570063, acc.: 100.00%, op_acc: 93.26%] [G loss: 5.860408]\n",
            "(1024, 1)\n",
            "Training Metrics: 508 [D loss: 0.813865, acc.: 99.76%, op_acc: 76.95%] [G loss: 5.717403]\n",
            "Validating on test set\n",
            "Validation Metrics: 508 [D loss: 0.556881, acc.: 100.00%, op_acc: 88.77%] [G loss: 5.741420]\n",
            "(1024, 1)\n",
            "Training Metrics: 509 [D loss: 0.821869, acc.: 99.66%, op_acc: 74.56%] [G loss: 5.853652]\n",
            "Validating on test set\n",
            "Validation Metrics: 509 [D loss: 0.589668, acc.: 100.00%, op_acc: 89.36%] [G loss: 5.857169]\n",
            "(1024, 1)\n",
            "Training Metrics: 510 [D loss: 0.827321, acc.: 99.61%, op_acc: 75.88%] [G loss: 5.847454]\n",
            "Validating on test set\n",
            "Validation Metrics: 510 [D loss: 0.728306, acc.: 100.00%, op_acc: 73.83%] [G loss: 5.944486]\n",
            "(1024, 1)\n",
            "Training Metrics: 511 [D loss: 0.873950, acc.: 99.71%, op_acc: 67.48%] [G loss: 5.835514]\n",
            "Validating on test set\n",
            "Validation Metrics: 511 [D loss: 0.662088, acc.: 100.00%, op_acc: 81.15%] [G loss: 5.727507]\n",
            "(1024, 1)\n",
            "Training Metrics: 512 [D loss: 0.882785, acc.: 99.56%, op_acc: 71.88%] [G loss: 6.028033]\n",
            "Validating on test set\n",
            "Validation Metrics: 512 [D loss: 0.704913, acc.: 100.00%, op_acc: 74.61%] [G loss: 5.802591]\n",
            "(1024, 1)\n",
            "Training Metrics: 513 [D loss: 0.902804, acc.: 99.56%, op_acc: 68.90%] [G loss: 5.852997]\n",
            "Validating on test set\n",
            "Validation Metrics: 513 [D loss: 0.677127, acc.: 100.00%, op_acc: 78.52%] [G loss: 6.212849]\n",
            "(1024, 1)\n",
            "Training Metrics: 514 [D loss: 0.828575, acc.: 99.61%, op_acc: 73.19%] [G loss: 6.460088]\n",
            "Validating on test set\n",
            "Validation Metrics: 514 [D loss: 1.674878, acc.: 100.00%, op_acc: 39.75%] [G loss: 6.872805]\n",
            "(1024, 1)\n",
            "Training Metrics: 515 [D loss: 1.363495, acc.: 99.51%, op_acc: 52.44%] [G loss: 7.709435]\n",
            "Validating on test set\n",
            "Validation Metrics: 515 [D loss: 0.899472, acc.: 100.00%, op_acc: 67.58%] [G loss: 7.356792]\n",
            "(1024, 1)\n",
            "Training Metrics: 516 [D loss: 1.036833, acc.: 99.22%, op_acc: 61.57%] [G loss: 5.719223]\n",
            "Validating on test set\n",
            "Validation Metrics: 516 [D loss: 0.745531, acc.: 100.00%, op_acc: 76.66%] [G loss: 5.596462]\n",
            "(1024, 1)\n",
            "Training Metrics: 517 [D loss: 0.954828, acc.: 99.51%, op_acc: 68.75%] [G loss: 5.989842]\n",
            "Validating on test set\n",
            "Validation Metrics: 517 [D loss: 0.638186, acc.: 100.00%, op_acc: 83.30%] [G loss: 5.794863]\n",
            "(1024, 1)\n",
            "Training Metrics: 518 [D loss: 0.823146, acc.: 99.51%, op_acc: 75.78%] [G loss: 5.612198]\n",
            "Validating on test set\n",
            "Validation Metrics: 518 [D loss: 0.630328, acc.: 100.00%, op_acc: 84.67%] [G loss: 5.518307]\n",
            "(1024, 1)\n",
            "Training Metrics: 519 [D loss: 0.820099, acc.: 99.56%, op_acc: 75.39%] [G loss: 5.655181]\n",
            "Validating on test set\n",
            "Validation Metrics: 519 [D loss: 0.585786, acc.: 100.00%, op_acc: 91.80%] [G loss: 5.513638]\n",
            "(1024, 1)\n",
            "Training Metrics: 520 [D loss: 0.806914, acc.: 99.76%, op_acc: 77.05%] [G loss: 5.650475]\n",
            "Validating on test set\n",
            "Validation Metrics: 520 [D loss: 0.706708, acc.: 100.00%, op_acc: 79.20%] [G loss: 5.738935]\n",
            "(1024, 1)\n",
            "Training Metrics: 521 [D loss: 0.861913, acc.: 99.66%, op_acc: 73.49%] [G loss: 5.377146]\n",
            "Validating on test set\n",
            "Validation Metrics: 521 [D loss: 0.907048, acc.: 100.00%, op_acc: 68.65%] [G loss: 5.762762]\n",
            "(1024, 1)\n",
            "Training Metrics: 522 [D loss: 1.013222, acc.: 99.71%, op_acc: 65.04%] [G loss: 5.981259]\n",
            "Validating on test set\n",
            "Validation Metrics: 522 [D loss: 0.685908, acc.: 100.00%, op_acc: 79.88%] [G loss: 5.642874]\n",
            "(1024, 1)\n",
            "Training Metrics: 523 [D loss: 0.898775, acc.: 99.56%, op_acc: 70.21%] [G loss: 5.908265]\n",
            "Validating on test set\n",
            "Validation Metrics: 523 [D loss: 0.700226, acc.: 100.00%, op_acc: 85.55%] [G loss: 5.851990]\n",
            "(1024, 1)\n",
            "Training Metrics: 524 [D loss: 0.864383, acc.: 99.76%, op_acc: 75.73%] [G loss: 5.571119]\n",
            "Validating on test set\n",
            "Validation Metrics: 524 [D loss: 0.758807, acc.: 100.00%, op_acc: 69.63%] [G loss: 5.819291]\n",
            "(1024, 1)\n",
            "Training Metrics: 525 [D loss: 0.955223, acc.: 99.61%, op_acc: 64.99%] [G loss: 5.810320]\n",
            "Validating on test set\n",
            "Validation Metrics: 525 [D loss: 0.567797, acc.: 100.00%, op_acc: 78.42%] [G loss: 5.624123]\n",
            "(1024, 1)\n",
            "Training Metrics: 526 [D loss: 0.817046, acc.: 99.61%, op_acc: 73.24%] [G loss: 5.626254]\n",
            "Validating on test set\n",
            "Validation Metrics: 526 [D loss: 0.455005, acc.: 100.00%, op_acc: 94.43%] [G loss: 5.490749]\n",
            "(1024, 1)\n",
            "Training Metrics: 527 [D loss: 0.774775, acc.: 99.66%, op_acc: 79.49%] [G loss: 6.005324]\n",
            "Validating on test set\n",
            "Validation Metrics: 527 [D loss: 0.722789, acc.: 100.00%, op_acc: 79.69%] [G loss: 6.151659]\n",
            "(1024, 1)\n",
            "Training Metrics: 528 [D loss: 0.880417, acc.: 99.76%, op_acc: 71.88%] [G loss: 6.224952]\n",
            "Validating on test set\n",
            "Validation Metrics: 528 [D loss: 0.430099, acc.: 100.00%, op_acc: 90.33%] [G loss: 6.191278]\n",
            "(1024, 1)\n",
            "Training Metrics: 529 [D loss: 0.728173, acc.: 99.71%, op_acc: 77.59%] [G loss: 5.836769]\n",
            "Validating on test set\n",
            "Validation Metrics: 529 [D loss: 0.428685, acc.: 100.00%, op_acc: 92.97%] [G loss: 5.810041]\n",
            "(1024, 1)\n",
            "Training Metrics: 530 [D loss: 0.724006, acc.: 99.80%, op_acc: 78.12%] [G loss: 6.057195]\n",
            "Validating on test set\n",
            "Validation Metrics: 530 [D loss: 0.467609, acc.: 100.00%, op_acc: 95.31%] [G loss: 6.024860]\n",
            "(1024, 1)\n",
            "Training Metrics: 531 [D loss: 0.802350, acc.: 99.46%, op_acc: 77.34%] [G loss: 5.859296]\n",
            "Validating on test set\n",
            "Validation Metrics: 531 [D loss: 0.411949, acc.: 100.00%, op_acc: 95.41%] [G loss: 5.864360]\n",
            "(1024, 1)\n",
            "Training Metrics: 532 [D loss: 0.723502, acc.: 99.76%, op_acc: 78.03%] [G loss: 6.370557]\n",
            "Validating on test set\n",
            "Validation Metrics: 532 [D loss: 0.477837, acc.: 100.00%, op_acc: 86.91%] [G loss: 6.426085]\n",
            "(1024, 1)\n",
            "Training Metrics: 533 [D loss: 0.736682, acc.: 99.71%, op_acc: 75.20%] [G loss: 5.881470]\n",
            "Validating on test set\n",
            "Validation Metrics: 533 [D loss: 0.370998, acc.: 100.00%, op_acc: 97.46%] [G loss: 5.809850]\n",
            "(1024, 1)\n",
            "Training Metrics: 534 [D loss: 0.726653, acc.: 99.76%, op_acc: 79.74%] [G loss: 6.375205]\n",
            "Validating on test set\n",
            "Validation Metrics: 534 [D loss: 0.377232, acc.: 100.00%, op_acc: 97.85%] [G loss: 6.391377]\n",
            "(1024, 1)\n",
            "Training Metrics: 535 [D loss: 0.763774, acc.: 99.71%, op_acc: 77.83%] [G loss: 5.946591]\n",
            "Validating on test set\n",
            "Validation Metrics: 535 [D loss: 0.418536, acc.: 100.00%, op_acc: 92.68%] [G loss: 5.998913]\n",
            "(1024, 1)\n",
            "Training Metrics: 536 [D loss: 0.762633, acc.: 99.66%, op_acc: 77.98%] [G loss: 6.114755]\n",
            "Validating on test set\n",
            "Validation Metrics: 536 [D loss: 0.506173, acc.: 100.00%, op_acc: 83.89%] [G loss: 6.144170]\n",
            "(1024, 1)\n",
            "Training Metrics: 537 [D loss: 0.736034, acc.: 99.80%, op_acc: 74.17%] [G loss: 6.055592]\n",
            "Validating on test set\n",
            "Validation Metrics: 537 [D loss: 0.396233, acc.: 100.00%, op_acc: 91.31%] [G loss: 6.043113]\n",
            "(1024, 1)\n",
            "Training Metrics: 538 [D loss: 0.713945, acc.: 99.80%, op_acc: 77.69%] [G loss: 5.961699]\n",
            "Validating on test set\n",
            "Validation Metrics: 538 [D loss: 0.386148, acc.: 100.00%, op_acc: 93.46%] [G loss: 5.905496]\n",
            "(1024, 1)\n",
            "Training Metrics: 539 [D loss: 0.701477, acc.: 99.85%, op_acc: 79.74%] [G loss: 5.980189]\n",
            "Validating on test set\n",
            "Validation Metrics: 539 [D loss: 0.328372, acc.: 100.00%, op_acc: 97.66%] [G loss: 5.970173]\n",
            "(1024, 1)\n",
            "Training Metrics: 540 [D loss: 0.661429, acc.: 99.80%, op_acc: 80.86%] [G loss: 5.949946]\n",
            "Validating on test set\n",
            "Validation Metrics: 540 [D loss: 0.339663, acc.: 100.00%, op_acc: 95.02%] [G loss: 5.980083]\n",
            "(1024, 1)\n",
            "Training Metrics: 541 [D loss: 0.693263, acc.: 99.90%, op_acc: 79.93%] [G loss: 6.579371]\n",
            "Validating on test set\n",
            "Validation Metrics: 541 [D loss: 0.372390, acc.: 100.00%, op_acc: 92.68%] [G loss: 6.602534]\n",
            "(1024, 1)\n",
            "Training Metrics: 542 [D loss: 0.723537, acc.: 99.76%, op_acc: 77.49%] [G loss: 5.620677]\n",
            "Validating on test set\n",
            "Validation Metrics: 542 [D loss: 0.325628, acc.: 100.00%, op_acc: 95.70%] [G loss: 5.612687]\n",
            "(1024, 1)\n",
            "Training Metrics: 543 [D loss: 0.704329, acc.: 99.90%, op_acc: 79.05%] [G loss: 6.477709]\n",
            "Validating on test set\n",
            "Validation Metrics: 543 [D loss: 0.338514, acc.: 100.00%, op_acc: 95.90%] [G loss: 6.468626]\n",
            "(1024, 1)\n",
            "Training Metrics: 544 [D loss: 0.674835, acc.: 99.85%, op_acc: 79.64%] [G loss: 6.070756]\n",
            "Validating on test set\n",
            "Validation Metrics: 544 [D loss: 0.321947, acc.: 100.00%, op_acc: 94.63%] [G loss: 6.120001]\n",
            "(1024, 1)\n",
            "Training Metrics: 545 [D loss: 0.658699, acc.: 99.51%, op_acc: 80.57%] [G loss: 6.148184]\n",
            "Validating on test set\n",
            "Validation Metrics: 545 [D loss: 0.302424, acc.: 100.00%, op_acc: 96.68%] [G loss: 6.125401]\n",
            "(1024, 1)\n",
            "Training Metrics: 546 [D loss: 0.657576, acc.: 99.61%, op_acc: 79.49%] [G loss: 6.161576]\n",
            "Validating on test set\n",
            "Validation Metrics: 546 [D loss: 0.281484, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.151577]\n",
            "(1024, 1)\n",
            "Training Metrics: 547 [D loss: 0.652011, acc.: 99.76%, op_acc: 81.74%] [G loss: 6.057048]\n",
            "Validating on test set\n",
            "Validation Metrics: 547 [D loss: 0.268429, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.058540]\n",
            "(1024, 1)\n",
            "Training Metrics: 548 [D loss: 0.667709, acc.: 99.90%, op_acc: 80.71%] [G loss: 6.340705]\n",
            "Validating on test set\n",
            "Validation Metrics: 548 [D loss: 0.285665, acc.: 100.00%, op_acc: 97.36%] [G loss: 6.371391]\n",
            "(1024, 1)\n",
            "Training Metrics: 549 [D loss: 0.638261, acc.: 99.90%, op_acc: 81.45%] [G loss: 6.257113]\n",
            "Validating on test set\n",
            "Validation Metrics: 549 [D loss: 0.333223, acc.: 100.00%, op_acc: 93.16%] [G loss: 6.354823]\n",
            "(1024, 1)\n",
            "Training Metrics: 550 [D loss: 0.663031, acc.: 99.76%, op_acc: 78.52%] [G loss: 6.119647]\n",
            "Validating on test set\n",
            "Validation Metrics: 550 [D loss: 0.380536, acc.: 100.00%, op_acc: 87.89%] [G loss: 6.155763]\n",
            "(1024, 1)\n",
            "Training Metrics: 551 [D loss: 0.664526, acc.: 99.80%, op_acc: 77.25%] [G loss: 6.396597]\n",
            "Validating on test set\n",
            "Validation Metrics: 551 [D loss: 0.286470, acc.: 100.00%, op_acc: 97.95%] [G loss: 6.381321]\n",
            "(1024, 1)\n",
            "Training Metrics: 552 [D loss: 0.657684, acc.: 99.80%, op_acc: 80.27%] [G loss: 6.215220]\n",
            "Validating on test set\n",
            "Validation Metrics: 552 [D loss: 0.258366, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.177683]\n",
            "(1024, 1)\n",
            "Training Metrics: 553 [D loss: 0.602826, acc.: 99.85%, op_acc: 83.69%] [G loss: 6.506332]\n",
            "Validating on test set\n",
            "Validation Metrics: 553 [D loss: 0.248852, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.499267]\n",
            "(1024, 1)\n",
            "Training Metrics: 554 [D loss: 0.629406, acc.: 99.85%, op_acc: 82.32%] [G loss: 6.420416]\n",
            "Validating on test set\n",
            "Validation Metrics: 554 [D loss: 0.250237, acc.: 100.00%, op_acc: 98.14%] [G loss: 6.419377]\n",
            "(1024, 1)\n",
            "Training Metrics: 555 [D loss: 0.665576, acc.: 99.85%, op_acc: 80.86%] [G loss: 6.456931]\n",
            "Validating on test set\n",
            "Validation Metrics: 555 [D loss: 0.228168, acc.: 100.00%, op_acc: 98.73%] [G loss: 6.468256]\n",
            "(1024, 1)\n",
            "Training Metrics: 556 [D loss: 0.645446, acc.: 99.80%, op_acc: 80.81%] [G loss: 6.513937]\n",
            "Validating on test set\n",
            "Validation Metrics: 556 [D loss: 0.281461, acc.: 100.00%, op_acc: 95.41%] [G loss: 6.573931]\n",
            "(1024, 1)\n",
            "Training Metrics: 557 [D loss: 0.612986, acc.: 99.80%, op_acc: 81.15%] [G loss: 6.685320]\n",
            "Validating on test set\n",
            "Validation Metrics: 557 [D loss: 0.352518, acc.: 100.00%, op_acc: 88.18%] [G loss: 6.806662]\n",
            "(1024, 1)\n",
            "Training Metrics: 558 [D loss: 0.736184, acc.: 100.00%, op_acc: 75.68%] [G loss: 6.443030]\n",
            "Validating on test set\n",
            "Validation Metrics: 558 [D loss: 0.378179, acc.: 100.00%, op_acc: 88.48%] [G loss: 6.424896]\n",
            "(1024, 1)\n",
            "Training Metrics: 559 [D loss: 0.743908, acc.: 99.90%, op_acc: 72.80%] [G loss: 7.030331]\n",
            "Validating on test set\n",
            "Validation Metrics: 559 [D loss: 0.292432, acc.: 100.00%, op_acc: 96.58%] [G loss: 6.967798]\n",
            "(1024, 1)\n",
            "Training Metrics: 560 [D loss: 0.733282, acc.: 99.80%, op_acc: 79.54%] [G loss: 6.051451]\n",
            "Validating on test set\n",
            "Validation Metrics: 560 [D loss: 0.244615, acc.: 100.00%, op_acc: 98.24%] [G loss: 5.912038]\n",
            "(1024, 1)\n",
            "Training Metrics: 561 [D loss: 0.654560, acc.: 99.85%, op_acc: 79.59%] [G loss: 7.391298]\n",
            "Validating on test set\n",
            "Validation Metrics: 561 [D loss: 0.671359, acc.: 100.00%, op_acc: 81.84%] [G loss: 7.131583]\n",
            "(1024, 1)\n",
            "Training Metrics: 562 [D loss: 0.976342, acc.: 99.90%, op_acc: 68.46%] [G loss: 8.315047]\n",
            "Validating on test set\n",
            "Validation Metrics: 562 [D loss: 0.826709, acc.: 100.00%, op_acc: 70.21%] [G loss: 8.438373]\n",
            "(1024, 1)\n",
            "Training Metrics: 563 [D loss: 1.047104, acc.: 99.80%, op_acc: 63.67%] [G loss: 8.254221]\n",
            "Validating on test set\n",
            "Validation Metrics: 563 [D loss: 0.626668, acc.: 100.00%, op_acc: 82.81%] [G loss: 8.276615]\n",
            "(1024, 1)\n",
            "Training Metrics: 564 [D loss: 0.885097, acc.: 99.76%, op_acc: 69.63%] [G loss: 6.588917]\n",
            "Validating on test set\n",
            "Validation Metrics: 564 [D loss: 0.402801, acc.: 100.00%, op_acc: 92.09%] [G loss: 6.307864]\n",
            "(1024, 1)\n",
            "Training Metrics: 565 [D loss: 0.738249, acc.: 99.90%, op_acc: 78.52%] [G loss: 6.798142]\n",
            "Validating on test set\n",
            "Validation Metrics: 565 [D loss: 0.430449, acc.: 100.00%, op_acc: 88.38%] [G loss: 6.717356]\n",
            "(1024, 1)\n",
            "Training Metrics: 566 [D loss: 0.706865, acc.: 99.95%, op_acc: 77.44%] [G loss: 6.245615]\n",
            "Validating on test set\n",
            "Validation Metrics: 566 [D loss: 0.322551, acc.: 100.00%, op_acc: 92.48%] [G loss: 6.105968]\n",
            "(1024, 1)\n",
            "Training Metrics: 567 [D loss: 0.712013, acc.: 99.90%, op_acc: 77.59%] [G loss: 6.730193]\n",
            "Validating on test set\n",
            "Validation Metrics: 567 [D loss: 0.324893, acc.: 100.00%, op_acc: 94.53%] [G loss: 6.586278]\n",
            "(1024, 1)\n",
            "Training Metrics: 568 [D loss: 0.742199, acc.: 99.61%, op_acc: 75.10%] [G loss: 6.455899]\n",
            "Validating on test set\n",
            "Validation Metrics: 568 [D loss: 0.399243, acc.: 100.00%, op_acc: 86.33%] [G loss: 6.447666]\n",
            "(1024, 1)\n",
            "Training Metrics: 569 [D loss: 0.737867, acc.: 99.61%, op_acc: 74.02%] [G loss: 5.946410]\n",
            "Validating on test set\n",
            "Validation Metrics: 569 [D loss: 0.338865, acc.: 100.00%, op_acc: 93.26%] [G loss: 5.907397]\n",
            "(1024, 1)\n",
            "Training Metrics: 570 [D loss: 0.715968, acc.: 99.85%, op_acc: 77.15%] [G loss: 5.504638]\n",
            "Validating on test set\n",
            "Validation Metrics: 570 [D loss: 0.293747, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.506511]\n",
            "(1024, 1)\n",
            "Training Metrics: 571 [D loss: 0.697449, acc.: 99.66%, op_acc: 78.42%] [G loss: 5.924765]\n",
            "Validating on test set\n",
            "Validation Metrics: 571 [D loss: 0.307414, acc.: 100.00%, op_acc: 95.90%] [G loss: 5.926405]\n",
            "(1024, 1)\n",
            "Training Metrics: 572 [D loss: 0.671571, acc.: 99.90%, op_acc: 78.81%] [G loss: 5.768299]\n",
            "Validating on test set\n",
            "Validation Metrics: 572 [D loss: 0.286044, acc.: 100.00%, op_acc: 96.97%] [G loss: 5.779497]\n",
            "(1024, 1)\n",
            "Training Metrics: 573 [D loss: 0.652703, acc.: 99.71%, op_acc: 80.08%] [G loss: 5.972263]\n",
            "Validating on test set\n",
            "Validation Metrics: 573 [D loss: 0.265352, acc.: 100.00%, op_acc: 97.66%] [G loss: 5.931281]\n",
            "(1024, 1)\n",
            "Training Metrics: 574 [D loss: 0.662678, acc.: 99.95%, op_acc: 80.18%] [G loss: 6.343934]\n",
            "Validating on test set\n",
            "Validation Metrics: 574 [D loss: 0.226335, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.336814]\n",
            "(1024, 1)\n",
            "Training Metrics: 575 [D loss: 0.653849, acc.: 99.76%, op_acc: 79.69%] [G loss: 5.492806]\n",
            "Validating on test set\n",
            "Validation Metrics: 575 [D loss: 0.224253, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.492173]\n",
            "(1024, 1)\n",
            "Training Metrics: 576 [D loss: 0.686161, acc.: 99.76%, op_acc: 80.22%] [G loss: 6.404897]\n",
            "Validating on test set\n",
            "Validation Metrics: 576 [D loss: 0.239448, acc.: 100.00%, op_acc: 97.36%] [G loss: 6.434498]\n",
            "(1024, 1)\n",
            "Training Metrics: 577 [D loss: 0.675256, acc.: 99.80%, op_acc: 79.49%] [G loss: 5.460136]\n",
            "Validating on test set\n",
            "Validation Metrics: 577 [D loss: 0.239333, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.434608]\n",
            "(1024, 1)\n",
            "Training Metrics: 578 [D loss: 0.680632, acc.: 99.90%, op_acc: 78.96%] [G loss: 5.924280]\n",
            "Validating on test set\n",
            "Validation Metrics: 578 [D loss: 0.215285, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.914697]\n",
            "(1024, 1)\n",
            "Training Metrics: 579 [D loss: 0.626204, acc.: 99.95%, op_acc: 80.08%] [G loss: 6.574676]\n",
            "Validating on test set\n",
            "Validation Metrics: 579 [D loss: 0.247900, acc.: 100.00%, op_acc: 97.66%] [G loss: 6.586284]\n",
            "(1024, 1)\n",
            "Training Metrics: 580 [D loss: 0.693785, acc.: 99.90%, op_acc: 81.20%] [G loss: 5.677716]\n",
            "Validating on test set\n",
            "Validation Metrics: 580 [D loss: 0.299592, acc.: 100.00%, op_acc: 93.65%] [G loss: 5.700653]\n",
            "(1024, 1)\n",
            "Training Metrics: 581 [D loss: 0.636184, acc.: 99.80%, op_acc: 79.59%] [G loss: 6.150317]\n",
            "Validating on test set\n",
            "Validation Metrics: 581 [D loss: 0.322275, acc.: 100.00%, op_acc: 92.68%] [G loss: 6.279115]\n",
            "(1024, 1)\n",
            "Training Metrics: 582 [D loss: 0.656976, acc.: 99.56%, op_acc: 78.81%] [G loss: 5.857608]\n",
            "Validating on test set\n",
            "Validation Metrics: 582 [D loss: 0.326735, acc.: 100.00%, op_acc: 90.04%] [G loss: 5.802636]\n",
            "(1024, 1)\n",
            "Training Metrics: 583 [D loss: 0.692428, acc.: 99.80%, op_acc: 75.78%] [G loss: 5.684820]\n",
            "Validating on test set\n",
            "Validation Metrics: 583 [D loss: 0.233388, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.595841]\n",
            "(1024, 1)\n",
            "Training Metrics: 584 [D loss: 0.648443, acc.: 99.95%, op_acc: 81.40%] [G loss: 6.055039]\n",
            "Validating on test set\n",
            "Validation Metrics: 584 [D loss: 0.204891, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.056783]\n",
            "(1024, 1)\n",
            "Training Metrics: 585 [D loss: 0.601594, acc.: 99.80%, op_acc: 80.47%] [G loss: 6.424162]\n",
            "Validating on test set\n",
            "Validation Metrics: 585 [D loss: 0.182366, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.426037]\n",
            "(1024, 1)\n",
            "Training Metrics: 586 [D loss: 0.611619, acc.: 99.95%, op_acc: 82.37%] [G loss: 6.640784]\n",
            "Validating on test set\n",
            "Validation Metrics: 586 [D loss: 0.195446, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.637561]\n",
            "(1024, 1)\n",
            "Training Metrics: 587 [D loss: 0.623612, acc.: 99.76%, op_acc: 80.42%] [G loss: 6.118989]\n",
            "Validating on test set\n",
            "Validation Metrics: 587 [D loss: 0.182911, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.125604]\n",
            "(1024, 1)\n",
            "Training Metrics: 588 [D loss: 0.667140, acc.: 99.90%, op_acc: 81.20%] [G loss: 6.207378]\n",
            "Validating on test set\n",
            "Validation Metrics: 588 [D loss: 0.223224, acc.: 100.00%, op_acc: 97.07%] [G loss: 6.239861]\n",
            "(1024, 1)\n",
            "Training Metrics: 589 [D loss: 0.603648, acc.: 99.90%, op_acc: 81.30%] [G loss: 6.332119]\n",
            "Validating on test set\n",
            "Validation Metrics: 589 [D loss: 0.222273, acc.: 100.00%, op_acc: 96.00%] [G loss: 6.360823]\n",
            "(1024, 1)\n",
            "Training Metrics: 590 [D loss: 0.639055, acc.: 99.80%, op_acc: 79.93%] [G loss: 6.428699]\n",
            "Validating on test set\n",
            "Validation Metrics: 590 [D loss: 0.194622, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.389610]\n",
            "(1024, 1)\n",
            "Training Metrics: 591 [D loss: 0.606162, acc.: 99.90%, op_acc: 81.30%] [G loss: 5.944102]\n",
            "Validating on test set\n",
            "Validation Metrics: 591 [D loss: 0.208080, acc.: 100.00%, op_acc: 98.34%] [G loss: 5.947917]\n",
            "(1024, 1)\n",
            "Training Metrics: 592 [D loss: 0.632637, acc.: 99.90%, op_acc: 81.59%] [G loss: 6.602695]\n",
            "Validating on test set\n",
            "Validation Metrics: 592 [D loss: 0.178147, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.610629]\n",
            "(1024, 1)\n",
            "Training Metrics: 593 [D loss: 0.659736, acc.: 99.61%, op_acc: 78.96%] [G loss: 5.709688]\n",
            "Validating on test set\n",
            "Validation Metrics: 593 [D loss: 0.189480, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.703604]\n",
            "(1024, 1)\n",
            "Training Metrics: 594 [D loss: 0.646890, acc.: 99.95%, op_acc: 80.86%] [G loss: 6.880491]\n",
            "Validating on test set\n",
            "Validation Metrics: 594 [D loss: 0.169873, acc.: 100.00%, op_acc: 98.73%] [G loss: 6.861455]\n",
            "(1024, 1)\n",
            "Training Metrics: 595 [D loss: 0.645729, acc.: 99.80%, op_acc: 80.03%] [G loss: 5.778042]\n",
            "Validating on test set\n",
            "Validation Metrics: 595 [D loss: 0.177298, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.774374]\n",
            "(1024, 1)\n",
            "Training Metrics: 596 [D loss: 0.644051, acc.: 99.95%, op_acc: 80.42%] [G loss: 7.264528]\n",
            "Validating on test set\n",
            "Validation Metrics: 596 [D loss: 0.198176, acc.: 100.00%, op_acc: 97.75%] [G loss: 7.270055]\n",
            "(1024, 1)\n",
            "Training Metrics: 597 [D loss: 0.728000, acc.: 99.85%, op_acc: 76.17%] [G loss: 6.212086]\n",
            "Validating on test set\n",
            "Validation Metrics: 597 [D loss: 0.255511, acc.: 100.00%, op_acc: 94.82%] [G loss: 6.249524]\n",
            "(1024, 1)\n",
            "Training Metrics: 598 [D loss: 0.756621, acc.: 99.90%, op_acc: 78.27%] [G loss: 7.136279]\n",
            "Validating on test set\n",
            "Validation Metrics: 598 [D loss: 0.178000, acc.: 100.00%, op_acc: 98.83%] [G loss: 7.121012]\n",
            "(1024, 1)\n",
            "Training Metrics: 599 [D loss: 0.636687, acc.: 99.80%, op_acc: 80.66%] [G loss: 6.051874]\n",
            "Validating on test set\n",
            "Validation Metrics: 599 [D loss: 0.168700, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.039950]\n",
            "(1024, 1)\n",
            "Training Metrics: 600 [D loss: 0.556562, acc.: 99.90%, op_acc: 81.93%] [G loss: 6.155503]\n",
            "Validating on test set\n",
            "Validation Metrics: 600 [D loss: 0.149621, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.130367]\n",
            "(1024, 1)\n",
            "Training Metrics: 601 [D loss: 0.599568, acc.: 99.85%, op_acc: 80.76%] [G loss: 6.688235]\n",
            "Validating on test set\n",
            "Validation Metrics: 601 [D loss: 0.194360, acc.: 100.00%, op_acc: 96.78%] [G loss: 6.693884]\n",
            "(1024, 1)\n",
            "Training Metrics: 602 [D loss: 0.587543, acc.: 99.95%, op_acc: 80.18%] [G loss: 6.863547]\n",
            "Validating on test set\n",
            "Validation Metrics: 602 [D loss: 0.191051, acc.: 100.00%, op_acc: 98.05%] [G loss: 6.871507]\n",
            "(1024, 1)\n",
            "Training Metrics: 603 [D loss: 0.618655, acc.: 99.95%, op_acc: 80.18%] [G loss: 6.350667]\n",
            "Validating on test set\n",
            "Validation Metrics: 603 [D loss: 0.234813, acc.: 100.00%, op_acc: 95.80%] [G loss: 6.378820]\n",
            "(1024, 1)\n",
            "Training Metrics: 604 [D loss: 0.616854, acc.: 99.95%, op_acc: 80.03%] [G loss: 7.143568]\n",
            "Validating on test set\n",
            "Validation Metrics: 604 [D loss: 0.177932, acc.: 100.00%, op_acc: 98.54%] [G loss: 7.153193]\n",
            "(1024, 1)\n",
            "Training Metrics: 605 [D loss: 0.624630, acc.: 99.66%, op_acc: 80.27%] [G loss: 5.599488]\n",
            "Validating on test set\n",
            "Validation Metrics: 605 [D loss: 0.165259, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.566051]\n",
            "(1024, 1)\n",
            "Training Metrics: 606 [D loss: 0.613079, acc.: 99.85%, op_acc: 81.79%] [G loss: 6.542455]\n",
            "Validating on test set\n",
            "Validation Metrics: 606 [D loss: 0.184671, acc.: 100.00%, op_acc: 98.14%] [G loss: 6.535324]\n",
            "(1024, 1)\n",
            "Training Metrics: 607 [D loss: 0.649567, acc.: 99.76%, op_acc: 81.49%] [G loss: 6.471574]\n",
            "Validating on test set\n",
            "Validation Metrics: 607 [D loss: 0.158978, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.464889]\n",
            "(1024, 1)\n",
            "Training Metrics: 608 [D loss: 0.603810, acc.: 99.76%, op_acc: 81.59%] [G loss: 6.245916]\n",
            "Validating on test set\n",
            "Validation Metrics: 608 [D loss: 0.176059, acc.: 100.00%, op_acc: 97.85%] [G loss: 6.250817]\n",
            "(1024, 1)\n",
            "Training Metrics: 609 [D loss: 0.581550, acc.: 99.80%, op_acc: 81.64%] [G loss: 6.670054]\n",
            "Validating on test set\n",
            "Validation Metrics: 609 [D loss: 0.182265, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.656630]\n",
            "(1024, 1)\n",
            "Training Metrics: 610 [D loss: 0.586227, acc.: 99.80%, op_acc: 81.84%] [G loss: 6.494590]\n",
            "Validating on test set\n",
            "Validation Metrics: 610 [D loss: 0.157269, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.494965]\n",
            "(1024, 1)\n",
            "Training Metrics: 611 [D loss: 0.602612, acc.: 99.61%, op_acc: 80.76%] [G loss: 6.277539]\n",
            "Validating on test set\n",
            "Validation Metrics: 611 [D loss: 0.146601, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.282384]\n",
            "(1024, 1)\n",
            "Training Metrics: 612 [D loss: 0.550702, acc.: 100.00%, op_acc: 82.71%] [G loss: 6.488376]\n",
            "Validating on test set\n",
            "Validation Metrics: 612 [D loss: 0.155762, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.501707]\n",
            "(1024, 1)\n",
            "Training Metrics: 613 [D loss: 0.631887, acc.: 99.95%, op_acc: 80.86%] [G loss: 6.301560]\n",
            "Validating on test set\n",
            "Validation Metrics: 613 [D loss: 0.153170, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.317296]\n",
            "(1024, 1)\n",
            "Training Metrics: 614 [D loss: 0.604270, acc.: 99.85%, op_acc: 81.05%] [G loss: 6.218244]\n",
            "Validating on test set\n",
            "Validation Metrics: 614 [D loss: 0.185011, acc.: 100.00%, op_acc: 97.46%] [G loss: 6.222520]\n",
            "(1024, 1)\n",
            "Training Metrics: 615 [D loss: 0.602920, acc.: 99.90%, op_acc: 80.96%] [G loss: 6.770726]\n",
            "Validating on test set\n",
            "Validation Metrics: 615 [D loss: 0.157646, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.754076]\n",
            "(1024, 1)\n",
            "Training Metrics: 616 [D loss: 0.589342, acc.: 99.95%, op_acc: 81.93%] [G loss: 6.035944]\n",
            "Validating on test set\n",
            "Validation Metrics: 616 [D loss: 0.144377, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.052207]\n",
            "(1024, 1)\n",
            "Training Metrics: 617 [D loss: 0.607666, acc.: 99.85%, op_acc: 81.35%] [G loss: 6.857760]\n",
            "Validating on test set\n",
            "Validation Metrics: 617 [D loss: 0.160881, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.878980]\n",
            "(1024, 1)\n",
            "Training Metrics: 618 [D loss: 0.638781, acc.: 99.80%, op_acc: 79.93%] [G loss: 5.717757]\n",
            "Validating on test set\n",
            "Validation Metrics: 618 [D loss: 0.157927, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.706483]\n",
            "(1024, 1)\n",
            "Training Metrics: 619 [D loss: 0.593537, acc.: 99.95%, op_acc: 82.57%] [G loss: 6.903523]\n",
            "Validating on test set\n",
            "Validation Metrics: 619 [D loss: 0.159480, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.905581]\n",
            "(1024, 1)\n",
            "Training Metrics: 620 [D loss: 0.586185, acc.: 99.85%, op_acc: 81.84%] [G loss: 6.237027]\n",
            "Validating on test set\n",
            "Validation Metrics: 620 [D loss: 0.159232, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.220541]\n",
            "(1024, 1)\n",
            "Training Metrics: 621 [D loss: 0.616732, acc.: 99.85%, op_acc: 79.44%] [G loss: 6.974133]\n",
            "Validating on test set\n",
            "Validation Metrics: 621 [D loss: 0.138887, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.990323]\n",
            "(1024, 1)\n",
            "Training Metrics: 622 [D loss: 0.596903, acc.: 99.95%, op_acc: 82.03%] [G loss: 6.652804]\n",
            "Validating on test set\n",
            "Validation Metrics: 622 [D loss: 0.151367, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.655342]\n",
            "(1024, 1)\n",
            "Training Metrics: 623 [D loss: 0.599030, acc.: 99.80%, op_acc: 80.22%] [G loss: 6.809234]\n",
            "Validating on test set\n",
            "Validation Metrics: 623 [D loss: 0.133414, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.817993]\n",
            "(1024, 1)\n",
            "Training Metrics: 624 [D loss: 0.550056, acc.: 99.85%, op_acc: 83.64%] [G loss: 6.441208]\n",
            "Validating on test set\n",
            "Validation Metrics: 624 [D loss: 0.155417, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.439316]\n",
            "(1024, 1)\n",
            "Training Metrics: 625 [D loss: 0.539083, acc.: 99.95%, op_acc: 82.91%] [G loss: 6.642244]\n",
            "Validating on test set\n",
            "Validation Metrics: 625 [D loss: 0.141728, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.645503]\n",
            "(1024, 1)\n",
            "Training Metrics: 626 [D loss: 0.548631, acc.: 99.85%, op_acc: 81.79%] [G loss: 6.584546]\n",
            "Validating on test set\n",
            "Validation Metrics: 626 [D loss: 0.157062, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.600875]\n",
            "(1024, 1)\n",
            "Training Metrics: 627 [D loss: 0.585085, acc.: 99.95%, op_acc: 81.30%] [G loss: 6.471102]\n",
            "Validating on test set\n",
            "Validation Metrics: 627 [D loss: 0.144605, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.465871]\n",
            "(1024, 1)\n",
            "Training Metrics: 628 [D loss: 0.640225, acc.: 99.66%, op_acc: 81.10%] [G loss: 6.513997]\n",
            "Validating on test set\n",
            "Validation Metrics: 628 [D loss: 0.163961, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.498289]\n",
            "(1024, 1)\n",
            "Training Metrics: 629 [D loss: 0.650091, acc.: 99.66%, op_acc: 78.22%] [G loss: 6.295732]\n",
            "Validating on test set\n",
            "Validation Metrics: 629 [D loss: 0.168855, acc.: 100.00%, op_acc: 97.95%] [G loss: 6.329591]\n",
            "(1024, 1)\n",
            "Training Metrics: 630 [D loss: 0.607738, acc.: 99.95%, op_acc: 81.40%] [G loss: 6.483741]\n",
            "Validating on test set\n",
            "Validation Metrics: 630 [D loss: 0.297286, acc.: 100.00%, op_acc: 92.48%] [G loss: 6.601412]\n",
            "(1024, 1)\n",
            "Training Metrics: 631 [D loss: 0.618804, acc.: 99.90%, op_acc: 78.56%] [G loss: 6.736571]\n",
            "Validating on test set\n",
            "Validation Metrics: 631 [D loss: 0.633255, acc.: 100.00%, op_acc: 81.25%] [G loss: 7.114153]\n",
            "(1024, 1)\n",
            "Training Metrics: 632 [D loss: 0.795048, acc.: 99.90%, op_acc: 73.29%] [G loss: 6.654080]\n",
            "Validating on test set\n",
            "Validation Metrics: 632 [D loss: 1.114600, acc.: 100.00%, op_acc: 64.36%] [G loss: 7.149233]\n",
            "(1024, 1)\n",
            "Training Metrics: 633 [D loss: 1.058832, acc.: 99.80%, op_acc: 63.77%] [G loss: 8.182701]\n",
            "Validating on test set\n",
            "Validation Metrics: 633 [D loss: 1.362476, acc.: 100.00%, op_acc: 53.42%] [G loss: 8.780087]\n",
            "(1024, 1)\n",
            "Training Metrics: 634 [D loss: 1.200036, acc.: 99.71%, op_acc: 60.84%] [G loss: 6.817349]\n",
            "Validating on test set\n",
            "Validation Metrics: 634 [D loss: 0.551802, acc.: 100.00%, op_acc: 79.98%] [G loss: 6.212180]\n",
            "(1024, 1)\n",
            "Training Metrics: 635 [D loss: 0.799417, acc.: 99.85%, op_acc: 69.87%] [G loss: 7.349782]\n",
            "Validating on test set\n",
            "Validation Metrics: 635 [D loss: 0.527664, acc.: 100.00%, op_acc: 80.96%] [G loss: 7.438787]\n",
            "(1024, 1)\n",
            "Training Metrics: 636 [D loss: 0.784707, acc.: 99.95%, op_acc: 72.46%] [G loss: 6.496603]\n",
            "Validating on test set\n",
            "Validation Metrics: 636 [D loss: 0.506191, acc.: 100.00%, op_acc: 80.66%] [G loss: 6.445798]\n",
            "(1024, 1)\n",
            "Training Metrics: 637 [D loss: 0.768583, acc.: 99.90%, op_acc: 70.21%] [G loss: 7.036870]\n",
            "Validating on test set\n",
            "Validation Metrics: 637 [D loss: 0.404849, acc.: 100.00%, op_acc: 87.70%] [G loss: 6.954432]\n",
            "(1024, 1)\n",
            "Training Metrics: 638 [D loss: 0.668012, acc.: 99.85%, op_acc: 78.12%] [G loss: 6.252649]\n",
            "Validating on test set\n",
            "Validation Metrics: 638 [D loss: 0.319317, acc.: 100.00%, op_acc: 87.11%] [G loss: 6.159788]\n",
            "(1024, 1)\n",
            "Training Metrics: 639 [D loss: 0.646024, acc.: 99.80%, op_acc: 78.81%] [G loss: 6.165164]\n",
            "Validating on test set\n",
            "Validation Metrics: 639 [D loss: 0.315310, acc.: 100.00%, op_acc: 90.23%] [G loss: 6.175521]\n",
            "(1024, 1)\n",
            "Training Metrics: 640 [D loss: 0.640380, acc.: 99.85%, op_acc: 78.91%] [G loss: 6.552852]\n",
            "Validating on test set\n",
            "Validation Metrics: 640 [D loss: 0.289139, acc.: 100.00%, op_acc: 91.11%] [G loss: 6.493346]\n",
            "(1024, 1)\n",
            "Training Metrics: 641 [D loss: 0.652608, acc.: 99.90%, op_acc: 78.12%] [G loss: 6.276073]\n",
            "Validating on test set\n",
            "Validation Metrics: 641 [D loss: 0.281788, acc.: 100.00%, op_acc: 91.11%] [G loss: 6.278327]\n",
            "(1024, 1)\n",
            "Training Metrics: 642 [D loss: 0.618809, acc.: 99.95%, op_acc: 78.47%] [G loss: 6.846289]\n",
            "Validating on test set\n",
            "Validation Metrics: 642 [D loss: 0.246737, acc.: 100.00%, op_acc: 94.04%] [G loss: 6.831009]\n",
            "(1024, 1)\n",
            "Training Metrics: 643 [D loss: 0.643022, acc.: 99.85%, op_acc: 78.22%] [G loss: 6.660421]\n",
            "Validating on test set\n",
            "Validation Metrics: 643 [D loss: 0.246301, acc.: 100.00%, op_acc: 95.02%] [G loss: 6.662372]\n",
            "(1024, 1)\n",
            "Training Metrics: 644 [D loss: 0.608462, acc.: 99.80%, op_acc: 79.69%] [G loss: 6.877538]\n",
            "Validating on test set\n",
            "Validation Metrics: 644 [D loss: 0.250261, acc.: 100.00%, op_acc: 94.43%] [G loss: 6.844120]\n",
            "(1024, 1)\n",
            "Training Metrics: 645 [D loss: 0.621326, acc.: 99.85%, op_acc: 79.83%] [G loss: 6.488618]\n",
            "Validating on test set\n",
            "Validation Metrics: 645 [D loss: 0.266641, acc.: 100.00%, op_acc: 96.39%] [G loss: 6.491582]\n",
            "(1024, 1)\n",
            "Training Metrics: 646 [D loss: 0.671071, acc.: 99.80%, op_acc: 79.54%] [G loss: 7.031445]\n",
            "Validating on test set\n",
            "Validation Metrics: 646 [D loss: 0.224984, acc.: 100.00%, op_acc: 98.24%] [G loss: 7.074042]\n",
            "(1024, 1)\n",
            "Training Metrics: 647 [D loss: 0.624149, acc.: 99.80%, op_acc: 81.20%] [G loss: 6.329708]\n",
            "Validating on test set\n",
            "Validation Metrics: 647 [D loss: 0.308236, acc.: 100.00%, op_acc: 95.51%] [G loss: 6.364889]\n",
            "(1024, 1)\n",
            "Training Metrics: 648 [D loss: 0.680393, acc.: 99.90%, op_acc: 79.79%] [G loss: 6.962132]\n",
            "Validating on test set\n",
            "Validation Metrics: 648 [D loss: 0.283576, acc.: 100.00%, op_acc: 95.70%] [G loss: 7.098022]\n",
            "(1024, 1)\n",
            "Training Metrics: 649 [D loss: 0.612098, acc.: 99.95%, op_acc: 80.62%] [G loss: 6.930130]\n",
            "Validating on test set\n",
            "Validation Metrics: 649 [D loss: 0.517743, acc.: 100.00%, op_acc: 84.86%] [G loss: 7.048084]\n",
            "(1024, 1)\n",
            "Training Metrics: 650 [D loss: 0.708820, acc.: 99.90%, op_acc: 75.73%] [G loss: 7.316348]\n",
            "Validating on test set\n",
            "Validation Metrics: 650 [D loss: 0.296006, acc.: 100.00%, op_acc: 95.12%] [G loss: 7.252324]\n",
            "(1024, 1)\n",
            "Training Metrics: 651 [D loss: 0.674769, acc.: 99.90%, op_acc: 77.10%] [G loss: 7.363885]\n",
            "Validating on test set\n",
            "Validation Metrics: 651 [D loss: 0.195584, acc.: 100.00%, op_acc: 99.02%] [G loss: 7.227633]\n",
            "(1024, 1)\n",
            "Training Metrics: 652 [D loss: 0.627316, acc.: 99.85%, op_acc: 80.13%] [G loss: 6.524028]\n",
            "Validating on test set\n",
            "Validation Metrics: 652 [D loss: 0.163339, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.521442]\n",
            "(1024, 1)\n",
            "Training Metrics: 653 [D loss: 0.628287, acc.: 99.80%, op_acc: 80.42%] [G loss: 6.929592]\n",
            "Validating on test set\n",
            "Validation Metrics: 653 [D loss: 0.232831, acc.: 100.00%, op_acc: 96.19%] [G loss: 6.958110]\n",
            "(1024, 1)\n",
            "Training Metrics: 654 [D loss: 0.693890, acc.: 99.95%, op_acc: 78.61%] [G loss: 6.517832]\n",
            "Validating on test set\n",
            "Validation Metrics: 654 [D loss: 0.180331, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.498742]\n",
            "(1024, 1)\n",
            "Training Metrics: 655 [D loss: 0.605187, acc.: 99.90%, op_acc: 82.08%] [G loss: 6.258354]\n",
            "Validating on test set\n",
            "Validation Metrics: 655 [D loss: 0.176449, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.263155]\n",
            "(1024, 1)\n",
            "Training Metrics: 656 [D loss: 0.602018, acc.: 99.80%, op_acc: 82.08%] [G loss: 6.490038]\n",
            "Validating on test set\n",
            "Validation Metrics: 656 [D loss: 0.176820, acc.: 100.00%, op_acc: 98.73%] [G loss: 6.498140]\n",
            "(1024, 1)\n",
            "Training Metrics: 657 [D loss: 0.547210, acc.: 99.80%, op_acc: 82.52%] [G loss: 6.458201]\n",
            "Validating on test set\n",
            "Validation Metrics: 657 [D loss: 0.232008, acc.: 100.00%, op_acc: 95.21%] [G loss: 6.443032]\n",
            "(1024, 1)\n",
            "Training Metrics: 658 [D loss: 0.598004, acc.: 99.66%, op_acc: 81.59%] [G loss: 5.695403]\n",
            "Validating on test set\n",
            "Validation Metrics: 658 [D loss: 0.178239, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.685922]\n",
            "(1024, 1)\n",
            "Training Metrics: 659 [D loss: 0.551917, acc.: 99.90%, op_acc: 83.30%] [G loss: 6.671635]\n",
            "Validating on test set\n",
            "Validation Metrics: 659 [D loss: 0.170653, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.661744]\n",
            "(1024, 1)\n",
            "Training Metrics: 660 [D loss: 0.611389, acc.: 99.95%, op_acc: 80.42%] [G loss: 6.264441]\n",
            "Validating on test set\n",
            "Validation Metrics: 660 [D loss: 0.168317, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.274238]\n",
            "(1024, 1)\n",
            "Training Metrics: 661 [D loss: 0.593988, acc.: 99.90%, op_acc: 81.88%] [G loss: 6.896167]\n",
            "Validating on test set\n",
            "Validation Metrics: 661 [D loss: 0.184272, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.892283]\n",
            "(1024, 1)\n",
            "Training Metrics: 662 [D loss: 0.598702, acc.: 99.71%, op_acc: 81.15%] [G loss: 5.993678]\n",
            "Validating on test set\n",
            "Validation Metrics: 662 [D loss: 0.169461, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.989708]\n",
            "(1024, 1)\n",
            "Training Metrics: 663 [D loss: 0.558768, acc.: 99.95%, op_acc: 83.40%] [G loss: 6.584455]\n",
            "Validating on test set\n",
            "Validation Metrics: 663 [D loss: 0.174453, acc.: 100.00%, op_acc: 98.63%] [G loss: 6.571134]\n",
            "(1024, 1)\n",
            "Training Metrics: 664 [D loss: 0.577147, acc.: 99.95%, op_acc: 81.93%] [G loss: 6.462334]\n",
            "Validating on test set\n",
            "Validation Metrics: 664 [D loss: 0.172279, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.430532]\n",
            "(1024, 1)\n",
            "Training Metrics: 665 [D loss: 0.590255, acc.: 99.95%, op_acc: 82.42%] [G loss: 6.764665]\n",
            "Validating on test set\n",
            "Validation Metrics: 665 [D loss: 0.147886, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.786192]\n",
            "(1024, 1)\n",
            "Training Metrics: 666 [D loss: 0.607394, acc.: 99.80%, op_acc: 80.08%] [G loss: 6.062878]\n",
            "Validating on test set\n",
            "Validation Metrics: 666 [D loss: 0.187530, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.072593]\n",
            "(1024, 1)\n",
            "Training Metrics: 667 [D loss: 0.603465, acc.: 99.95%, op_acc: 81.54%] [G loss: 7.216262]\n",
            "Validating on test set\n",
            "Validation Metrics: 667 [D loss: 0.176851, acc.: 100.00%, op_acc: 98.14%] [G loss: 7.232774]\n",
            "(1024, 1)\n",
            "Training Metrics: 668 [D loss: 0.557246, acc.: 99.85%, op_acc: 83.94%] [G loss: 6.363739]\n",
            "Validating on test set\n",
            "Validation Metrics: 668 [D loss: 0.172164, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.348891]\n",
            "(1024, 1)\n",
            "Training Metrics: 669 [D loss: 0.587470, acc.: 99.85%, op_acc: 81.45%] [G loss: 7.391019]\n",
            "Validating on test set\n",
            "Validation Metrics: 669 [D loss: 0.176262, acc.: 100.00%, op_acc: 98.44%] [G loss: 7.364373]\n",
            "(1024, 1)\n",
            "Training Metrics: 670 [D loss: 0.623148, acc.: 99.95%, op_acc: 80.96%] [G loss: 5.872573]\n",
            "Validating on test set\n",
            "Validation Metrics: 670 [D loss: 0.179680, acc.: 100.00%, op_acc: 98.05%] [G loss: 5.861140]\n",
            "(1024, 1)\n",
            "Training Metrics: 671 [D loss: 0.602079, acc.: 100.00%, op_acc: 81.40%] [G loss: 7.872808]\n",
            "Validating on test set\n",
            "Validation Metrics: 671 [D loss: 0.206835, acc.: 100.00%, op_acc: 97.46%] [G loss: 7.919724]\n",
            "(1024, 1)\n",
            "Training Metrics: 672 [D loss: 0.644138, acc.: 99.85%, op_acc: 79.83%] [G loss: 6.161274]\n",
            "Validating on test set\n",
            "Validation Metrics: 672 [D loss: 0.231503, acc.: 100.00%, op_acc: 95.41%] [G loss: 6.173066]\n",
            "(1024, 1)\n",
            "Training Metrics: 673 [D loss: 0.659272, acc.: 99.90%, op_acc: 78.71%] [G loss: 6.999413]\n",
            "Validating on test set\n",
            "Validation Metrics: 673 [D loss: 0.248462, acc.: 100.00%, op_acc: 96.39%] [G loss: 7.167436]\n",
            "(1024, 1)\n",
            "Training Metrics: 674 [D loss: 0.676489, acc.: 99.85%, op_acc: 78.37%] [G loss: 7.195853]\n",
            "Validating on test set\n",
            "Validation Metrics: 674 [D loss: 0.492036, acc.: 100.00%, op_acc: 85.35%] [G loss: 7.344274]\n",
            "(1024, 1)\n",
            "Training Metrics: 675 [D loss: 0.788085, acc.: 99.76%, op_acc: 73.68%] [G loss: 7.997847]\n",
            "Validating on test set\n",
            "Validation Metrics: 675 [D loss: 0.192242, acc.: 100.00%, op_acc: 98.83%] [G loss: 8.059327]\n",
            "(1024, 1)\n",
            "Training Metrics: 676 [D loss: 0.645818, acc.: 99.76%, op_acc: 81.49%] [G loss: 6.986421]\n",
            "Validating on test set\n",
            "Validation Metrics: 676 [D loss: 0.199348, acc.: 100.00%, op_acc: 98.14%] [G loss: 6.957579]\n",
            "(1024, 1)\n",
            "Training Metrics: 677 [D loss: 0.613437, acc.: 99.80%, op_acc: 81.35%] [G loss: 6.614966]\n",
            "Validating on test set\n",
            "Validation Metrics: 677 [D loss: 0.146287, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.607573]\n",
            "(1024, 1)\n",
            "Training Metrics: 678 [D loss: 0.592377, acc.: 99.95%, op_acc: 81.35%] [G loss: 5.559502]\n",
            "Validating on test set\n",
            "Validation Metrics: 678 [D loss: 0.166619, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.524332]\n",
            "(1024, 1)\n",
            "Training Metrics: 679 [D loss: 0.581826, acc.: 100.00%, op_acc: 81.93%] [G loss: 6.861415]\n",
            "Validating on test set\n",
            "Validation Metrics: 679 [D loss: 0.196249, acc.: 100.00%, op_acc: 98.05%] [G loss: 6.855894]\n",
            "(1024, 1)\n",
            "Training Metrics: 680 [D loss: 0.551091, acc.: 99.80%, op_acc: 82.57%] [G loss: 6.675285]\n",
            "Validating on test set\n",
            "Validation Metrics: 680 [D loss: 0.166922, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.667232]\n",
            "(1024, 1)\n",
            "Training Metrics: 681 [D loss: 0.563700, acc.: 99.90%, op_acc: 82.67%] [G loss: 6.710031]\n",
            "Validating on test set\n",
            "Validation Metrics: 681 [D loss: 0.166551, acc.: 100.00%, op_acc: 97.85%] [G loss: 6.686819]\n",
            "(1024, 1)\n",
            "Training Metrics: 682 [D loss: 0.566628, acc.: 99.85%, op_acc: 81.88%] [G loss: 6.719050]\n",
            "Validating on test set\n",
            "Validation Metrics: 682 [D loss: 0.164263, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.728339]\n",
            "(1024, 1)\n",
            "Training Metrics: 683 [D loss: 0.616682, acc.: 99.90%, op_acc: 81.88%] [G loss: 6.396525]\n",
            "Validating on test set\n",
            "Validation Metrics: 683 [D loss: 0.151191, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.366718]\n",
            "(1024, 1)\n",
            "Training Metrics: 684 [D loss: 0.615582, acc.: 99.95%, op_acc: 79.74%] [G loss: 6.471993]\n",
            "Validating on test set\n",
            "Validation Metrics: 684 [D loss: 0.178427, acc.: 100.00%, op_acc: 97.95%] [G loss: 6.464343]\n",
            "(1024, 1)\n",
            "Training Metrics: 685 [D loss: 0.633909, acc.: 99.85%, op_acc: 81.20%] [G loss: 6.505540]\n",
            "Validating on test set\n",
            "Validation Metrics: 685 [D loss: 0.190315, acc.: 100.00%, op_acc: 97.66%] [G loss: 6.525043]\n",
            "(1024, 1)\n",
            "Training Metrics: 686 [D loss: 0.609418, acc.: 99.85%, op_acc: 80.13%] [G loss: 6.143513]\n",
            "Validating on test set\n",
            "Validation Metrics: 686 [D loss: 0.169662, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.187506]\n",
            "(1024, 1)\n",
            "Training Metrics: 687 [D loss: 0.543610, acc.: 99.95%, op_acc: 84.08%] [G loss: 6.925844]\n",
            "Validating on test set\n",
            "Validation Metrics: 687 [D loss: 0.170928, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.947921]\n",
            "(1024, 1)\n",
            "Training Metrics: 688 [D loss: 0.591834, acc.: 100.00%, op_acc: 81.64%] [G loss: 6.290967]\n",
            "Validating on test set\n",
            "Validation Metrics: 688 [D loss: 0.354411, acc.: 100.00%, op_acc: 92.29%] [G loss: 6.360432]\n",
            "(1024, 1)\n",
            "Training Metrics: 689 [D loss: 0.718885, acc.: 99.85%, op_acc: 77.83%] [G loss: 7.213610]\n",
            "Validating on test set\n",
            "Validation Metrics: 689 [D loss: 0.184998, acc.: 100.00%, op_acc: 98.24%] [G loss: 7.166909]\n",
            "(1024, 1)\n",
            "Training Metrics: 690 [D loss: 0.653126, acc.: 99.95%, op_acc: 78.76%] [G loss: 6.789634]\n",
            "Validating on test set\n",
            "Validation Metrics: 690 [D loss: 0.234386, acc.: 100.00%, op_acc: 95.21%] [G loss: 6.795336]\n",
            "(1024, 1)\n",
            "Training Metrics: 691 [D loss: 0.607597, acc.: 99.85%, op_acc: 80.08%] [G loss: 7.306809]\n",
            "Validating on test set\n",
            "Validation Metrics: 691 [D loss: 0.199969, acc.: 100.00%, op_acc: 98.63%] [G loss: 7.416749]\n",
            "(1024, 1)\n",
            "Training Metrics: 692 [D loss: 0.602343, acc.: 99.90%, op_acc: 82.62%] [G loss: 7.375453]\n",
            "Validating on test set\n",
            "Validation Metrics: 692 [D loss: 0.215654, acc.: 100.00%, op_acc: 96.58%] [G loss: 7.361353]\n",
            "(1024, 1)\n",
            "Training Metrics: 693 [D loss: 0.591901, acc.: 100.00%, op_acc: 81.10%] [G loss: 7.709616]\n",
            "Validating on test set\n",
            "Validation Metrics: 693 [D loss: 0.178494, acc.: 100.00%, op_acc: 98.14%] [G loss: 7.717452]\n",
            "(1024, 1)\n",
            "Training Metrics: 694 [D loss: 0.559227, acc.: 99.90%, op_acc: 82.18%] [G loss: 7.323961]\n",
            "Validating on test set\n",
            "Validation Metrics: 694 [D loss: 0.184057, acc.: 100.00%, op_acc: 97.66%] [G loss: 7.301358]\n",
            "(1024, 1)\n",
            "Training Metrics: 695 [D loss: 0.567574, acc.: 100.00%, op_acc: 81.98%] [G loss: 6.936975]\n",
            "Validating on test set\n",
            "Validation Metrics: 695 [D loss: 0.149582, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.915658]\n",
            "(1024, 1)\n",
            "Training Metrics: 696 [D loss: 0.568174, acc.: 100.00%, op_acc: 82.47%] [G loss: 7.390685]\n",
            "Validating on test set\n",
            "Validation Metrics: 696 [D loss: 0.328573, acc.: 100.00%, op_acc: 90.43%] [G loss: 7.506471]\n",
            "(1024, 1)\n",
            "Training Metrics: 697 [D loss: 0.702843, acc.: 99.80%, op_acc: 77.59%] [G loss: 7.499924]\n",
            "Validating on test set\n",
            "Validation Metrics: 697 [D loss: 0.236964, acc.: 100.00%, op_acc: 93.55%] [G loss: 7.505549]\n",
            "(1024, 1)\n",
            "Training Metrics: 698 [D loss: 0.619834, acc.: 99.85%, op_acc: 79.64%] [G loss: 7.550952]\n",
            "Validating on test set\n",
            "Validation Metrics: 698 [D loss: 0.226190, acc.: 100.00%, op_acc: 95.31%] [G loss: 7.540601]\n",
            "(1024, 1)\n",
            "Training Metrics: 699 [D loss: 0.593312, acc.: 99.85%, op_acc: 81.25%] [G loss: 6.771287]\n",
            "Validating on test set\n",
            "Validation Metrics: 699 [D loss: 0.239151, acc.: 100.00%, op_acc: 93.75%] [G loss: 6.768112]\n",
            "(1024, 1)\n",
            "Training Metrics: 700 [D loss: 0.572862, acc.: 99.85%, op_acc: 81.10%] [G loss: 6.997365]\n",
            "Validating on test set\n",
            "Validation Metrics: 700 [D loss: 0.387618, acc.: 100.00%, op_acc: 87.79%] [G loss: 6.996074]\n",
            "(1024, 1)\n",
            "Training Metrics: 701 [D loss: 0.676319, acc.: 99.90%, op_acc: 77.05%] [G loss: 7.629804]\n",
            "Validating on test set\n",
            "Validation Metrics: 701 [D loss: 0.695227, acc.: 100.00%, op_acc: 76.86%] [G loss: 7.885167]\n",
            "(1024, 1)\n",
            "Training Metrics: 702 [D loss: 0.804534, acc.: 99.85%, op_acc: 71.97%] [G loss: 9.422825]\n",
            "Validating on test set\n",
            "Validation Metrics: 702 [D loss: 0.511367, acc.: 100.00%, op_acc: 81.35%] [G loss: 9.684165]\n",
            "(1024, 1)\n",
            "Training Metrics: 703 [D loss: 0.784882, acc.: 99.80%, op_acc: 69.34%] [G loss: 8.590871]\n",
            "Validating on test set\n",
            "Validation Metrics: 703 [D loss: 0.516006, acc.: 100.00%, op_acc: 86.23%] [G loss: 8.400715]\n",
            "(1024, 1)\n",
            "Training Metrics: 704 [D loss: 0.753648, acc.: 99.80%, op_acc: 76.71%] [G loss: 8.312482]\n",
            "Validating on test set\n",
            "Validation Metrics: 704 [D loss: 1.339172, acc.: 100.00%, op_acc: 61.43%] [G loss: 8.933701]\n",
            "(1024, 1)\n",
            "Training Metrics: 705 [D loss: 1.186089, acc.: 99.76%, op_acc: 61.04%] [G loss: 10.359490]\n",
            "Validating on test set\n",
            "Validation Metrics: 705 [D loss: 0.648160, acc.: 100.00%, op_acc: 89.06%] [G loss: 10.232121]\n",
            "(1024, 1)\n",
            "Training Metrics: 706 [D loss: 0.904227, acc.: 99.51%, op_acc: 67.29%] [G loss: 8.380450]\n",
            "Validating on test set\n",
            "Validation Metrics: 706 [D loss: 0.634132, acc.: 100.00%, op_acc: 79.39%] [G loss: 8.459682]\n",
            "(1024, 1)\n",
            "Training Metrics: 707 [D loss: 0.831822, acc.: 99.85%, op_acc: 72.46%] [G loss: 6.228123]\n",
            "Validating on test set\n",
            "Validation Metrics: 707 [D loss: 0.683116, acc.: 100.00%, op_acc: 73.34%] [G loss: 6.266429]\n",
            "(1024, 1)\n",
            "Training Metrics: 708 [D loss: 0.855866, acc.: 99.95%, op_acc: 68.36%] [G loss: 5.115530]\n",
            "Validating on test set\n",
            "Validation Metrics: 708 [D loss: 0.722769, acc.: 100.00%, op_acc: 71.78%] [G loss: 5.141953]\n",
            "(1024, 1)\n",
            "Training Metrics: 709 [D loss: 0.875912, acc.: 99.95%, op_acc: 68.70%] [G loss: 6.161721]\n",
            "Validating on test set\n",
            "Validation Metrics: 709 [D loss: 1.275009, acc.: 100.00%, op_acc: 62.11%] [G loss: 6.757003]\n",
            "(1024, 1)\n",
            "Training Metrics: 710 [D loss: 1.234455, acc.: 100.00%, op_acc: 61.72%] [G loss: 5.469788]\n",
            "Validating on test set\n",
            "Validation Metrics: 710 [D loss: 1.760258, acc.: 100.00%, op_acc: 49.61%] [G loss: 5.896114]\n",
            "(1024, 1)\n",
            "Training Metrics: 711 [D loss: 1.323118, acc.: 99.95%, op_acc: 58.94%] [G loss: 7.880307]\n",
            "Validating on test set\n",
            "Validation Metrics: 711 [D loss: 0.866891, acc.: 100.00%, op_acc: 71.09%] [G loss: 7.452959]\n",
            "(1024, 1)\n",
            "Training Metrics: 712 [D loss: 0.972258, acc.: 99.95%, op_acc: 67.53%] [G loss: 5.983295]\n",
            "Validating on test set\n",
            "Validation Metrics: 712 [D loss: 0.735979, acc.: 100.00%, op_acc: 71.78%] [G loss: 5.775245]\n",
            "(1024, 1)\n",
            "Training Metrics: 713 [D loss: 0.843602, acc.: 100.00%, op_acc: 67.68%] [G loss: 6.807020]\n",
            "Validating on test set\n",
            "Validation Metrics: 713 [D loss: 0.638238, acc.: 100.00%, op_acc: 73.14%] [G loss: 6.772315]\n",
            "(1024, 1)\n",
            "Training Metrics: 714 [D loss: 0.817366, acc.: 99.80%, op_acc: 71.34%] [G loss: 5.263038]\n",
            "Validating on test set\n",
            "Validation Metrics: 714 [D loss: 0.559714, acc.: 100.00%, op_acc: 87.50%] [G loss: 5.201558]\n",
            "(1024, 1)\n",
            "Training Metrics: 715 [D loss: 0.754207, acc.: 100.00%, op_acc: 75.44%] [G loss: 6.586275]\n",
            "Validating on test set\n",
            "Validation Metrics: 715 [D loss: 0.529969, acc.: 100.00%, op_acc: 82.52%] [G loss: 6.566905]\n",
            "(1024, 1)\n",
            "Training Metrics: 716 [D loss: 0.790575, acc.: 99.95%, op_acc: 73.83%] [G loss: 6.435137]\n",
            "Validating on test set\n",
            "Validation Metrics: 716 [D loss: 0.501600, acc.: 100.00%, op_acc: 87.11%] [G loss: 6.429799]\n",
            "(1024, 1)\n",
            "Training Metrics: 717 [D loss: 0.744028, acc.: 99.76%, op_acc: 74.12%] [G loss: 6.123018]\n",
            "Validating on test set\n",
            "Validation Metrics: 717 [D loss: 0.499429, acc.: 100.00%, op_acc: 76.66%] [G loss: 6.092902]\n",
            "(1024, 1)\n",
            "Training Metrics: 718 [D loss: 0.765092, acc.: 99.85%, op_acc: 72.41%] [G loss: 6.674039]\n",
            "Validating on test set\n",
            "Validation Metrics: 718 [D loss: 0.407051, acc.: 100.00%, op_acc: 88.38%] [G loss: 6.670347]\n",
            "(1024, 1)\n",
            "Training Metrics: 719 [D loss: 0.695527, acc.: 99.90%, op_acc: 75.15%] [G loss: 6.743176]\n",
            "Validating on test set\n",
            "Validation Metrics: 719 [D loss: 0.387607, acc.: 100.00%, op_acc: 89.26%] [G loss: 6.704063]\n",
            "(1024, 1)\n",
            "Training Metrics: 720 [D loss: 0.732765, acc.: 100.00%, op_acc: 75.98%] [G loss: 6.958140]\n",
            "Validating on test set\n",
            "Validation Metrics: 720 [D loss: 0.401255, acc.: 100.00%, op_acc: 85.64%] [G loss: 6.975232]\n",
            "(1024, 1)\n",
            "Training Metrics: 721 [D loss: 0.742369, acc.: 99.85%, op_acc: 71.83%] [G loss: 7.053625]\n",
            "Validating on test set\n",
            "Validation Metrics: 721 [D loss: 0.361385, acc.: 100.00%, op_acc: 87.70%] [G loss: 7.055621]\n",
            "(1024, 1)\n",
            "Training Metrics: 722 [D loss: 0.705954, acc.: 99.85%, op_acc: 75.83%] [G loss: 6.846619]\n",
            "Validating on test set\n",
            "Validation Metrics: 722 [D loss: 0.429799, acc.: 100.00%, op_acc: 82.81%] [G loss: 6.830710]\n",
            "(1024, 1)\n",
            "Training Metrics: 723 [D loss: 0.679563, acc.: 99.95%, op_acc: 74.37%] [G loss: 6.622463]\n",
            "Validating on test set\n",
            "Validation Metrics: 723 [D loss: 0.326180, acc.: 100.00%, op_acc: 93.26%] [G loss: 6.615824]\n",
            "(1024, 1)\n",
            "Training Metrics: 724 [D loss: 0.640254, acc.: 99.80%, op_acc: 76.66%] [G loss: 6.961368]\n",
            "Validating on test set\n",
            "Validation Metrics: 724 [D loss: 0.501666, acc.: 100.00%, op_acc: 86.23%] [G loss: 7.055636]\n",
            "(1024, 1)\n",
            "Training Metrics: 725 [D loss: 0.687098, acc.: 99.90%, op_acc: 77.49%] [G loss: 6.310215]\n",
            "Validating on test set\n",
            "Validation Metrics: 725 [D loss: 0.379687, acc.: 100.00%, op_acc: 88.77%] [G loss: 6.309520]\n",
            "(1024, 1)\n",
            "Training Metrics: 726 [D loss: 0.687104, acc.: 99.90%, op_acc: 75.49%] [G loss: 6.967700]\n",
            "Validating on test set\n",
            "Validation Metrics: 726 [D loss: 0.310939, acc.: 100.00%, op_acc: 94.43%] [G loss: 6.944020]\n",
            "(1024, 1)\n",
            "Training Metrics: 727 [D loss: 0.712813, acc.: 99.71%, op_acc: 76.32%] [G loss: 6.106424]\n",
            "Validating on test set\n",
            "Validation Metrics: 727 [D loss: 0.487064, acc.: 100.00%, op_acc: 86.82%] [G loss: 6.218491]\n",
            "(1024, 1)\n",
            "Training Metrics: 728 [D loss: 0.786270, acc.: 100.00%, op_acc: 73.83%] [G loss: 7.564040]\n",
            "Validating on test set\n",
            "Validation Metrics: 728 [D loss: 0.441431, acc.: 100.00%, op_acc: 84.96%] [G loss: 7.541378]\n",
            "(1024, 1)\n",
            "Training Metrics: 729 [D loss: 0.743225, acc.: 100.00%, op_acc: 74.90%] [G loss: 6.778008]\n",
            "Validating on test set\n",
            "Validation Metrics: 729 [D loss: 0.352731, acc.: 100.00%, op_acc: 91.02%] [G loss: 6.768073]\n",
            "(1024, 1)\n",
            "Training Metrics: 730 [D loss: 0.663265, acc.: 99.90%, op_acc: 75.73%] [G loss: 7.186852]\n",
            "Validating on test set\n",
            "Validation Metrics: 730 [D loss: 0.340215, acc.: 100.00%, op_acc: 91.60%] [G loss: 7.219489]\n",
            "(1024, 1)\n",
            "Training Metrics: 731 [D loss: 0.649512, acc.: 99.95%, op_acc: 77.25%] [G loss: 6.924231]\n",
            "Validating on test set\n",
            "Validation Metrics: 731 [D loss: 0.404805, acc.: 100.00%, op_acc: 87.60%] [G loss: 6.988958]\n",
            "(1024, 1)\n",
            "Training Metrics: 732 [D loss: 0.689213, acc.: 99.80%, op_acc: 76.86%] [G loss: 7.352333]\n",
            "Validating on test set\n",
            "Validation Metrics: 732 [D loss: 0.366054, acc.: 100.00%, op_acc: 91.02%] [G loss: 7.322093]\n",
            "(1024, 1)\n",
            "Training Metrics: 733 [D loss: 0.706558, acc.: 99.95%, op_acc: 76.27%] [G loss: 7.277000]\n",
            "Validating on test set\n",
            "Validation Metrics: 733 [D loss: 0.323874, acc.: 100.00%, op_acc: 93.85%] [G loss: 7.234359]\n",
            "(1024, 1)\n",
            "Training Metrics: 734 [D loss: 0.615608, acc.: 99.95%, op_acc: 78.12%] [G loss: 7.023353]\n",
            "Validating on test set\n",
            "Validation Metrics: 734 [D loss: 0.308861, acc.: 100.00%, op_acc: 94.63%] [G loss: 7.043009]\n",
            "(1024, 1)\n",
            "Training Metrics: 735 [D loss: 0.660490, acc.: 99.85%, op_acc: 78.96%] [G loss: 7.405357]\n",
            "Validating on test set\n",
            "Validation Metrics: 735 [D loss: 0.380068, acc.: 100.00%, op_acc: 90.04%] [G loss: 7.434918]\n",
            "(1024, 1)\n",
            "Training Metrics: 736 [D loss: 0.737330, acc.: 99.85%, op_acc: 76.03%] [G loss: 6.417398]\n",
            "Validating on test set\n",
            "Validation Metrics: 736 [D loss: 0.437506, acc.: 100.00%, op_acc: 88.18%] [G loss: 6.593951]\n",
            "(1024, 1)\n",
            "Training Metrics: 737 [D loss: 0.684267, acc.: 99.90%, op_acc: 76.90%] [G loss: 7.816121]\n",
            "Validating on test set\n",
            "Validation Metrics: 737 [D loss: 0.527867, acc.: 100.00%, op_acc: 78.42%] [G loss: 7.827232]\n",
            "(1024, 1)\n",
            "Training Metrics: 738 [D loss: 0.773878, acc.: 99.90%, op_acc: 72.41%] [G loss: 7.260395]\n",
            "Validating on test set\n",
            "Validation Metrics: 738 [D loss: 0.408855, acc.: 100.00%, op_acc: 89.94%] [G loss: 7.283997]\n",
            "(1024, 1)\n",
            "Training Metrics: 739 [D loss: 0.684065, acc.: 99.90%, op_acc: 76.12%] [G loss: 7.707472]\n",
            "Validating on test set\n",
            "Validation Metrics: 739 [D loss: 0.344784, acc.: 100.00%, op_acc: 90.53%] [G loss: 7.616441]\n",
            "(1024, 1)\n",
            "Training Metrics: 740 [D loss: 0.679095, acc.: 99.80%, op_acc: 79.83%] [G loss: 6.605641]\n",
            "Validating on test set\n",
            "Validation Metrics: 740 [D loss: 0.306497, acc.: 100.00%, op_acc: 92.87%] [G loss: 6.608816]\n",
            "(1024, 1)\n",
            "Training Metrics: 741 [D loss: 0.665696, acc.: 100.00%, op_acc: 78.66%] [G loss: 6.550604]\n",
            "Validating on test set\n",
            "Validation Metrics: 741 [D loss: 0.287639, acc.: 100.00%, op_acc: 96.09%] [G loss: 6.536027]\n",
            "(1024, 1)\n",
            "Training Metrics: 742 [D loss: 0.673531, acc.: 100.00%, op_acc: 78.12%] [G loss: 7.379689]\n",
            "Validating on test set\n",
            "Validation Metrics: 742 [D loss: 0.274720, acc.: 100.00%, op_acc: 93.07%] [G loss: 7.401365]\n",
            "(1024, 1)\n",
            "Training Metrics: 743 [D loss: 0.678483, acc.: 99.80%, op_acc: 79.15%] [G loss: 6.434803]\n",
            "Validating on test set\n",
            "Validation Metrics: 743 [D loss: 0.329404, acc.: 100.00%, op_acc: 90.33%] [G loss: 6.437845]\n",
            "(1024, 1)\n",
            "Training Metrics: 744 [D loss: 0.664228, acc.: 99.85%, op_acc: 78.86%] [G loss: 7.083909]\n",
            "Validating on test set\n",
            "Validation Metrics: 744 [D loss: 0.255281, acc.: 100.00%, op_acc: 97.17%] [G loss: 7.110106]\n",
            "(1024, 1)\n",
            "Training Metrics: 745 [D loss: 0.638303, acc.: 99.80%, op_acc: 80.37%] [G loss: 6.979156]\n",
            "Validating on test set\n",
            "Validation Metrics: 745 [D loss: 0.274318, acc.: 100.00%, op_acc: 94.73%] [G loss: 6.924338]\n",
            "(1024, 1)\n",
            "Training Metrics: 746 [D loss: 0.596528, acc.: 99.90%, op_acc: 81.98%] [G loss: 6.845028]\n",
            "Validating on test set\n",
            "Validation Metrics: 746 [D loss: 0.277822, acc.: 100.00%, op_acc: 95.70%] [G loss: 6.858872]\n",
            "(1024, 1)\n",
            "Training Metrics: 747 [D loss: 0.588352, acc.: 99.90%, op_acc: 79.93%] [G loss: 6.775389]\n",
            "Validating on test set\n",
            "Validation Metrics: 747 [D loss: 0.224510, acc.: 100.00%, op_acc: 97.75%] [G loss: 6.786601]\n",
            "(1024, 1)\n",
            "Training Metrics: 748 [D loss: 0.673811, acc.: 99.95%, op_acc: 77.49%] [G loss: 7.326259]\n",
            "Validating on test set\n",
            "Validation Metrics: 748 [D loss: 0.332248, acc.: 100.00%, op_acc: 92.77%] [G loss: 7.431108]\n",
            "(1024, 1)\n",
            "Training Metrics: 749 [D loss: 0.706012, acc.: 99.76%, op_acc: 79.15%] [G loss: 6.179117]\n",
            "Validating on test set\n",
            "Validation Metrics: 749 [D loss: 0.266470, acc.: 100.00%, op_acc: 97.27%] [G loss: 6.140148]\n",
            "(1024, 1)\n",
            "Training Metrics: 750 [D loss: 0.655136, acc.: 99.85%, op_acc: 80.32%] [G loss: 6.635110]\n",
            "Validating on test set\n",
            "Validation Metrics: 750 [D loss: 0.314176, acc.: 100.00%, op_acc: 95.80%] [G loss: 6.805383]\n",
            "(1024, 1)\n",
            "Training Metrics: 751 [D loss: 0.688641, acc.: 99.85%, op_acc: 79.05%] [G loss: 7.353272]\n",
            "Validating on test set\n",
            "Validation Metrics: 751 [D loss: 0.242639, acc.: 100.00%, op_acc: 97.46%] [G loss: 7.306497]\n",
            "(1024, 1)\n",
            "Training Metrics: 752 [D loss: 0.610559, acc.: 99.80%, op_acc: 81.84%] [G loss: 6.420958]\n",
            "Validating on test set\n",
            "Validation Metrics: 752 [D loss: 0.269346, acc.: 100.00%, op_acc: 96.39%] [G loss: 6.387017]\n",
            "(1024, 1)\n",
            "Training Metrics: 753 [D loss: 0.626481, acc.: 99.85%, op_acc: 79.98%] [G loss: 6.902020]\n",
            "Validating on test set\n",
            "Validation Metrics: 753 [D loss: 0.248468, acc.: 100.00%, op_acc: 96.88%] [G loss: 6.882074]\n",
            "(1024, 1)\n",
            "Training Metrics: 754 [D loss: 0.618809, acc.: 99.95%, op_acc: 81.05%] [G loss: 6.592422]\n",
            "Validating on test set\n",
            "Validation Metrics: 754 [D loss: 0.351095, acc.: 100.00%, op_acc: 90.62%] [G loss: 6.672042]\n",
            "(1024, 1)\n",
            "Training Metrics: 755 [D loss: 0.630640, acc.: 99.95%, op_acc: 79.44%] [G loss: 6.804069]\n",
            "Validating on test set\n",
            "Validation Metrics: 755 [D loss: 0.291410, acc.: 100.00%, op_acc: 96.97%] [G loss: 6.826759]\n",
            "(1024, 1)\n",
            "Training Metrics: 756 [D loss: 0.612188, acc.: 100.00%, op_acc: 81.10%] [G loss: 6.991006]\n",
            "Validating on test set\n",
            "Validation Metrics: 756 [D loss: 0.260530, acc.: 100.00%, op_acc: 90.14%] [G loss: 6.964408]\n",
            "(1024, 1)\n",
            "Training Metrics: 757 [D loss: 0.583570, acc.: 100.00%, op_acc: 79.15%] [G loss: 6.906699]\n",
            "Validating on test set\n",
            "Validation Metrics: 757 [D loss: 0.511165, acc.: 100.00%, op_acc: 81.64%] [G loss: 7.018191]\n",
            "(1024, 1)\n",
            "Training Metrics: 758 [D loss: 0.780185, acc.: 99.95%, op_acc: 69.53%] [G loss: 7.155159]\n",
            "Validating on test set\n",
            "Validation Metrics: 758 [D loss: 0.333387, acc.: 100.00%, op_acc: 94.24%] [G loss: 7.118171]\n",
            "(1024, 1)\n",
            "Training Metrics: 759 [D loss: 0.696938, acc.: 99.85%, op_acc: 76.61%] [G loss: 7.457084]\n",
            "Validating on test set\n",
            "Validation Metrics: 759 [D loss: 0.469203, acc.: 100.00%, op_acc: 83.89%] [G loss: 7.643685]\n",
            "(1024, 1)\n",
            "Training Metrics: 760 [D loss: 0.736671, acc.: 99.76%, op_acc: 72.66%] [G loss: 8.286219]\n",
            "Validating on test set\n",
            "Validation Metrics: 760 [D loss: 0.380536, acc.: 100.00%, op_acc: 88.96%] [G loss: 8.268841]\n",
            "(1024, 1)\n",
            "Training Metrics: 761 [D loss: 0.741858, acc.: 99.85%, op_acc: 77.73%] [G loss: 7.823395]\n",
            "Validating on test set\n",
            "Validation Metrics: 761 [D loss: 0.369199, acc.: 100.00%, op_acc: 86.72%] [G loss: 7.926919]\n",
            "(1024, 1)\n",
            "Training Metrics: 762 [D loss: 0.683752, acc.: 99.71%, op_acc: 74.41%] [G loss: 6.438921]\n",
            "Validating on test set\n",
            "Validation Metrics: 762 [D loss: 0.440481, acc.: 100.00%, op_acc: 86.43%] [G loss: 6.655015]\n",
            "(1024, 1)\n",
            "Training Metrics: 763 [D loss: 0.761504, acc.: 100.00%, op_acc: 74.07%] [G loss: 7.209527]\n",
            "Validating on test set\n",
            "Validation Metrics: 763 [D loss: 0.465949, acc.: 100.00%, op_acc: 85.25%] [G loss: 7.168767]\n",
            "(1024, 1)\n",
            "Training Metrics: 764 [D loss: 0.753810, acc.: 99.90%, op_acc: 75.34%] [G loss: 6.606813]\n",
            "Validating on test set\n",
            "Validation Metrics: 764 [D loss: 0.339833, acc.: 100.00%, op_acc: 96.48%] [G loss: 6.625756]\n",
            "(1024, 1)\n",
            "Training Metrics: 765 [D loss: 0.692927, acc.: 99.95%, op_acc: 81.05%] [G loss: 6.979221]\n",
            "Validating on test set\n",
            "Validation Metrics: 765 [D loss: 0.482906, acc.: 100.00%, op_acc: 86.13%] [G loss: 7.024243]\n",
            "(1024, 1)\n",
            "Training Metrics: 766 [D loss: 0.767136, acc.: 99.95%, op_acc: 76.32%] [G loss: 6.908824]\n",
            "Validating on test set\n",
            "Validation Metrics: 766 [D loss: 0.329215, acc.: 100.00%, op_acc: 92.48%] [G loss: 6.800436]\n",
            "(1024, 1)\n",
            "Training Metrics: 767 [D loss: 0.665737, acc.: 99.90%, op_acc: 80.03%] [G loss: 6.911116]\n",
            "Validating on test set\n",
            "Validation Metrics: 767 [D loss: 0.281774, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.895394]\n",
            "(1024, 1)\n",
            "Training Metrics: 768 [D loss: 0.623803, acc.: 99.95%, op_acc: 82.08%] [G loss: 6.249974]\n",
            "Validating on test set\n",
            "Validation Metrics: 768 [D loss: 0.238532, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.237409]\n",
            "(1024, 1)\n",
            "Training Metrics: 769 [D loss: 0.612796, acc.: 99.95%, op_acc: 81.25%] [G loss: 6.793171]\n",
            "Validating on test set\n",
            "Validation Metrics: 769 [D loss: 0.688208, acc.: 100.00%, op_acc: 83.20%] [G loss: 7.315446]\n",
            "(1024, 1)\n",
            "Training Metrics: 770 [D loss: 0.905516, acc.: 99.90%, op_acc: 72.27%] [G loss: 5.451193]\n",
            "Validating on test set\n",
            "Validation Metrics: 770 [D loss: 0.662622, acc.: 100.00%, op_acc: 83.01%] [G loss: 5.740319]\n",
            "(1024, 1)\n",
            "Training Metrics: 771 [D loss: 0.821869, acc.: 99.90%, op_acc: 75.34%] [G loss: 5.986969]\n",
            "Validating on test set\n",
            "Validation Metrics: 771 [D loss: 1.695820, acc.: 100.00%, op_acc: 64.06%] [G loss: 6.873094]\n",
            "(1024, 1)\n",
            "Training Metrics: 772 [D loss: 1.240871, acc.: 99.95%, op_acc: 66.99%] [G loss: 1.608824]\n",
            "Validating on test set\n",
            "Validation Metrics: 772 [D loss: 1.464278, acc.: 40.33%, op_acc: 75.00%] [G loss: 1.520828]\n",
            "(1024, 1)\n",
            "Training Metrics: 773 [D loss: 2.234947, acc.: 53.27%, op_acc: 64.65%] [G loss: 26.226921]\n",
            "Validating on test set\n",
            "Validation Metrics: 773 [D loss: 3.125500, acc.: 100.00%, op_acc: 38.67%] [G loss: 19.369968]\n",
            "(1024, 1)\n",
            "Training Metrics: 774 [D loss: 3.705211, acc.: 92.09%, op_acc: 40.77%] [G loss: 17.544281]\n",
            "Validating on test set\n",
            "Validation Metrics: 774 [D loss: 1.394901, acc.: 100.00%, op_acc: 58.89%] [G loss: 17.524446]\n",
            "(1024, 1)\n",
            "Training Metrics: 775 [D loss: 2.244861, acc.: 95.95%, op_acc: 58.59%] [G loss: 16.992313]\n",
            "Validating on test set\n",
            "Validation Metrics: 775 [D loss: 0.783575, acc.: 100.00%, op_acc: 77.05%] [G loss: 16.263765]\n",
            "(1024, 1)\n",
            "Training Metrics: 776 [D loss: 1.425968, acc.: 97.51%, op_acc: 65.92%] [G loss: 15.811396]\n",
            "Validating on test set\n",
            "Validation Metrics: 776 [D loss: 1.496210, acc.: 100.00%, op_acc: 48.73%] [G loss: 13.059565]\n",
            "(1024, 1)\n",
            "Training Metrics: 777 [D loss: 1.523915, acc.: 98.24%, op_acc: 59.23%] [G loss: 12.978247]\n",
            "Validating on test set\n",
            "Validation Metrics: 777 [D loss: 5.929766, acc.: 28.32%, op_acc: 15.23%] [G loss: 4.903194]\n",
            "(1024, 1)\n",
            "Training Metrics: 778 [D loss: 3.404018, acc.: 64.55%, op_acc: 38.28%] [G loss: 17.350336]\n",
            "Validating on test set\n",
            "Validation Metrics: 778 [D loss: 3.368435, acc.: 100.00%, op_acc: 27.15%] [G loss: 14.441505]\n",
            "(1024, 1)\n",
            "Training Metrics: 779 [D loss: 2.564912, acc.: 96.09%, op_acc: 43.60%] [G loss: 16.986115]\n",
            "Validating on test set\n",
            "Validation Metrics: 779 [D loss: 2.716192, acc.: 100.00%, op_acc: 33.01%] [G loss: 15.122311]\n",
            "(1024, 1)\n",
            "Training Metrics: 780 [D loss: 2.257808, acc.: 94.29%, op_acc: 48.00%] [G loss: 12.435368]\n",
            "Validating on test set\n",
            "Validation Metrics: 780 [D loss: 3.357493, acc.: 100.00%, op_acc: 28.22%] [G loss: 10.795527]\n",
            "(1024, 1)\n",
            "Training Metrics: 781 [D loss: 2.343896, acc.: 97.75%, op_acc: 47.46%] [G loss: 9.281316]\n",
            "Validating on test set\n",
            "Validation Metrics: 781 [D loss: 3.936016, acc.: 100.00%, op_acc: 17.68%] [G loss: 9.416718]\n",
            "(1024, 1)\n",
            "Training Metrics: 782 [D loss: 2.471800, acc.: 98.44%, op_acc: 39.21%] [G loss: 8.700630]\n",
            "Validating on test set\n",
            "Validation Metrics: 782 [D loss: 3.208694, acc.: 100.00%, op_acc: 20.80%] [G loss: 9.250613]\n",
            "(1024, 1)\n",
            "Training Metrics: 783 [D loss: 2.286083, acc.: 98.88%, op_acc: 40.33%] [G loss: 8.374599]\n",
            "Validating on test set\n",
            "Validation Metrics: 783 [D loss: 2.828958, acc.: 100.00%, op_acc: 23.83%] [G loss: 7.819568]\n",
            "(1024, 1)\n",
            "Training Metrics: 784 [D loss: 1.930053, acc.: 98.93%, op_acc: 44.24%] [G loss: 6.956200]\n",
            "Validating on test set\n",
            "Validation Metrics: 784 [D loss: 2.248948, acc.: 100.00%, op_acc: 33.89%] [G loss: 6.868913]\n",
            "(1024, 1)\n",
            "Training Metrics: 785 [D loss: 1.658358, acc.: 98.97%, op_acc: 48.10%] [G loss: 6.668298]\n",
            "Validating on test set\n",
            "Validation Metrics: 785 [D loss: 2.466554, acc.: 100.00%, op_acc: 17.97%] [G loss: 7.352444]\n",
            "(1024, 1)\n",
            "Training Metrics: 786 [D loss: 1.814207, acc.: 98.78%, op_acc: 41.85%] [G loss: 7.226464]\n",
            "Validating on test set\n",
            "Validation Metrics: 786 [D loss: 1.635538, acc.: 100.00%, op_acc: 45.70%] [G loss: 7.319549]\n",
            "(1024, 1)\n",
            "Training Metrics: 787 [D loss: 1.430299, acc.: 99.07%, op_acc: 50.54%] [G loss: 7.133368]\n",
            "Validating on test set\n",
            "Validation Metrics: 787 [D loss: 1.615610, acc.: 100.00%, op_acc: 43.55%] [G loss: 6.308077]\n",
            "(1024, 1)\n",
            "Training Metrics: 788 [D loss: 1.379033, acc.: 99.37%, op_acc: 51.17%] [G loss: 6.368630]\n",
            "Validating on test set\n",
            "Validation Metrics: 788 [D loss: 1.494864, acc.: 100.00%, op_acc: 50.10%] [G loss: 6.050385]\n",
            "(1024, 1)\n",
            "Training Metrics: 789 [D loss: 1.281069, acc.: 99.12%, op_acc: 56.79%] [G loss: 6.107536]\n",
            "Validating on test set\n",
            "Validation Metrics: 789 [D loss: 1.397012, acc.: 100.00%, op_acc: 46.29%] [G loss: 5.987009]\n",
            "(1024, 1)\n",
            "Training Metrics: 790 [D loss: 1.193998, acc.: 99.17%, op_acc: 58.35%] [G loss: 5.744968]\n",
            "Validating on test set\n",
            "Validation Metrics: 790 [D loss: 1.315336, acc.: 100.00%, op_acc: 63.48%] [G loss: 5.701138]\n",
            "(1024, 1)\n",
            "Training Metrics: 791 [D loss: 1.186467, acc.: 99.17%, op_acc: 63.57%] [G loss: 5.578208]\n",
            "Validating on test set\n",
            "Validation Metrics: 791 [D loss: 1.161201, acc.: 100.00%, op_acc: 72.17%] [G loss: 5.453056]\n",
            "(1024, 1)\n",
            "Training Metrics: 792 [D loss: 1.087313, acc.: 99.22%, op_acc: 68.80%] [G loss: 5.466731]\n",
            "Validating on test set\n",
            "Validation Metrics: 792 [D loss: 1.112059, acc.: 100.00%, op_acc: 74.32%] [G loss: 5.433813]\n",
            "(1024, 1)\n",
            "Training Metrics: 793 [D loss: 1.062878, acc.: 99.27%, op_acc: 69.82%] [G loss: 5.510792]\n",
            "Validating on test set\n",
            "Validation Metrics: 793 [D loss: 1.082386, acc.: 100.00%, op_acc: 72.46%] [G loss: 5.443902]\n",
            "(1024, 1)\n",
            "Training Metrics: 794 [D loss: 1.083301, acc.: 99.17%, op_acc: 67.19%] [G loss: 5.420708]\n",
            "Validating on test set\n",
            "Validation Metrics: 794 [D loss: 1.116354, acc.: 100.00%, op_acc: 67.29%] [G loss: 5.442926]\n",
            "(1024, 1)\n",
            "Training Metrics: 795 [D loss: 1.092929, acc.: 99.17%, op_acc: 66.50%] [G loss: 5.356799]\n",
            "Validating on test set\n",
            "Validation Metrics: 795 [D loss: 1.646927, acc.: 100.00%, op_acc: 49.71%] [G loss: 5.668520]\n",
            "(1024, 1)\n",
            "Training Metrics: 796 [D loss: 1.305469, acc.: 99.27%, op_acc: 57.47%] [G loss: 5.996805]\n",
            "Validating on test set\n",
            "Validation Metrics: 796 [D loss: 1.366863, acc.: 100.00%, op_acc: 55.37%] [G loss: 5.671405]\n",
            "(1024, 1)\n",
            "Training Metrics: 797 [D loss: 1.246969, acc.: 99.22%, op_acc: 59.77%] [G loss: 5.987434]\n",
            "Validating on test set\n",
            "Validation Metrics: 797 [D loss: 1.047731, acc.: 100.00%, op_acc: 72.07%] [G loss: 5.957594]\n",
            "(1024, 1)\n",
            "Training Metrics: 798 [D loss: 1.006046, acc.: 99.41%, op_acc: 70.07%] [G loss: 5.858146]\n",
            "Validating on test set\n",
            "Validation Metrics: 798 [D loss: 1.030719, acc.: 100.00%, op_acc: 70.12%] [G loss: 5.845836]\n",
            "(1024, 1)\n",
            "Training Metrics: 799 [D loss: 1.067352, acc.: 99.27%, op_acc: 64.16%] [G loss: 5.692770]\n",
            "Validating on test set\n",
            "Validation Metrics: 799 [D loss: 0.950474, acc.: 100.00%, op_acc: 77.83%] [G loss: 5.670103]\n",
            "(1024, 1)\n",
            "Training Metrics: 800 [D loss: 1.025763, acc.: 99.12%, op_acc: 72.80%] [G loss: 5.584707]\n",
            "Validating on test set\n",
            "Validation Metrics: 800 [D loss: 0.806397, acc.: 100.00%, op_acc: 87.50%] [G loss: 5.539623]\n",
            "(1024, 1)\n",
            "Training Metrics: 801 [D loss: 0.921793, acc.: 99.46%, op_acc: 76.03%] [G loss: 5.607481]\n",
            "Validating on test set\n",
            "Validation Metrics: 801 [D loss: 0.823986, acc.: 100.00%, op_acc: 83.69%] [G loss: 5.578599]\n",
            "(1024, 1)\n",
            "Training Metrics: 802 [D loss: 0.951667, acc.: 99.32%, op_acc: 72.85%] [G loss: 5.534537]\n",
            "Validating on test set\n",
            "Validation Metrics: 802 [D loss: 0.850894, acc.: 100.00%, op_acc: 82.91%] [G loss: 5.539055]\n",
            "(1024, 1)\n",
            "Training Metrics: 803 [D loss: 0.926609, acc.: 99.17%, op_acc: 75.34%] [G loss: 5.451644]\n",
            "Validating on test set\n",
            "Validation Metrics: 803 [D loss: 0.770892, acc.: 100.00%, op_acc: 86.13%] [G loss: 5.539985]\n",
            "(1024, 1)\n",
            "Training Metrics: 804 [D loss: 0.952702, acc.: 99.37%, op_acc: 73.29%] [G loss: 5.519818]\n",
            "Validating on test set\n",
            "Validation Metrics: 804 [D loss: 0.901147, acc.: 100.00%, op_acc: 78.12%] [G loss: 5.563493]\n",
            "(1024, 1)\n",
            "Training Metrics: 805 [D loss: 0.938661, acc.: 99.46%, op_acc: 72.41%] [G loss: 5.736934]\n",
            "Validating on test set\n",
            "Validation Metrics: 805 [D loss: 0.759127, acc.: 100.00%, op_acc: 84.86%] [G loss: 5.758286]\n",
            "(1024, 1)\n",
            "Training Metrics: 806 [D loss: 0.875839, acc.: 99.27%, op_acc: 76.46%] [G loss: 5.609057]\n",
            "Validating on test set\n",
            "Validation Metrics: 806 [D loss: 0.766505, acc.: 100.00%, op_acc: 85.45%] [G loss: 5.611596]\n",
            "(1024, 1)\n",
            "Training Metrics: 807 [D loss: 0.903548, acc.: 99.32%, op_acc: 75.00%] [G loss: 5.607553]\n",
            "Validating on test set\n",
            "Validation Metrics: 807 [D loss: 0.712989, acc.: 100.00%, op_acc: 84.18%] [G loss: 5.520000]\n",
            "(1024, 1)\n",
            "Training Metrics: 808 [D loss: 0.844742, acc.: 99.32%, op_acc: 75.98%] [G loss: 5.398787]\n",
            "Validating on test set\n",
            "Validation Metrics: 808 [D loss: 0.643609, acc.: 100.00%, op_acc: 92.97%] [G loss: 5.370375]\n",
            "(1024, 1)\n",
            "Training Metrics: 809 [D loss: 0.825333, acc.: 99.51%, op_acc: 78.32%] [G loss: 5.372284]\n",
            "Validating on test set\n",
            "Validation Metrics: 809 [D loss: 0.569384, acc.: 100.00%, op_acc: 92.48%] [G loss: 5.238642]\n",
            "(1024, 1)\n",
            "Training Metrics: 810 [D loss: 0.802367, acc.: 99.61%, op_acc: 78.08%] [G loss: 5.236765]\n",
            "Validating on test set\n",
            "Validation Metrics: 810 [D loss: 0.634913, acc.: 100.00%, op_acc: 83.79%] [G loss: 5.223643]\n",
            "(1024, 1)\n",
            "Training Metrics: 811 [D loss: 0.798387, acc.: 99.46%, op_acc: 74.85%] [G loss: 5.004755]\n",
            "Validating on test set\n",
            "Validation Metrics: 811 [D loss: 0.653975, acc.: 100.00%, op_acc: 91.89%] [G loss: 5.279085]\n",
            "(1024, 1)\n",
            "Training Metrics: 812 [D loss: 0.893840, acc.: 99.32%, op_acc: 76.66%] [G loss: 5.519120]\n",
            "Validating on test set\n",
            "Validation Metrics: 812 [D loss: 0.649718, acc.: 100.00%, op_acc: 95.80%] [G loss: 5.464564]\n",
            "(1024, 1)\n",
            "Training Metrics: 813 [D loss: 0.827558, acc.: 99.37%, op_acc: 79.30%] [G loss: 5.484496]\n",
            "Validating on test set\n",
            "Validation Metrics: 813 [D loss: 0.542736, acc.: 100.00%, op_acc: 95.80%] [G loss: 5.510113]\n",
            "(1024, 1)\n",
            "Training Metrics: 814 [D loss: 0.776273, acc.: 99.22%, op_acc: 79.25%] [G loss: 5.600970]\n",
            "Validating on test set\n",
            "Validation Metrics: 814 [D loss: 0.529376, acc.: 100.00%, op_acc: 96.48%] [G loss: 5.559824]\n",
            "(1024, 1)\n",
            "Training Metrics: 815 [D loss: 0.759843, acc.: 99.56%, op_acc: 81.25%] [G loss: 5.537966]\n",
            "Validating on test set\n",
            "Validation Metrics: 815 [D loss: 0.631468, acc.: 100.00%, op_acc: 88.18%] [G loss: 5.518228]\n",
            "(1024, 1)\n",
            "Training Metrics: 816 [D loss: 0.848643, acc.: 99.41%, op_acc: 76.32%] [G loss: 5.086159]\n",
            "Validating on test set\n",
            "Validation Metrics: 816 [D loss: 0.730032, acc.: 100.00%, op_acc: 80.37%] [G loss: 5.504762]\n",
            "(1024, 1)\n",
            "Training Metrics: 817 [D loss: 0.869398, acc.: 99.66%, op_acc: 71.88%] [G loss: 5.771160]\n",
            "Validating on test set\n",
            "Validation Metrics: 817 [D loss: 0.581574, acc.: 100.00%, op_acc: 92.29%] [G loss: 5.685724]\n",
            "(1024, 1)\n",
            "Training Metrics: 818 [D loss: 0.816741, acc.: 99.37%, op_acc: 77.69%] [G loss: 5.876563]\n",
            "Validating on test set\n",
            "Validation Metrics: 818 [D loss: 0.562080, acc.: 100.00%, op_acc: 90.72%] [G loss: 5.867954]\n",
            "(1024, 1)\n",
            "Training Metrics: 819 [D loss: 0.818911, acc.: 99.27%, op_acc: 78.47%] [G loss: 5.509799]\n",
            "Validating on test set\n",
            "Validation Metrics: 819 [D loss: 0.643184, acc.: 100.00%, op_acc: 87.01%] [G loss: 5.507506]\n",
            "(1024, 1)\n",
            "Training Metrics: 820 [D loss: 0.824259, acc.: 99.61%, op_acc: 77.34%] [G loss: 5.404090]\n",
            "Validating on test set\n",
            "Validation Metrics: 820 [D loss: 0.573743, acc.: 100.00%, op_acc: 90.23%] [G loss: 5.462873]\n",
            "(1024, 1)\n",
            "Training Metrics: 821 [D loss: 0.822189, acc.: 99.56%, op_acc: 76.27%] [G loss: 5.287743]\n",
            "Validating on test set\n",
            "Validation Metrics: 821 [D loss: 0.806254, acc.: 100.00%, op_acc: 76.37%] [G loss: 5.461318]\n",
            "(1024, 1)\n",
            "Training Metrics: 822 [D loss: 0.920116, acc.: 99.61%, op_acc: 69.87%] [G loss: 5.814523]\n",
            "Validating on test set\n",
            "Validation Metrics: 822 [D loss: 0.586399, acc.: 100.00%, op_acc: 85.64%] [G loss: 5.754357]\n",
            "(1024, 1)\n",
            "Training Metrics: 823 [D loss: 0.856042, acc.: 99.41%, op_acc: 74.51%] [G loss: 5.723663]\n",
            "Validating on test set\n",
            "Validation Metrics: 823 [D loss: 0.464599, acc.: 100.00%, op_acc: 95.51%] [G loss: 5.609218]\n",
            "(1024, 1)\n",
            "Training Metrics: 824 [D loss: 0.751447, acc.: 99.22%, op_acc: 80.27%] [G loss: 5.380383]\n",
            "Validating on test set\n",
            "Validation Metrics: 824 [D loss: 0.414814, acc.: 100.00%, op_acc: 97.27%] [G loss: 5.352950]\n",
            "(1024, 1)\n",
            "Training Metrics: 825 [D loss: 0.727801, acc.: 99.46%, op_acc: 81.93%] [G loss: 5.503464]\n",
            "Validating on test set\n",
            "Validation Metrics: 825 [D loss: 0.431280, acc.: 100.00%, op_acc: 96.48%] [G loss: 5.497254]\n",
            "(1024, 1)\n",
            "Training Metrics: 826 [D loss: 0.691366, acc.: 99.51%, op_acc: 80.42%] [G loss: 5.493157]\n",
            "Validating on test set\n",
            "Validation Metrics: 826 [D loss: 0.444669, acc.: 100.00%, op_acc: 95.12%] [G loss: 5.535434]\n",
            "(1024, 1)\n",
            "Training Metrics: 827 [D loss: 0.715895, acc.: 99.56%, op_acc: 80.03%] [G loss: 5.463214]\n",
            "Validating on test set\n",
            "Validation Metrics: 827 [D loss: 0.419092, acc.: 100.00%, op_acc: 96.39%] [G loss: 5.436580]\n",
            "(1024, 1)\n",
            "Training Metrics: 828 [D loss: 0.718779, acc.: 99.22%, op_acc: 81.01%] [G loss: 5.258351]\n",
            "Validating on test set\n",
            "Validation Metrics: 828 [D loss: 0.375426, acc.: 100.00%, op_acc: 97.36%] [G loss: 5.219889]\n",
            "(1024, 1)\n",
            "Training Metrics: 829 [D loss: 0.705843, acc.: 99.71%, op_acc: 80.66%] [G loss: 5.471251]\n",
            "Validating on test set\n",
            "Validation Metrics: 829 [D loss: 0.384363, acc.: 100.00%, op_acc: 96.88%] [G loss: 5.465672]\n",
            "(1024, 1)\n",
            "Training Metrics: 830 [D loss: 0.738023, acc.: 99.51%, op_acc: 80.76%] [G loss: 5.359047]\n",
            "Validating on test set\n",
            "Validation Metrics: 830 [D loss: 0.352949, acc.: 100.00%, op_acc: 97.36%] [G loss: 5.384943]\n",
            "(1024, 1)\n",
            "Training Metrics: 831 [D loss: 0.712813, acc.: 99.46%, op_acc: 82.08%] [G loss: 5.391462]\n",
            "Validating on test set\n",
            "Validation Metrics: 831 [D loss: 0.370198, acc.: 100.00%, op_acc: 97.95%] [G loss: 5.368696]\n",
            "(1024, 1)\n",
            "Training Metrics: 832 [D loss: 0.702923, acc.: 99.66%, op_acc: 82.42%] [G loss: 5.476073]\n",
            "Validating on test set\n",
            "Validation Metrics: 832 [D loss: 0.369736, acc.: 100.00%, op_acc: 97.66%] [G loss: 5.481858]\n",
            "(1024, 1)\n",
            "Training Metrics: 833 [D loss: 0.696888, acc.: 99.56%, op_acc: 81.05%] [G loss: 5.527428]\n",
            "Validating on test set\n",
            "Validation Metrics: 833 [D loss: 0.367310, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.510808]\n",
            "(1024, 1)\n",
            "Training Metrics: 834 [D loss: 0.690130, acc.: 99.46%, op_acc: 81.98%] [G loss: 5.364722]\n",
            "Validating on test set\n",
            "Validation Metrics: 834 [D loss: 0.351447, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.368559]\n",
            "(1024, 1)\n",
            "Training Metrics: 835 [D loss: 0.678095, acc.: 99.61%, op_acc: 81.93%] [G loss: 5.542192]\n",
            "Validating on test set\n",
            "Validation Metrics: 835 [D loss: 0.351465, acc.: 100.00%, op_acc: 97.95%] [G loss: 5.508551]\n",
            "(1024, 1)\n",
            "Training Metrics: 836 [D loss: 0.671658, acc.: 99.61%, op_acc: 81.74%] [G loss: 5.516213]\n",
            "Validating on test set\n",
            "Validation Metrics: 836 [D loss: 0.338670, acc.: 100.00%, op_acc: 98.05%] [G loss: 5.519660]\n",
            "(1024, 1)\n",
            "Training Metrics: 837 [D loss: 0.687496, acc.: 99.66%, op_acc: 81.74%] [G loss: 5.510329]\n",
            "Validating on test set\n",
            "Validation Metrics: 837 [D loss: 0.341724, acc.: 100.00%, op_acc: 98.34%] [G loss: 5.484627]\n",
            "(1024, 1)\n",
            "Training Metrics: 838 [D loss: 0.664854, acc.: 99.51%, op_acc: 81.88%] [G loss: 5.544023]\n",
            "Validating on test set\n",
            "Validation Metrics: 838 [D loss: 0.327386, acc.: 100.00%, op_acc: 98.05%] [G loss: 5.578533]\n",
            "(1024, 1)\n",
            "Training Metrics: 839 [D loss: 0.695192, acc.: 99.66%, op_acc: 80.62%] [G loss: 5.581272]\n",
            "Validating on test set\n",
            "Validation Metrics: 839 [D loss: 0.325361, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.556272]\n",
            "(1024, 1)\n",
            "Training Metrics: 840 [D loss: 0.690253, acc.: 99.51%, op_acc: 81.54%] [G loss: 5.543331]\n",
            "Validating on test set\n",
            "Validation Metrics: 840 [D loss: 0.312674, acc.: 100.00%, op_acc: 98.54%] [G loss: 5.538692]\n",
            "(1024, 1)\n",
            "Training Metrics: 841 [D loss: 0.640498, acc.: 99.61%, op_acc: 81.88%] [G loss: 5.408330]\n",
            "Validating on test set\n",
            "Validation Metrics: 841 [D loss: 0.331391, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.410229]\n",
            "(1024, 1)\n",
            "Training Metrics: 842 [D loss: 0.671107, acc.: 99.41%, op_acc: 83.01%] [G loss: 5.461669]\n",
            "Validating on test set\n",
            "Validation Metrics: 842 [D loss: 0.333281, acc.: 100.00%, op_acc: 96.88%] [G loss: 5.443963]\n",
            "(1024, 1)\n",
            "Training Metrics: 843 [D loss: 0.593788, acc.: 99.56%, op_acc: 83.84%] [G loss: 5.448833]\n",
            "Validating on test set\n",
            "Validation Metrics: 843 [D loss: 0.320007, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.461576]\n",
            "(1024, 1)\n",
            "Training Metrics: 844 [D loss: 0.646753, acc.: 99.76%, op_acc: 82.03%] [G loss: 5.576739]\n",
            "Validating on test set\n",
            "Validation Metrics: 844 [D loss: 0.349361, acc.: 100.00%, op_acc: 97.85%] [G loss: 5.624256]\n",
            "(1024, 1)\n",
            "Training Metrics: 845 [D loss: 0.717904, acc.: 99.37%, op_acc: 80.08%] [G loss: 5.558782]\n",
            "Validating on test set\n",
            "Validation Metrics: 845 [D loss: 0.524110, acc.: 100.00%, op_acc: 90.53%] [G loss: 5.705251]\n",
            "(1024, 1)\n",
            "Training Metrics: 846 [D loss: 0.758239, acc.: 99.71%, op_acc: 79.20%] [G loss: 5.692853]\n",
            "Validating on test set\n",
            "Validation Metrics: 846 [D loss: 0.398393, acc.: 100.00%, op_acc: 91.50%] [G loss: 5.745709]\n",
            "(1024, 1)\n",
            "Training Metrics: 847 [D loss: 0.770572, acc.: 99.66%, op_acc: 76.86%] [G loss: 5.879648]\n",
            "Validating on test set\n",
            "Validation Metrics: 847 [D loss: 0.384163, acc.: 100.00%, op_acc: 95.41%] [G loss: 5.879131]\n",
            "(1024, 1)\n",
            "Training Metrics: 848 [D loss: 0.724229, acc.: 99.56%, op_acc: 80.37%] [G loss: 5.650441]\n",
            "Validating on test set\n",
            "Validation Metrics: 848 [D loss: 0.334470, acc.: 100.00%, op_acc: 97.95%] [G loss: 5.575531]\n",
            "(1024, 1)\n",
            "Training Metrics: 849 [D loss: 0.679202, acc.: 99.46%, op_acc: 81.35%] [G loss: 5.705630]\n",
            "Validating on test set\n",
            "Validation Metrics: 849 [D loss: 0.286512, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.685375]\n",
            "(1024, 1)\n",
            "Training Metrics: 850 [D loss: 0.657060, acc.: 99.85%, op_acc: 82.23%] [G loss: 5.668867]\n",
            "Validating on test set\n",
            "Validation Metrics: 850 [D loss: 0.317823, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.646012]\n",
            "(1024, 1)\n",
            "Training Metrics: 851 [D loss: 0.672339, acc.: 99.56%, op_acc: 81.01%] [G loss: 5.609409]\n",
            "Validating on test set\n",
            "Validation Metrics: 851 [D loss: 0.278228, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.544038]\n",
            "(1024, 1)\n",
            "Training Metrics: 852 [D loss: 0.678890, acc.: 99.66%, op_acc: 80.42%] [G loss: 5.532410]\n",
            "Validating on test set\n",
            "Validation Metrics: 852 [D loss: 0.495730, acc.: 100.00%, op_acc: 89.26%] [G loss: 5.965023]\n",
            "(1024, 1)\n",
            "Training Metrics: 853 [D loss: 0.786108, acc.: 99.51%, op_acc: 77.59%] [G loss: 5.505414]\n",
            "Validating on test set\n",
            "Validation Metrics: 853 [D loss: 0.819584, acc.: 100.00%, op_acc: 79.10%] [G loss: 5.856698]\n",
            "(1024, 1)\n",
            "Training Metrics: 854 [D loss: 0.904200, acc.: 99.90%, op_acc: 72.46%] [G loss: 5.216012]\n",
            "Validating on test set\n",
            "Validation Metrics: 854 [D loss: 0.488749, acc.: 100.00%, op_acc: 88.28%] [G loss: 5.121252]\n",
            "(1024, 1)\n",
            "Training Metrics: 855 [D loss: 0.776490, acc.: 99.61%, op_acc: 75.20%] [G loss: 5.265443]\n",
            "Validating on test set\n",
            "Validation Metrics: 855 [D loss: 0.413600, acc.: 100.00%, op_acc: 96.48%] [G loss: 5.171759]\n",
            "(1024, 1)\n",
            "Training Metrics: 856 [D loss: 0.763083, acc.: 99.56%, op_acc: 79.74%] [G loss: 5.580990]\n",
            "Validating on test set\n",
            "Validation Metrics: 856 [D loss: 0.363204, acc.: 100.00%, op_acc: 93.55%] [G loss: 5.535388]\n",
            "(1024, 1)\n",
            "Training Metrics: 857 [D loss: 0.721849, acc.: 99.80%, op_acc: 77.69%] [G loss: 5.378046]\n",
            "Validating on test set\n",
            "Validation Metrics: 857 [D loss: 0.375067, acc.: 100.00%, op_acc: 92.97%] [G loss: 5.310815]\n",
            "(1024, 1)\n",
            "Training Metrics: 858 [D loss: 0.716410, acc.: 99.80%, op_acc: 79.25%] [G loss: 5.620456]\n",
            "Validating on test set\n",
            "Validation Metrics: 858 [D loss: 0.291533, acc.: 100.00%, op_acc: 97.85%] [G loss: 5.565265]\n",
            "(1024, 1)\n",
            "Training Metrics: 859 [D loss: 0.656907, acc.: 99.90%, op_acc: 80.47%] [G loss: 5.338221]\n",
            "Validating on test set\n",
            "Validation Metrics: 859 [D loss: 0.299206, acc.: 100.00%, op_acc: 97.95%] [G loss: 5.290294]\n",
            "(1024, 1)\n",
            "Training Metrics: 860 [D loss: 0.662096, acc.: 99.66%, op_acc: 81.49%] [G loss: 5.357859]\n",
            "Validating on test set\n",
            "Validation Metrics: 860 [D loss: 0.287140, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.348028]\n",
            "(1024, 1)\n",
            "Training Metrics: 861 [D loss: 0.621141, acc.: 99.85%, op_acc: 82.23%] [G loss: 5.390907]\n",
            "Validating on test set\n",
            "Validation Metrics: 861 [D loss: 0.247015, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.474417]\n",
            "(1024, 1)\n",
            "Training Metrics: 862 [D loss: 0.653875, acc.: 99.76%, op_acc: 82.71%] [G loss: 5.565916]\n",
            "Validating on test set\n",
            "Validation Metrics: 862 [D loss: 0.263728, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.502584]\n",
            "(1024, 1)\n",
            "Training Metrics: 863 [D loss: 0.712626, acc.: 99.37%, op_acc: 81.45%] [G loss: 5.289699]\n",
            "Validating on test set\n",
            "Validation Metrics: 863 [D loss: 0.259853, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.289089]\n",
            "(1024, 1)\n",
            "Training Metrics: 864 [D loss: 0.613672, acc.: 99.51%, op_acc: 82.08%] [G loss: 5.396579]\n",
            "Validating on test set\n",
            "Validation Metrics: 864 [D loss: 0.235704, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.345238]\n",
            "(1024, 1)\n",
            "Training Metrics: 865 [D loss: 0.627579, acc.: 99.66%, op_acc: 82.28%] [G loss: 5.326198]\n",
            "Validating on test set\n",
            "Validation Metrics: 865 [D loss: 0.277797, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.379836]\n",
            "(1024, 1)\n",
            "Training Metrics: 866 [D loss: 0.579814, acc.: 99.66%, op_acc: 83.74%] [G loss: 5.500169]\n",
            "Validating on test set\n",
            "Validation Metrics: 866 [D loss: 0.263840, acc.: 100.00%, op_acc: 97.75%] [G loss: 5.525461]\n",
            "(1024, 1)\n",
            "Training Metrics: 867 [D loss: 0.595418, acc.: 99.56%, op_acc: 83.45%] [G loss: 5.481060]\n",
            "Validating on test set\n",
            "Validation Metrics: 867 [D loss: 0.463079, acc.: 100.00%, op_acc: 91.41%] [G loss: 5.682413]\n",
            "(1024, 1)\n",
            "Training Metrics: 868 [D loss: 0.766124, acc.: 99.51%, op_acc: 77.34%] [G loss: 5.985261]\n",
            "Validating on test set\n",
            "Validation Metrics: 868 [D loss: 0.409205, acc.: 100.00%, op_acc: 88.57%] [G loss: 6.016334]\n",
            "(1024, 1)\n",
            "Training Metrics: 869 [D loss: 0.740462, acc.: 99.85%, op_acc: 75.73%] [G loss: 5.848751]\n",
            "Validating on test set\n",
            "Validation Metrics: 869 [D loss: 0.403983, acc.: 100.00%, op_acc: 95.02%] [G loss: 6.014274]\n",
            "(1024, 1)\n",
            "Training Metrics: 870 [D loss: 0.681399, acc.: 99.71%, op_acc: 81.40%] [G loss: 6.289082]\n",
            "Validating on test set\n",
            "Validation Metrics: 870 [D loss: 0.284743, acc.: 100.00%, op_acc: 98.24%] [G loss: 6.304697]\n",
            "(1024, 1)\n",
            "Training Metrics: 871 [D loss: 0.672719, acc.: 99.56%, op_acc: 81.93%] [G loss: 6.240054]\n",
            "Validating on test set\n",
            "Validation Metrics: 871 [D loss: 0.248368, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.143529]\n",
            "(1024, 1)\n",
            "Training Metrics: 872 [D loss: 0.619527, acc.: 99.66%, op_acc: 82.13%] [G loss: 6.229107]\n",
            "Validating on test set\n",
            "Validation Metrics: 872 [D loss: 0.267021, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.213516]\n",
            "(1024, 1)\n",
            "Training Metrics: 873 [D loss: 0.606362, acc.: 99.71%, op_acc: 83.89%] [G loss: 6.176663]\n",
            "Validating on test set\n",
            "Validation Metrics: 873 [D loss: 0.253663, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.102087]\n",
            "(1024, 1)\n",
            "Training Metrics: 874 [D loss: 0.609349, acc.: 99.71%, op_acc: 82.86%] [G loss: 5.985174]\n",
            "Validating on test set\n",
            "Validation Metrics: 874 [D loss: 0.249563, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.915174]\n",
            "(1024, 1)\n",
            "Training Metrics: 875 [D loss: 0.599633, acc.: 99.80%, op_acc: 83.59%] [G loss: 5.872753]\n",
            "Validating on test set\n",
            "Validation Metrics: 875 [D loss: 0.250567, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.826917]\n",
            "(1024, 1)\n",
            "Training Metrics: 876 [D loss: 0.619073, acc.: 99.46%, op_acc: 82.28%] [G loss: 5.744854]\n",
            "Validating on test set\n",
            "Validation Metrics: 876 [D loss: 0.281150, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.746592]\n",
            "(1024, 1)\n",
            "Training Metrics: 877 [D loss: 0.642215, acc.: 99.61%, op_acc: 83.06%] [G loss: 5.439481]\n",
            "Validating on test set\n",
            "Validation Metrics: 877 [D loss: 0.258215, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.697888]\n",
            "(1024, 1)\n",
            "Training Metrics: 878 [D loss: 0.652125, acc.: 99.56%, op_acc: 80.47%] [G loss: 5.949640]\n",
            "Validating on test set\n",
            "Validation Metrics: 878 [D loss: 0.246086, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.933018]\n",
            "(1024, 1)\n",
            "Training Metrics: 879 [D loss: 0.654248, acc.: 99.66%, op_acc: 81.20%] [G loss: 5.652588]\n",
            "Validating on test set\n",
            "Validation Metrics: 879 [D loss: 0.251970, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.635152]\n",
            "(1024, 1)\n",
            "Training Metrics: 880 [D loss: 0.621824, acc.: 99.71%, op_acc: 81.84%] [G loss: 5.876940]\n",
            "Validating on test set\n",
            "Validation Metrics: 880 [D loss: 0.254912, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.874309]\n",
            "(1024, 1)\n",
            "Training Metrics: 881 [D loss: 0.660815, acc.: 99.66%, op_acc: 82.18%] [G loss: 5.790846]\n",
            "Validating on test set\n",
            "Validation Metrics: 881 [D loss: 0.258327, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.768137]\n",
            "(1024, 1)\n",
            "Training Metrics: 882 [D loss: 0.641400, acc.: 99.71%, op_acc: 81.40%] [G loss: 5.752509]\n",
            "Validating on test set\n",
            "Validation Metrics: 882 [D loss: 0.243879, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.758643]\n",
            "(1024, 1)\n",
            "Training Metrics: 883 [D loss: 0.618735, acc.: 99.76%, op_acc: 82.96%] [G loss: 5.865421]\n",
            "Validating on test set\n",
            "Validation Metrics: 883 [D loss: 0.232494, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.846306]\n",
            "(1024, 1)\n",
            "Training Metrics: 884 [D loss: 0.657734, acc.: 99.85%, op_acc: 79.98%] [G loss: 5.879687]\n",
            "Validating on test set\n",
            "Validation Metrics: 884 [D loss: 0.242847, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.863517]\n",
            "(1024, 1)\n",
            "Training Metrics: 885 [D loss: 0.628016, acc.: 99.71%, op_acc: 82.18%] [G loss: 5.879581]\n",
            "Validating on test set\n",
            "Validation Metrics: 885 [D loss: 0.251214, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.881034]\n",
            "(1024, 1)\n",
            "Training Metrics: 886 [D loss: 0.634075, acc.: 99.66%, op_acc: 82.13%] [G loss: 6.040208]\n",
            "Validating on test set\n",
            "Validation Metrics: 886 [D loss: 0.248285, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.043235]\n",
            "(1024, 1)\n",
            "Training Metrics: 887 [D loss: 0.626391, acc.: 99.85%, op_acc: 81.98%] [G loss: 6.062470]\n",
            "Validating on test set\n",
            "Validation Metrics: 887 [D loss: 0.263290, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.074574]\n",
            "(1024, 1)\n",
            "Training Metrics: 888 [D loss: 0.620517, acc.: 99.61%, op_acc: 83.50%] [G loss: 6.027399]\n",
            "Validating on test set\n",
            "Validation Metrics: 888 [D loss: 0.241899, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.020253]\n",
            "(1024, 1)\n",
            "Training Metrics: 889 [D loss: 0.589792, acc.: 99.66%, op_acc: 83.30%] [G loss: 5.979448]\n",
            "Validating on test set\n",
            "Validation Metrics: 889 [D loss: 0.241421, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.987596]\n",
            "(1024, 1)\n",
            "Training Metrics: 890 [D loss: 0.633624, acc.: 99.71%, op_acc: 81.64%] [G loss: 6.079506]\n",
            "Validating on test set\n",
            "Validation Metrics: 890 [D loss: 0.239421, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.076406]\n",
            "(1024, 1)\n",
            "Training Metrics: 891 [D loss: 0.626283, acc.: 99.71%, op_acc: 81.59%] [G loss: 5.872835]\n",
            "Validating on test set\n",
            "Validation Metrics: 891 [D loss: 0.250566, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.856100]\n",
            "(1024, 1)\n",
            "Training Metrics: 892 [D loss: 0.598445, acc.: 99.76%, op_acc: 82.67%] [G loss: 6.282517]\n",
            "Validating on test set\n",
            "Validation Metrics: 892 [D loss: 0.244957, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.301856]\n",
            "(1024, 1)\n",
            "Training Metrics: 893 [D loss: 0.704025, acc.: 99.61%, op_acc: 81.30%] [G loss: 5.845011]\n",
            "Validating on test set\n",
            "Validation Metrics: 893 [D loss: 0.266556, acc.: 100.00%, op_acc: 98.44%] [G loss: 5.852979]\n",
            "(1024, 1)\n",
            "Training Metrics: 894 [D loss: 0.678610, acc.: 99.80%, op_acc: 81.93%] [G loss: 6.020544]\n",
            "Validating on test set\n",
            "Validation Metrics: 894 [D loss: 0.251628, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.010921]\n",
            "(1024, 1)\n",
            "Training Metrics: 895 [D loss: 0.709155, acc.: 99.56%, op_acc: 80.81%] [G loss: 5.807534]\n",
            "Validating on test set\n",
            "Validation Metrics: 895 [D loss: 0.243771, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.779229]\n",
            "(1024, 1)\n",
            "Training Metrics: 896 [D loss: 0.633684, acc.: 99.85%, op_acc: 81.74%] [G loss: 6.165497]\n",
            "Validating on test set\n",
            "Validation Metrics: 896 [D loss: 0.271818, acc.: 100.00%, op_acc: 98.63%] [G loss: 6.201959]\n",
            "(1024, 1)\n",
            "Training Metrics: 897 [D loss: 0.644990, acc.: 99.51%, op_acc: 83.94%] [G loss: 5.779361]\n",
            "Validating on test set\n",
            "Validation Metrics: 897 [D loss: 0.227433, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.787418]\n",
            "(1024, 1)\n",
            "Training Metrics: 898 [D loss: 0.602067, acc.: 99.66%, op_acc: 82.91%] [G loss: 5.911468]\n",
            "Validating on test set\n",
            "Validation Metrics: 898 [D loss: 0.247580, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.883618]\n",
            "(1024, 1)\n",
            "Training Metrics: 899 [D loss: 0.603019, acc.: 99.66%, op_acc: 83.40%] [G loss: 5.852057]\n",
            "Validating on test set\n",
            "Validation Metrics: 899 [D loss: 0.239037, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.861144]\n",
            "(1024, 1)\n",
            "Training Metrics: 900 [D loss: 0.618988, acc.: 99.80%, op_acc: 83.20%] [G loss: 5.868324]\n",
            "Validating on test set\n",
            "Validation Metrics: 900 [D loss: 0.243723, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.862357]\n",
            "(1024, 1)\n",
            "Training Metrics: 901 [D loss: 0.633415, acc.: 99.66%, op_acc: 81.88%] [G loss: 5.785848]\n",
            "Validating on test set\n",
            "Validation Metrics: 901 [D loss: 0.259461, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.793697]\n",
            "(1024, 1)\n",
            "Training Metrics: 902 [D loss: 0.627257, acc.: 99.95%, op_acc: 81.93%] [G loss: 6.092570]\n",
            "Validating on test set\n",
            "Validation Metrics: 902 [D loss: 0.236166, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.050491]\n",
            "(1024, 1)\n",
            "Training Metrics: 903 [D loss: 0.613582, acc.: 99.71%, op_acc: 83.11%] [G loss: 6.061509]\n",
            "Validating on test set\n",
            "Validation Metrics: 903 [D loss: 0.266141, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.054188]\n",
            "(1024, 1)\n",
            "Training Metrics: 904 [D loss: 0.691951, acc.: 99.80%, op_acc: 78.71%] [G loss: 6.263293]\n",
            "Validating on test set\n",
            "Validation Metrics: 904 [D loss: 0.278499, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.283851]\n",
            "(1024, 1)\n",
            "Training Metrics: 905 [D loss: 0.809099, acc.: 99.80%, op_acc: 80.71%] [G loss: 6.230949]\n",
            "Validating on test set\n",
            "Validation Metrics: 905 [D loss: 0.354448, acc.: 100.00%, op_acc: 94.73%] [G loss: 6.334140]\n",
            "(1024, 1)\n",
            "Training Metrics: 906 [D loss: 0.688372, acc.: 99.61%, op_acc: 80.18%] [G loss: 6.318254]\n",
            "Validating on test set\n",
            "Validation Metrics: 906 [D loss: 0.500628, acc.: 100.00%, op_acc: 89.75%] [G loss: 6.491841]\n",
            "(1024, 1)\n",
            "Training Metrics: 907 [D loss: 0.727910, acc.: 99.71%, op_acc: 77.05%] [G loss: 6.191487]\n",
            "Validating on test set\n",
            "Validation Metrics: 907 [D loss: 0.573374, acc.: 100.00%, op_acc: 85.06%] [G loss: 6.288333]\n",
            "(1024, 1)\n",
            "Training Metrics: 908 [D loss: 0.860350, acc.: 99.76%, op_acc: 75.59%] [G loss: 6.351965]\n",
            "Validating on test set\n",
            "Validation Metrics: 908 [D loss: 0.498591, acc.: 100.00%, op_acc: 89.16%] [G loss: 6.474541]\n",
            "(1024, 1)\n",
            "Training Metrics: 909 [D loss: 0.782023, acc.: 99.71%, op_acc: 75.49%] [G loss: 5.872987]\n",
            "Validating on test set\n",
            "Validation Metrics: 909 [D loss: 0.589758, acc.: 100.00%, op_acc: 80.96%] [G loss: 5.953609]\n",
            "(1024, 1)\n",
            "Training Metrics: 910 [D loss: 0.838482, acc.: 99.85%, op_acc: 71.14%] [G loss: 6.388327]\n",
            "Validating on test set\n",
            "Validation Metrics: 910 [D loss: 0.724928, acc.: 100.00%, op_acc: 80.37%] [G loss: 6.663348]\n",
            "(1024, 1)\n",
            "Training Metrics: 911 [D loss: 0.837455, acc.: 99.76%, op_acc: 75.00%] [G loss: 6.740685]\n",
            "Validating on test set\n",
            "Validation Metrics: 911 [D loss: 1.923624, acc.: 100.00%, op_acc: 70.02%] [G loss: 8.051899]\n",
            "(1024, 1)\n",
            "Training Metrics: 912 [D loss: 1.518620, acc.: 99.80%, op_acc: 67.63%] [G loss: 8.034990]\n",
            "Validating on test set\n",
            "Validation Metrics: 912 [D loss: 0.847232, acc.: 100.00%, op_acc: 79.69%] [G loss: 7.071501]\n",
            "(1024, 1)\n",
            "Training Metrics: 913 [D loss: 0.903455, acc.: 99.80%, op_acc: 72.75%] [G loss: 7.199184]\n",
            "Validating on test set\n",
            "Validation Metrics: 913 [D loss: 0.823328, acc.: 100.00%, op_acc: 74.12%] [G loss: 7.323274]\n",
            "(1024, 1)\n",
            "Training Metrics: 914 [D loss: 0.936205, acc.: 99.66%, op_acc: 70.12%] [G loss: 6.830870]\n",
            "Validating on test set\n",
            "Validation Metrics: 914 [D loss: 0.488973, acc.: 100.00%, op_acc: 87.30%] [G loss: 6.537492]\n",
            "(1024, 1)\n",
            "Training Metrics: 915 [D loss: 0.737117, acc.: 99.61%, op_acc: 76.81%] [G loss: 6.223655]\n",
            "Validating on test set\n",
            "Validation Metrics: 915 [D loss: 0.443969, acc.: 100.00%, op_acc: 91.60%] [G loss: 6.165483]\n",
            "(1024, 1)\n",
            "Training Metrics: 916 [D loss: 0.676296, acc.: 99.76%, op_acc: 79.44%] [G loss: 5.999899]\n",
            "Validating on test set\n",
            "Validation Metrics: 916 [D loss: 0.426800, acc.: 100.00%, op_acc: 91.89%] [G loss: 5.970730]\n",
            "(1024, 1)\n",
            "Training Metrics: 917 [D loss: 0.718880, acc.: 99.85%, op_acc: 78.47%] [G loss: 6.290052]\n",
            "Validating on test set\n",
            "Validation Metrics: 917 [D loss: 0.386905, acc.: 100.00%, op_acc: 96.97%] [G loss: 6.266889]\n",
            "(1024, 1)\n",
            "Training Metrics: 918 [D loss: 0.718293, acc.: 99.76%, op_acc: 80.86%] [G loss: 6.109621]\n",
            "Validating on test set\n",
            "Validation Metrics: 918 [D loss: 0.358349, acc.: 100.00%, op_acc: 98.73%] [G loss: 6.063836]\n",
            "(1024, 1)\n",
            "Training Metrics: 919 [D loss: 0.696225, acc.: 99.85%, op_acc: 82.86%] [G loss: 6.179193]\n",
            "Validating on test set\n",
            "Validation Metrics: 919 [D loss: 0.327193, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.130075]\n",
            "(1024, 1)\n",
            "Training Metrics: 920 [D loss: 0.675481, acc.: 99.76%, op_acc: 82.03%] [G loss: 6.075106]\n",
            "Validating on test set\n",
            "Validation Metrics: 920 [D loss: 0.344638, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.051956]\n",
            "(1024, 1)\n",
            "Training Metrics: 921 [D loss: 0.664795, acc.: 99.66%, op_acc: 81.54%] [G loss: 6.169641]\n",
            "Validating on test set\n",
            "Validation Metrics: 921 [D loss: 0.329762, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.151569]\n",
            "(1024, 1)\n",
            "Training Metrics: 922 [D loss: 0.685830, acc.: 99.61%, op_acc: 82.13%] [G loss: 6.171545]\n",
            "Validating on test set\n",
            "Validation Metrics: 922 [D loss: 0.366691, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.163390]\n",
            "(1024, 1)\n",
            "Training Metrics: 923 [D loss: 0.717921, acc.: 99.66%, op_acc: 82.08%] [G loss: 5.911816]\n",
            "Validating on test set\n",
            "Validation Metrics: 923 [D loss: 0.309585, acc.: 100.00%, op_acc: 97.66%] [G loss: 5.907885]\n",
            "(1024, 1)\n",
            "Training Metrics: 924 [D loss: 0.646525, acc.: 99.85%, op_acc: 81.84%] [G loss: 6.241424]\n",
            "Validating on test set\n",
            "Validation Metrics: 924 [D loss: 0.399527, acc.: 100.00%, op_acc: 95.12%] [G loss: 6.247476]\n",
            "(1024, 1)\n",
            "Training Metrics: 925 [D loss: 0.693553, acc.: 99.80%, op_acc: 79.93%] [G loss: 6.222931]\n",
            "Validating on test set\n",
            "Validation Metrics: 925 [D loss: 0.324887, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.213551]\n",
            "(1024, 1)\n",
            "Training Metrics: 926 [D loss: 0.681115, acc.: 99.76%, op_acc: 79.44%] [G loss: 6.135263]\n",
            "Validating on test set\n",
            "Validation Metrics: 926 [D loss: 0.355623, acc.: 100.00%, op_acc: 98.14%] [G loss: 6.123827]\n",
            "(1024, 1)\n",
            "Training Metrics: 927 [D loss: 0.686400, acc.: 99.66%, op_acc: 81.93%] [G loss: 6.050431]\n",
            "Validating on test set\n",
            "Validation Metrics: 927 [D loss: 0.357574, acc.: 100.00%, op_acc: 94.34%] [G loss: 6.089060]\n",
            "(1024, 1)\n",
            "Training Metrics: 928 [D loss: 0.666666, acc.: 99.71%, op_acc: 79.35%] [G loss: 6.098321]\n",
            "Validating on test set\n",
            "Validation Metrics: 928 [D loss: 0.292172, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.047924]\n",
            "(1024, 1)\n",
            "Training Metrics: 929 [D loss: 0.664467, acc.: 99.80%, op_acc: 82.71%] [G loss: 6.022799]\n",
            "Validating on test set\n",
            "Validation Metrics: 929 [D loss: 0.363637, acc.: 100.00%, op_acc: 97.36%] [G loss: 6.040465]\n",
            "(1024, 1)\n",
            "Training Metrics: 930 [D loss: 0.676003, acc.: 99.61%, op_acc: 81.93%] [G loss: 6.032029]\n",
            "Validating on test set\n",
            "Validation Metrics: 930 [D loss: 0.323916, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.033662]\n",
            "(1024, 1)\n",
            "Training Metrics: 931 [D loss: 0.631588, acc.: 100.00%, op_acc: 82.76%] [G loss: 6.202742]\n",
            "Validating on test set\n",
            "Validation Metrics: 931 [D loss: 0.285936, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.190563]\n",
            "(1024, 1)\n",
            "Training Metrics: 932 [D loss: 0.669767, acc.: 99.61%, op_acc: 81.93%] [G loss: 5.893420]\n",
            "Validating on test set\n",
            "Validation Metrics: 932 [D loss: 0.291048, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.901782]\n",
            "(1024, 1)\n",
            "Training Metrics: 933 [D loss: 0.659765, acc.: 99.80%, op_acc: 81.84%] [G loss: 5.964001]\n",
            "Validating on test set\n",
            "Validation Metrics: 933 [D loss: 0.280471, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.959363]\n",
            "(1024, 1)\n",
            "Training Metrics: 934 [D loss: 0.669961, acc.: 99.85%, op_acc: 81.54%] [G loss: 6.193398]\n",
            "Validating on test set\n",
            "Validation Metrics: 934 [D loss: 0.304319, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.185744]\n",
            "(1024, 1)\n",
            "Training Metrics: 935 [D loss: 0.668744, acc.: 99.51%, op_acc: 83.25%] [G loss: 6.206015]\n",
            "Validating on test set\n",
            "Validation Metrics: 935 [D loss: 0.271564, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.197683]\n",
            "(1024, 1)\n",
            "Training Metrics: 936 [D loss: 0.649901, acc.: 99.61%, op_acc: 82.32%] [G loss: 5.811355]\n",
            "Validating on test set\n",
            "Validation Metrics: 936 [D loss: 0.294394, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.812207]\n",
            "(1024, 1)\n",
            "Training Metrics: 937 [D loss: 0.652850, acc.: 99.66%, op_acc: 81.30%] [G loss: 6.041965]\n",
            "Validating on test set\n",
            "Validation Metrics: 937 [D loss: 0.271633, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.044750]\n",
            "(1024, 1)\n",
            "Training Metrics: 938 [D loss: 0.662130, acc.: 99.66%, op_acc: 81.79%] [G loss: 5.654324]\n",
            "Validating on test set\n",
            "Validation Metrics: 938 [D loss: 0.273989, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.636542]\n",
            "(1024, 1)\n",
            "Training Metrics: 939 [D loss: 0.696930, acc.: 99.80%, op_acc: 79.88%] [G loss: 6.221096]\n",
            "Validating on test set\n",
            "Validation Metrics: 939 [D loss: 0.287002, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.225426]\n",
            "(1024, 1)\n",
            "Training Metrics: 940 [D loss: 0.717212, acc.: 99.66%, op_acc: 82.96%] [G loss: 5.850702]\n",
            "Validating on test set\n",
            "Validation Metrics: 940 [D loss: 0.255666, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.868606]\n",
            "(1024, 1)\n",
            "Training Metrics: 941 [D loss: 0.620752, acc.: 99.80%, op_acc: 81.35%] [G loss: 6.011401]\n",
            "Validating on test set\n",
            "Validation Metrics: 941 [D loss: 0.299583, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.019029]\n",
            "(1024, 1)\n",
            "Training Metrics: 942 [D loss: 0.672469, acc.: 99.76%, op_acc: 82.57%] [G loss: 5.971603]\n",
            "Validating on test set\n",
            "Validation Metrics: 942 [D loss: 0.252907, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.008408]\n",
            "(1024, 1)\n",
            "Training Metrics: 943 [D loss: 0.611512, acc.: 99.61%, op_acc: 82.67%] [G loss: 5.985983]\n",
            "Validating on test set\n",
            "Validation Metrics: 943 [D loss: 0.252971, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.957547]\n",
            "(1024, 1)\n",
            "Training Metrics: 944 [D loss: 0.619930, acc.: 99.95%, op_acc: 83.64%] [G loss: 6.179742]\n",
            "Validating on test set\n",
            "Validation Metrics: 944 [D loss: 0.278199, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.193798]\n",
            "(1024, 1)\n",
            "Training Metrics: 945 [D loss: 0.651157, acc.: 99.90%, op_acc: 82.91%] [G loss: 6.231898]\n",
            "Validating on test set\n",
            "Validation Metrics: 945 [D loss: 0.275191, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.251743]\n",
            "(1024, 1)\n",
            "Training Metrics: 946 [D loss: 0.666107, acc.: 99.66%, op_acc: 81.93%] [G loss: 5.838213]\n",
            "Validating on test set\n",
            "Validation Metrics: 946 [D loss: 0.332979, acc.: 100.00%, op_acc: 94.53%] [G loss: 5.880680]\n",
            "(1024, 1)\n",
            "Training Metrics: 947 [D loss: 0.680633, acc.: 99.71%, op_acc: 79.54%] [G loss: 6.411459]\n",
            "Validating on test set\n",
            "Validation Metrics: 947 [D loss: 0.243027, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.388709]\n",
            "(1024, 1)\n",
            "Training Metrics: 948 [D loss: 0.677127, acc.: 99.85%, op_acc: 80.42%] [G loss: 5.936940]\n",
            "Validating on test set\n",
            "Validation Metrics: 948 [D loss: 0.265840, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.914222]\n",
            "(1024, 1)\n",
            "Training Metrics: 949 [D loss: 0.666814, acc.: 99.95%, op_acc: 80.18%] [G loss: 6.714247]\n",
            "Validating on test set\n",
            "Validation Metrics: 949 [D loss: 0.250812, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.699811]\n",
            "(1024, 1)\n",
            "Training Metrics: 950 [D loss: 0.655786, acc.: 99.80%, op_acc: 82.32%] [G loss: 6.196830]\n",
            "Validating on test set\n",
            "Validation Metrics: 950 [D loss: 0.229763, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.201101]\n",
            "(1024, 1)\n",
            "Training Metrics: 951 [D loss: 0.597713, acc.: 99.85%, op_acc: 82.42%] [G loss: 6.365317]\n",
            "Validating on test set\n",
            "Validation Metrics: 951 [D loss: 0.264029, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.364963]\n",
            "(1024, 1)\n",
            "Training Metrics: 952 [D loss: 0.651893, acc.: 99.61%, op_acc: 82.52%] [G loss: 6.094180]\n",
            "Validating on test set\n",
            "Validation Metrics: 952 [D loss: 0.231331, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.097978]\n",
            "(1024, 1)\n",
            "Training Metrics: 953 [D loss: 0.617634, acc.: 99.56%, op_acc: 82.32%] [G loss: 6.107881]\n",
            "Validating on test set\n",
            "Validation Metrics: 953 [D loss: 0.257088, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.109227]\n",
            "(1024, 1)\n",
            "Training Metrics: 954 [D loss: 0.681207, acc.: 99.71%, op_acc: 81.20%] [G loss: 5.788560]\n",
            "Validating on test set\n",
            "Validation Metrics: 954 [D loss: 0.239305, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.789938]\n",
            "(1024, 1)\n",
            "Training Metrics: 955 [D loss: 0.629403, acc.: 99.56%, op_acc: 81.10%] [G loss: 6.051670]\n",
            "Validating on test set\n",
            "Validation Metrics: 955 [D loss: 0.247954, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.044994]\n",
            "(1024, 1)\n",
            "Training Metrics: 956 [D loss: 0.702280, acc.: 99.61%, op_acc: 82.86%] [G loss: 5.589636]\n",
            "Validating on test set\n",
            "Validation Metrics: 956 [D loss: 0.234458, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.573759]\n",
            "(1024, 1)\n",
            "Training Metrics: 957 [D loss: 0.658520, acc.: 99.76%, op_acc: 80.32%] [G loss: 5.833669]\n",
            "Validating on test set\n",
            "Validation Metrics: 957 [D loss: 0.248016, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.845650]\n",
            "(1024, 1)\n",
            "Training Metrics: 958 [D loss: 0.678116, acc.: 99.76%, op_acc: 82.18%] [G loss: 6.022483]\n",
            "Validating on test set\n",
            "Validation Metrics: 958 [D loss: 0.221412, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.017011]\n",
            "(1024, 1)\n",
            "Training Metrics: 959 [D loss: 0.594239, acc.: 99.85%, op_acc: 81.30%] [G loss: 6.022304]\n",
            "Validating on test set\n",
            "Validation Metrics: 959 [D loss: 0.241694, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.022480]\n",
            "(1024, 1)\n",
            "Training Metrics: 960 [D loss: 0.595123, acc.: 99.71%, op_acc: 83.11%] [G loss: 5.865765]\n",
            "Validating on test set\n",
            "Validation Metrics: 960 [D loss: 0.219139, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.871253]\n",
            "(1024, 1)\n",
            "Training Metrics: 961 [D loss: 0.614267, acc.: 99.66%, op_acc: 82.18%] [G loss: 5.892203]\n",
            "Validating on test set\n",
            "Validation Metrics: 961 [D loss: 0.267799, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.910145]\n",
            "(1024, 1)\n",
            "Training Metrics: 962 [D loss: 0.639292, acc.: 99.80%, op_acc: 82.18%] [G loss: 5.862313]\n",
            "Validating on test set\n",
            "Validation Metrics: 962 [D loss: 0.213401, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.869610]\n",
            "(1024, 1)\n",
            "Training Metrics: 963 [D loss: 0.581422, acc.: 99.76%, op_acc: 82.86%] [G loss: 5.789562]\n",
            "Validating on test set\n",
            "Validation Metrics: 963 [D loss: 0.252625, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.785169]\n",
            "(1024, 1)\n",
            "Training Metrics: 964 [D loss: 0.613519, acc.: 99.71%, op_acc: 83.06%] [G loss: 5.868469]\n",
            "Validating on test set\n",
            "Validation Metrics: 964 [D loss: 0.214115, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.883629]\n",
            "(1024, 1)\n",
            "Training Metrics: 965 [D loss: 0.644637, acc.: 99.76%, op_acc: 82.18%] [G loss: 5.787724]\n",
            "Validating on test set\n",
            "Validation Metrics: 965 [D loss: 0.224602, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.773410]\n",
            "(1024, 1)\n",
            "Training Metrics: 966 [D loss: 0.569801, acc.: 99.85%, op_acc: 83.01%] [G loss: 6.151850]\n",
            "Validating on test set\n",
            "Validation Metrics: 966 [D loss: 0.215965, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.154380]\n",
            "(1024, 1)\n",
            "Training Metrics: 967 [D loss: 0.651991, acc.: 99.85%, op_acc: 81.49%] [G loss: 5.820122]\n",
            "Validating on test set\n",
            "Validation Metrics: 967 [D loss: 0.257992, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.815778]\n",
            "(1024, 1)\n",
            "Training Metrics: 968 [D loss: 0.635416, acc.: 99.80%, op_acc: 82.03%] [G loss: 5.949800]\n",
            "Validating on test set\n",
            "Validation Metrics: 968 [D loss: 0.220350, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.979331]\n",
            "(1024, 1)\n",
            "Training Metrics: 969 [D loss: 0.683242, acc.: 99.66%, op_acc: 81.20%] [G loss: 6.010970]\n",
            "Validating on test set\n",
            "Validation Metrics: 969 [D loss: 0.252135, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.985598]\n",
            "(1024, 1)\n",
            "Training Metrics: 970 [D loss: 0.643637, acc.: 99.85%, op_acc: 82.28%] [G loss: 6.204646]\n",
            "Validating on test set\n",
            "Validation Metrics: 970 [D loss: 0.214399, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.061579]\n",
            "(1024, 1)\n",
            "Training Metrics: 971 [D loss: 0.632613, acc.: 99.76%, op_acc: 81.69%] [G loss: 6.002988]\n",
            "Validating on test set\n",
            "Validation Metrics: 971 [D loss: 0.597360, acc.: 100.00%, op_acc: 91.50%] [G loss: 4.573285]\n",
            "(1024, 1)\n",
            "Training Metrics: 972 [D loss: 0.882235, acc.: 99.80%, op_acc: 75.10%] [G loss: 7.512180]\n",
            "Validating on test set\n",
            "Validation Metrics: 972 [D loss: 0.238963, acc.: 100.00%, op_acc: 99.02%] [G loss: 7.278267]\n",
            "(1024, 1)\n",
            "Training Metrics: 973 [D loss: 0.733349, acc.: 99.37%, op_acc: 81.59%] [G loss: 7.679677]\n",
            "Validating on test set\n",
            "Validation Metrics: 973 [D loss: 0.406675, acc.: 100.00%, op_acc: 91.02%] [G loss: 7.067749]\n",
            "(1024, 1)\n",
            "Training Metrics: 974 [D loss: 0.837780, acc.: 99.46%, op_acc: 74.71%] [G loss: 6.994075]\n",
            "Validating on test set\n",
            "Validation Metrics: 974 [D loss: 1.506800, acc.: 100.00%, op_acc: 65.43%] [G loss: 6.759746]\n",
            "(1024, 1)\n",
            "Training Metrics: 975 [D loss: 1.282675, acc.: 99.27%, op_acc: 65.72%] [G loss: 4.971330]\n",
            "Validating on test set\n",
            "Validation Metrics: 975 [D loss: 2.528557, acc.: 100.00%, op_acc: 44.24%] [G loss: 7.719672]\n",
            "(1024, 1)\n",
            "Training Metrics: 976 [D loss: 1.792892, acc.: 99.51%, op_acc: 52.54%] [G loss: 6.691176]\n",
            "Validating on test set\n",
            "Validation Metrics: 976 [D loss: 1.194692, acc.: 100.00%, op_acc: 66.02%] [G loss: 5.162788]\n",
            "(1024, 1)\n",
            "Training Metrics: 977 [D loss: 1.213232, acc.: 99.37%, op_acc: 62.21%] [G loss: 5.714742]\n",
            "Validating on test set\n",
            "Validation Metrics: 977 [D loss: 1.405919, acc.: 100.00%, op_acc: 57.62%] [G loss: 5.466234]\n",
            "(1024, 1)\n",
            "Training Metrics: 978 [D loss: 1.228036, acc.: 99.56%, op_acc: 59.91%] [G loss: 6.610995]\n",
            "Validating on test set\n",
            "Validation Metrics: 978 [D loss: 1.179626, acc.: 100.00%, op_acc: 65.92%] [G loss: 6.351817]\n",
            "(1024, 1)\n",
            "Training Metrics: 979 [D loss: 1.115857, acc.: 99.22%, op_acc: 66.02%] [G loss: 5.828510]\n",
            "Validating on test set\n",
            "Validation Metrics: 979 [D loss: 0.792277, acc.: 100.00%, op_acc: 79.00%] [G loss: 5.725429]\n",
            "(1024, 1)\n",
            "Training Metrics: 980 [D loss: 0.986480, acc.: 99.22%, op_acc: 69.63%] [G loss: 5.630323]\n",
            "Validating on test set\n",
            "Validation Metrics: 980 [D loss: 0.562318, acc.: 100.00%, op_acc: 86.82%] [G loss: 5.490747]\n",
            "(1024, 1)\n",
            "Training Metrics: 981 [D loss: 0.877797, acc.: 99.32%, op_acc: 75.29%] [G loss: 5.452889]\n",
            "Validating on test set\n",
            "Validation Metrics: 981 [D loss: 0.528956, acc.: 100.00%, op_acc: 90.82%] [G loss: 5.358100]\n",
            "(1024, 1)\n",
            "Training Metrics: 982 [D loss: 0.865891, acc.: 99.61%, op_acc: 72.90%] [G loss: 5.401445]\n",
            "Validating on test set\n",
            "Validation Metrics: 982 [D loss: 0.479880, acc.: 100.00%, op_acc: 90.62%] [G loss: 5.287753]\n",
            "(1024, 1)\n",
            "Training Metrics: 983 [D loss: 0.786151, acc.: 99.41%, op_acc: 77.25%] [G loss: 5.237576]\n",
            "Validating on test set\n",
            "Validation Metrics: 983 [D loss: 0.431058, acc.: 100.00%, op_acc: 95.80%] [G loss: 5.191113]\n",
            "(1024, 1)\n",
            "Training Metrics: 984 [D loss: 0.718039, acc.: 99.37%, op_acc: 80.47%] [G loss: 5.269934]\n",
            "Validating on test set\n",
            "Validation Metrics: 984 [D loss: 0.416345, acc.: 100.00%, op_acc: 91.50%] [G loss: 5.231562]\n",
            "(1024, 1)\n",
            "Training Metrics: 985 [D loss: 0.777212, acc.: 99.51%, op_acc: 77.78%] [G loss: 5.308436]\n",
            "Validating on test set\n",
            "Validation Metrics: 985 [D loss: 0.373255, acc.: 100.00%, op_acc: 92.68%] [G loss: 5.311898]\n",
            "(1024, 1)\n",
            "Training Metrics: 986 [D loss: 0.735555, acc.: 99.76%, op_acc: 77.54%] [G loss: 5.234817]\n",
            "Validating on test set\n",
            "Validation Metrics: 986 [D loss: 0.499904, acc.: 100.00%, op_acc: 86.52%] [G loss: 5.313835]\n",
            "(1024, 1)\n",
            "Training Metrics: 987 [D loss: 0.760105, acc.: 99.46%, op_acc: 76.22%] [G loss: 5.641906]\n",
            "Validating on test set\n",
            "Validation Metrics: 987 [D loss: 0.674259, acc.: 100.00%, op_acc: 89.84%] [G loss: 5.890723]\n",
            "(1024, 1)\n",
            "Training Metrics: 988 [D loss: 0.898029, acc.: 99.56%, op_acc: 75.83%] [G loss: 5.770009]\n",
            "Validating on test set\n",
            "Validation Metrics: 988 [D loss: 0.454390, acc.: 100.00%, op_acc: 92.09%] [G loss: 5.582980]\n",
            "(1024, 1)\n",
            "Training Metrics: 989 [D loss: 0.774256, acc.: 99.41%, op_acc: 76.32%] [G loss: 5.246235]\n",
            "Validating on test set\n",
            "Validation Metrics: 989 [D loss: 0.446447, acc.: 100.00%, op_acc: 91.50%] [G loss: 5.387647]\n",
            "(1024, 1)\n",
            "Training Metrics: 990 [D loss: 0.811189, acc.: 99.80%, op_acc: 75.54%] [G loss: 5.544076]\n",
            "Validating on test set\n",
            "Validation Metrics: 990 [D loss: 0.324689, acc.: 100.00%, op_acc: 93.85%] [G loss: 5.465749]\n",
            "(1024, 1)\n",
            "Training Metrics: 991 [D loss: 0.729261, acc.: 99.80%, op_acc: 77.83%] [G loss: 5.567124]\n",
            "Validating on test set\n",
            "Validation Metrics: 991 [D loss: 0.379725, acc.: 100.00%, op_acc: 91.99%] [G loss: 5.573375]\n",
            "(1024, 1)\n",
            "Training Metrics: 992 [D loss: 0.661863, acc.: 99.90%, op_acc: 80.96%] [G loss: 5.734122]\n",
            "Validating on test set\n",
            "Validation Metrics: 992 [D loss: 0.337869, acc.: 100.00%, op_acc: 97.07%] [G loss: 5.708724]\n",
            "(1024, 1)\n",
            "Training Metrics: 993 [D loss: 0.707274, acc.: 99.61%, op_acc: 80.62%] [G loss: 5.811340]\n",
            "Validating on test set\n",
            "Validation Metrics: 993 [D loss: 0.312743, acc.: 100.00%, op_acc: 96.78%] [G loss: 5.754806]\n",
            "(1024, 1)\n",
            "Training Metrics: 994 [D loss: 0.684085, acc.: 99.61%, op_acc: 79.64%] [G loss: 5.409063]\n",
            "Validating on test set\n",
            "Validation Metrics: 994 [D loss: 0.361826, acc.: 100.00%, op_acc: 93.75%] [G loss: 5.436859]\n",
            "(1024, 1)\n",
            "Training Metrics: 995 [D loss: 0.686481, acc.: 99.76%, op_acc: 79.93%] [G loss: 5.436545]\n",
            "Validating on test set\n",
            "Validation Metrics: 995 [D loss: 0.313528, acc.: 100.00%, op_acc: 95.80%] [G loss: 5.407864]\n",
            "(1024, 1)\n",
            "Training Metrics: 996 [D loss: 0.684770, acc.: 99.41%, op_acc: 79.35%] [G loss: 5.355988]\n",
            "Validating on test set\n",
            "Validation Metrics: 996 [D loss: 0.310143, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.365249]\n",
            "(1024, 1)\n",
            "Training Metrics: 997 [D loss: 0.630991, acc.: 99.85%, op_acc: 81.93%] [G loss: 5.367986]\n",
            "Validating on test set\n",
            "Validation Metrics: 997 [D loss: 0.305644, acc.: 100.00%, op_acc: 97.95%] [G loss: 5.350861]\n",
            "(1024, 1)\n",
            "Training Metrics: 998 [D loss: 0.658760, acc.: 99.71%, op_acc: 81.79%] [G loss: 5.673016]\n",
            "Validating on test set\n",
            "Validation Metrics: 998 [D loss: 0.326676, acc.: 100.00%, op_acc: 97.36%] [G loss: 5.736000]\n",
            "(1024, 1)\n",
            "Training Metrics: 999 [D loss: 0.694945, acc.: 99.41%, op_acc: 80.42%] [G loss: 5.559875]\n",
            "Validating on test set\n",
            "Validation Metrics: 999 [D loss: 0.409619, acc.: 100.00%, op_acc: 93.16%] [G loss: 5.591411]\n",
            "(1024, 1)\n",
            "Training Metrics: 1000 [D loss: 0.761714, acc.: 99.56%, op_acc: 78.37%] [G loss: 5.540557]\n",
            "Validating on test set\n",
            "Validation Metrics: 1000 [D loss: 0.348092, acc.: 100.00%, op_acc: 94.53%] [G loss: 5.529034]\n",
            "(1024, 1)\n",
            "Training Metrics: 1001 [D loss: 0.720862, acc.: 99.61%, op_acc: 78.52%] [G loss: 5.627913]\n",
            "Validating on test set\n",
            "Validation Metrics: 1001 [D loss: 0.326141, acc.: 100.00%, op_acc: 95.70%] [G loss: 5.526478]\n",
            "(1024, 1)\n",
            "Training Metrics: 1002 [D loss: 0.696296, acc.: 99.76%, op_acc: 78.86%] [G loss: 5.747508]\n",
            "Validating on test set\n",
            "Validation Metrics: 1002 [D loss: 0.422522, acc.: 100.00%, op_acc: 89.16%] [G loss: 5.681040]\n",
            "(1024, 1)\n",
            "Training Metrics: 1003 [D loss: 0.751818, acc.: 99.90%, op_acc: 75.83%] [G loss: 5.671955]\n",
            "Validating on test set\n",
            "Validation Metrics: 1003 [D loss: 0.365887, acc.: 100.00%, op_acc: 92.38%] [G loss: 5.641050]\n",
            "(1024, 1)\n",
            "Training Metrics: 1004 [D loss: 0.763305, acc.: 99.80%, op_acc: 79.74%] [G loss: 5.685030]\n",
            "Validating on test set\n",
            "Validation Metrics: 1004 [D loss: 0.394815, acc.: 100.00%, op_acc: 88.67%] [G loss: 5.657228]\n",
            "(1024, 1)\n",
            "Training Metrics: 1005 [D loss: 0.710270, acc.: 99.76%, op_acc: 75.73%] [G loss: 5.531642]\n",
            "Validating on test set\n",
            "Validation Metrics: 1005 [D loss: 0.401942, acc.: 100.00%, op_acc: 89.06%] [G loss: 5.603830]\n",
            "(1024, 1)\n",
            "Training Metrics: 1006 [D loss: 0.787550, acc.: 99.66%, op_acc: 77.15%] [G loss: 5.511455]\n",
            "Validating on test set\n",
            "Validation Metrics: 1006 [D loss: 0.469289, acc.: 100.00%, op_acc: 90.04%] [G loss: 5.510281]\n",
            "(1024, 1)\n",
            "Training Metrics: 1007 [D loss: 0.733703, acc.: 99.80%, op_acc: 75.24%] [G loss: 5.278070]\n",
            "Validating on test set\n",
            "Validation Metrics: 1007 [D loss: 0.453990, acc.: 100.00%, op_acc: 91.21%] [G loss: 5.121758]\n",
            "(1024, 1)\n",
            "Training Metrics: 1008 [D loss: 0.742885, acc.: 99.80%, op_acc: 77.34%] [G loss: 5.151935]\n",
            "Validating on test set\n",
            "Validation Metrics: 1008 [D loss: 0.406517, acc.: 100.00%, op_acc: 93.46%] [G loss: 4.916845]\n",
            "(1024, 1)\n",
            "Training Metrics: 1009 [D loss: 0.755104, acc.: 99.90%, op_acc: 78.66%] [G loss: 5.622112]\n",
            "Validating on test set\n",
            "Validation Metrics: 1009 [D loss: 0.408602, acc.: 100.00%, op_acc: 93.46%] [G loss: 5.446019]\n",
            "(1024, 1)\n",
            "Training Metrics: 1010 [D loss: 0.701719, acc.: 99.76%, op_acc: 78.12%] [G loss: 5.405202]\n",
            "Validating on test set\n",
            "Validation Metrics: 1010 [D loss: 0.552875, acc.: 100.00%, op_acc: 82.91%] [G loss: 5.480204]\n",
            "(1024, 1)\n",
            "Training Metrics: 1011 [D loss: 0.788766, acc.: 99.61%, op_acc: 75.59%] [G loss: 5.667334]\n",
            "Validating on test set\n",
            "Validation Metrics: 1011 [D loss: 0.418786, acc.: 100.00%, op_acc: 90.92%] [G loss: 5.589614]\n",
            "(1024, 1)\n",
            "Training Metrics: 1012 [D loss: 0.697412, acc.: 99.80%, op_acc: 78.22%] [G loss: 5.735565]\n",
            "Validating on test set\n",
            "Validation Metrics: 1012 [D loss: 0.311028, acc.: 100.00%, op_acc: 92.68%] [G loss: 5.640280]\n",
            "(1024, 1)\n",
            "Training Metrics: 1013 [D loss: 0.639262, acc.: 99.76%, op_acc: 80.42%] [G loss: 5.538651]\n",
            "Validating on test set\n",
            "Validation Metrics: 1013 [D loss: 0.426491, acc.: 100.00%, op_acc: 89.75%] [G loss: 5.568277]\n",
            "(1024, 1)\n",
            "Training Metrics: 1014 [D loss: 0.695423, acc.: 99.80%, op_acc: 76.27%] [G loss: 5.734900]\n",
            "Validating on test set\n",
            "Validation Metrics: 1014 [D loss: 0.388985, acc.: 100.00%, op_acc: 91.11%] [G loss: 5.864568]\n",
            "(1024, 1)\n",
            "Training Metrics: 1015 [D loss: 0.697547, acc.: 99.41%, op_acc: 80.22%] [G loss: 5.602460]\n",
            "Validating on test set\n",
            "Validation Metrics: 1015 [D loss: 0.470763, acc.: 100.00%, op_acc: 89.94%] [G loss: 5.672781]\n",
            "(1024, 1)\n",
            "Training Metrics: 1016 [D loss: 0.754044, acc.: 99.80%, op_acc: 76.03%] [G loss: 5.685592]\n",
            "Validating on test set\n",
            "Validation Metrics: 1016 [D loss: 0.418927, acc.: 100.00%, op_acc: 91.31%] [G loss: 5.772080]\n",
            "(1024, 1)\n",
            "Training Metrics: 1017 [D loss: 0.735006, acc.: 99.61%, op_acc: 78.12%] [G loss: 5.678778]\n",
            "Validating on test set\n",
            "Validation Metrics: 1017 [D loss: 0.368355, acc.: 100.00%, op_acc: 93.85%] [G loss: 5.593115]\n",
            "(1024, 1)\n",
            "Training Metrics: 1018 [D loss: 0.708179, acc.: 99.90%, op_acc: 78.71%] [G loss: 5.475453]\n",
            "Validating on test set\n",
            "Validation Metrics: 1018 [D loss: 0.306827, acc.: 100.00%, op_acc: 95.61%] [G loss: 5.455629]\n",
            "(1024, 1)\n",
            "Training Metrics: 1019 [D loss: 0.674109, acc.: 99.80%, op_acc: 79.59%] [G loss: 5.326096]\n",
            "Validating on test set\n",
            "Validation Metrics: 1019 [D loss: 0.258410, acc.: 100.00%, op_acc: 97.36%] [G loss: 5.294144]\n",
            "(1024, 1)\n",
            "Training Metrics: 1020 [D loss: 0.587656, acc.: 99.85%, op_acc: 82.86%] [G loss: 5.297985]\n",
            "Validating on test set\n",
            "Validation Metrics: 1020 [D loss: 0.322175, acc.: 100.00%, op_acc: 96.29%] [G loss: 5.368587]\n",
            "(1024, 1)\n",
            "Training Metrics: 1021 [D loss: 0.708809, acc.: 99.71%, op_acc: 80.42%] [G loss: 5.618566]\n",
            "Validating on test set\n",
            "Validation Metrics: 1021 [D loss: 0.210064, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.562643]\n",
            "(1024, 1)\n",
            "Training Metrics: 1022 [D loss: 0.620996, acc.: 99.76%, op_acc: 80.57%] [G loss: 5.613321]\n",
            "Validating on test set\n",
            "Validation Metrics: 1022 [D loss: 0.258037, acc.: 100.00%, op_acc: 98.34%] [G loss: 5.661368]\n",
            "(1024, 1)\n",
            "Training Metrics: 1023 [D loss: 0.701427, acc.: 99.76%, op_acc: 80.03%] [G loss: 5.580342]\n",
            "Validating on test set\n",
            "Validation Metrics: 1023 [D loss: 0.245901, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.563644]\n",
            "(1024, 1)\n",
            "Training Metrics: 1024 [D loss: 0.694559, acc.: 99.80%, op_acc: 79.54%] [G loss: 5.561576]\n",
            "Validating on test set\n",
            "Validation Metrics: 1024 [D loss: 0.414668, acc.: 100.00%, op_acc: 89.75%] [G loss: 5.651880]\n",
            "(1024, 1)\n",
            "Training Metrics: 1025 [D loss: 0.742117, acc.: 99.85%, op_acc: 78.27%] [G loss: 5.889927]\n",
            "Validating on test set\n",
            "Validation Metrics: 1025 [D loss: 0.220615, acc.: 100.00%, op_acc: 97.66%] [G loss: 5.842465]\n",
            "(1024, 1)\n",
            "Training Metrics: 1026 [D loss: 0.620814, acc.: 99.85%, op_acc: 79.69%] [G loss: 5.715861]\n",
            "Validating on test set\n",
            "Validation Metrics: 1026 [D loss: 0.232195, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.652838]\n",
            "(1024, 1)\n",
            "Training Metrics: 1027 [D loss: 0.644142, acc.: 99.76%, op_acc: 81.01%] [G loss: 5.541802]\n",
            "Validating on test set\n",
            "Validation Metrics: 1027 [D loss: 0.217900, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.480855]\n",
            "(1024, 1)\n",
            "Training Metrics: 1028 [D loss: 0.601289, acc.: 99.80%, op_acc: 82.96%] [G loss: 5.326684]\n",
            "Validating on test set\n",
            "Validation Metrics: 1028 [D loss: 0.210458, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.324154]\n",
            "(1024, 1)\n",
            "Training Metrics: 1029 [D loss: 0.588656, acc.: 99.66%, op_acc: 83.40%] [G loss: 5.329711]\n",
            "Validating on test set\n",
            "Validation Metrics: 1029 [D loss: 0.231025, acc.: 100.00%, op_acc: 98.24%] [G loss: 5.317264]\n",
            "(1024, 1)\n",
            "Training Metrics: 1030 [D loss: 0.623372, acc.: 99.76%, op_acc: 81.15%] [G loss: 5.339455]\n",
            "Validating on test set\n",
            "Validation Metrics: 1030 [D loss: 0.257279, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.396413]\n",
            "(1024, 1)\n",
            "Training Metrics: 1031 [D loss: 0.643004, acc.: 99.80%, op_acc: 81.10%] [G loss: 5.713294]\n",
            "Validating on test set\n",
            "Validation Metrics: 1031 [D loss: 0.191089, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.619161]\n",
            "(1024, 1)\n",
            "Training Metrics: 1032 [D loss: 0.591410, acc.: 99.37%, op_acc: 82.13%] [G loss: 5.153112]\n",
            "Validating on test set\n",
            "Validation Metrics: 1032 [D loss: 0.204334, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.112759]\n",
            "(1024, 1)\n",
            "Training Metrics: 1033 [D loss: 0.562702, acc.: 99.85%, op_acc: 83.45%] [G loss: 5.272818]\n",
            "Validating on test set\n",
            "Validation Metrics: 1033 [D loss: 0.190448, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.197277]\n",
            "(1024, 1)\n",
            "Training Metrics: 1034 [D loss: 0.597807, acc.: 99.76%, op_acc: 81.93%] [G loss: 5.363214]\n",
            "Validating on test set\n",
            "Validation Metrics: 1034 [D loss: 0.203357, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.466157]\n",
            "(1024, 1)\n",
            "Training Metrics: 1035 [D loss: 0.573307, acc.: 99.90%, op_acc: 82.47%] [G loss: 5.791973]\n",
            "Validating on test set\n",
            "Validation Metrics: 1035 [D loss: 0.237658, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.869846]\n",
            "(1024, 1)\n",
            "Training Metrics: 1036 [D loss: 0.644960, acc.: 99.61%, op_acc: 82.03%] [G loss: 5.940707]\n",
            "Validating on test set\n",
            "Validation Metrics: 1036 [D loss: 0.190490, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.888708]\n",
            "(1024, 1)\n",
            "Training Metrics: 1037 [D loss: 0.631576, acc.: 99.56%, op_acc: 82.52%] [G loss: 5.605802]\n",
            "Validating on test set\n",
            "Validation Metrics: 1037 [D loss: 0.207180, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.573321]\n",
            "(1024, 1)\n",
            "Training Metrics: 1038 [D loss: 0.607246, acc.: 99.76%, op_acc: 81.49%] [G loss: 5.594298]\n",
            "Validating on test set\n",
            "Validation Metrics: 1038 [D loss: 0.193303, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.536727]\n",
            "(1024, 1)\n",
            "Training Metrics: 1039 [D loss: 0.633102, acc.: 99.66%, op_acc: 80.96%] [G loss: 5.702415]\n",
            "Validating on test set\n",
            "Validation Metrics: 1039 [D loss: 0.199219, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.722998]\n",
            "(1024, 1)\n",
            "Training Metrics: 1040 [D loss: 0.636521, acc.: 99.85%, op_acc: 81.05%] [G loss: 5.677414]\n",
            "Validating on test set\n",
            "Validation Metrics: 1040 [D loss: 0.190926, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.584180]\n",
            "(1024, 1)\n",
            "Training Metrics: 1041 [D loss: 0.602339, acc.: 99.90%, op_acc: 80.81%] [G loss: 5.779010]\n",
            "Validating on test set\n",
            "Validation Metrics: 1041 [D loss: 0.219374, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.777779]\n",
            "(1024, 1)\n",
            "Training Metrics: 1042 [D loss: 0.641829, acc.: 99.61%, op_acc: 81.20%] [G loss: 5.643739]\n",
            "Validating on test set\n",
            "Validation Metrics: 1042 [D loss: 0.185852, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.656721]\n",
            "(1024, 1)\n",
            "Training Metrics: 1043 [D loss: 0.596123, acc.: 99.56%, op_acc: 82.47%] [G loss: 5.538270]\n",
            "Validating on test set\n",
            "Validation Metrics: 1043 [D loss: 0.181458, acc.: 100.00%, op_acc: 98.34%] [G loss: 5.553274]\n",
            "(1024, 1)\n",
            "Training Metrics: 1044 [D loss: 0.598479, acc.: 99.85%, op_acc: 83.20%] [G loss: 5.351619]\n",
            "Validating on test set\n",
            "Validation Metrics: 1044 [D loss: 0.205627, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.425086]\n",
            "(1024, 1)\n",
            "Training Metrics: 1045 [D loss: 0.601804, acc.: 99.80%, op_acc: 81.59%] [G loss: 5.684372]\n",
            "Validating on test set\n",
            "Validation Metrics: 1045 [D loss: 0.184191, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.648198]\n",
            "(1024, 1)\n",
            "Training Metrics: 1046 [D loss: 0.627382, acc.: 99.76%, op_acc: 81.49%] [G loss: 5.736066]\n",
            "Validating on test set\n",
            "Validation Metrics: 1046 [D loss: 0.193025, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.649212]\n",
            "(1024, 1)\n",
            "Training Metrics: 1047 [D loss: 0.623580, acc.: 99.76%, op_acc: 81.88%] [G loss: 5.706996]\n",
            "Validating on test set\n",
            "Validation Metrics: 1047 [D loss: 0.179449, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.605489]\n",
            "(1024, 1)\n",
            "Training Metrics: 1048 [D loss: 0.589833, acc.: 99.85%, op_acc: 83.25%] [G loss: 5.639290]\n",
            "Validating on test set\n",
            "Validation Metrics: 1048 [D loss: 0.245825, acc.: 100.00%, op_acc: 98.44%] [G loss: 5.876139]\n",
            "(1024, 1)\n",
            "Training Metrics: 1049 [D loss: 0.654028, acc.: 99.76%, op_acc: 82.28%] [G loss: 5.868346]\n",
            "Validating on test set\n",
            "Validation Metrics: 1049 [D loss: 0.251030, acc.: 100.00%, op_acc: 95.51%] [G loss: 5.849746]\n",
            "(1024, 1)\n",
            "Training Metrics: 1050 [D loss: 0.645115, acc.: 99.76%, op_acc: 79.93%] [G loss: 5.503284]\n",
            "Validating on test set\n",
            "Validation Metrics: 1050 [D loss: 0.332872, acc.: 100.00%, op_acc: 91.02%] [G loss: 5.760544]\n",
            "(1024, 1)\n",
            "Training Metrics: 1051 [D loss: 0.651578, acc.: 99.95%, op_acc: 77.44%] [G loss: 6.081664]\n",
            "Validating on test set\n",
            "Validation Metrics: 1051 [D loss: 0.343859, acc.: 100.00%, op_acc: 88.38%] [G loss: 6.231561]\n",
            "(1024, 1)\n",
            "Training Metrics: 1052 [D loss: 0.699681, acc.: 99.71%, op_acc: 75.24%] [G loss: 6.257518]\n",
            "Validating on test set\n",
            "Validation Metrics: 1052 [D loss: 0.248814, acc.: 100.00%, op_acc: 96.58%] [G loss: 6.174645]\n",
            "(1024, 1)\n",
            "Training Metrics: 1053 [D loss: 0.656625, acc.: 99.85%, op_acc: 80.08%] [G loss: 5.972696]\n",
            "Validating on test set\n",
            "Validation Metrics: 1053 [D loss: 0.181809, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.853949]\n",
            "(1024, 1)\n",
            "Training Metrics: 1054 [D loss: 0.605419, acc.: 99.85%, op_acc: 82.47%] [G loss: 6.099626]\n",
            "Validating on test set\n",
            "Validation Metrics: 1054 [D loss: 0.187143, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.996211]\n",
            "(1024, 1)\n",
            "Training Metrics: 1055 [D loss: 0.582073, acc.: 99.95%, op_acc: 82.13%] [G loss: 5.709155]\n",
            "Validating on test set\n",
            "Validation Metrics: 1055 [D loss: 0.174304, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.583785]\n",
            "(1024, 1)\n",
            "Training Metrics: 1056 [D loss: 0.593020, acc.: 99.85%, op_acc: 81.69%] [G loss: 5.612110]\n",
            "Validating on test set\n",
            "Validation Metrics: 1056 [D loss: 0.165695, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.449024]\n",
            "(1024, 1)\n",
            "Training Metrics: 1057 [D loss: 0.525470, acc.: 99.85%, op_acc: 84.23%] [G loss: 5.794278]\n",
            "Validating on test set\n",
            "Validation Metrics: 1057 [D loss: 0.789418, acc.: 100.00%, op_acc: 83.98%] [G loss: 6.999094]\n",
            "(1024, 1)\n",
            "Training Metrics: 1058 [D loss: 0.867977, acc.: 99.90%, op_acc: 76.12%] [G loss: 6.925741]\n",
            "Validating on test set\n",
            "Validation Metrics: 1058 [D loss: 0.468350, acc.: 100.00%, op_acc: 88.67%] [G loss: 6.696381]\n",
            "(1024, 1)\n",
            "Training Metrics: 1059 [D loss: 0.778086, acc.: 99.80%, op_acc: 74.56%] [G loss: 7.103561]\n",
            "Validating on test set\n",
            "Validation Metrics: 1059 [D loss: 0.206360, acc.: 100.00%, op_acc: 94.92%] [G loss: 6.757283]\n",
            "(1024, 1)\n",
            "Training Metrics: 1060 [D loss: 0.649417, acc.: 99.80%, op_acc: 80.47%] [G loss: 6.809897]\n",
            "Validating on test set\n",
            "Validation Metrics: 1060 [D loss: 0.166422, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.700062]\n",
            "(1024, 1)\n",
            "Training Metrics: 1061 [D loss: 0.571686, acc.: 99.85%, op_acc: 82.03%] [G loss: 6.156106]\n",
            "Validating on test set\n",
            "Validation Metrics: 1061 [D loss: 0.180450, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.171958]\n",
            "(1024, 1)\n",
            "Training Metrics: 1062 [D loss: 0.578307, acc.: 99.76%, op_acc: 82.28%] [G loss: 6.108827]\n",
            "Validating on test set\n",
            "Validation Metrics: 1062 [D loss: 0.172966, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.289024]\n",
            "(1024, 1)\n",
            "Training Metrics: 1063 [D loss: 0.544482, acc.: 99.71%, op_acc: 82.86%] [G loss: 6.199260]\n",
            "Validating on test set\n",
            "Validation Metrics: 1063 [D loss: 0.150685, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.982239]\n",
            "(1024, 1)\n",
            "Training Metrics: 1064 [D loss: 0.534097, acc.: 99.85%, op_acc: 83.25%] [G loss: 5.867256]\n",
            "Validating on test set\n",
            "Validation Metrics: 1064 [D loss: 0.163238, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.038074]\n",
            "(1024, 1)\n",
            "Training Metrics: 1065 [D loss: 0.593396, acc.: 99.56%, op_acc: 81.69%] [G loss: 5.982197]\n",
            "Validating on test set\n",
            "Validation Metrics: 1065 [D loss: 0.155123, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.750466]\n",
            "(1024, 1)\n",
            "Training Metrics: 1066 [D loss: 0.550709, acc.: 99.76%, op_acc: 83.15%] [G loss: 5.691045]\n",
            "Validating on test set\n",
            "Validation Metrics: 1066 [D loss: 0.155985, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.756966]\n",
            "(1024, 1)\n",
            "Training Metrics: 1067 [D loss: 0.546040, acc.: 99.76%, op_acc: 83.35%] [G loss: 5.793476]\n",
            "Validating on test set\n",
            "Validation Metrics: 1067 [D loss: 0.142023, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.704427]\n",
            "(1024, 1)\n",
            "Training Metrics: 1068 [D loss: 0.560738, acc.: 99.90%, op_acc: 83.25%] [G loss: 5.714149]\n",
            "Validating on test set\n",
            "Validation Metrics: 1068 [D loss: 0.147150, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.598685]\n",
            "(1024, 1)\n",
            "Training Metrics: 1069 [D loss: 0.525774, acc.: 99.95%, op_acc: 83.06%] [G loss: 5.723551]\n",
            "Validating on test set\n",
            "Validation Metrics: 1069 [D loss: 0.156334, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.755669]\n",
            "(1024, 1)\n",
            "Training Metrics: 1070 [D loss: 0.546146, acc.: 99.71%, op_acc: 83.30%] [G loss: 6.157356]\n",
            "Validating on test set\n",
            "Validation Metrics: 1070 [D loss: 0.161276, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.233334]\n",
            "(1024, 1)\n",
            "Training Metrics: 1071 [D loss: 0.570727, acc.: 99.71%, op_acc: 82.18%] [G loss: 5.752615]\n",
            "Validating on test set\n",
            "Validation Metrics: 1071 [D loss: 0.189096, acc.: 100.00%, op_acc: 96.09%] [G loss: 5.716354]\n",
            "(1024, 1)\n",
            "Training Metrics: 1072 [D loss: 0.633426, acc.: 99.85%, op_acc: 80.03%] [G loss: 5.875681]\n",
            "Validating on test set\n",
            "Validation Metrics: 1072 [D loss: 0.217070, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.980088]\n",
            "(1024, 1)\n",
            "Training Metrics: 1073 [D loss: 0.627313, acc.: 99.76%, op_acc: 82.18%] [G loss: 6.014803]\n",
            "Validating on test set\n",
            "Validation Metrics: 1073 [D loss: 0.173041, acc.: 100.00%, op_acc: 98.44%] [G loss: 5.813211]\n",
            "(1024, 1)\n",
            "Training Metrics: 1074 [D loss: 0.634760, acc.: 99.85%, op_acc: 80.86%] [G loss: 6.015659]\n",
            "Validating on test set\n",
            "Validation Metrics: 1074 [D loss: 0.141560, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.888327]\n",
            "(1024, 1)\n",
            "Training Metrics: 1075 [D loss: 0.594099, acc.: 99.80%, op_acc: 81.15%] [G loss: 5.683075]\n",
            "Validating on test set\n",
            "Validation Metrics: 1075 [D loss: 0.171122, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.862089]\n",
            "(1024, 1)\n",
            "Training Metrics: 1076 [D loss: 0.573713, acc.: 99.76%, op_acc: 82.52%] [G loss: 5.975232]\n",
            "Validating on test set\n",
            "Validation Metrics: 1076 [D loss: 0.226848, acc.: 100.00%, op_acc: 94.63%] [G loss: 6.259531]\n",
            "(1024, 1)\n",
            "Training Metrics: 1077 [D loss: 0.621089, acc.: 99.76%, op_acc: 81.20%] [G loss: 6.284076]\n",
            "Validating on test set\n",
            "Validation Metrics: 1077 [D loss: 0.211028, acc.: 100.00%, op_acc: 97.75%] [G loss: 6.068454]\n",
            "(1024, 1)\n",
            "Training Metrics: 1078 [D loss: 0.596063, acc.: 99.90%, op_acc: 81.49%] [G loss: 6.057956]\n",
            "Validating on test set\n",
            "Validation Metrics: 1078 [D loss: 0.147457, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.906845]\n",
            "(1024, 1)\n",
            "Training Metrics: 1079 [D loss: 0.575622, acc.: 99.95%, op_acc: 81.93%] [G loss: 6.149831]\n",
            "Validating on test set\n",
            "Validation Metrics: 1079 [D loss: 0.170741, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.069403]\n",
            "(1024, 1)\n",
            "Training Metrics: 1080 [D loss: 0.603639, acc.: 99.80%, op_acc: 82.42%] [G loss: 6.036592]\n",
            "Validating on test set\n",
            "Validation Metrics: 1080 [D loss: 0.141755, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.266647]\n",
            "(1024, 1)\n",
            "Training Metrics: 1081 [D loss: 0.563970, acc.: 99.85%, op_acc: 83.20%] [G loss: 6.083083]\n",
            "Validating on test set\n",
            "Validation Metrics: 1081 [D loss: 0.209528, acc.: 100.00%, op_acc: 93.55%] [G loss: 6.231385]\n",
            "(1024, 1)\n",
            "Training Metrics: 1082 [D loss: 0.567385, acc.: 99.76%, op_acc: 80.91%] [G loss: 5.979055]\n",
            "Validating on test set\n",
            "Validation Metrics: 1082 [D loss: 0.168727, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.772986]\n",
            "(1024, 1)\n",
            "Training Metrics: 1083 [D loss: 0.579321, acc.: 99.80%, op_acc: 83.30%] [G loss: 5.985625]\n",
            "Validating on test set\n",
            "Validation Metrics: 1083 [D loss: 0.141255, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.776382]\n",
            "(1024, 1)\n",
            "Training Metrics: 1084 [D loss: 0.530642, acc.: 99.76%, op_acc: 82.91%] [G loss: 5.833646]\n",
            "Validating on test set\n",
            "Validation Metrics: 1084 [D loss: 0.146669, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.936409]\n",
            "(1024, 1)\n",
            "Training Metrics: 1085 [D loss: 0.552556, acc.: 99.95%, op_acc: 82.71%] [G loss: 6.033412]\n",
            "Validating on test set\n",
            "Validation Metrics: 1085 [D loss: 0.152442, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.094564]\n",
            "(1024, 1)\n",
            "Training Metrics: 1086 [D loss: 0.518306, acc.: 99.85%, op_acc: 83.94%] [G loss: 5.948109]\n",
            "Validating on test set\n",
            "Validation Metrics: 1086 [D loss: 0.207678, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.386141]\n",
            "(1024, 1)\n",
            "Training Metrics: 1087 [D loss: 0.613071, acc.: 99.76%, op_acc: 81.25%] [G loss: 6.390437]\n",
            "Validating on test set\n",
            "Validation Metrics: 1087 [D loss: 0.169512, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.101966]\n",
            "(1024, 1)\n",
            "Training Metrics: 1088 [D loss: 0.556063, acc.: 99.80%, op_acc: 83.01%] [G loss: 6.044003]\n",
            "Validating on test set\n",
            "Validation Metrics: 1088 [D loss: 0.259246, acc.: 100.00%, op_acc: 92.29%] [G loss: 6.474088]\n",
            "(1024, 1)\n",
            "Training Metrics: 1089 [D loss: 0.614068, acc.: 99.85%, op_acc: 79.35%] [G loss: 6.340264]\n",
            "Validating on test set\n",
            "Validation Metrics: 1089 [D loss: 0.226771, acc.: 100.00%, op_acc: 98.54%] [G loss: 6.272161]\n",
            "(1024, 1)\n",
            "Training Metrics: 1090 [D loss: 0.558187, acc.: 99.95%, op_acc: 83.40%] [G loss: 6.236914]\n",
            "Validating on test set\n",
            "Validation Metrics: 1090 [D loss: 0.163224, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.862963]\n",
            "(1024, 1)\n",
            "Training Metrics: 1091 [D loss: 0.583317, acc.: 99.66%, op_acc: 81.69%] [G loss: 6.104868]\n",
            "Validating on test set\n",
            "Validation Metrics: 1091 [D loss: 0.205116, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.339342]\n",
            "(1024, 1)\n",
            "Training Metrics: 1092 [D loss: 0.613538, acc.: 99.76%, op_acc: 82.57%] [G loss: 6.103632]\n",
            "Validating on test set\n",
            "Validation Metrics: 1092 [D loss: 0.148269, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.794054]\n",
            "(1024, 1)\n",
            "Training Metrics: 1093 [D loss: 0.546454, acc.: 99.90%, op_acc: 82.18%] [G loss: 5.423672]\n",
            "Validating on test set\n",
            "Validation Metrics: 1093 [D loss: 0.209647, acc.: 100.00%, op_acc: 95.02%] [G loss: 5.480959]\n",
            "(1024, 1)\n",
            "Training Metrics: 1094 [D loss: 0.600987, acc.: 99.71%, op_acc: 79.93%] [G loss: 5.618763]\n",
            "Validating on test set\n",
            "Validation Metrics: 1094 [D loss: 0.250594, acc.: 100.00%, op_acc: 95.90%] [G loss: 5.984935]\n",
            "(1024, 1)\n",
            "Training Metrics: 1095 [D loss: 0.672256, acc.: 99.80%, op_acc: 79.25%] [G loss: 5.877841]\n",
            "Validating on test set\n",
            "Validation Metrics: 1095 [D loss: 0.157397, acc.: 100.00%, op_acc: 97.75%] [G loss: 5.554721]\n",
            "(1024, 1)\n",
            "Training Metrics: 1096 [D loss: 0.577864, acc.: 99.71%, op_acc: 80.76%] [G loss: 5.774855]\n",
            "Validating on test set\n",
            "Validation Metrics: 1096 [D loss: 0.173965, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.740827]\n",
            "(1024, 1)\n",
            "Training Metrics: 1097 [D loss: 0.587435, acc.: 99.85%, op_acc: 82.18%] [G loss: 5.727573]\n",
            "Validating on test set\n",
            "Validation Metrics: 1097 [D loss: 0.167481, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.783166]\n",
            "(1024, 1)\n",
            "Training Metrics: 1098 [D loss: 0.572622, acc.: 99.71%, op_acc: 83.40%] [G loss: 5.967014]\n",
            "Validating on test set\n",
            "Validation Metrics: 1098 [D loss: 0.148349, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.003755]\n",
            "(1024, 1)\n",
            "Training Metrics: 1099 [D loss: 0.549416, acc.: 99.61%, op_acc: 82.67%] [G loss: 5.825321]\n",
            "Validating on test set\n",
            "Validation Metrics: 1099 [D loss: 0.143721, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.906650]\n",
            "(1024, 1)\n",
            "Training Metrics: 1100 [D loss: 0.627467, acc.: 99.71%, op_acc: 80.47%] [G loss: 5.764965]\n",
            "Validating on test set\n",
            "Validation Metrics: 1100 [D loss: 0.142622, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.704528]\n",
            "(1024, 1)\n",
            "Training Metrics: 1101 [D loss: 0.593510, acc.: 99.80%, op_acc: 82.18%] [G loss: 5.817495]\n",
            "Validating on test set\n",
            "Validation Metrics: 1101 [D loss: 0.128162, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.732243]\n",
            "(1024, 1)\n",
            "Training Metrics: 1102 [D loss: 0.595222, acc.: 99.71%, op_acc: 81.35%] [G loss: 5.575940]\n",
            "Validating on test set\n",
            "Validation Metrics: 1102 [D loss: 0.139443, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.585235]\n",
            "(1024, 1)\n",
            "Training Metrics: 1103 [D loss: 0.539958, acc.: 99.90%, op_acc: 82.81%] [G loss: 5.619654]\n",
            "Validating on test set\n",
            "Validation Metrics: 1103 [D loss: 0.191062, acc.: 100.00%, op_acc: 97.56%] [G loss: 5.650720]\n",
            "(1024, 1)\n",
            "Training Metrics: 1104 [D loss: 0.570047, acc.: 99.95%, op_acc: 81.84%] [G loss: 5.756429]\n",
            "Validating on test set\n",
            "Validation Metrics: 1104 [D loss: 0.207479, acc.: 100.00%, op_acc: 96.09%] [G loss: 5.923369]\n",
            "(1024, 1)\n",
            "Training Metrics: 1105 [D loss: 0.612809, acc.: 99.71%, op_acc: 81.05%] [G loss: 6.063538]\n",
            "Validating on test set\n",
            "Validation Metrics: 1105 [D loss: 0.190743, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.985784]\n",
            "(1024, 1)\n",
            "Training Metrics: 1106 [D loss: 0.595170, acc.: 99.80%, op_acc: 81.98%] [G loss: 5.978997]\n",
            "Validating on test set\n",
            "Validation Metrics: 1106 [D loss: 0.130738, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.852165]\n",
            "(1024, 1)\n",
            "Training Metrics: 1107 [D loss: 0.609205, acc.: 99.76%, op_acc: 81.93%] [G loss: 5.666089]\n",
            "Validating on test set\n",
            "Validation Metrics: 1107 [D loss: 0.130773, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.568295]\n",
            "(1024, 1)\n",
            "Training Metrics: 1108 [D loss: 0.558030, acc.: 99.66%, op_acc: 83.25%] [G loss: 5.675819]\n",
            "Validating on test set\n",
            "Validation Metrics: 1108 [D loss: 0.170908, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.600420]\n",
            "(1024, 1)\n",
            "Training Metrics: 1109 [D loss: 0.601728, acc.: 99.76%, op_acc: 82.71%] [G loss: 5.473296]\n",
            "Validating on test set\n",
            "Validation Metrics: 1109 [D loss: 0.194695, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.456263]\n",
            "(1024, 1)\n",
            "Training Metrics: 1110 [D loss: 0.574883, acc.: 100.00%, op_acc: 82.47%] [G loss: 5.845705]\n",
            "Validating on test set\n",
            "Validation Metrics: 1110 [D loss: 0.193021, acc.: 100.00%, op_acc: 97.95%] [G loss: 5.861856]\n",
            "(1024, 1)\n",
            "Training Metrics: 1111 [D loss: 0.581060, acc.: 99.76%, op_acc: 82.91%] [G loss: 5.931842]\n",
            "Validating on test set\n",
            "Validation Metrics: 1111 [D loss: 0.223316, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.269502]\n",
            "(1024, 1)\n",
            "Training Metrics: 1112 [D loss: 0.641213, acc.: 99.61%, op_acc: 79.88%] [G loss: 6.055659]\n",
            "Validating on test set\n",
            "Validation Metrics: 1112 [D loss: 0.239453, acc.: 100.00%, op_acc: 97.07%] [G loss: 6.026658]\n",
            "(1024, 1)\n",
            "Training Metrics: 1113 [D loss: 0.651799, acc.: 99.85%, op_acc: 80.18%] [G loss: 6.174908]\n",
            "Validating on test set\n",
            "Validation Metrics: 1113 [D loss: 0.204176, acc.: 100.00%, op_acc: 98.73%] [G loss: 6.199438]\n",
            "(1024, 1)\n",
            "Training Metrics: 1114 [D loss: 0.666790, acc.: 99.66%, op_acc: 80.18%] [G loss: 6.076278]\n",
            "Validating on test set\n",
            "Validation Metrics: 1114 [D loss: 0.132782, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.822306]\n",
            "(1024, 1)\n",
            "Training Metrics: 1115 [D loss: 0.589157, acc.: 99.85%, op_acc: 81.54%] [G loss: 5.913373]\n",
            "Validating on test set\n",
            "Validation Metrics: 1115 [D loss: 0.162244, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.822207]\n",
            "(1024, 1)\n",
            "Training Metrics: 1116 [D loss: 0.560665, acc.: 99.76%, op_acc: 82.13%] [G loss: 5.715233]\n",
            "Validating on test set\n",
            "Validation Metrics: 1116 [D loss: 0.343761, acc.: 100.00%, op_acc: 94.14%] [G loss: 5.948884]\n",
            "(1024, 1)\n",
            "Training Metrics: 1117 [D loss: 0.639845, acc.: 99.90%, op_acc: 81.05%] [G loss: 5.904940]\n",
            "Validating on test set\n",
            "Validation Metrics: 1117 [D loss: 0.210825, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.958391]\n",
            "(1024, 1)\n",
            "Training Metrics: 1118 [D loss: 0.597147, acc.: 99.76%, op_acc: 82.52%] [G loss: 6.329620]\n",
            "Validating on test set\n",
            "Validation Metrics: 1118 [D loss: 0.276065, acc.: 100.00%, op_acc: 92.38%] [G loss: 6.620118]\n",
            "(1024, 1)\n",
            "Training Metrics: 1119 [D loss: 0.643742, acc.: 99.90%, op_acc: 78.56%] [G loss: 6.145262]\n",
            "Validating on test set\n",
            "Validation Metrics: 1119 [D loss: 0.236001, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.752308]\n",
            "(1024, 1)\n",
            "Training Metrics: 1120 [D loss: 0.589957, acc.: 99.85%, op_acc: 81.79%] [G loss: 6.225684]\n",
            "Validating on test set\n",
            "Validation Metrics: 1120 [D loss: 0.204278, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.248939]\n",
            "(1024, 1)\n",
            "Training Metrics: 1121 [D loss: 0.627258, acc.: 99.51%, op_acc: 81.25%] [G loss: 5.720795]\n",
            "Validating on test set\n",
            "Validation Metrics: 1121 [D loss: 0.153076, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.629973]\n",
            "(1024, 1)\n",
            "Training Metrics: 1122 [D loss: 0.572361, acc.: 99.95%, op_acc: 82.67%] [G loss: 5.566672]\n",
            "Validating on test set\n",
            "Validation Metrics: 1122 [D loss: 0.174552, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.460867]\n",
            "(1024, 1)\n",
            "Training Metrics: 1123 [D loss: 0.585939, acc.: 99.85%, op_acc: 82.03%] [G loss: 5.879970]\n",
            "Validating on test set\n",
            "Validation Metrics: 1123 [D loss: 0.179424, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.134932]\n",
            "(1024, 1)\n",
            "Training Metrics: 1124 [D loss: 0.613142, acc.: 99.85%, op_acc: 81.64%] [G loss: 6.010005]\n",
            "Validating on test set\n",
            "Validation Metrics: 1124 [D loss: 0.197179, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.095252]\n",
            "(1024, 1)\n",
            "Training Metrics: 1125 [D loss: 0.586225, acc.: 100.00%, op_acc: 81.84%] [G loss: 6.004432]\n",
            "Validating on test set\n",
            "Validation Metrics: 1125 [D loss: 0.148979, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.859694]\n",
            "(1024, 1)\n",
            "Training Metrics: 1126 [D loss: 0.575247, acc.: 99.80%, op_acc: 83.45%] [G loss: 5.950946]\n",
            "Validating on test set\n",
            "Validation Metrics: 1126 [D loss: 0.121977, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.831511]\n",
            "(1024, 1)\n",
            "Training Metrics: 1127 [D loss: 0.526983, acc.: 99.76%, op_acc: 82.52%] [G loss: 5.711245]\n",
            "Validating on test set\n",
            "Validation Metrics: 1127 [D loss: 0.149904, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.657213]\n",
            "(1024, 1)\n",
            "Training Metrics: 1128 [D loss: 0.519003, acc.: 99.95%, op_acc: 84.03%] [G loss: 5.703618]\n",
            "Validating on test set\n",
            "Validation Metrics: 1128 [D loss: 0.178464, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.839691]\n",
            "(1024, 1)\n",
            "Training Metrics: 1129 [D loss: 0.532367, acc.: 99.90%, op_acc: 83.30%] [G loss: 5.931880]\n",
            "Validating on test set\n",
            "Validation Metrics: 1129 [D loss: 0.216263, acc.: 100.00%, op_acc: 93.55%] [G loss: 5.959887]\n",
            "(1024, 1)\n",
            "Training Metrics: 1130 [D loss: 0.604029, acc.: 99.76%, op_acc: 77.83%] [G loss: 5.969576]\n",
            "Validating on test set\n",
            "Validation Metrics: 1130 [D loss: 0.159014, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.015922]\n",
            "(1024, 1)\n",
            "Training Metrics: 1131 [D loss: 0.593880, acc.: 99.85%, op_acc: 82.42%] [G loss: 5.963640]\n",
            "Validating on test set\n",
            "Validation Metrics: 1131 [D loss: 0.135370, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.858304]\n",
            "(1024, 1)\n",
            "Training Metrics: 1132 [D loss: 0.562986, acc.: 99.76%, op_acc: 83.40%] [G loss: 5.890139]\n",
            "Validating on test set\n",
            "Validation Metrics: 1132 [D loss: 0.131530, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.820688]\n",
            "(1024, 1)\n",
            "Training Metrics: 1133 [D loss: 0.526662, acc.: 99.80%, op_acc: 83.30%] [G loss: 5.859139]\n",
            "Validating on test set\n",
            "Validation Metrics: 1133 [D loss: 0.153189, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.862628]\n",
            "(1024, 1)\n",
            "Training Metrics: 1134 [D loss: 0.571846, acc.: 99.80%, op_acc: 81.98%] [G loss: 5.670816]\n",
            "Validating on test set\n",
            "Validation Metrics: 1134 [D loss: 0.157999, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.630044]\n",
            "(1024, 1)\n",
            "Training Metrics: 1135 [D loss: 0.550925, acc.: 99.95%, op_acc: 82.76%] [G loss: 6.015986]\n",
            "Validating on test set\n",
            "Validation Metrics: 1135 [D loss: 0.127655, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.072534]\n",
            "(1024, 1)\n",
            "Training Metrics: 1136 [D loss: 0.567390, acc.: 99.61%, op_acc: 82.91%] [G loss: 5.793884]\n",
            "Validating on test set\n",
            "Validation Metrics: 1136 [D loss: 0.132798, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.766837]\n",
            "(1024, 1)\n",
            "Training Metrics: 1137 [D loss: 0.572281, acc.: 99.80%, op_acc: 82.86%] [G loss: 6.069367]\n",
            "Validating on test set\n",
            "Validation Metrics: 1137 [D loss: 0.180586, acc.: 100.00%, op_acc: 98.83%] [G loss: 6.136931]\n",
            "(1024, 1)\n",
            "Training Metrics: 1138 [D loss: 0.587976, acc.: 99.85%, op_acc: 82.52%] [G loss: 6.081252]\n",
            "Validating on test set\n",
            "Validation Metrics: 1138 [D loss: 0.230852, acc.: 100.00%, op_acc: 92.19%] [G loss: 6.154593]\n",
            "(1024, 1)\n",
            "Training Metrics: 1139 [D loss: 0.572211, acc.: 99.80%, op_acc: 80.71%] [G loss: 6.058667]\n",
            "Validating on test set\n",
            "Validation Metrics: 1139 [D loss: 0.163023, acc.: 100.00%, op_acc: 98.54%] [G loss: 5.953870]\n",
            "(1024, 1)\n",
            "Training Metrics: 1140 [D loss: 0.550594, acc.: 99.66%, op_acc: 84.23%] [G loss: 5.697201]\n",
            "Validating on test set\n",
            "Validation Metrics: 1140 [D loss: 0.144857, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.584575]\n",
            "(1024, 1)\n",
            "Training Metrics: 1141 [D loss: 0.558625, acc.: 99.95%, op_acc: 83.11%] [G loss: 5.703662]\n",
            "Validating on test set\n",
            "Validation Metrics: 1141 [D loss: 0.115619, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.769172]\n",
            "(1024, 1)\n",
            "Training Metrics: 1142 [D loss: 0.542708, acc.: 99.61%, op_acc: 83.35%] [G loss: 5.681306]\n",
            "Validating on test set\n",
            "Validation Metrics: 1142 [D loss: 0.128887, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.590753]\n",
            "(1024, 1)\n",
            "Training Metrics: 1143 [D loss: 0.562571, acc.: 99.76%, op_acc: 82.57%] [G loss: 5.413585]\n",
            "Validating on test set\n",
            "Validation Metrics: 1143 [D loss: 0.293036, acc.: 100.00%, op_acc: 93.46%] [G loss: 5.556062]\n",
            "(1024, 1)\n",
            "Training Metrics: 1144 [D loss: 0.648380, acc.: 99.85%, op_acc: 79.69%] [G loss: 5.889154]\n",
            "Validating on test set\n",
            "Validation Metrics: 1144 [D loss: 0.128969, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.119662]\n",
            "(1024, 1)\n",
            "Training Metrics: 1145 [D loss: 0.530620, acc.: 99.90%, op_acc: 83.84%] [G loss: 5.782672]\n",
            "Validating on test set\n",
            "Validation Metrics: 1145 [D loss: 0.153046, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.870811]\n",
            "(1024, 1)\n",
            "Training Metrics: 1146 [D loss: 0.523580, acc.: 99.95%, op_acc: 83.30%] [G loss: 6.210512]\n",
            "Validating on test set\n",
            "Validation Metrics: 1146 [D loss: 0.149759, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.109237]\n",
            "(1024, 1)\n",
            "Training Metrics: 1147 [D loss: 0.565701, acc.: 99.76%, op_acc: 82.47%] [G loss: 6.042016]\n",
            "Validating on test set\n",
            "Validation Metrics: 1147 [D loss: 0.218415, acc.: 100.00%, op_acc: 94.43%] [G loss: 6.185960]\n",
            "(1024, 1)\n",
            "Training Metrics: 1148 [D loss: 0.655877, acc.: 99.71%, op_acc: 79.20%] [G loss: 5.972587]\n",
            "Validating on test set\n",
            "Validation Metrics: 1148 [D loss: 0.166626, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.868782]\n",
            "(1024, 1)\n",
            "Training Metrics: 1149 [D loss: 0.575786, acc.: 99.80%, op_acc: 82.71%] [G loss: 6.222251]\n",
            "Validating on test set\n",
            "Validation Metrics: 1149 [D loss: 0.166686, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.258889]\n",
            "(1024, 1)\n",
            "Training Metrics: 1150 [D loss: 0.573474, acc.: 99.66%, op_acc: 82.62%] [G loss: 5.657593]\n",
            "Validating on test set\n",
            "Validation Metrics: 1150 [D loss: 0.123857, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.663502]\n",
            "(1024, 1)\n",
            "Training Metrics: 1151 [D loss: 0.613734, acc.: 99.80%, op_acc: 81.79%] [G loss: 5.619485]\n",
            "Validating on test set\n",
            "Validation Metrics: 1151 [D loss: 0.121047, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.473176]\n",
            "(1024, 1)\n",
            "Training Metrics: 1152 [D loss: 0.569445, acc.: 99.41%, op_acc: 83.01%] [G loss: 5.416552]\n",
            "Validating on test set\n",
            "Validation Metrics: 1152 [D loss: 0.116939, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.451301]\n",
            "(1024, 1)\n",
            "Training Metrics: 1153 [D loss: 0.519385, acc.: 99.85%, op_acc: 82.86%] [G loss: 5.524858]\n",
            "Validating on test set\n",
            "Validation Metrics: 1153 [D loss: 0.124013, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.503933]\n",
            "(1024, 1)\n",
            "Training Metrics: 1154 [D loss: 0.519861, acc.: 99.80%, op_acc: 82.76%] [G loss: 5.760984]\n",
            "Validating on test set\n",
            "Validation Metrics: 1154 [D loss: 0.141398, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.920338]\n",
            "(1024, 1)\n",
            "Training Metrics: 1155 [D loss: 0.536363, acc.: 99.80%, op_acc: 82.03%] [G loss: 5.613293]\n",
            "Validating on test set\n",
            "Validation Metrics: 1155 [D loss: 0.127680, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.479380]\n",
            "(1024, 1)\n",
            "Training Metrics: 1156 [D loss: 0.559106, acc.: 99.80%, op_acc: 81.45%] [G loss: 5.821070]\n",
            "Validating on test set\n",
            "Validation Metrics: 1156 [D loss: 0.123650, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.745912]\n",
            "(1024, 1)\n",
            "Training Metrics: 1157 [D loss: 0.527099, acc.: 99.80%, op_acc: 83.25%] [G loss: 5.820371]\n",
            "Validating on test set\n",
            "Validation Metrics: 1157 [D loss: 0.106063, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.839262]\n",
            "(1024, 1)\n",
            "Training Metrics: 1158 [D loss: 0.539086, acc.: 99.56%, op_acc: 82.42%] [G loss: 5.623194]\n",
            "Validating on test set\n",
            "Validation Metrics: 1158 [D loss: 0.171607, acc.: 100.00%, op_acc: 96.78%] [G loss: 5.760429]\n",
            "(1024, 1)\n",
            "Training Metrics: 1159 [D loss: 0.602409, acc.: 99.76%, op_acc: 80.37%] [G loss: 5.758674]\n",
            "Validating on test set\n",
            "Validation Metrics: 1159 [D loss: 0.184036, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.955733]\n",
            "(1024, 1)\n",
            "Training Metrics: 1160 [D loss: 0.618539, acc.: 99.85%, op_acc: 79.74%] [G loss: 5.987556]\n",
            "Validating on test set\n",
            "Validation Metrics: 1160 [D loss: 0.108077, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.739126]\n",
            "(1024, 1)\n",
            "Training Metrics: 1161 [D loss: 0.583925, acc.: 100.00%, op_acc: 82.32%] [G loss: 5.825047]\n",
            "Validating on test set\n",
            "Validation Metrics: 1161 [D loss: 0.112257, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.814162]\n",
            "(1024, 1)\n",
            "Training Metrics: 1162 [D loss: 0.590192, acc.: 99.71%, op_acc: 81.88%] [G loss: 5.692202]\n",
            "Validating on test set\n",
            "Validation Metrics: 1162 [D loss: 0.127538, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.655292]\n",
            "(1024, 1)\n",
            "Training Metrics: 1163 [D loss: 0.493784, acc.: 99.90%, op_acc: 83.94%] [G loss: 5.790999]\n",
            "Validating on test set\n",
            "Validation Metrics: 1163 [D loss: 0.118888, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.729028]\n",
            "(1024, 1)\n",
            "Training Metrics: 1164 [D loss: 0.578167, acc.: 99.71%, op_acc: 81.93%] [G loss: 5.808496]\n",
            "Validating on test set\n",
            "Validation Metrics: 1164 [D loss: 0.104910, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.765268]\n",
            "(1024, 1)\n",
            "Training Metrics: 1165 [D loss: 0.568740, acc.: 99.76%, op_acc: 83.01%] [G loss: 5.729321]\n",
            "Validating on test set\n",
            "Validation Metrics: 1165 [D loss: 0.110602, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.716542]\n",
            "(1024, 1)\n",
            "Training Metrics: 1166 [D loss: 0.511953, acc.: 99.85%, op_acc: 84.42%] [G loss: 5.821463]\n",
            "Validating on test set\n",
            "Validation Metrics: 1166 [D loss: 0.115609, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.861204]\n",
            "(1024, 1)\n",
            "Training Metrics: 1167 [D loss: 0.532250, acc.: 99.66%, op_acc: 84.08%] [G loss: 5.652399]\n",
            "Validating on test set\n",
            "Validation Metrics: 1167 [D loss: 0.122700, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.638477]\n",
            "(1024, 1)\n",
            "Training Metrics: 1168 [D loss: 0.553832, acc.: 99.76%, op_acc: 83.15%] [G loss: 5.667932]\n",
            "Validating on test set\n",
            "Validation Metrics: 1168 [D loss: 0.112799, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.707144]\n",
            "(1024, 1)\n",
            "Training Metrics: 1169 [D loss: 0.595097, acc.: 99.85%, op_acc: 82.32%] [G loss: 5.632991]\n",
            "Validating on test set\n",
            "Validation Metrics: 1169 [D loss: 0.119352, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.595566]\n",
            "(1024, 1)\n",
            "Training Metrics: 1170 [D loss: 0.583231, acc.: 99.71%, op_acc: 81.54%] [G loss: 5.651310]\n",
            "Validating on test set\n",
            "Validation Metrics: 1170 [D loss: 0.113142, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.661695]\n",
            "(1024, 1)\n",
            "Training Metrics: 1171 [D loss: 0.522426, acc.: 99.85%, op_acc: 83.84%] [G loss: 5.689345]\n",
            "Validating on test set\n",
            "Validation Metrics: 1171 [D loss: 0.387473, acc.: 100.00%, op_acc: 93.75%] [G loss: 6.019290]\n",
            "(1024, 1)\n",
            "Training Metrics: 1172 [D loss: 0.647408, acc.: 99.95%, op_acc: 81.49%] [G loss: 6.444972]\n",
            "Validating on test set\n",
            "Validation Metrics: 1172 [D loss: 0.127144, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.546946]\n",
            "(1024, 1)\n",
            "Training Metrics: 1173 [D loss: 0.585650, acc.: 99.85%, op_acc: 82.28%] [G loss: 6.187221]\n",
            "Validating on test set\n",
            "Validation Metrics: 1173 [D loss: 0.100965, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.099674]\n",
            "(1024, 1)\n",
            "Training Metrics: 1174 [D loss: 0.497964, acc.: 99.76%, op_acc: 84.38%] [G loss: 6.305001]\n",
            "Validating on test set\n",
            "Validation Metrics: 1174 [D loss: 0.100636, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.235221]\n",
            "(1024, 1)\n",
            "Training Metrics: 1175 [D loss: 0.552003, acc.: 99.71%, op_acc: 83.11%] [G loss: 5.762913]\n",
            "Validating on test set\n",
            "Validation Metrics: 1175 [D loss: 0.122155, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.810114]\n",
            "(1024, 1)\n",
            "Training Metrics: 1176 [D loss: 0.548090, acc.: 99.90%, op_acc: 83.89%] [G loss: 5.839723]\n",
            "Validating on test set\n",
            "Validation Metrics: 1176 [D loss: 0.138556, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.810401]\n",
            "(1024, 1)\n",
            "Training Metrics: 1177 [D loss: 0.568223, acc.: 99.85%, op_acc: 81.64%] [G loss: 6.045672]\n",
            "Validating on test set\n",
            "Validation Metrics: 1177 [D loss: 0.108603, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.003763]\n",
            "(1024, 1)\n",
            "Training Metrics: 1178 [D loss: 0.565298, acc.: 99.90%, op_acc: 81.10%] [G loss: 5.887455]\n",
            "Validating on test set\n",
            "Validation Metrics: 1178 [D loss: 0.113978, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.868510]\n",
            "(1024, 1)\n",
            "Training Metrics: 1179 [D loss: 0.543696, acc.: 99.76%, op_acc: 83.01%] [G loss: 5.915394]\n",
            "Validating on test set\n",
            "Validation Metrics: 1179 [D loss: 0.102777, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.897814]\n",
            "(1024, 1)\n",
            "Training Metrics: 1180 [D loss: 0.569132, acc.: 99.85%, op_acc: 81.40%] [G loss: 5.830908]\n",
            "Validating on test set\n",
            "Validation Metrics: 1180 [D loss: 0.114040, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.845554]\n",
            "(1024, 1)\n",
            "Training Metrics: 1181 [D loss: 0.542748, acc.: 99.80%, op_acc: 83.20%] [G loss: 5.671589]\n",
            "Validating on test set\n",
            "Validation Metrics: 1181 [D loss: 0.096291, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.666011]\n",
            "(1024, 1)\n",
            "Training Metrics: 1182 [D loss: 0.547873, acc.: 99.95%, op_acc: 83.25%] [G loss: 5.928037]\n",
            "Validating on test set\n",
            "Validation Metrics: 1182 [D loss: 0.096563, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.910982]\n",
            "(1024, 1)\n",
            "Training Metrics: 1183 [D loss: 0.487455, acc.: 99.95%, op_acc: 84.23%] [G loss: 6.257300]\n",
            "Validating on test set\n",
            "Validation Metrics: 1183 [D loss: 0.104736, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.272848]\n",
            "(1024, 1)\n",
            "Training Metrics: 1184 [D loss: 0.516794, acc.: 99.85%, op_acc: 84.52%] [G loss: 6.180923]\n",
            "Validating on test set\n",
            "Validation Metrics: 1184 [D loss: 0.110649, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.208263]\n",
            "(1024, 1)\n",
            "Training Metrics: 1185 [D loss: 0.506309, acc.: 99.76%, op_acc: 83.94%] [G loss: 6.164524]\n",
            "Validating on test set\n",
            "Validation Metrics: 1185 [D loss: 0.096827, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.191146]\n",
            "(1024, 1)\n",
            "Training Metrics: 1186 [D loss: 0.523311, acc.: 99.61%, op_acc: 84.18%] [G loss: 5.742831]\n",
            "Validating on test set\n",
            "Validation Metrics: 1186 [D loss: 0.093665, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.710481]\n",
            "(1024, 1)\n",
            "Training Metrics: 1187 [D loss: 0.483412, acc.: 99.90%, op_acc: 84.38%] [G loss: 5.994360]\n",
            "Validating on test set\n",
            "Validation Metrics: 1187 [D loss: 0.110111, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.997584]\n",
            "(1024, 1)\n",
            "Training Metrics: 1188 [D loss: 0.542475, acc.: 99.90%, op_acc: 82.57%] [G loss: 5.759480]\n",
            "Validating on test set\n",
            "Validation Metrics: 1188 [D loss: 0.110151, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.759257]\n",
            "(1024, 1)\n",
            "Training Metrics: 1189 [D loss: 0.564999, acc.: 99.90%, op_acc: 81.10%] [G loss: 6.249029]\n",
            "Validating on test set\n",
            "Validation Metrics: 1189 [D loss: 0.091814, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.233170]\n",
            "(1024, 1)\n",
            "Training Metrics: 1190 [D loss: 0.561956, acc.: 99.85%, op_acc: 81.74%] [G loss: 6.101110]\n",
            "Validating on test set\n",
            "Validation Metrics: 1190 [D loss: 0.095087, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.079516]\n",
            "(1024, 1)\n",
            "Training Metrics: 1191 [D loss: 0.561176, acc.: 99.76%, op_acc: 81.69%] [G loss: 6.063496]\n",
            "Validating on test set\n",
            "Validation Metrics: 1191 [D loss: 0.110247, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.078525]\n",
            "(1024, 1)\n",
            "Training Metrics: 1192 [D loss: 0.531109, acc.: 99.76%, op_acc: 83.20%] [G loss: 5.625199]\n",
            "Validating on test set\n",
            "Validation Metrics: 1192 [D loss: 0.111869, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.612045]\n",
            "(1024, 1)\n",
            "Training Metrics: 1193 [D loss: 0.491371, acc.: 99.95%, op_acc: 84.28%] [G loss: 5.829669]\n",
            "Validating on test set\n",
            "Validation Metrics: 1193 [D loss: 0.097608, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.837716]\n",
            "(1024, 1)\n",
            "Training Metrics: 1194 [D loss: 0.519200, acc.: 99.90%, op_acc: 82.08%] [G loss: 5.903770]\n",
            "Validating on test set\n",
            "Validation Metrics: 1194 [D loss: 0.096806, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.914399]\n",
            "(1024, 1)\n",
            "Training Metrics: 1195 [D loss: 0.527659, acc.: 99.80%, op_acc: 81.45%] [G loss: 5.912677]\n",
            "Validating on test set\n",
            "Validation Metrics: 1195 [D loss: 0.108037, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.933729]\n",
            "(1024, 1)\n",
            "Training Metrics: 1196 [D loss: 0.561067, acc.: 99.85%, op_acc: 83.40%] [G loss: 6.006537]\n",
            "Validating on test set\n",
            "Validation Metrics: 1196 [D loss: 0.104050, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.958820]\n",
            "(1024, 1)\n",
            "Training Metrics: 1197 [D loss: 0.532193, acc.: 99.85%, op_acc: 82.32%] [G loss: 5.891312]\n",
            "Validating on test set\n",
            "Validation Metrics: 1197 [D loss: 0.088945, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.891620]\n",
            "(1024, 1)\n",
            "Training Metrics: 1198 [D loss: 0.529206, acc.: 99.90%, op_acc: 83.94%] [G loss: 6.043767]\n",
            "Validating on test set\n",
            "Validation Metrics: 1198 [D loss: 0.085962, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.026748]\n",
            "(1024, 1)\n",
            "Training Metrics: 1199 [D loss: 0.556548, acc.: 99.71%, op_acc: 82.71%] [G loss: 5.561328]\n",
            "Validating on test set\n",
            "Validation Metrics: 1199 [D loss: 0.103096, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.558958]\n",
            "(1024, 1)\n",
            "Training Metrics: 1200 [D loss: 0.535940, acc.: 99.80%, op_acc: 83.01%] [G loss: 6.004551]\n",
            "Validating on test set\n",
            "Validation Metrics: 1200 [D loss: 0.093563, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.988811]\n",
            "(1024, 1)\n",
            "Training Metrics: 1201 [D loss: 0.553666, acc.: 99.76%, op_acc: 82.42%] [G loss: 5.670761]\n",
            "Validating on test set\n",
            "Validation Metrics: 1201 [D loss: 0.096072, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.689188]\n",
            "(1024, 1)\n",
            "Training Metrics: 1202 [D loss: 0.483402, acc.: 99.85%, op_acc: 84.42%] [G loss: 5.822994]\n",
            "Validating on test set\n",
            "Validation Metrics: 1202 [D loss: 0.106244, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.872978]\n",
            "(1024, 1)\n",
            "Training Metrics: 1203 [D loss: 0.508888, acc.: 99.76%, op_acc: 84.08%] [G loss: 5.843987]\n",
            "Validating on test set\n",
            "Validation Metrics: 1203 [D loss: 0.114886, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.830286]\n",
            "(1024, 1)\n",
            "Training Metrics: 1204 [D loss: 0.468936, acc.: 99.85%, op_acc: 84.91%] [G loss: 5.948291]\n",
            "Validating on test set\n",
            "Validation Metrics: 1204 [D loss: 0.095581, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.945066]\n",
            "(1024, 1)\n",
            "Training Metrics: 1205 [D loss: 0.502435, acc.: 99.85%, op_acc: 84.81%] [G loss: 6.071468]\n",
            "Validating on test set\n",
            "Validation Metrics: 1205 [D loss: 0.093632, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.049050]\n",
            "(1024, 1)\n",
            "Training Metrics: 1206 [D loss: 0.504906, acc.: 99.80%, op_acc: 83.06%] [G loss: 5.760674]\n",
            "Validating on test set\n",
            "Validation Metrics: 1206 [D loss: 0.111028, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.764796]\n",
            "(1024, 1)\n",
            "Training Metrics: 1207 [D loss: 0.523189, acc.: 99.80%, op_acc: 82.76%] [G loss: 6.032183]\n",
            "Validating on test set\n",
            "Validation Metrics: 1207 [D loss: 0.123632, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.033147]\n",
            "(1024, 1)\n",
            "Training Metrics: 1208 [D loss: 0.537456, acc.: 99.80%, op_acc: 82.32%] [G loss: 5.997973]\n",
            "Validating on test set\n",
            "Validation Metrics: 1208 [D loss: 0.084380, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.038975]\n",
            "(1024, 1)\n",
            "Training Metrics: 1209 [D loss: 0.507441, acc.: 99.80%, op_acc: 83.64%] [G loss: 6.148350]\n",
            "Validating on test set\n",
            "Validation Metrics: 1209 [D loss: 0.088811, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.144541]\n",
            "(1024, 1)\n",
            "Training Metrics: 1210 [D loss: 0.485115, acc.: 99.95%, op_acc: 84.13%] [G loss: 6.000403]\n",
            "Validating on test set\n",
            "Validation Metrics: 1210 [D loss: 0.099399, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.923718]\n",
            "(1024, 1)\n",
            "Training Metrics: 1211 [D loss: 0.519105, acc.: 99.90%, op_acc: 84.08%] [G loss: 6.132840]\n",
            "Validating on test set\n",
            "Validation Metrics: 1211 [D loss: 0.120545, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.149849]\n",
            "(1024, 1)\n",
            "Training Metrics: 1212 [D loss: 0.531431, acc.: 99.85%, op_acc: 83.59%] [G loss: 5.925276]\n",
            "Validating on test set\n",
            "Validation Metrics: 1212 [D loss: 0.087169, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.969233]\n",
            "(1024, 1)\n",
            "Training Metrics: 1213 [D loss: 0.503688, acc.: 99.95%, op_acc: 84.38%] [G loss: 6.369657]\n",
            "Validating on test set\n",
            "Validation Metrics: 1213 [D loss: 0.086797, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.325064]\n",
            "(1024, 1)\n",
            "Training Metrics: 1214 [D loss: 0.475292, acc.: 99.90%, op_acc: 84.38%] [G loss: 6.054617]\n",
            "Validating on test set\n",
            "Validation Metrics: 1214 [D loss: 0.094736, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.009992]\n",
            "(1024, 1)\n",
            "Training Metrics: 1215 [D loss: 0.547839, acc.: 99.76%, op_acc: 81.98%] [G loss: 6.135190]\n",
            "Validating on test set\n",
            "Validation Metrics: 1215 [D loss: 0.122660, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.159709]\n",
            "(1024, 1)\n",
            "Training Metrics: 1216 [D loss: 0.566716, acc.: 99.76%, op_acc: 82.86%] [G loss: 5.961725]\n",
            "Validating on test set\n",
            "Validation Metrics: 1216 [D loss: 0.093780, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.058892]\n",
            "(1024, 1)\n",
            "Training Metrics: 1217 [D loss: 0.510196, acc.: 99.80%, op_acc: 84.03%] [G loss: 6.167244]\n",
            "Validating on test set\n",
            "Validation Metrics: 1217 [D loss: 0.080625, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.106312]\n",
            "(1024, 1)\n",
            "Training Metrics: 1218 [D loss: 0.483382, acc.: 99.85%, op_acc: 83.35%] [G loss: 6.114259]\n",
            "Validating on test set\n",
            "Validation Metrics: 1218 [D loss: 0.086257, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.082453]\n",
            "(1024, 1)\n",
            "Training Metrics: 1219 [D loss: 0.520303, acc.: 99.85%, op_acc: 83.30%] [G loss: 5.844398]\n",
            "Validating on test set\n",
            "Validation Metrics: 1219 [D loss: 0.103090, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.848732]\n",
            "(1024, 1)\n",
            "Training Metrics: 1220 [D loss: 0.525982, acc.: 99.66%, op_acc: 82.28%] [G loss: 5.830050]\n",
            "Validating on test set\n",
            "Validation Metrics: 1220 [D loss: 0.107217, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.813867]\n",
            "(1024, 1)\n",
            "Training Metrics: 1221 [D loss: 0.518419, acc.: 99.85%, op_acc: 84.13%] [G loss: 5.995632]\n",
            "Validating on test set\n",
            "Validation Metrics: 1221 [D loss: 0.087933, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.984598]\n",
            "(1024, 1)\n",
            "Training Metrics: 1222 [D loss: 0.504337, acc.: 99.90%, op_acc: 83.11%] [G loss: 5.873530]\n",
            "Validating on test set\n",
            "Validation Metrics: 1222 [D loss: 0.089203, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.851830]\n",
            "(1024, 1)\n",
            "Training Metrics: 1223 [D loss: 0.490940, acc.: 99.76%, op_acc: 83.74%] [G loss: 5.935373]\n",
            "Validating on test set\n",
            "Validation Metrics: 1223 [D loss: 0.090499, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.946839]\n",
            "(1024, 1)\n",
            "Training Metrics: 1224 [D loss: 0.497661, acc.: 99.80%, op_acc: 84.18%] [G loss: 5.904364]\n",
            "Validating on test set\n",
            "Validation Metrics: 1224 [D loss: 0.098476, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.906129]\n",
            "(1024, 1)\n",
            "Training Metrics: 1225 [D loss: 0.484629, acc.: 100.00%, op_acc: 84.03%] [G loss: 6.019876]\n",
            "Validating on test set\n",
            "Validation Metrics: 1225 [D loss: 0.085560, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.037956]\n",
            "(1024, 1)\n",
            "Training Metrics: 1226 [D loss: 0.471834, acc.: 99.76%, op_acc: 84.52%] [G loss: 6.280068]\n",
            "Validating on test set\n",
            "Validation Metrics: 1226 [D loss: 0.083980, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.251177]\n",
            "(1024, 1)\n",
            "Training Metrics: 1227 [D loss: 0.562411, acc.: 99.90%, op_acc: 82.08%] [G loss: 6.097103]\n",
            "Validating on test set\n",
            "Validation Metrics: 1227 [D loss: 0.095295, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.063347]\n",
            "(1024, 1)\n",
            "Training Metrics: 1228 [D loss: 0.569392, acc.: 99.51%, op_acc: 83.30%] [G loss: 5.758445]\n",
            "Validating on test set\n",
            "Validation Metrics: 1228 [D loss: 0.101075, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.738726]\n",
            "(1024, 1)\n",
            "Training Metrics: 1229 [D loss: 0.481776, acc.: 99.90%, op_acc: 83.84%] [G loss: 5.914307]\n",
            "Validating on test set\n",
            "Validation Metrics: 1229 [D loss: 0.089843, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.907019]\n",
            "(1024, 1)\n",
            "Training Metrics: 1230 [D loss: 0.509016, acc.: 99.85%, op_acc: 83.06%] [G loss: 5.878875]\n",
            "Validating on test set\n",
            "Validation Metrics: 1230 [D loss: 0.086341, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.888205]\n",
            "(1024, 1)\n",
            "Training Metrics: 1231 [D loss: 0.514808, acc.: 99.85%, op_acc: 83.74%] [G loss: 5.877055]\n",
            "Validating on test set\n",
            "Validation Metrics: 1231 [D loss: 0.090693, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.855272]\n",
            "(1024, 1)\n",
            "Training Metrics: 1232 [D loss: 0.543333, acc.: 99.76%, op_acc: 83.15%] [G loss: 5.953099]\n",
            "Validating on test set\n",
            "Validation Metrics: 1232 [D loss: 0.101251, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.954563]\n",
            "(1024, 1)\n",
            "Training Metrics: 1233 [D loss: 0.522300, acc.: 99.95%, op_acc: 83.01%] [G loss: 5.950675]\n",
            "Validating on test set\n",
            "Validation Metrics: 1233 [D loss: 0.089326, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.921079]\n",
            "(1024, 1)\n",
            "Training Metrics: 1234 [D loss: 0.489182, acc.: 99.90%, op_acc: 83.50%] [G loss: 6.057005]\n",
            "Validating on test set\n",
            "Validation Metrics: 1234 [D loss: 0.091687, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.064584]\n",
            "(1024, 1)\n",
            "Training Metrics: 1235 [D loss: 0.508305, acc.: 99.80%, op_acc: 83.15%] [G loss: 6.153049]\n",
            "Validating on test set\n",
            "Validation Metrics: 1235 [D loss: 0.098214, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.164413]\n",
            "(1024, 1)\n",
            "Training Metrics: 1236 [D loss: 0.503713, acc.: 99.90%, op_acc: 85.60%] [G loss: 6.271751]\n",
            "Validating on test set\n",
            "Validation Metrics: 1236 [D loss: 0.099475, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.279316]\n",
            "(1024, 1)\n",
            "Training Metrics: 1237 [D loss: 0.535382, acc.: 99.85%, op_acc: 82.03%] [G loss: 6.561328]\n",
            "Validating on test set\n",
            "Validation Metrics: 1237 [D loss: 0.090628, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.551245]\n",
            "(1024, 1)\n",
            "Training Metrics: 1238 [D loss: 0.496422, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.553181]\n",
            "Validating on test set\n",
            "Validation Metrics: 1238 [D loss: 0.089067, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.516700]\n",
            "(1024, 1)\n",
            "Training Metrics: 1239 [D loss: 0.490533, acc.: 99.76%, op_acc: 83.64%] [G loss: 6.235051]\n",
            "Validating on test set\n",
            "Validation Metrics: 1239 [D loss: 0.091648, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.263449]\n",
            "(1024, 1)\n",
            "Training Metrics: 1240 [D loss: 0.518692, acc.: 99.85%, op_acc: 84.18%] [G loss: 6.312095]\n",
            "Validating on test set\n",
            "Validation Metrics: 1240 [D loss: 0.099024, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.312448]\n",
            "(1024, 1)\n",
            "Training Metrics: 1241 [D loss: 0.525550, acc.: 99.80%, op_acc: 83.35%] [G loss: 6.137242]\n",
            "Validating on test set\n",
            "Validation Metrics: 1241 [D loss: 0.089728, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.131032]\n",
            "(1024, 1)\n",
            "Training Metrics: 1242 [D loss: 0.556188, acc.: 99.85%, op_acc: 81.79%] [G loss: 6.134601]\n",
            "Validating on test set\n",
            "Validation Metrics: 1242 [D loss: 0.091581, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.109990]\n",
            "(1024, 1)\n",
            "Training Metrics: 1243 [D loss: 0.565552, acc.: 99.85%, op_acc: 81.64%] [G loss: 5.871099]\n",
            "Validating on test set\n",
            "Validation Metrics: 1243 [D loss: 0.094347, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.909252]\n",
            "(1024, 1)\n",
            "Training Metrics: 1244 [D loss: 0.512700, acc.: 99.80%, op_acc: 83.79%] [G loss: 5.939291]\n",
            "Validating on test set\n",
            "Validation Metrics: 1244 [D loss: 0.102956, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.929114]\n",
            "(1024, 1)\n",
            "Training Metrics: 1245 [D loss: 0.498514, acc.: 99.90%, op_acc: 83.50%] [G loss: 6.115417]\n",
            "Validating on test set\n",
            "Validation Metrics: 1245 [D loss: 0.088246, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.125903]\n",
            "(1024, 1)\n",
            "Training Metrics: 1246 [D loss: 0.470829, acc.: 99.76%, op_acc: 84.52%] [G loss: 5.655343]\n",
            "Validating on test set\n",
            "Validation Metrics: 1246 [D loss: 0.096716, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.644030]\n",
            "(1024, 1)\n",
            "Training Metrics: 1247 [D loss: 0.480506, acc.: 99.85%, op_acc: 83.94%] [G loss: 5.881247]\n",
            "Validating on test set\n",
            "Validation Metrics: 1247 [D loss: 0.092928, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.871380]\n",
            "(1024, 1)\n",
            "Training Metrics: 1248 [D loss: 0.505989, acc.: 100.00%, op_acc: 83.54%] [G loss: 6.313882]\n",
            "Validating on test set\n",
            "Validation Metrics: 1248 [D loss: 0.091795, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.311681]\n",
            "(1024, 1)\n",
            "Training Metrics: 1249 [D loss: 0.509344, acc.: 99.90%, op_acc: 83.06%] [G loss: 6.163743]\n",
            "Validating on test set\n",
            "Validation Metrics: 1249 [D loss: 0.091552, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.146403]\n",
            "(1024, 1)\n",
            "Training Metrics: 1250 [D loss: 0.526247, acc.: 99.80%, op_acc: 82.71%] [G loss: 5.934696]\n",
            "Validating on test set\n",
            "Validation Metrics: 1250 [D loss: 0.093109, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.938268]\n",
            "(1024, 1)\n",
            "Training Metrics: 1251 [D loss: 0.519007, acc.: 99.80%, op_acc: 83.45%] [G loss: 5.814028]\n",
            "Validating on test set\n",
            "Validation Metrics: 1251 [D loss: 0.088801, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.825598]\n",
            "(1024, 1)\n",
            "Training Metrics: 1252 [D loss: 0.475756, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.115144]\n",
            "Validating on test set\n",
            "Validation Metrics: 1252 [D loss: 0.094380, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.109708]\n",
            "(1024, 1)\n",
            "Training Metrics: 1253 [D loss: 0.501506, acc.: 99.76%, op_acc: 84.42%] [G loss: 6.003934]\n",
            "Validating on test set\n",
            "Validation Metrics: 1253 [D loss: 0.085384, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.997516]\n",
            "(1024, 1)\n",
            "Training Metrics: 1254 [D loss: 0.509062, acc.: 99.85%, op_acc: 83.45%] [G loss: 5.865323]\n",
            "Validating on test set\n",
            "Validation Metrics: 1254 [D loss: 0.094745, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.886270]\n",
            "(1024, 1)\n",
            "Training Metrics: 1255 [D loss: 0.516404, acc.: 99.90%, op_acc: 84.81%] [G loss: 5.884567]\n",
            "Validating on test set\n",
            "Validation Metrics: 1255 [D loss: 0.090117, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.913276]\n",
            "(1024, 1)\n",
            "Training Metrics: 1256 [D loss: 0.440620, acc.: 99.85%, op_acc: 85.64%] [G loss: 5.893069]\n",
            "Validating on test set\n",
            "Validation Metrics: 1256 [D loss: 0.092208, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.882551]\n",
            "(1024, 1)\n",
            "Training Metrics: 1257 [D loss: 0.515926, acc.: 99.85%, op_acc: 83.64%] [G loss: 5.712851]\n",
            "Validating on test set\n",
            "Validation Metrics: 1257 [D loss: 0.083536, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.719678]\n",
            "(1024, 1)\n",
            "Training Metrics: 1258 [D loss: 0.515508, acc.: 99.85%, op_acc: 84.08%] [G loss: 6.085043]\n",
            "Validating on test set\n",
            "Validation Metrics: 1258 [D loss: 0.095660, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.067268]\n",
            "(1024, 1)\n",
            "Training Metrics: 1259 [D loss: 0.480928, acc.: 99.90%, op_acc: 84.62%] [G loss: 5.685006]\n",
            "Validating on test set\n",
            "Validation Metrics: 1259 [D loss: 0.079368, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.688526]\n",
            "(1024, 1)\n",
            "Training Metrics: 1260 [D loss: 0.481091, acc.: 99.95%, op_acc: 84.03%] [G loss: 5.953490]\n",
            "Validating on test set\n",
            "Validation Metrics: 1260 [D loss: 0.089385, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.929025]\n",
            "(1024, 1)\n",
            "Training Metrics: 1261 [D loss: 0.490991, acc.: 99.95%, op_acc: 82.86%] [G loss: 6.138921]\n",
            "Validating on test set\n",
            "Validation Metrics: 1261 [D loss: 0.083066, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.141773]\n",
            "(1024, 1)\n",
            "Training Metrics: 1262 [D loss: 0.534676, acc.: 99.85%, op_acc: 82.57%] [G loss: 6.199943]\n",
            "Validating on test set\n",
            "Validation Metrics: 1262 [D loss: 0.090233, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.203794]\n",
            "(1024, 1)\n",
            "Training Metrics: 1263 [D loss: 0.562401, acc.: 99.90%, op_acc: 83.20%] [G loss: 6.418483]\n",
            "Validating on test set\n",
            "Validation Metrics: 1263 [D loss: 0.080175, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.422305]\n",
            "(1024, 1)\n",
            "Training Metrics: 1264 [D loss: 0.533580, acc.: 99.76%, op_acc: 83.11%] [G loss: 5.967632]\n",
            "Validating on test set\n",
            "Validation Metrics: 1264 [D loss: 0.084479, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.954896]\n",
            "(1024, 1)\n",
            "Training Metrics: 1265 [D loss: 0.566523, acc.: 99.76%, op_acc: 82.86%] [G loss: 5.759946]\n",
            "Validating on test set\n",
            "Validation Metrics: 1265 [D loss: 0.088620, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.766551]\n",
            "(1024, 1)\n",
            "Training Metrics: 1266 [D loss: 0.521057, acc.: 99.95%, op_acc: 83.35%] [G loss: 6.020721]\n",
            "Validating on test set\n",
            "Validation Metrics: 1266 [D loss: 0.087031, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.016288]\n",
            "(1024, 1)\n",
            "Training Metrics: 1267 [D loss: 0.520856, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.058412]\n",
            "Validating on test set\n",
            "Validation Metrics: 1267 [D loss: 0.088699, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.071614]\n",
            "(1024, 1)\n",
            "Training Metrics: 1268 [D loss: 0.559151, acc.: 99.80%, op_acc: 82.23%] [G loss: 5.909495]\n",
            "Validating on test set\n",
            "Validation Metrics: 1268 [D loss: 0.086985, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.912553]\n",
            "(1024, 1)\n",
            "Training Metrics: 1269 [D loss: 0.570874, acc.: 99.66%, op_acc: 84.23%] [G loss: 5.569995]\n",
            "Validating on test set\n",
            "Validation Metrics: 1269 [D loss: 0.089840, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.587175]\n",
            "(1024, 1)\n",
            "Training Metrics: 1270 [D loss: 0.539401, acc.: 99.90%, op_acc: 83.01%] [G loss: 5.700420]\n",
            "Validating on test set\n",
            "Validation Metrics: 1270 [D loss: 0.082449, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.699018]\n",
            "(1024, 1)\n",
            "Training Metrics: 1271 [D loss: 0.449451, acc.: 99.90%, op_acc: 85.60%] [G loss: 5.917182]\n",
            "Validating on test set\n",
            "Validation Metrics: 1271 [D loss: 0.088172, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.890750]\n",
            "(1024, 1)\n",
            "Training Metrics: 1272 [D loss: 0.501420, acc.: 99.90%, op_acc: 83.40%] [G loss: 6.031097]\n",
            "Validating on test set\n",
            "Validation Metrics: 1272 [D loss: 0.080660, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.033193]\n",
            "(1024, 1)\n",
            "Training Metrics: 1273 [D loss: 0.473073, acc.: 99.95%, op_acc: 84.18%] [G loss: 5.803602]\n",
            "Validating on test set\n",
            "Validation Metrics: 1273 [D loss: 0.086354, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.806295]\n",
            "(1024, 1)\n",
            "Training Metrics: 1274 [D loss: 0.497839, acc.: 99.90%, op_acc: 83.79%] [G loss: 6.048666]\n",
            "Validating on test set\n",
            "Validation Metrics: 1274 [D loss: 0.081250, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.060796]\n",
            "(1024, 1)\n",
            "Training Metrics: 1275 [D loss: 0.564604, acc.: 99.85%, op_acc: 81.40%] [G loss: 6.170553]\n",
            "Validating on test set\n",
            "Validation Metrics: 1275 [D loss: 0.078721, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.174032]\n",
            "(1024, 1)\n",
            "Training Metrics: 1276 [D loss: 0.544966, acc.: 99.76%, op_acc: 81.30%] [G loss: 6.002575]\n",
            "Validating on test set\n",
            "Validation Metrics: 1276 [D loss: 0.083022, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.002187]\n",
            "(1024, 1)\n",
            "Training Metrics: 1277 [D loss: 0.519375, acc.: 99.90%, op_acc: 83.25%] [G loss: 6.062596]\n",
            "Validating on test set\n",
            "Validation Metrics: 1277 [D loss: 0.074979, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.055187]\n",
            "(1024, 1)\n",
            "Training Metrics: 1278 [D loss: 0.554288, acc.: 99.80%, op_acc: 82.37%] [G loss: 5.916397]\n",
            "Validating on test set\n",
            "Validation Metrics: 1278 [D loss: 0.085489, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.914733]\n",
            "(1024, 1)\n",
            "Training Metrics: 1279 [D loss: 0.495822, acc.: 99.71%, op_acc: 83.84%] [G loss: 5.769758]\n",
            "Validating on test set\n",
            "Validation Metrics: 1279 [D loss: 0.086425, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.747390]\n",
            "(1024, 1)\n",
            "Training Metrics: 1280 [D loss: 0.519501, acc.: 99.76%, op_acc: 83.25%] [G loss: 5.912347]\n",
            "Validating on test set\n",
            "Validation Metrics: 1280 [D loss: 0.088301, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.911919]\n",
            "(1024, 1)\n",
            "Training Metrics: 1281 [D loss: 0.506286, acc.: 99.90%, op_acc: 83.50%] [G loss: 5.752097]\n",
            "Validating on test set\n",
            "Validation Metrics: 1281 [D loss: 0.084938, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.752723]\n",
            "(1024, 1)\n",
            "Training Metrics: 1282 [D loss: 0.501404, acc.: 99.80%, op_acc: 84.08%] [G loss: 5.716085]\n",
            "Validating on test set\n",
            "Validation Metrics: 1282 [D loss: 0.090365, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.713850]\n",
            "(1024, 1)\n",
            "Training Metrics: 1283 [D loss: 0.493639, acc.: 99.90%, op_acc: 84.47%] [G loss: 5.972318]\n",
            "Validating on test set\n",
            "Validation Metrics: 1283 [D loss: 0.082255, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.964956]\n",
            "(1024, 1)\n",
            "Training Metrics: 1284 [D loss: 0.483393, acc.: 99.90%, op_acc: 83.74%] [G loss: 5.966958]\n",
            "Validating on test set\n",
            "Validation Metrics: 1284 [D loss: 0.081251, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.961549]\n",
            "(1024, 1)\n",
            "Training Metrics: 1285 [D loss: 0.477879, acc.: 99.80%, op_acc: 84.72%] [G loss: 6.284246]\n",
            "Validating on test set\n",
            "Validation Metrics: 1285 [D loss: 0.086341, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.288427]\n",
            "(1024, 1)\n",
            "Training Metrics: 1286 [D loss: 0.548800, acc.: 99.90%, op_acc: 83.45%] [G loss: 6.133965]\n",
            "Validating on test set\n",
            "Validation Metrics: 1286 [D loss: 0.083162, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.143717]\n",
            "(1024, 1)\n",
            "Training Metrics: 1287 [D loss: 0.488730, acc.: 99.85%, op_acc: 83.79%] [G loss: 6.126002]\n",
            "Validating on test set\n",
            "Validation Metrics: 1287 [D loss: 0.083013, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.124294]\n",
            "(1024, 1)\n",
            "Training Metrics: 1288 [D loss: 0.492094, acc.: 99.85%, op_acc: 84.28%] [G loss: 6.081059]\n",
            "Validating on test set\n",
            "Validation Metrics: 1288 [D loss: 0.084014, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.081565]\n",
            "(1024, 1)\n",
            "Training Metrics: 1289 [D loss: 0.516660, acc.: 99.76%, op_acc: 82.28%] [G loss: 5.803821]\n",
            "Validating on test set\n",
            "Validation Metrics: 1289 [D loss: 0.082036, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.800086]\n",
            "(1024, 1)\n",
            "Training Metrics: 1290 [D loss: 0.482980, acc.: 99.90%, op_acc: 84.42%] [G loss: 5.867959]\n",
            "Validating on test set\n",
            "Validation Metrics: 1290 [D loss: 0.083238, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.879611]\n",
            "(1024, 1)\n",
            "Training Metrics: 1291 [D loss: 0.499459, acc.: 99.71%, op_acc: 84.57%] [G loss: 5.925933]\n",
            "Validating on test set\n",
            "Validation Metrics: 1291 [D loss: 0.083622, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.920923]\n",
            "(1024, 1)\n",
            "Training Metrics: 1292 [D loss: 0.463181, acc.: 99.71%, op_acc: 84.67%] [G loss: 5.718610]\n",
            "Validating on test set\n",
            "Validation Metrics: 1292 [D loss: 0.082795, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.714428]\n",
            "(1024, 1)\n",
            "Training Metrics: 1293 [D loss: 0.493947, acc.: 99.85%, op_acc: 83.64%] [G loss: 5.789087]\n",
            "Validating on test set\n",
            "Validation Metrics: 1293 [D loss: 0.088365, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.788462]\n",
            "(1024, 1)\n",
            "Training Metrics: 1294 [D loss: 0.511068, acc.: 99.85%, op_acc: 82.71%] [G loss: 5.642387]\n",
            "Validating on test set\n",
            "Validation Metrics: 1294 [D loss: 0.080451, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.667853]\n",
            "(1024, 1)\n",
            "Training Metrics: 1295 [D loss: 0.486476, acc.: 99.85%, op_acc: 84.08%] [G loss: 5.992835]\n",
            "Validating on test set\n",
            "Validation Metrics: 1295 [D loss: 0.073149, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.969491]\n",
            "(1024, 1)\n",
            "Training Metrics: 1296 [D loss: 0.569519, acc.: 99.76%, op_acc: 82.03%] [G loss: 5.886621]\n",
            "Validating on test set\n",
            "Validation Metrics: 1296 [D loss: 0.080665, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.870509]\n",
            "(1024, 1)\n",
            "Training Metrics: 1297 [D loss: 0.493421, acc.: 100.00%, op_acc: 83.59%] [G loss: 5.844933]\n",
            "Validating on test set\n",
            "Validation Metrics: 1297 [D loss: 0.075604, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.852707]\n",
            "(1024, 1)\n",
            "Training Metrics: 1298 [D loss: 0.489374, acc.: 99.90%, op_acc: 83.89%] [G loss: 6.132683]\n",
            "Validating on test set\n",
            "Validation Metrics: 1298 [D loss: 0.080922, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.130678]\n",
            "(1024, 1)\n",
            "Training Metrics: 1299 [D loss: 0.505335, acc.: 99.85%, op_acc: 83.64%] [G loss: 6.219323]\n",
            "Validating on test set\n",
            "Validation Metrics: 1299 [D loss: 0.071116, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.228448]\n",
            "(1024, 1)\n",
            "Training Metrics: 1300 [D loss: 0.460558, acc.: 99.90%, op_acc: 84.38%] [G loss: 6.047253]\n",
            "Validating on test set\n",
            "Validation Metrics: 1300 [D loss: 0.081775, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.037805]\n",
            "(1024, 1)\n",
            "Training Metrics: 1301 [D loss: 0.484406, acc.: 99.85%, op_acc: 83.94%] [G loss: 6.129928]\n",
            "Validating on test set\n",
            "Validation Metrics: 1301 [D loss: 0.077174, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.123512]\n",
            "(1024, 1)\n",
            "Training Metrics: 1302 [D loss: 0.456592, acc.: 99.90%, op_acc: 85.74%] [G loss: 5.892713]\n",
            "Validating on test set\n",
            "Validation Metrics: 1302 [D loss: 0.078472, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.905118]\n",
            "(1024, 1)\n",
            "Training Metrics: 1303 [D loss: 0.470069, acc.: 99.90%, op_acc: 83.74%] [G loss: 6.131515]\n",
            "Validating on test set\n",
            "Validation Metrics: 1303 [D loss: 0.075133, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.133215]\n",
            "(1024, 1)\n",
            "Training Metrics: 1304 [D loss: 0.507939, acc.: 99.76%, op_acc: 83.89%] [G loss: 6.075602]\n",
            "Validating on test set\n",
            "Validation Metrics: 1304 [D loss: 0.073556, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.068930]\n",
            "(1024, 1)\n",
            "Training Metrics: 1305 [D loss: 0.492156, acc.: 99.95%, op_acc: 83.30%] [G loss: 6.185507]\n",
            "Validating on test set\n",
            "Validation Metrics: 1305 [D loss: 0.084128, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.190988]\n",
            "(1024, 1)\n",
            "Training Metrics: 1306 [D loss: 0.518282, acc.: 99.80%, op_acc: 84.13%] [G loss: 6.006401]\n",
            "Validating on test set\n",
            "Validation Metrics: 1306 [D loss: 0.076211, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.001485]\n",
            "(1024, 1)\n",
            "Training Metrics: 1307 [D loss: 0.511560, acc.: 99.85%, op_acc: 82.86%] [G loss: 6.035489]\n",
            "Validating on test set\n",
            "Validation Metrics: 1307 [D loss: 0.077395, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.050068]\n",
            "(1024, 1)\n",
            "Training Metrics: 1308 [D loss: 0.476326, acc.: 99.80%, op_acc: 84.86%] [G loss: 5.962532]\n",
            "Validating on test set\n",
            "Validation Metrics: 1308 [D loss: 0.074498, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.972705]\n",
            "(1024, 1)\n",
            "Training Metrics: 1309 [D loss: 0.493061, acc.: 99.80%, op_acc: 82.96%] [G loss: 6.021635]\n",
            "Validating on test set\n",
            "Validation Metrics: 1309 [D loss: 0.079856, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.012745]\n",
            "(1024, 1)\n",
            "Training Metrics: 1310 [D loss: 0.489091, acc.: 99.95%, op_acc: 83.84%] [G loss: 6.126343]\n",
            "Validating on test set\n",
            "Validation Metrics: 1310 [D loss: 0.071559, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.129505]\n",
            "(1024, 1)\n",
            "Training Metrics: 1311 [D loss: 0.513230, acc.: 99.80%, op_acc: 83.45%] [G loss: 5.878760]\n",
            "Validating on test set\n",
            "Validation Metrics: 1311 [D loss: 0.074290, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.863909]\n",
            "(1024, 1)\n",
            "Training Metrics: 1312 [D loss: 0.521477, acc.: 99.71%, op_acc: 81.88%] [G loss: 5.913794]\n",
            "Validating on test set\n",
            "Validation Metrics: 1312 [D loss: 0.081195, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.920104]\n",
            "(1024, 1)\n",
            "Training Metrics: 1313 [D loss: 0.487698, acc.: 99.80%, op_acc: 84.72%] [G loss: 6.068599]\n",
            "Validating on test set\n",
            "Validation Metrics: 1313 [D loss: 0.069705, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.068896]\n",
            "(1024, 1)\n",
            "Training Metrics: 1314 [D loss: 0.490557, acc.: 99.90%, op_acc: 83.35%] [G loss: 5.732410]\n",
            "Validating on test set\n",
            "Validation Metrics: 1314 [D loss: 0.079342, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.735334]\n",
            "(1024, 1)\n",
            "Training Metrics: 1315 [D loss: 0.488662, acc.: 99.90%, op_acc: 83.84%] [G loss: 6.023445]\n",
            "Validating on test set\n",
            "Validation Metrics: 1315 [D loss: 0.072997, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.030695]\n",
            "(1024, 1)\n",
            "Training Metrics: 1316 [D loss: 0.502150, acc.: 99.66%, op_acc: 83.79%] [G loss: 5.936865]\n",
            "Validating on test set\n",
            "Validation Metrics: 1316 [D loss: 0.077481, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.931122]\n",
            "(1024, 1)\n",
            "Training Metrics: 1317 [D loss: 0.491625, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.293401]\n",
            "Validating on test set\n",
            "Validation Metrics: 1317 [D loss: 0.074142, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.285673]\n",
            "(1024, 1)\n",
            "Training Metrics: 1318 [D loss: 0.506002, acc.: 99.85%, op_acc: 82.76%] [G loss: 5.950056]\n",
            "Validating on test set\n",
            "Validation Metrics: 1318 [D loss: 0.073097, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.934963]\n",
            "(1024, 1)\n",
            "Training Metrics: 1319 [D loss: 0.533411, acc.: 99.95%, op_acc: 81.74%] [G loss: 6.396900]\n",
            "Validating on test set\n",
            "Validation Metrics: 1319 [D loss: 0.074653, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.391262]\n",
            "(1024, 1)\n",
            "Training Metrics: 1320 [D loss: 0.504734, acc.: 99.80%, op_acc: 84.67%] [G loss: 6.073441]\n",
            "Validating on test set\n",
            "Validation Metrics: 1320 [D loss: 0.075670, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.079596]\n",
            "(1024, 1)\n",
            "Training Metrics: 1321 [D loss: 0.467391, acc.: 99.90%, op_acc: 83.79%] [G loss: 6.177243]\n",
            "Validating on test set\n",
            "Validation Metrics: 1321 [D loss: 0.077470, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.168040]\n",
            "(1024, 1)\n",
            "Training Metrics: 1322 [D loss: 0.447890, acc.: 100.00%, op_acc: 84.42%] [G loss: 6.365531]\n",
            "Validating on test set\n",
            "Validation Metrics: 1322 [D loss: 0.074914, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.349019]\n",
            "(1024, 1)\n",
            "Training Metrics: 1323 [D loss: 0.477569, acc.: 99.80%, op_acc: 84.67%] [G loss: 5.982567]\n",
            "Validating on test set\n",
            "Validation Metrics: 1323 [D loss: 0.074743, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.989155]\n",
            "(1024, 1)\n",
            "Training Metrics: 1324 [D loss: 0.481245, acc.: 99.76%, op_acc: 83.01%] [G loss: 5.958724]\n",
            "Validating on test set\n",
            "Validation Metrics: 1324 [D loss: 0.074392, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.952762]\n",
            "(1024, 1)\n",
            "Training Metrics: 1325 [D loss: 0.504682, acc.: 99.71%, op_acc: 82.18%] [G loss: 5.909420]\n",
            "Validating on test set\n",
            "Validation Metrics: 1325 [D loss: 0.073058, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.886742]\n",
            "(1024, 1)\n",
            "Training Metrics: 1326 [D loss: 0.489932, acc.: 99.90%, op_acc: 83.64%] [G loss: 6.144345]\n",
            "Validating on test set\n",
            "Validation Metrics: 1326 [D loss: 0.073144, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.139701]\n",
            "(1024, 1)\n",
            "Training Metrics: 1327 [D loss: 0.493903, acc.: 99.90%, op_acc: 83.89%] [G loss: 6.128733]\n",
            "Validating on test set\n",
            "Validation Metrics: 1327 [D loss: 0.074220, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.130154]\n",
            "(1024, 1)\n",
            "Training Metrics: 1328 [D loss: 0.475741, acc.: 99.85%, op_acc: 84.08%] [G loss: 6.227901]\n",
            "Validating on test set\n",
            "Validation Metrics: 1328 [D loss: 0.077924, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.222991]\n",
            "(1024, 1)\n",
            "Training Metrics: 1329 [D loss: 0.497415, acc.: 99.95%, op_acc: 84.67%] [G loss: 6.184823]\n",
            "Validating on test set\n",
            "Validation Metrics: 1329 [D loss: 0.076172, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.194275]\n",
            "(1024, 1)\n",
            "Training Metrics: 1330 [D loss: 0.498603, acc.: 100.00%, op_acc: 83.15%] [G loss: 6.358588]\n",
            "Validating on test set\n",
            "Validation Metrics: 1330 [D loss: 0.080618, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.353705]\n",
            "(1024, 1)\n",
            "Training Metrics: 1331 [D loss: 0.504676, acc.: 99.85%, op_acc: 82.23%] [G loss: 6.148147]\n",
            "Validating on test set\n",
            "Validation Metrics: 1331 [D loss: 0.074169, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.147329]\n",
            "(1024, 1)\n",
            "Training Metrics: 1332 [D loss: 0.524388, acc.: 99.90%, op_acc: 82.57%] [G loss: 6.359532]\n",
            "Validating on test set\n",
            "Validation Metrics: 1332 [D loss: 0.085158, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.362771]\n",
            "(1024, 1)\n",
            "Training Metrics: 1333 [D loss: 0.518865, acc.: 99.76%, op_acc: 84.23%] [G loss: 5.969795]\n",
            "Validating on test set\n",
            "Validation Metrics: 1333 [D loss: 0.078688, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.979076]\n",
            "(1024, 1)\n",
            "Training Metrics: 1334 [D loss: 0.507023, acc.: 99.85%, op_acc: 83.40%] [G loss: 6.174756]\n",
            "Validating on test set\n",
            "Validation Metrics: 1334 [D loss: 0.073517, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.131410]\n",
            "(1024, 1)\n",
            "Training Metrics: 1335 [D loss: 0.479545, acc.: 99.76%, op_acc: 84.52%] [G loss: 5.904552]\n",
            "Validating on test set\n",
            "Validation Metrics: 1335 [D loss: 0.072087, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.899940]\n",
            "(1024, 1)\n",
            "Training Metrics: 1336 [D loss: 0.488793, acc.: 99.71%, op_acc: 83.98%] [G loss: 5.567058]\n",
            "Validating on test set\n",
            "Validation Metrics: 1336 [D loss: 0.075845, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.565257]\n",
            "(1024, 1)\n",
            "Training Metrics: 1337 [D loss: 0.466838, acc.: 99.90%, op_acc: 83.20%] [G loss: 5.976047]\n",
            "Validating on test set\n",
            "Validation Metrics: 1337 [D loss: 0.075398, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.979293]\n",
            "(1024, 1)\n",
            "Training Metrics: 1338 [D loss: 0.446442, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.034570]\n",
            "Validating on test set\n",
            "Validation Metrics: 1338 [D loss: 0.067808, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.026129]\n",
            "(1024, 1)\n",
            "Training Metrics: 1339 [D loss: 0.471096, acc.: 99.85%, op_acc: 83.74%] [G loss: 6.073561]\n",
            "Validating on test set\n",
            "Validation Metrics: 1339 [D loss: 0.077994, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.066684]\n",
            "(1024, 1)\n",
            "Training Metrics: 1340 [D loss: 0.483211, acc.: 99.85%, op_acc: 83.98%] [G loss: 5.883197]\n",
            "Validating on test set\n",
            "Validation Metrics: 1340 [D loss: 0.069278, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.861697]\n",
            "(1024, 1)\n",
            "Training Metrics: 1341 [D loss: 0.467371, acc.: 99.95%, op_acc: 83.54%] [G loss: 6.227988]\n",
            "Validating on test set\n",
            "Validation Metrics: 1341 [D loss: 0.065641, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.233393]\n",
            "(1024, 1)\n",
            "Training Metrics: 1342 [D loss: 0.493505, acc.: 99.85%, op_acc: 84.08%] [G loss: 6.308409]\n",
            "Validating on test set\n",
            "Validation Metrics: 1342 [D loss: 0.073370, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.306381]\n",
            "(1024, 1)\n",
            "Training Metrics: 1343 [D loss: 0.452070, acc.: 99.95%, op_acc: 84.96%] [G loss: 6.234198]\n",
            "Validating on test set\n",
            "Validation Metrics: 1343 [D loss: 0.065844, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.232603]\n",
            "(1024, 1)\n",
            "Training Metrics: 1344 [D loss: 0.473307, acc.: 99.76%, op_acc: 84.86%] [G loss: 5.963098]\n",
            "Validating on test set\n",
            "Validation Metrics: 1344 [D loss: 0.074331, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.960939]\n",
            "(1024, 1)\n",
            "Training Metrics: 1345 [D loss: 0.454561, acc.: 99.80%, op_acc: 85.55%] [G loss: 6.107316]\n",
            "Validating on test set\n",
            "Validation Metrics: 1345 [D loss: 0.068537, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.094501]\n",
            "(1024, 1)\n",
            "Training Metrics: 1346 [D loss: 0.477281, acc.: 99.90%, op_acc: 84.72%] [G loss: 6.063490]\n",
            "Validating on test set\n",
            "Validation Metrics: 1346 [D loss: 0.077033, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.066044]\n",
            "(1024, 1)\n",
            "Training Metrics: 1347 [D loss: 0.503908, acc.: 99.85%, op_acc: 83.45%] [G loss: 6.341389]\n",
            "Validating on test set\n",
            "Validation Metrics: 1347 [D loss: 0.068403, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.344107]\n",
            "(1024, 1)\n",
            "Training Metrics: 1348 [D loss: 0.502064, acc.: 99.95%, op_acc: 83.54%] [G loss: 5.976740]\n",
            "Validating on test set\n",
            "Validation Metrics: 1348 [D loss: 0.069055, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.965577]\n",
            "(1024, 1)\n",
            "Training Metrics: 1349 [D loss: 0.478970, acc.: 99.95%, op_acc: 83.50%] [G loss: 6.396357]\n",
            "Validating on test set\n",
            "Validation Metrics: 1349 [D loss: 0.066595, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.391879]\n",
            "(1024, 1)\n",
            "Training Metrics: 1350 [D loss: 0.532846, acc.: 99.85%, op_acc: 83.20%] [G loss: 6.279462]\n",
            "Validating on test set\n",
            "Validation Metrics: 1350 [D loss: 0.066717, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.270172]\n",
            "(1024, 1)\n",
            "Training Metrics: 1351 [D loss: 0.471783, acc.: 99.90%, op_acc: 82.23%] [G loss: 6.224942]\n",
            "Validating on test set\n",
            "Validation Metrics: 1351 [D loss: 0.073787, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.222491]\n",
            "(1024, 1)\n",
            "Training Metrics: 1352 [D loss: 0.483956, acc.: 99.76%, op_acc: 84.77%] [G loss: 6.206472]\n",
            "Validating on test set\n",
            "Validation Metrics: 1352 [D loss: 0.066224, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.206088]\n",
            "(1024, 1)\n",
            "Training Metrics: 1353 [D loss: 0.476769, acc.: 99.85%, op_acc: 84.81%] [G loss: 6.181168]\n",
            "Validating on test set\n",
            "Validation Metrics: 1353 [D loss: 0.065398, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.179738]\n",
            "(1024, 1)\n",
            "Training Metrics: 1354 [D loss: 0.497073, acc.: 99.85%, op_acc: 84.08%] [G loss: 6.279895]\n",
            "Validating on test set\n",
            "Validation Metrics: 1354 [D loss: 0.068964, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.276299]\n",
            "(1024, 1)\n",
            "Training Metrics: 1355 [D loss: 0.465517, acc.: 99.85%, op_acc: 85.01%] [G loss: 5.910434]\n",
            "Validating on test set\n",
            "Validation Metrics: 1355 [D loss: 0.073270, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.912584]\n",
            "(1024, 1)\n",
            "Training Metrics: 1356 [D loss: 0.498471, acc.: 99.85%, op_acc: 83.89%] [G loss: 6.464650]\n",
            "Validating on test set\n",
            "Validation Metrics: 1356 [D loss: 0.068454, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.472233]\n",
            "(1024, 1)\n",
            "Training Metrics: 1357 [D loss: 0.452454, acc.: 99.85%, op_acc: 85.25%] [G loss: 5.948077]\n",
            "Validating on test set\n",
            "Validation Metrics: 1357 [D loss: 0.069498, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.943954]\n",
            "(1024, 1)\n",
            "Training Metrics: 1358 [D loss: 0.503734, acc.: 99.80%, op_acc: 83.50%] [G loss: 6.190934]\n",
            "Validating on test set\n",
            "Validation Metrics: 1358 [D loss: 0.078042, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.216898]\n",
            "(1024, 1)\n",
            "Training Metrics: 1359 [D loss: 0.459399, acc.: 99.95%, op_acc: 85.06%] [G loss: 6.277714]\n",
            "Validating on test set\n",
            "Validation Metrics: 1359 [D loss: 0.063965, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.281409]\n",
            "(1024, 1)\n",
            "Training Metrics: 1360 [D loss: 0.481315, acc.: 99.85%, op_acc: 84.86%] [G loss: 6.030583]\n",
            "Validating on test set\n",
            "Validation Metrics: 1360 [D loss: 0.068251, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.015414]\n",
            "(1024, 1)\n",
            "Training Metrics: 1361 [D loss: 0.505749, acc.: 99.76%, op_acc: 84.08%] [G loss: 5.931469]\n",
            "Validating on test set\n",
            "Validation Metrics: 1361 [D loss: 0.071475, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.917783]\n",
            "(1024, 1)\n",
            "Training Metrics: 1362 [D loss: 0.498451, acc.: 99.80%, op_acc: 84.33%] [G loss: 5.897150]\n",
            "Validating on test set\n",
            "Validation Metrics: 1362 [D loss: 0.066340, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.901334]\n",
            "(1024, 1)\n",
            "Training Metrics: 1363 [D loss: 0.484919, acc.: 99.90%, op_acc: 84.33%] [G loss: 6.105821]\n",
            "Validating on test set\n",
            "Validation Metrics: 1363 [D loss: 0.070049, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.107791]\n",
            "(1024, 1)\n",
            "Training Metrics: 1364 [D loss: 0.521103, acc.: 99.76%, op_acc: 82.67%] [G loss: 5.871806]\n",
            "Validating on test set\n",
            "Validation Metrics: 1364 [D loss: 0.076100, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.884046]\n",
            "(1024, 1)\n",
            "Training Metrics: 1365 [D loss: 0.556144, acc.: 99.85%, op_acc: 82.67%] [G loss: 6.099865]\n",
            "Validating on test set\n",
            "Validation Metrics: 1365 [D loss: 0.068304, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.091695]\n",
            "(1024, 1)\n",
            "Training Metrics: 1366 [D loss: 0.457077, acc.: 99.90%, op_acc: 85.21%] [G loss: 6.151080]\n",
            "Validating on test set\n",
            "Validation Metrics: 1366 [D loss: 0.063354, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.132252]\n",
            "(1024, 1)\n",
            "Training Metrics: 1367 [D loss: 0.470540, acc.: 99.85%, op_acc: 84.18%] [G loss: 6.155035]\n",
            "Validating on test set\n",
            "Validation Metrics: 1367 [D loss: 0.068442, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.148315]\n",
            "(1024, 1)\n",
            "Training Metrics: 1368 [D loss: 0.512581, acc.: 99.76%, op_acc: 83.94%] [G loss: 5.819046]\n",
            "Validating on test set\n",
            "Validation Metrics: 1368 [D loss: 0.066874, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.813733]\n",
            "(1024, 1)\n",
            "Training Metrics: 1369 [D loss: 0.469631, acc.: 99.85%, op_acc: 83.69%] [G loss: 6.000722]\n",
            "Validating on test set\n",
            "Validation Metrics: 1369 [D loss: 0.067821, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.997016]\n",
            "(1024, 1)\n",
            "Training Metrics: 1370 [D loss: 0.463690, acc.: 99.85%, op_acc: 85.01%] [G loss: 6.079203]\n",
            "Validating on test set\n",
            "Validation Metrics: 1370 [D loss: 0.065239, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.086552]\n",
            "(1024, 1)\n",
            "Training Metrics: 1371 [D loss: 0.448582, acc.: 99.80%, op_acc: 84.91%] [G loss: 5.961464]\n",
            "Validating on test set\n",
            "Validation Metrics: 1371 [D loss: 0.065841, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.966178]\n",
            "(1024, 1)\n",
            "Training Metrics: 1372 [D loss: 0.462598, acc.: 100.00%, op_acc: 84.67%] [G loss: 6.087205]\n",
            "Validating on test set\n",
            "Validation Metrics: 1372 [D loss: 0.066714, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.087499]\n",
            "(1024, 1)\n",
            "Training Metrics: 1373 [D loss: 0.480786, acc.: 99.80%, op_acc: 83.89%] [G loss: 5.936576]\n",
            "Validating on test set\n",
            "Validation Metrics: 1373 [D loss: 0.071786, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.935665]\n",
            "(1024, 1)\n",
            "Training Metrics: 1374 [D loss: 0.468223, acc.: 99.80%, op_acc: 84.52%] [G loss: 5.775025]\n",
            "Validating on test set\n",
            "Validation Metrics: 1374 [D loss: 0.068884, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.773303]\n",
            "(1024, 1)\n",
            "Training Metrics: 1375 [D loss: 0.439407, acc.: 99.85%, op_acc: 84.81%] [G loss: 5.877260]\n",
            "Validating on test set\n",
            "Validation Metrics: 1375 [D loss: 0.068874, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.882395]\n",
            "(1024, 1)\n",
            "Training Metrics: 1376 [D loss: 0.421334, acc.: 99.90%, op_acc: 85.74%] [G loss: 6.239147]\n",
            "Validating on test set\n",
            "Validation Metrics: 1376 [D loss: 0.063955, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.236568]\n",
            "(1024, 1)\n",
            "Training Metrics: 1377 [D loss: 0.498728, acc.: 99.80%, op_acc: 83.50%] [G loss: 6.046665]\n",
            "Validating on test set\n",
            "Validation Metrics: 1377 [D loss: 0.066426, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.042297]\n",
            "(1024, 1)\n",
            "Training Metrics: 1378 [D loss: 0.487810, acc.: 99.95%, op_acc: 82.76%] [G loss: 6.382823]\n",
            "Validating on test set\n",
            "Validation Metrics: 1378 [D loss: 0.059559, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.390605]\n",
            "(1024, 1)\n",
            "Training Metrics: 1379 [D loss: 0.476721, acc.: 99.95%, op_acc: 85.89%] [G loss: 6.173466]\n",
            "Validating on test set\n",
            "Validation Metrics: 1379 [D loss: 0.061552, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.171885]\n",
            "(1024, 1)\n",
            "Training Metrics: 1380 [D loss: 0.473613, acc.: 99.90%, op_acc: 85.21%] [G loss: 6.078836]\n",
            "Validating on test set\n",
            "Validation Metrics: 1380 [D loss: 0.066558, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.087776]\n",
            "(1024, 1)\n",
            "Training Metrics: 1381 [D loss: 0.487302, acc.: 99.90%, op_acc: 83.94%] [G loss: 6.214015]\n",
            "Validating on test set\n",
            "Validation Metrics: 1381 [D loss: 0.073589, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.228619]\n",
            "(1024, 1)\n",
            "Training Metrics: 1382 [D loss: 0.536590, acc.: 99.80%, op_acc: 83.79%] [G loss: 6.018931]\n",
            "Validating on test set\n",
            "Validation Metrics: 1382 [D loss: 0.063317, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.018122]\n",
            "(1024, 1)\n",
            "Training Metrics: 1383 [D loss: 0.485212, acc.: 99.90%, op_acc: 83.15%] [G loss: 6.301874]\n",
            "Validating on test set\n",
            "Validation Metrics: 1383 [D loss: 0.069458, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.297356]\n",
            "(1024, 1)\n",
            "Training Metrics: 1384 [D loss: 0.503513, acc.: 99.90%, op_acc: 83.59%] [G loss: 5.899197]\n",
            "Validating on test set\n",
            "Validation Metrics: 1384 [D loss: 0.066708, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.894775]\n",
            "(1024, 1)\n",
            "Training Metrics: 1385 [D loss: 0.497003, acc.: 99.90%, op_acc: 83.59%] [G loss: 6.249888]\n",
            "Validating on test set\n",
            "Validation Metrics: 1385 [D loss: 0.064272, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.254871]\n",
            "(1024, 1)\n",
            "Training Metrics: 1386 [D loss: 0.503927, acc.: 99.95%, op_acc: 83.11%] [G loss: 6.133509]\n",
            "Validating on test set\n",
            "Validation Metrics: 1386 [D loss: 0.073284, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.130977]\n",
            "(1024, 1)\n",
            "Training Metrics: 1387 [D loss: 0.500863, acc.: 99.85%, op_acc: 83.84%] [G loss: 6.575572]\n",
            "Validating on test set\n",
            "Validation Metrics: 1387 [D loss: 0.061747, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.565915]\n",
            "(1024, 1)\n",
            "Training Metrics: 1388 [D loss: 0.467629, acc.: 99.95%, op_acc: 83.20%] [G loss: 6.284392]\n",
            "Validating on test set\n",
            "Validation Metrics: 1388 [D loss: 0.063593, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.290137]\n",
            "(1024, 1)\n",
            "Training Metrics: 1389 [D loss: 0.503915, acc.: 99.80%, op_acc: 82.71%] [G loss: 5.869859]\n",
            "Validating on test set\n",
            "Validation Metrics: 1389 [D loss: 0.059927, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.861777]\n",
            "(1024, 1)\n",
            "Training Metrics: 1390 [D loss: 0.497919, acc.: 99.80%, op_acc: 82.81%] [G loss: 5.844417]\n",
            "Validating on test set\n",
            "Validation Metrics: 1390 [D loss: 0.068400, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.849191]\n",
            "(1024, 1)\n",
            "Training Metrics: 1391 [D loss: 0.478122, acc.: 99.90%, op_acc: 84.62%] [G loss: 6.141320]\n",
            "Validating on test set\n",
            "Validation Metrics: 1391 [D loss: 0.059731, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.157144]\n",
            "(1024, 1)\n",
            "Training Metrics: 1392 [D loss: 0.478170, acc.: 99.80%, op_acc: 83.69%] [G loss: 6.050119]\n",
            "Validating on test set\n",
            "Validation Metrics: 1392 [D loss: 0.066050, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.035844]\n",
            "(1024, 1)\n",
            "Training Metrics: 1393 [D loss: 0.522521, acc.: 99.76%, op_acc: 83.30%] [G loss: 5.883739]\n",
            "Validating on test set\n",
            "Validation Metrics: 1393 [D loss: 0.064071, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.897472]\n",
            "(1024, 1)\n",
            "Training Metrics: 1394 [D loss: 0.451902, acc.: 99.85%, op_acc: 85.94%] [G loss: 6.217966]\n",
            "Validating on test set\n",
            "Validation Metrics: 1394 [D loss: 0.064379, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.235229]\n",
            "(1024, 1)\n",
            "Training Metrics: 1395 [D loss: 0.473061, acc.: 99.85%, op_acc: 84.38%] [G loss: 5.952665]\n",
            "Validating on test set\n",
            "Validation Metrics: 1395 [D loss: 0.068448, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.957150]\n",
            "(1024, 1)\n",
            "Training Metrics: 1396 [D loss: 0.455815, acc.: 99.95%, op_acc: 84.23%] [G loss: 6.229968]\n",
            "Validating on test set\n",
            "Validation Metrics: 1396 [D loss: 0.057466, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.228329]\n",
            "(1024, 1)\n",
            "Training Metrics: 1397 [D loss: 0.467111, acc.: 100.00%, op_acc: 84.47%] [G loss: 6.249884]\n",
            "Validating on test set\n",
            "Validation Metrics: 1397 [D loss: 0.075813, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.241890]\n",
            "(1024, 1)\n",
            "Training Metrics: 1398 [D loss: 0.465759, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.550293]\n",
            "Validating on test set\n",
            "Validation Metrics: 1398 [D loss: 0.060311, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.541828]\n",
            "(1024, 1)\n",
            "Training Metrics: 1399 [D loss: 0.458649, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.270285]\n",
            "Validating on test set\n",
            "Validation Metrics: 1399 [D loss: 0.058911, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.272435]\n",
            "(1024, 1)\n",
            "Training Metrics: 1400 [D loss: 0.425124, acc.: 99.95%, op_acc: 85.69%] [G loss: 6.250925]\n",
            "Validating on test set\n",
            "Validation Metrics: 1400 [D loss: 0.067399, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.246667]\n",
            "(1024, 1)\n",
            "Training Metrics: 1401 [D loss: 0.500076, acc.: 99.90%, op_acc: 83.45%] [G loss: 6.555112]\n",
            "Validating on test set\n",
            "Validation Metrics: 1401 [D loss: 0.066457, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.552062]\n",
            "(1024, 1)\n",
            "Training Metrics: 1402 [D loss: 0.493809, acc.: 99.66%, op_acc: 83.45%] [G loss: 6.012749]\n",
            "Validating on test set\n",
            "Validation Metrics: 1402 [D loss: 0.058457, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.004209]\n",
            "(1024, 1)\n",
            "Training Metrics: 1403 [D loss: 0.451179, acc.: 99.80%, op_acc: 85.25%] [G loss: 6.028664]\n",
            "Validating on test set\n",
            "Validation Metrics: 1403 [D loss: 0.070777, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.034287]\n",
            "(1024, 1)\n",
            "Training Metrics: 1404 [D loss: 0.482599, acc.: 99.85%, op_acc: 83.64%] [G loss: 6.069519]\n",
            "Validating on test set\n",
            "Validation Metrics: 1404 [D loss: 0.066163, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.067627]\n",
            "(1024, 1)\n",
            "Training Metrics: 1405 [D loss: 0.459538, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.256958]\n",
            "Validating on test set\n",
            "Validation Metrics: 1405 [D loss: 0.081126, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.261940]\n",
            "(1024, 1)\n",
            "Training Metrics: 1406 [D loss: 0.483427, acc.: 99.85%, op_acc: 82.81%] [G loss: 6.045261]\n",
            "Validating on test set\n",
            "Validation Metrics: 1406 [D loss: 0.073420, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.036466]\n",
            "(1024, 1)\n",
            "Training Metrics: 1407 [D loss: 0.441895, acc.: 99.80%, op_acc: 85.40%] [G loss: 5.985229]\n",
            "Validating on test set\n",
            "Validation Metrics: 1407 [D loss: 0.071729, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.985257]\n",
            "(1024, 1)\n",
            "Training Metrics: 1408 [D loss: 0.481568, acc.: 99.71%, op_acc: 83.84%] [G loss: 5.964391]\n",
            "Validating on test set\n",
            "Validation Metrics: 1408 [D loss: 0.065132, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.978999]\n",
            "(1024, 1)\n",
            "Training Metrics: 1409 [D loss: 0.470579, acc.: 99.90%, op_acc: 84.28%] [G loss: 6.098782]\n",
            "Validating on test set\n",
            "Validation Metrics: 1409 [D loss: 0.061692, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.085880]\n",
            "(1024, 1)\n",
            "Training Metrics: 1410 [D loss: 0.467739, acc.: 99.71%, op_acc: 85.01%] [G loss: 5.764170]\n",
            "Validating on test set\n",
            "Validation Metrics: 1410 [D loss: 0.069164, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.758563]\n",
            "(1024, 1)\n",
            "Training Metrics: 1411 [D loss: 0.520196, acc.: 99.95%, op_acc: 83.25%] [G loss: 5.651890]\n",
            "Validating on test set\n",
            "Validation Metrics: 1411 [D loss: 0.067218, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.677281]\n",
            "(1024, 1)\n",
            "Training Metrics: 1412 [D loss: 0.532348, acc.: 100.00%, op_acc: 83.11%] [G loss: 6.389376]\n",
            "Validating on test set\n",
            "Validation Metrics: 1412 [D loss: 0.068953, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.379510]\n",
            "(1024, 1)\n",
            "Training Metrics: 1413 [D loss: 0.474406, acc.: 99.90%, op_acc: 84.42%] [G loss: 6.229412]\n",
            "Validating on test set\n",
            "Validation Metrics: 1413 [D loss: 0.071148, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.225797]\n",
            "(1024, 1)\n",
            "Training Metrics: 1414 [D loss: 0.473060, acc.: 99.80%, op_acc: 82.67%] [G loss: 6.260442]\n",
            "Validating on test set\n",
            "Validation Metrics: 1414 [D loss: 0.071048, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.257316]\n",
            "(1024, 1)\n",
            "Training Metrics: 1415 [D loss: 0.471116, acc.: 99.85%, op_acc: 84.86%] [G loss: 5.921206]\n",
            "Validating on test set\n",
            "Validation Metrics: 1415 [D loss: 0.069519, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.906714]\n",
            "(1024, 1)\n",
            "Training Metrics: 1416 [D loss: 0.508820, acc.: 99.85%, op_acc: 83.15%] [G loss: 6.199708]\n",
            "Validating on test set\n",
            "Validation Metrics: 1416 [D loss: 0.064698, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.205156]\n",
            "(1024, 1)\n",
            "Training Metrics: 1417 [D loss: 0.512801, acc.: 99.85%, op_acc: 82.42%] [G loss: 5.709262]\n",
            "Validating on test set\n",
            "Validation Metrics: 1417 [D loss: 0.070178, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.732788]\n",
            "(1024, 1)\n",
            "Training Metrics: 1418 [D loss: 0.465967, acc.: 99.90%, op_acc: 84.62%] [G loss: 6.101462]\n",
            "Validating on test set\n",
            "Validation Metrics: 1418 [D loss: 0.067996, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.092079]\n",
            "(1024, 1)\n",
            "Training Metrics: 1419 [D loss: 0.478821, acc.: 99.71%, op_acc: 84.08%] [G loss: 5.784052]\n",
            "Validating on test set\n",
            "Validation Metrics: 1419 [D loss: 0.065199, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.792388]\n",
            "(1024, 1)\n",
            "Training Metrics: 1420 [D loss: 0.459368, acc.: 99.95%, op_acc: 84.91%] [G loss: 6.088312]\n",
            "Validating on test set\n",
            "Validation Metrics: 1420 [D loss: 0.065083, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.092041]\n",
            "(1024, 1)\n",
            "Training Metrics: 1421 [D loss: 0.448685, acc.: 99.95%, op_acc: 85.01%] [G loss: 6.288459]\n",
            "Validating on test set\n",
            "Validation Metrics: 1421 [D loss: 0.061972, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.289261]\n",
            "(1024, 1)\n",
            "Training Metrics: 1422 [D loss: 0.440498, acc.: 99.95%, op_acc: 84.72%] [G loss: 6.244154]\n",
            "Validating on test set\n",
            "Validation Metrics: 1422 [D loss: 0.062198, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.249171]\n",
            "(1024, 1)\n",
            "Training Metrics: 1423 [D loss: 0.430107, acc.: 99.85%, op_acc: 85.11%] [G loss: 6.146969]\n",
            "Validating on test set\n",
            "Validation Metrics: 1423 [D loss: 0.064280, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.134557]\n",
            "(1024, 1)\n",
            "Training Metrics: 1424 [D loss: 0.433632, acc.: 99.90%, op_acc: 86.18%] [G loss: 6.486920]\n",
            "Validating on test set\n",
            "Validation Metrics: 1424 [D loss: 0.074334, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.508312]\n",
            "(1024, 1)\n",
            "Training Metrics: 1425 [D loss: 0.475658, acc.: 99.85%, op_acc: 85.01%] [G loss: 6.037825]\n",
            "Validating on test set\n",
            "Validation Metrics: 1425 [D loss: 0.062854, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.054004]\n",
            "(1024, 1)\n",
            "Training Metrics: 1426 [D loss: 0.481593, acc.: 99.85%, op_acc: 83.89%] [G loss: 6.518405]\n",
            "Validating on test set\n",
            "Validation Metrics: 1426 [D loss: 0.066673, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.504700]\n",
            "(1024, 1)\n",
            "Training Metrics: 1427 [D loss: 0.469699, acc.: 99.95%, op_acc: 84.77%] [G loss: 5.819226]\n",
            "Validating on test set\n",
            "Validation Metrics: 1427 [D loss: 0.073429, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.797546]\n",
            "(1024, 1)\n",
            "Training Metrics: 1428 [D loss: 0.457879, acc.: 99.85%, op_acc: 84.52%] [G loss: 6.140887]\n",
            "Validating on test set\n",
            "Validation Metrics: 1428 [D loss: 0.065271, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.146839]\n",
            "(1024, 1)\n",
            "Training Metrics: 1429 [D loss: 0.446332, acc.: 99.90%, op_acc: 84.28%] [G loss: 6.435126]\n",
            "Validating on test set\n",
            "Validation Metrics: 1429 [D loss: 0.072470, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.431231]\n",
            "(1024, 1)\n",
            "Training Metrics: 1430 [D loss: 0.470900, acc.: 99.95%, op_acc: 84.67%] [G loss: 6.132283]\n",
            "Validating on test set\n",
            "Validation Metrics: 1430 [D loss: 0.063788, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.125177]\n",
            "(1024, 1)\n",
            "Training Metrics: 1431 [D loss: 0.455759, acc.: 99.85%, op_acc: 84.96%] [G loss: 5.963614]\n",
            "Validating on test set\n",
            "Validation Metrics: 1431 [D loss: 0.078983, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.965099]\n",
            "(1024, 1)\n",
            "Training Metrics: 1432 [D loss: 0.526572, acc.: 99.90%, op_acc: 83.11%] [G loss: 6.380212]\n",
            "Validating on test set\n",
            "Validation Metrics: 1432 [D loss: 0.071894, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.375108]\n",
            "(1024, 1)\n",
            "Training Metrics: 1433 [D loss: 0.496589, acc.: 99.85%, op_acc: 83.79%] [G loss: 6.264011]\n",
            "Validating on test set\n",
            "Validation Metrics: 1433 [D loss: 0.075212, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.264252]\n",
            "(1024, 1)\n",
            "Training Metrics: 1434 [D loss: 0.517613, acc.: 99.80%, op_acc: 83.35%] [G loss: 6.024946]\n",
            "Validating on test set\n",
            "Validation Metrics: 1434 [D loss: 0.084996, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.022539]\n",
            "(1024, 1)\n",
            "Training Metrics: 1435 [D loss: 0.460421, acc.: 99.90%, op_acc: 85.11%] [G loss: 6.299844]\n",
            "Validating on test set\n",
            "Validation Metrics: 1435 [D loss: 0.085886, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.303424]\n",
            "(1024, 1)\n",
            "Training Metrics: 1436 [D loss: 0.460498, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.407809]\n",
            "Validating on test set\n",
            "Validation Metrics: 1436 [D loss: 0.075014, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.385729]\n",
            "(1024, 1)\n",
            "Training Metrics: 1437 [D loss: 0.536587, acc.: 99.95%, op_acc: 82.47%] [G loss: 6.344616]\n",
            "Validating on test set\n",
            "Validation Metrics: 1437 [D loss: 0.078568, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.358284]\n",
            "(1024, 1)\n",
            "Training Metrics: 1438 [D loss: 0.504141, acc.: 99.80%, op_acc: 83.15%] [G loss: 6.240113]\n",
            "Validating on test set\n",
            "Validation Metrics: 1438 [D loss: 0.075620, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.225863]\n",
            "(1024, 1)\n",
            "Training Metrics: 1439 [D loss: 0.542133, acc.: 99.90%, op_acc: 81.64%] [G loss: 6.384839]\n",
            "Validating on test set\n",
            "Validation Metrics: 1439 [D loss: 0.077526, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.391433]\n",
            "(1024, 1)\n",
            "Training Metrics: 1440 [D loss: 0.510377, acc.: 99.76%, op_acc: 84.86%] [G loss: 6.146466]\n",
            "Validating on test set\n",
            "Validation Metrics: 1440 [D loss: 0.086288, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.153795]\n",
            "(1024, 1)\n",
            "Training Metrics: 1441 [D loss: 0.495752, acc.: 99.90%, op_acc: 82.76%] [G loss: 6.407253]\n",
            "Validating on test set\n",
            "Validation Metrics: 1441 [D loss: 0.067027, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.399569]\n",
            "(1024, 1)\n",
            "Training Metrics: 1442 [D loss: 0.458231, acc.: 99.95%, op_acc: 85.01%] [G loss: 6.547652]\n",
            "Validating on test set\n",
            "Validation Metrics: 1442 [D loss: 0.070377, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.537570]\n",
            "(1024, 1)\n",
            "Training Metrics: 1443 [D loss: 0.452833, acc.: 99.80%, op_acc: 84.67%] [G loss: 5.995871]\n",
            "Validating on test set\n",
            "Validation Metrics: 1443 [D loss: 0.073355, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.994992]\n",
            "(1024, 1)\n",
            "Training Metrics: 1444 [D loss: 0.508255, acc.: 99.95%, op_acc: 81.84%] [G loss: 6.256895]\n",
            "Validating on test set\n",
            "Validation Metrics: 1444 [D loss: 0.070759, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.240937]\n",
            "(1024, 1)\n",
            "Training Metrics: 1445 [D loss: 0.480487, acc.: 99.90%, op_acc: 83.50%] [G loss: 6.088046]\n",
            "Validating on test set\n",
            "Validation Metrics: 1445 [D loss: 0.071107, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.080593]\n",
            "(1024, 1)\n",
            "Training Metrics: 1446 [D loss: 0.464185, acc.: 99.76%, op_acc: 84.13%] [G loss: 5.924479]\n",
            "Validating on test set\n",
            "Validation Metrics: 1446 [D loss: 0.074064, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.924010]\n",
            "(1024, 1)\n",
            "Training Metrics: 1447 [D loss: 0.480331, acc.: 99.76%, op_acc: 84.18%] [G loss: 5.970605]\n",
            "Validating on test set\n",
            "Validation Metrics: 1447 [D loss: 0.066271, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.977772]\n",
            "(1024, 1)\n",
            "Training Metrics: 1448 [D loss: 0.465242, acc.: 99.90%, op_acc: 83.79%] [G loss: 6.235357]\n",
            "Validating on test set\n",
            "Validation Metrics: 1448 [D loss: 0.071884, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.232955]\n",
            "(1024, 1)\n",
            "Training Metrics: 1449 [D loss: 0.460253, acc.: 99.90%, op_acc: 83.69%] [G loss: 6.094654]\n",
            "Validating on test set\n",
            "Validation Metrics: 1449 [D loss: 0.073595, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.090059]\n",
            "(1024, 1)\n",
            "Training Metrics: 1450 [D loss: 0.469903, acc.: 99.90%, op_acc: 84.57%] [G loss: 6.313103]\n",
            "Validating on test set\n",
            "Validation Metrics: 1450 [D loss: 0.068489, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.298354]\n",
            "(1024, 1)\n",
            "Training Metrics: 1451 [D loss: 0.472820, acc.: 99.95%, op_acc: 85.01%] [G loss: 6.327556]\n",
            "Validating on test set\n",
            "Validation Metrics: 1451 [D loss: 0.064332, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.317980]\n",
            "(1024, 1)\n",
            "Training Metrics: 1452 [D loss: 0.516108, acc.: 99.76%, op_acc: 84.18%] [G loss: 5.913004]\n",
            "Validating on test set\n",
            "Validation Metrics: 1452 [D loss: 0.068279, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.910899]\n",
            "(1024, 1)\n",
            "Training Metrics: 1453 [D loss: 0.483253, acc.: 99.95%, op_acc: 83.79%] [G loss: 6.391157]\n",
            "Validating on test set\n",
            "Validation Metrics: 1453 [D loss: 0.062880, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.398798]\n",
            "(1024, 1)\n",
            "Training Metrics: 1454 [D loss: 0.468189, acc.: 99.85%, op_acc: 84.62%] [G loss: 6.456912]\n",
            "Validating on test set\n",
            "Validation Metrics: 1454 [D loss: 0.076358, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.457001]\n",
            "(1024, 1)\n",
            "Training Metrics: 1455 [D loss: 0.516946, acc.: 99.90%, op_acc: 82.57%] [G loss: 6.144907]\n",
            "Validating on test set\n",
            "Validation Metrics: 1455 [D loss: 0.079167, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.138714]\n",
            "(1024, 1)\n",
            "Training Metrics: 1456 [D loss: 0.475825, acc.: 99.85%, op_acc: 84.67%] [G loss: 6.316321]\n",
            "Validating on test set\n",
            "Validation Metrics: 1456 [D loss: 0.081564, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.306907]\n",
            "(1024, 1)\n",
            "Training Metrics: 1457 [D loss: 0.474003, acc.: 99.95%, op_acc: 84.86%] [G loss: 6.021019]\n",
            "Validating on test set\n",
            "Validation Metrics: 1457 [D loss: 0.065665, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.002139]\n",
            "(1024, 1)\n",
            "Training Metrics: 1458 [D loss: 0.490402, acc.: 99.85%, op_acc: 83.64%] [G loss: 6.285098]\n",
            "Validating on test set\n",
            "Validation Metrics: 1458 [D loss: 0.067350, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.280535]\n",
            "(1024, 1)\n",
            "Training Metrics: 1459 [D loss: 0.454381, acc.: 99.90%, op_acc: 83.89%] [G loss: 6.523491]\n",
            "Validating on test set\n",
            "Validation Metrics: 1459 [D loss: 0.060322, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.510642]\n",
            "(1024, 1)\n",
            "Training Metrics: 1460 [D loss: 0.466826, acc.: 99.80%, op_acc: 83.98%] [G loss: 5.963287]\n",
            "Validating on test set\n",
            "Validation Metrics: 1460 [D loss: 0.080334, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.963888]\n",
            "(1024, 1)\n",
            "Training Metrics: 1461 [D loss: 0.492959, acc.: 99.90%, op_acc: 82.76%] [G loss: 6.570634]\n",
            "Validating on test set\n",
            "Validation Metrics: 1461 [D loss: 0.066071, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.562628]\n",
            "(1024, 1)\n",
            "Training Metrics: 1462 [D loss: 0.564682, acc.: 99.80%, op_acc: 82.08%] [G loss: 6.169621]\n",
            "Validating on test set\n",
            "Validation Metrics: 1462 [D loss: 0.062905, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.170275]\n",
            "(1024, 1)\n",
            "Training Metrics: 1463 [D loss: 0.465107, acc.: 99.90%, op_acc: 84.08%] [G loss: 6.014881]\n",
            "Validating on test set\n",
            "Validation Metrics: 1463 [D loss: 0.065993, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.992030]\n",
            "(1024, 1)\n",
            "Training Metrics: 1464 [D loss: 0.477339, acc.: 99.95%, op_acc: 83.54%] [G loss: 6.292217]\n",
            "Validating on test set\n",
            "Validation Metrics: 1464 [D loss: 0.068959, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.292758]\n",
            "(1024, 1)\n",
            "Training Metrics: 1465 [D loss: 0.447551, acc.: 99.85%, op_acc: 84.91%] [G loss: 6.150405]\n",
            "Validating on test set\n",
            "Validation Metrics: 1465 [D loss: 0.068470, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.145182]\n",
            "(1024, 1)\n",
            "Training Metrics: 1466 [D loss: 0.518342, acc.: 99.85%, op_acc: 82.91%] [G loss: 6.123771]\n",
            "Validating on test set\n",
            "Validation Metrics: 1466 [D loss: 0.062389, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.110715]\n",
            "(1024, 1)\n",
            "Training Metrics: 1467 [D loss: 0.498462, acc.: 99.90%, op_acc: 82.62%] [G loss: 6.347685]\n",
            "Validating on test set\n",
            "Validation Metrics: 1467 [D loss: 0.068776, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.326956]\n",
            "(1024, 1)\n",
            "Training Metrics: 1468 [D loss: 0.537386, acc.: 99.85%, op_acc: 83.01%] [G loss: 5.929019]\n",
            "Validating on test set\n",
            "Validation Metrics: 1468 [D loss: 0.066272, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.930797]\n",
            "(1024, 1)\n",
            "Training Metrics: 1469 [D loss: 0.473558, acc.: 99.90%, op_acc: 83.45%] [G loss: 6.199510]\n",
            "Validating on test set\n",
            "Validation Metrics: 1469 [D loss: 0.064217, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.200928]\n",
            "(1024, 1)\n",
            "Training Metrics: 1470 [D loss: 0.497335, acc.: 99.95%, op_acc: 82.91%] [G loss: 6.212858]\n",
            "Validating on test set\n",
            "Validation Metrics: 1470 [D loss: 0.062228, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.223167]\n",
            "(1024, 1)\n",
            "Training Metrics: 1471 [D loss: 0.463135, acc.: 99.80%, op_acc: 83.59%] [G loss: 6.049108]\n",
            "Validating on test set\n",
            "Validation Metrics: 1471 [D loss: 0.068909, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.032453]\n",
            "(1024, 1)\n",
            "Training Metrics: 1472 [D loss: 0.475398, acc.: 100.00%, op_acc: 84.38%] [G loss: 6.084450]\n",
            "Validating on test set\n",
            "Validation Metrics: 1472 [D loss: 0.068356, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.073620]\n",
            "(1024, 1)\n",
            "Training Metrics: 1473 [D loss: 0.461641, acc.: 99.90%, op_acc: 84.62%] [G loss: 6.196213]\n",
            "Validating on test set\n",
            "Validation Metrics: 1473 [D loss: 0.064563, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.186344]\n",
            "(1024, 1)\n",
            "Training Metrics: 1474 [D loss: 0.458056, acc.: 99.90%, op_acc: 85.06%] [G loss: 6.453743]\n",
            "Validating on test set\n",
            "Validation Metrics: 1474 [D loss: 0.063000, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.451528]\n",
            "(1024, 1)\n",
            "Training Metrics: 1475 [D loss: 0.468976, acc.: 99.76%, op_acc: 84.91%] [G loss: 5.965770]\n",
            "Validating on test set\n",
            "Validation Metrics: 1475 [D loss: 0.065117, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.964161]\n",
            "(1024, 1)\n",
            "Training Metrics: 1476 [D loss: 0.484955, acc.: 99.95%, op_acc: 83.11%] [G loss: 6.332073]\n",
            "Validating on test set\n",
            "Validation Metrics: 1476 [D loss: 0.067219, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.314551]\n",
            "(1024, 1)\n",
            "Training Metrics: 1477 [D loss: 0.491629, acc.: 99.85%, op_acc: 84.62%] [G loss: 6.116508]\n",
            "Validating on test set\n",
            "Validation Metrics: 1477 [D loss: 0.062459, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.136379]\n",
            "(1024, 1)\n",
            "Training Metrics: 1478 [D loss: 0.460269, acc.: 99.80%, op_acc: 85.35%] [G loss: 6.158720]\n",
            "Validating on test set\n",
            "Validation Metrics: 1478 [D loss: 0.066997, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.173664]\n",
            "(1024, 1)\n",
            "Training Metrics: 1479 [D loss: 0.447711, acc.: 99.80%, op_acc: 84.86%] [G loss: 6.113216]\n",
            "Validating on test set\n",
            "Validation Metrics: 1479 [D loss: 0.070723, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.111362]\n",
            "(1024, 1)\n",
            "Training Metrics: 1480 [D loss: 0.475208, acc.: 100.00%, op_acc: 84.13%] [G loss: 6.304741]\n",
            "Validating on test set\n",
            "Validation Metrics: 1480 [D loss: 0.057902, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.311277]\n",
            "(1024, 1)\n",
            "Training Metrics: 1481 [D loss: 0.450118, acc.: 99.90%, op_acc: 86.04%] [G loss: 6.200316]\n",
            "Validating on test set\n",
            "Validation Metrics: 1481 [D loss: 0.059310, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.186724]\n",
            "(1024, 1)\n",
            "Training Metrics: 1482 [D loss: 0.446230, acc.: 99.80%, op_acc: 84.62%] [G loss: 6.030058]\n",
            "Validating on test set\n",
            "Validation Metrics: 1482 [D loss: 0.068418, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.020475]\n",
            "(1024, 1)\n",
            "Training Metrics: 1483 [D loss: 0.475911, acc.: 99.76%, op_acc: 85.50%] [G loss: 5.949961]\n",
            "Validating on test set\n",
            "Validation Metrics: 1483 [D loss: 0.066620, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.955313]\n",
            "(1024, 1)\n",
            "Training Metrics: 1484 [D loss: 0.455122, acc.: 99.66%, op_acc: 84.86%] [G loss: 5.734384]\n",
            "Validating on test set\n",
            "Validation Metrics: 1484 [D loss: 0.080164, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.732549]\n",
            "(1024, 1)\n",
            "Training Metrics: 1485 [D loss: 0.471751, acc.: 100.00%, op_acc: 84.72%] [G loss: 6.032888]\n",
            "Validating on test set\n",
            "Validation Metrics: 1485 [D loss: 0.059968, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.048606]\n",
            "(1024, 1)\n",
            "Training Metrics: 1486 [D loss: 0.460325, acc.: 99.71%, op_acc: 85.01%] [G loss: 6.083988]\n",
            "Validating on test set\n",
            "Validation Metrics: 1486 [D loss: 0.062190, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.073171]\n",
            "(1024, 1)\n",
            "Training Metrics: 1487 [D loss: 0.437633, acc.: 99.80%, op_acc: 85.84%] [G loss: 5.967858]\n",
            "Validating on test set\n",
            "Validation Metrics: 1487 [D loss: 0.096605, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.982488]\n",
            "(1024, 1)\n",
            "Training Metrics: 1488 [D loss: 0.479103, acc.: 100.00%, op_acc: 84.33%] [G loss: 5.887195]\n",
            "Validating on test set\n",
            "Validation Metrics: 1488 [D loss: 0.065983, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.890894]\n",
            "(1024, 1)\n",
            "Training Metrics: 1489 [D loss: 0.472140, acc.: 99.85%, op_acc: 84.91%] [G loss: 6.109661]\n",
            "Validating on test set\n",
            "Validation Metrics: 1489 [D loss: 0.076379, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.107555]\n",
            "(1024, 1)\n",
            "Training Metrics: 1490 [D loss: 0.468322, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.180255]\n",
            "Validating on test set\n",
            "Validation Metrics: 1490 [D loss: 0.063465, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.177104]\n",
            "(1024, 1)\n",
            "Training Metrics: 1491 [D loss: 0.468840, acc.: 99.90%, op_acc: 84.18%] [G loss: 6.278667]\n",
            "Validating on test set\n",
            "Validation Metrics: 1491 [D loss: 0.074230, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.278375]\n",
            "(1024, 1)\n",
            "Training Metrics: 1492 [D loss: 0.475856, acc.: 99.90%, op_acc: 84.13%] [G loss: 5.947088]\n",
            "Validating on test set\n",
            "Validation Metrics: 1492 [D loss: 0.068197, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.939966]\n",
            "(1024, 1)\n",
            "Training Metrics: 1493 [D loss: 0.460584, acc.: 99.95%, op_acc: 84.72%] [G loss: 6.196002]\n",
            "Validating on test set\n",
            "Validation Metrics: 1493 [D loss: 0.071176, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.204475]\n",
            "(1024, 1)\n",
            "Training Metrics: 1494 [D loss: 0.481557, acc.: 99.85%, op_acc: 84.03%] [G loss: 6.358232]\n",
            "Validating on test set\n",
            "Validation Metrics: 1494 [D loss: 0.074985, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.353726]\n",
            "(1024, 1)\n",
            "Training Metrics: 1495 [D loss: 0.451334, acc.: 99.95%, op_acc: 84.67%] [G loss: 6.471583]\n",
            "Validating on test set\n",
            "Validation Metrics: 1495 [D loss: 0.061641, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.472699]\n",
            "(1024, 1)\n",
            "Training Metrics: 1496 [D loss: 0.438853, acc.: 99.80%, op_acc: 85.11%] [G loss: 6.239106]\n",
            "Validating on test set\n",
            "Validation Metrics: 1496 [D loss: 0.070936, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.239167]\n",
            "(1024, 1)\n",
            "Training Metrics: 1497 [D loss: 0.446153, acc.: 99.80%, op_acc: 85.25%] [G loss: 6.412806]\n",
            "Validating on test set\n",
            "Validation Metrics: 1497 [D loss: 0.067332, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.421375]\n",
            "(1024, 1)\n",
            "Training Metrics: 1498 [D loss: 0.454331, acc.: 99.76%, op_acc: 84.03%] [G loss: 5.658822]\n",
            "Validating on test set\n",
            "Validation Metrics: 1498 [D loss: 0.086049, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.659644]\n",
            "(1024, 1)\n",
            "Training Metrics: 1499 [D loss: 0.479816, acc.: 99.85%, op_acc: 83.94%] [G loss: 6.214797]\n",
            "Validating on test set\n",
            "Validation Metrics: 1499 [D loss: 0.064651, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.212550]\n",
            "(1024, 1)\n",
            "Training Metrics: 1500 [D loss: 0.472155, acc.: 100.00%, op_acc: 84.81%] [G loss: 6.240417]\n",
            "Validating on test set\n",
            "Validation Metrics: 1500 [D loss: 0.054735, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.230125]\n",
            "(1024, 1)\n",
            "Training Metrics: 1501 [D loss: 0.477371, acc.: 99.85%, op_acc: 84.03%] [G loss: 6.257965]\n",
            "Validating on test set\n",
            "Validation Metrics: 1501 [D loss: 0.066790, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.251914]\n",
            "(1024, 1)\n",
            "Training Metrics: 1502 [D loss: 0.478300, acc.: 99.71%, op_acc: 85.25%] [G loss: 6.038430]\n",
            "Validating on test set\n",
            "Validation Metrics: 1502 [D loss: 0.068562, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.044619]\n",
            "(1024, 1)\n",
            "Training Metrics: 1503 [D loss: 0.455713, acc.: 99.85%, op_acc: 84.67%] [G loss: 5.857345]\n",
            "Validating on test set\n",
            "Validation Metrics: 1503 [D loss: 0.072516, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.862096]\n",
            "(1024, 1)\n",
            "Training Metrics: 1504 [D loss: 0.430796, acc.: 99.95%, op_acc: 85.11%] [G loss: 6.493056]\n",
            "Validating on test set\n",
            "Validation Metrics: 1504 [D loss: 0.057307, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.497822]\n",
            "(1024, 1)\n",
            "Training Metrics: 1505 [D loss: 0.448617, acc.: 99.90%, op_acc: 84.86%] [G loss: 6.222007]\n",
            "Validating on test set\n",
            "Validation Metrics: 1505 [D loss: 0.069567, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.210859]\n",
            "(1024, 1)\n",
            "Training Metrics: 1506 [D loss: 0.450831, acc.: 99.85%, op_acc: 84.57%] [G loss: 6.127234]\n",
            "Validating on test set\n",
            "Validation Metrics: 1506 [D loss: 0.069596, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.117645]\n",
            "(1024, 1)\n",
            "Training Metrics: 1507 [D loss: 0.436020, acc.: 99.80%, op_acc: 85.74%] [G loss: 6.196187]\n",
            "Validating on test set\n",
            "Validation Metrics: 1507 [D loss: 0.062884, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.196379]\n",
            "(1024, 1)\n",
            "Training Metrics: 1508 [D loss: 0.475429, acc.: 99.95%, op_acc: 83.50%] [G loss: 6.267306]\n",
            "Validating on test set\n",
            "Validation Metrics: 1508 [D loss: 0.059866, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.260535]\n",
            "(1024, 1)\n",
            "Training Metrics: 1509 [D loss: 0.460334, acc.: 100.00%, op_acc: 84.23%] [G loss: 6.313259]\n",
            "Validating on test set\n",
            "Validation Metrics: 1509 [D loss: 0.061792, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.311935]\n",
            "(1024, 1)\n",
            "Training Metrics: 1510 [D loss: 0.493348, acc.: 99.80%, op_acc: 83.25%] [G loss: 6.653904]\n",
            "Validating on test set\n",
            "Validation Metrics: 1510 [D loss: 0.064843, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.670214]\n",
            "(1024, 1)\n",
            "Training Metrics: 1511 [D loss: 0.481648, acc.: 99.90%, op_acc: 85.21%] [G loss: 6.326662]\n",
            "Validating on test set\n",
            "Validation Metrics: 1511 [D loss: 0.054200, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.305465]\n",
            "(1024, 1)\n",
            "Training Metrics: 1512 [D loss: 0.455811, acc.: 99.90%, op_acc: 84.72%] [G loss: 6.383500]\n",
            "Validating on test set\n",
            "Validation Metrics: 1512 [D loss: 0.078555, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.380826]\n",
            "(1024, 1)\n",
            "Training Metrics: 1513 [D loss: 0.492399, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.684355]\n",
            "Validating on test set\n",
            "Validation Metrics: 1513 [D loss: 0.064337, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.687310]\n",
            "(1024, 1)\n",
            "Training Metrics: 1514 [D loss: 0.446817, acc.: 99.90%, op_acc: 84.52%] [G loss: 6.234054]\n",
            "Validating on test set\n",
            "Validation Metrics: 1514 [D loss: 0.059252, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.201828]\n",
            "(1024, 1)\n",
            "Training Metrics: 1515 [D loss: 0.441897, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.746910]\n",
            "Validating on test set\n",
            "Validation Metrics: 1515 [D loss: 0.062275, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.737973]\n",
            "(1024, 1)\n",
            "Training Metrics: 1516 [D loss: 0.468722, acc.: 99.76%, op_acc: 84.77%] [G loss: 6.032535]\n",
            "Validating on test set\n",
            "Validation Metrics: 1516 [D loss: 0.057017, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.015139]\n",
            "(1024, 1)\n",
            "Training Metrics: 1517 [D loss: 0.446453, acc.: 100.00%, op_acc: 85.16%] [G loss: 6.558962]\n",
            "Validating on test set\n",
            "Validation Metrics: 1517 [D loss: 0.061336, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.561246]\n",
            "(1024, 1)\n",
            "Training Metrics: 1518 [D loss: 0.489840, acc.: 99.90%, op_acc: 82.86%] [G loss: 6.367182]\n",
            "Validating on test set\n",
            "Validation Metrics: 1518 [D loss: 0.049554, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.360816]\n",
            "(1024, 1)\n",
            "Training Metrics: 1519 [D loss: 0.492458, acc.: 99.90%, op_acc: 82.23%] [G loss: 6.567326]\n",
            "Validating on test set\n",
            "Validation Metrics: 1519 [D loss: 0.061627, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.568878]\n",
            "(1024, 1)\n",
            "Training Metrics: 1520 [D loss: 0.527700, acc.: 99.76%, op_acc: 84.42%] [G loss: 6.205448]\n",
            "Validating on test set\n",
            "Validation Metrics: 1520 [D loss: 0.059270, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.203108]\n",
            "(1024, 1)\n",
            "Training Metrics: 1521 [D loss: 0.442690, acc.: 99.95%, op_acc: 85.50%] [G loss: 6.720040]\n",
            "Validating on test set\n",
            "Validation Metrics: 1521 [D loss: 0.060823, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.725955]\n",
            "(1024, 1)\n",
            "Training Metrics: 1522 [D loss: 0.427096, acc.: 99.90%, op_acc: 86.04%] [G loss: 6.307253]\n",
            "Validating on test set\n",
            "Validation Metrics: 1522 [D loss: 0.057574, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.310855]\n",
            "(1024, 1)\n",
            "Training Metrics: 1523 [D loss: 0.465501, acc.: 99.90%, op_acc: 85.21%] [G loss: 6.065388]\n",
            "Validating on test set\n",
            "Validation Metrics: 1523 [D loss: 0.058912, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.051299]\n",
            "(1024, 1)\n",
            "Training Metrics: 1524 [D loss: 0.458785, acc.: 99.95%, op_acc: 83.94%] [G loss: 6.582750]\n",
            "Validating on test set\n",
            "Validation Metrics: 1524 [D loss: 0.052647, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.601323]\n",
            "(1024, 1)\n",
            "Training Metrics: 1525 [D loss: 0.467913, acc.: 99.95%, op_acc: 83.84%] [G loss: 6.492557]\n",
            "Validating on test set\n",
            "Validation Metrics: 1525 [D loss: 0.061695, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.483737]\n",
            "(1024, 1)\n",
            "Training Metrics: 1526 [D loss: 0.465507, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.526227]\n",
            "Validating on test set\n",
            "Validation Metrics: 1526 [D loss: 0.056372, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.514892]\n",
            "(1024, 1)\n",
            "Training Metrics: 1527 [D loss: 0.447626, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.556712]\n",
            "Validating on test set\n",
            "Validation Metrics: 1527 [D loss: 0.058989, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.557642]\n",
            "(1024, 1)\n",
            "Training Metrics: 1528 [D loss: 0.437496, acc.: 99.90%, op_acc: 85.30%] [G loss: 6.284832]\n",
            "Validating on test set\n",
            "Validation Metrics: 1528 [D loss: 0.059275, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.280939]\n",
            "(1024, 1)\n",
            "Training Metrics: 1529 [D loss: 0.489132, acc.: 99.95%, op_acc: 83.35%] [G loss: 6.491538]\n",
            "Validating on test set\n",
            "Validation Metrics: 1529 [D loss: 0.056714, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.507316]\n",
            "(1024, 1)\n",
            "Training Metrics: 1530 [D loss: 0.473108, acc.: 99.90%, op_acc: 83.11%] [G loss: 6.434902]\n",
            "Validating on test set\n",
            "Validation Metrics: 1530 [D loss: 0.056512, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.435792]\n",
            "(1024, 1)\n",
            "Training Metrics: 1531 [D loss: 0.457835, acc.: 99.80%, op_acc: 84.18%] [G loss: 6.260515]\n",
            "Validating on test set\n",
            "Validation Metrics: 1531 [D loss: 0.052335, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.274968]\n",
            "(1024, 1)\n",
            "Training Metrics: 1532 [D loss: 0.460774, acc.: 99.80%, op_acc: 83.74%] [G loss: 6.070226]\n",
            "Validating on test set\n",
            "Validation Metrics: 1532 [D loss: 0.060125, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.068089]\n",
            "(1024, 1)\n",
            "Training Metrics: 1533 [D loss: 0.445262, acc.: 99.95%, op_acc: 84.57%] [G loss: 6.188447]\n",
            "Validating on test set\n",
            "Validation Metrics: 1533 [D loss: 0.057495, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.185619]\n",
            "(1024, 1)\n",
            "Training Metrics: 1534 [D loss: 0.421984, acc.: 99.95%, op_acc: 85.30%] [G loss: 6.390746]\n",
            "Validating on test set\n",
            "Validation Metrics: 1534 [D loss: 0.056885, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.370264]\n",
            "(1024, 1)\n",
            "Training Metrics: 1535 [D loss: 0.480618, acc.: 99.80%, op_acc: 84.33%] [G loss: 6.254552]\n",
            "Validating on test set\n",
            "Validation Metrics: 1535 [D loss: 0.058830, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.265364]\n",
            "(1024, 1)\n",
            "Training Metrics: 1536 [D loss: 0.484963, acc.: 99.90%, op_acc: 83.20%] [G loss: 6.108736]\n",
            "Validating on test set\n",
            "Validation Metrics: 1536 [D loss: 0.054559, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.108225]\n",
            "(1024, 1)\n",
            "Training Metrics: 1537 [D loss: 0.485996, acc.: 99.85%, op_acc: 84.57%] [G loss: 6.019918]\n",
            "Validating on test set\n",
            "Validation Metrics: 1537 [D loss: 0.058770, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.002802]\n",
            "(1024, 1)\n",
            "Training Metrics: 1538 [D loss: 0.460170, acc.: 99.95%, op_acc: 83.94%] [G loss: 6.164705]\n",
            "Validating on test set\n",
            "Validation Metrics: 1538 [D loss: 0.061166, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.170052]\n",
            "(1024, 1)\n",
            "Training Metrics: 1539 [D loss: 0.516762, acc.: 99.90%, op_acc: 83.15%] [G loss: 6.351452]\n",
            "Validating on test set\n",
            "Validation Metrics: 1539 [D loss: 0.062771, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.365737]\n",
            "(1024, 1)\n",
            "Training Metrics: 1540 [D loss: 0.482718, acc.: 99.95%, op_acc: 82.52%] [G loss: 6.376803]\n",
            "Validating on test set\n",
            "Validation Metrics: 1540 [D loss: 0.056510, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.374590]\n",
            "(1024, 1)\n",
            "Training Metrics: 1541 [D loss: 0.471488, acc.: 99.95%, op_acc: 84.72%] [G loss: 6.856259]\n",
            "Validating on test set\n",
            "Validation Metrics: 1541 [D loss: 0.048588, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.838396]\n",
            "(1024, 1)\n",
            "Training Metrics: 1542 [D loss: 0.490497, acc.: 99.76%, op_acc: 82.52%] [G loss: 6.335721]\n",
            "Validating on test set\n",
            "Validation Metrics: 1542 [D loss: 0.059876, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.346174]\n",
            "(1024, 1)\n",
            "Training Metrics: 1543 [D loss: 0.465076, acc.: 100.00%, op_acc: 84.72%] [G loss: 6.398337]\n",
            "Validating on test set\n",
            "Validation Metrics: 1543 [D loss: 0.051782, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.399910]\n",
            "(1024, 1)\n",
            "Training Metrics: 1544 [D loss: 0.450813, acc.: 100.00%, op_acc: 84.13%] [G loss: 6.610533]\n",
            "Validating on test set\n",
            "Validation Metrics: 1544 [D loss: 0.058045, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.611340]\n",
            "(1024, 1)\n",
            "Training Metrics: 1545 [D loss: 0.444449, acc.: 99.80%, op_acc: 85.16%] [G loss: 5.973983]\n",
            "Validating on test set\n",
            "Validation Metrics: 1545 [D loss: 0.058332, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.992607]\n",
            "(1024, 1)\n",
            "Training Metrics: 1546 [D loss: 0.406813, acc.: 99.90%, op_acc: 85.60%] [G loss: 6.422794]\n",
            "Validating on test set\n",
            "Validation Metrics: 1546 [D loss: 0.050252, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.429426]\n",
            "(1024, 1)\n",
            "Training Metrics: 1547 [D loss: 0.439707, acc.: 99.90%, op_acc: 85.21%] [G loss: 6.004012]\n",
            "Validating on test set\n",
            "Validation Metrics: 1547 [D loss: 0.055238, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.994925]\n",
            "(1024, 1)\n",
            "Training Metrics: 1548 [D loss: 0.454084, acc.: 99.95%, op_acc: 84.57%] [G loss: 6.547089]\n",
            "Validating on test set\n",
            "Validation Metrics: 1548 [D loss: 0.059586, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.557125]\n",
            "(1024, 1)\n",
            "Training Metrics: 1549 [D loss: 0.476493, acc.: 99.90%, op_acc: 83.69%] [G loss: 5.741453]\n",
            "Validating on test set\n",
            "Validation Metrics: 1549 [D loss: 0.058291, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.747551]\n",
            "(1024, 1)\n",
            "Training Metrics: 1550 [D loss: 0.475994, acc.: 99.90%, op_acc: 84.03%] [G loss: 6.411355]\n",
            "Validating on test set\n",
            "Validation Metrics: 1550 [D loss: 0.057583, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.419402]\n",
            "(1024, 1)\n",
            "Training Metrics: 1551 [D loss: 0.432860, acc.: 99.76%, op_acc: 86.23%] [G loss: 6.069633]\n",
            "Validating on test set\n",
            "Validation Metrics: 1551 [D loss: 0.055884, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.055764]\n",
            "(1024, 1)\n",
            "Training Metrics: 1552 [D loss: 0.450565, acc.: 99.85%, op_acc: 84.67%] [G loss: 6.192364]\n",
            "Validating on test set\n",
            "Validation Metrics: 1552 [D loss: 0.063607, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.181548]\n",
            "(1024, 1)\n",
            "Training Metrics: 1553 [D loss: 0.499304, acc.: 99.95%, op_acc: 82.86%] [G loss: 6.340622]\n",
            "Validating on test set\n",
            "Validation Metrics: 1553 [D loss: 0.056200, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.355651]\n",
            "(1024, 1)\n",
            "Training Metrics: 1554 [D loss: 0.491747, acc.: 99.90%, op_acc: 84.23%] [G loss: 6.286503]\n",
            "Validating on test set\n",
            "Validation Metrics: 1554 [D loss: 0.062208, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.278625]\n",
            "(1024, 1)\n",
            "Training Metrics: 1555 [D loss: 0.447642, acc.: 99.90%, op_acc: 83.64%] [G loss: 6.257154]\n",
            "Validating on test set\n",
            "Validation Metrics: 1555 [D loss: 0.056498, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.261828]\n",
            "(1024, 1)\n",
            "Training Metrics: 1556 [D loss: 0.504412, acc.: 99.85%, op_acc: 84.67%] [G loss: 6.294763]\n",
            "Validating on test set\n",
            "Validation Metrics: 1556 [D loss: 0.075769, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.324209]\n",
            "(1024, 1)\n",
            "Training Metrics: 1557 [D loss: 0.456750, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.148637]\n",
            "Validating on test set\n",
            "Validation Metrics: 1557 [D loss: 0.057882, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.164867]\n",
            "(1024, 1)\n",
            "Training Metrics: 1558 [D loss: 0.483828, acc.: 99.95%, op_acc: 84.33%] [G loss: 6.279043]\n",
            "Validating on test set\n",
            "Validation Metrics: 1558 [D loss: 0.059210, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.279068]\n",
            "(1024, 1)\n",
            "Training Metrics: 1559 [D loss: 0.464214, acc.: 99.80%, op_acc: 84.72%] [G loss: 6.466582]\n",
            "Validating on test set\n",
            "Validation Metrics: 1559 [D loss: 0.053770, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.456370]\n",
            "(1024, 1)\n",
            "Training Metrics: 1560 [D loss: 0.466167, acc.: 99.85%, op_acc: 83.98%] [G loss: 6.065078]\n",
            "Validating on test set\n",
            "Validation Metrics: 1560 [D loss: 0.069765, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.052732]\n",
            "(1024, 1)\n",
            "Training Metrics: 1561 [D loss: 0.531931, acc.: 99.90%, op_acc: 83.25%] [G loss: 6.350825]\n",
            "Validating on test set\n",
            "Validation Metrics: 1561 [D loss: 0.049254, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.361355]\n",
            "(1024, 1)\n",
            "Training Metrics: 1562 [D loss: 0.446182, acc.: 99.90%, op_acc: 84.77%] [G loss: 5.713515]\n",
            "Validating on test set\n",
            "Validation Metrics: 1562 [D loss: 0.064135, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.691499]\n",
            "(1024, 1)\n",
            "Training Metrics: 1563 [D loss: 0.515495, acc.: 99.95%, op_acc: 82.42%] [G loss: 6.292109]\n",
            "Validating on test set\n",
            "Validation Metrics: 1563 [D loss: 0.068489, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.306416]\n",
            "(1024, 1)\n",
            "Training Metrics: 1564 [D loss: 0.527421, acc.: 99.95%, op_acc: 84.38%] [G loss: 6.452830]\n",
            "Validating on test set\n",
            "Validation Metrics: 1564 [D loss: 0.058173, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.473928]\n",
            "(1024, 1)\n",
            "Training Metrics: 1565 [D loss: 0.482927, acc.: 99.76%, op_acc: 82.42%] [G loss: 6.122581]\n",
            "Validating on test set\n",
            "Validation Metrics: 1565 [D loss: 0.057531, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.100292]\n",
            "(1024, 1)\n",
            "Training Metrics: 1566 [D loss: 0.451541, acc.: 100.00%, op_acc: 84.28%] [G loss: 6.284216]\n",
            "Validating on test set\n",
            "Validation Metrics: 1566 [D loss: 0.073273, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.281487]\n",
            "(1024, 1)\n",
            "Training Metrics: 1567 [D loss: 0.470922, acc.: 99.90%, op_acc: 84.77%] [G loss: 6.149141]\n",
            "Validating on test set\n",
            "Validation Metrics: 1567 [D loss: 0.055318, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.176880]\n",
            "(1024, 1)\n",
            "Training Metrics: 1568 [D loss: 0.487456, acc.: 99.95%, op_acc: 83.20%] [G loss: 6.349921]\n",
            "Validating on test set\n",
            "Validation Metrics: 1568 [D loss: 0.078848, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.340988]\n",
            "(1024, 1)\n",
            "Training Metrics: 1569 [D loss: 0.441084, acc.: 99.80%, op_acc: 86.18%] [G loss: 6.191924]\n",
            "Validating on test set\n",
            "Validation Metrics: 1569 [D loss: 0.059850, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.153596]\n",
            "(1024, 1)\n",
            "Training Metrics: 1570 [D loss: 0.440361, acc.: 99.80%, op_acc: 85.16%] [G loss: 6.155346]\n",
            "Validating on test set\n",
            "Validation Metrics: 1570 [D loss: 0.059228, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.172051]\n",
            "(1024, 1)\n",
            "Training Metrics: 1571 [D loss: 0.473877, acc.: 99.90%, op_acc: 83.98%] [G loss: 6.391207]\n",
            "Validating on test set\n",
            "Validation Metrics: 1571 [D loss: 0.060894, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.388453]\n",
            "(1024, 1)\n",
            "Training Metrics: 1572 [D loss: 0.472898, acc.: 99.90%, op_acc: 83.64%] [G loss: 6.074721]\n",
            "Validating on test set\n",
            "Validation Metrics: 1572 [D loss: 0.056434, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.073318]\n",
            "(1024, 1)\n",
            "Training Metrics: 1573 [D loss: 0.510251, acc.: 99.85%, op_acc: 82.76%] [G loss: 6.495885]\n",
            "Validating on test set\n",
            "Validation Metrics: 1573 [D loss: 0.085824, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.520397]\n",
            "(1024, 1)\n",
            "Training Metrics: 1574 [D loss: 0.511670, acc.: 99.76%, op_acc: 82.96%] [G loss: 5.658285]\n",
            "Validating on test set\n",
            "Validation Metrics: 1574 [D loss: 0.057955, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.689612]\n",
            "(1024, 1)\n",
            "Training Metrics: 1575 [D loss: 0.537708, acc.: 99.76%, op_acc: 83.30%] [G loss: 6.020667]\n",
            "Validating on test set\n",
            "Validation Metrics: 1575 [D loss: 0.059092, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.989549]\n",
            "(1024, 1)\n",
            "Training Metrics: 1576 [D loss: 0.489970, acc.: 99.95%, op_acc: 83.64%] [G loss: 5.678937]\n",
            "Validating on test set\n",
            "Validation Metrics: 1576 [D loss: 0.067650, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.684347]\n",
            "(1024, 1)\n",
            "Training Metrics: 1577 [D loss: 0.513840, acc.: 99.90%, op_acc: 82.13%] [G loss: 6.064717]\n",
            "Validating on test set\n",
            "Validation Metrics: 1577 [D loss: 0.055418, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.069681]\n",
            "(1024, 1)\n",
            "Training Metrics: 1578 [D loss: 0.510991, acc.: 100.00%, op_acc: 82.47%] [G loss: 6.087029]\n",
            "Validating on test set\n",
            "Validation Metrics: 1578 [D loss: 0.055982, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.074885]\n",
            "(1024, 1)\n",
            "Training Metrics: 1579 [D loss: 0.522959, acc.: 99.80%, op_acc: 82.42%] [G loss: 6.258927]\n",
            "Validating on test set\n",
            "Validation Metrics: 1579 [D loss: 0.068194, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.267467]\n",
            "(1024, 1)\n",
            "Training Metrics: 1580 [D loss: 0.497612, acc.: 99.80%, op_acc: 84.13%] [G loss: 6.081493]\n",
            "Validating on test set\n",
            "Validation Metrics: 1580 [D loss: 0.057505, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.104636]\n",
            "(1024, 1)\n",
            "Training Metrics: 1581 [D loss: 0.466698, acc.: 99.95%, op_acc: 84.33%] [G loss: 6.286950]\n",
            "Validating on test set\n",
            "Validation Metrics: 1581 [D loss: 0.071457, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.293374]\n",
            "(1024, 1)\n",
            "Training Metrics: 1582 [D loss: 0.455629, acc.: 100.00%, op_acc: 84.86%] [G loss: 6.609542]\n",
            "Validating on test set\n",
            "Validation Metrics: 1582 [D loss: 0.047586, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.587770]\n",
            "(1024, 1)\n",
            "Training Metrics: 1583 [D loss: 0.445683, acc.: 99.95%, op_acc: 84.91%] [G loss: 6.278524]\n",
            "Validating on test set\n",
            "Validation Metrics: 1583 [D loss: 0.067937, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.271425]\n",
            "(1024, 1)\n",
            "Training Metrics: 1584 [D loss: 0.460854, acc.: 99.90%, op_acc: 84.33%] [G loss: 6.406710]\n",
            "Validating on test set\n",
            "Validation Metrics: 1584 [D loss: 0.049785, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.411594]\n",
            "(1024, 1)\n",
            "Training Metrics: 1585 [D loss: 0.438515, acc.: 99.76%, op_acc: 84.81%] [G loss: 6.189471]\n",
            "Validating on test set\n",
            "Validation Metrics: 1585 [D loss: 0.064077, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.184968]\n",
            "(1024, 1)\n",
            "Training Metrics: 1586 [D loss: 0.475051, acc.: 99.80%, op_acc: 85.25%] [G loss: 6.262088]\n",
            "Validating on test set\n",
            "Validation Metrics: 1586 [D loss: 0.060585, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.270355]\n",
            "(1024, 1)\n",
            "Training Metrics: 1587 [D loss: 0.477479, acc.: 99.85%, op_acc: 83.45%] [G loss: 5.832230]\n",
            "Validating on test set\n",
            "Validation Metrics: 1587 [D loss: 0.069089, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.834894]\n",
            "(1024, 1)\n",
            "Training Metrics: 1588 [D loss: 0.450245, acc.: 99.95%, op_acc: 84.96%] [G loss: 6.273239]\n",
            "Validating on test set\n",
            "Validation Metrics: 1588 [D loss: 0.045326, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.287022]\n",
            "(1024, 1)\n",
            "Training Metrics: 1589 [D loss: 0.438485, acc.: 99.90%, op_acc: 84.81%] [G loss: 5.968160]\n",
            "Validating on test set\n",
            "Validation Metrics: 1589 [D loss: 0.058972, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.953716]\n",
            "(1024, 1)\n",
            "Training Metrics: 1590 [D loss: 0.479785, acc.: 99.95%, op_acc: 83.84%] [G loss: 6.487898]\n",
            "Validating on test set\n",
            "Validation Metrics: 1590 [D loss: 0.065350, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.490199]\n",
            "(1024, 1)\n",
            "Training Metrics: 1591 [D loss: 0.434996, acc.: 99.90%, op_acc: 84.72%] [G loss: 6.038039]\n",
            "Validating on test set\n",
            "Validation Metrics: 1591 [D loss: 0.052946, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.044996]\n",
            "(1024, 1)\n",
            "Training Metrics: 1592 [D loss: 0.478100, acc.: 99.95%, op_acc: 85.16%] [G loss: 6.486755]\n",
            "Validating on test set\n",
            "Validation Metrics: 1592 [D loss: 0.064360, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.481265]\n",
            "(1024, 1)\n",
            "Training Metrics: 1593 [D loss: 0.446607, acc.: 100.00%, op_acc: 85.50%] [G loss: 6.327086]\n",
            "Validating on test set\n",
            "Validation Metrics: 1593 [D loss: 0.056632, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.335156]\n",
            "(1024, 1)\n",
            "Training Metrics: 1594 [D loss: 0.454118, acc.: 99.95%, op_acc: 85.21%] [G loss: 6.545690]\n",
            "Validating on test set\n",
            "Validation Metrics: 1594 [D loss: 0.065560, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.537973]\n",
            "(1024, 1)\n",
            "Training Metrics: 1595 [D loss: 0.464115, acc.: 100.00%, op_acc: 84.23%] [G loss: 6.717447]\n",
            "Validating on test set\n",
            "Validation Metrics: 1595 [D loss: 0.046843, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.720527]\n",
            "(1024, 1)\n",
            "Training Metrics: 1596 [D loss: 0.469432, acc.: 99.95%, op_acc: 83.64%] [G loss: 6.507192]\n",
            "Validating on test set\n",
            "Validation Metrics: 1596 [D loss: 0.062927, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.497892]\n",
            "(1024, 1)\n",
            "Training Metrics: 1597 [D loss: 0.488953, acc.: 99.76%, op_acc: 83.69%] [G loss: 6.261278]\n",
            "Validating on test set\n",
            "Validation Metrics: 1597 [D loss: 0.057365, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.262735]\n",
            "(1024, 1)\n",
            "Training Metrics: 1598 [D loss: 0.459940, acc.: 99.80%, op_acc: 84.96%] [G loss: 5.976082]\n",
            "Validating on test set\n",
            "Validation Metrics: 1598 [D loss: 0.054679, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.984389]\n",
            "(1024, 1)\n",
            "Training Metrics: 1599 [D loss: 0.418626, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.420934]\n",
            "Validating on test set\n",
            "Validation Metrics: 1599 [D loss: 0.081172, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.425834]\n",
            "(1024, 1)\n",
            "Training Metrics: 1600 [D loss: 0.473469, acc.: 99.80%, op_acc: 84.81%] [G loss: 5.636162]\n",
            "Validating on test set\n",
            "Validation Metrics: 1600 [D loss: 0.059679, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.650422]\n",
            "(1024, 1)\n",
            "Training Metrics: 1601 [D loss: 0.460267, acc.: 99.80%, op_acc: 84.18%] [G loss: 6.152477]\n",
            "Validating on test set\n",
            "Validation Metrics: 1601 [D loss: 0.060989, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.131620]\n",
            "(1024, 1)\n",
            "Training Metrics: 1602 [D loss: 0.421368, acc.: 99.80%, op_acc: 86.13%] [G loss: 6.067067]\n",
            "Validating on test set\n",
            "Validation Metrics: 1602 [D loss: 0.062627, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.067144]\n",
            "(1024, 1)\n",
            "Training Metrics: 1603 [D loss: 0.466886, acc.: 99.95%, op_acc: 83.98%] [G loss: 6.281872]\n",
            "Validating on test set\n",
            "Validation Metrics: 1603 [D loss: 0.050478, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.267037]\n",
            "(1024, 1)\n",
            "Training Metrics: 1604 [D loss: 0.435378, acc.: 99.95%, op_acc: 84.67%] [G loss: 6.267076]\n",
            "Validating on test set\n",
            "Validation Metrics: 1604 [D loss: 0.053095, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.265280]\n",
            "(1024, 1)\n",
            "Training Metrics: 1605 [D loss: 0.455329, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.406322]\n",
            "Validating on test set\n",
            "Validation Metrics: 1605 [D loss: 0.055058, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.399001]\n",
            "(1024, 1)\n",
            "Training Metrics: 1606 [D loss: 0.438830, acc.: 100.00%, op_acc: 85.35%] [G loss: 6.440350]\n",
            "Validating on test set\n",
            "Validation Metrics: 1606 [D loss: 0.074421, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.453490]\n",
            "(1024, 1)\n",
            "Training Metrics: 1607 [D loss: 0.433454, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.400987]\n",
            "Validating on test set\n",
            "Validation Metrics: 1607 [D loss: 0.047550, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.410441]\n",
            "(1024, 1)\n",
            "Training Metrics: 1608 [D loss: 0.473641, acc.: 99.95%, op_acc: 83.89%] [G loss: 6.411120]\n",
            "Validating on test set\n",
            "Validation Metrics: 1608 [D loss: 0.073207, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.402598]\n",
            "(1024, 1)\n",
            "Training Metrics: 1609 [D loss: 0.482865, acc.: 100.00%, op_acc: 84.23%] [G loss: 6.139260]\n",
            "Validating on test set\n",
            "Validation Metrics: 1609 [D loss: 0.056264, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.137915]\n",
            "(1024, 1)\n",
            "Training Metrics: 1610 [D loss: 0.448136, acc.: 99.95%, op_acc: 85.35%] [G loss: 6.582945]\n",
            "Validating on test set\n",
            "Validation Metrics: 1610 [D loss: 0.052126, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.561203]\n",
            "(1024, 1)\n",
            "Training Metrics: 1611 [D loss: 0.462128, acc.: 99.90%, op_acc: 84.42%] [G loss: 6.402966]\n",
            "Validating on test set\n",
            "Validation Metrics: 1611 [D loss: 0.055831, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.402656]\n",
            "(1024, 1)\n",
            "Training Metrics: 1612 [D loss: 0.448346, acc.: 99.90%, op_acc: 84.23%] [G loss: 6.354067]\n",
            "Validating on test set\n",
            "Validation Metrics: 1612 [D loss: 0.059260, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.342366]\n",
            "(1024, 1)\n",
            "Training Metrics: 1613 [D loss: 0.454769, acc.: 99.90%, op_acc: 85.35%] [G loss: 6.081312]\n",
            "Validating on test set\n",
            "Validation Metrics: 1613 [D loss: 0.057052, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.071866]\n",
            "(1024, 1)\n",
            "Training Metrics: 1614 [D loss: 0.487846, acc.: 99.80%, op_acc: 85.06%] [G loss: 6.169607]\n",
            "Validating on test set\n",
            "Validation Metrics: 1614 [D loss: 0.053964, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.168639]\n",
            "(1024, 1)\n",
            "Training Metrics: 1615 [D loss: 0.450762, acc.: 99.90%, op_acc: 84.77%] [G loss: 6.292193]\n",
            "Validating on test set\n",
            "Validation Metrics: 1615 [D loss: 0.065019, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.304494]\n",
            "(1024, 1)\n",
            "Training Metrics: 1616 [D loss: 0.415421, acc.: 99.90%, op_acc: 86.23%] [G loss: 6.012988]\n",
            "Validating on test set\n",
            "Validation Metrics: 1616 [D loss: 0.048108, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.017089]\n",
            "(1024, 1)\n",
            "Training Metrics: 1617 [D loss: 0.453328, acc.: 99.85%, op_acc: 84.91%] [G loss: 6.313806]\n",
            "Validating on test set\n",
            "Validation Metrics: 1617 [D loss: 0.081231, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.321682]\n",
            "(1024, 1)\n",
            "Training Metrics: 1618 [D loss: 0.453028, acc.: 99.95%, op_acc: 84.52%] [G loss: 6.220822]\n",
            "Validating on test set\n",
            "Validation Metrics: 1618 [D loss: 0.055434, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.267676]\n",
            "(1024, 1)\n",
            "Training Metrics: 1619 [D loss: 0.461288, acc.: 99.85%, op_acc: 84.18%] [G loss: 6.102371]\n",
            "Validating on test set\n",
            "Validation Metrics: 1619 [D loss: 0.070016, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.068048]\n",
            "(1024, 1)\n",
            "Training Metrics: 1620 [D loss: 0.464079, acc.: 99.85%, op_acc: 83.30%] [G loss: 6.135278]\n",
            "Validating on test set\n",
            "Validation Metrics: 1620 [D loss: 0.069333, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.123373]\n",
            "(1024, 1)\n",
            "Training Metrics: 1621 [D loss: 0.462109, acc.: 99.95%, op_acc: 84.86%] [G loss: 6.128134]\n",
            "Validating on test set\n",
            "Validation Metrics: 1621 [D loss: 0.050079, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.155228]\n",
            "(1024, 1)\n",
            "Training Metrics: 1622 [D loss: 0.445744, acc.: 99.90%, op_acc: 85.64%] [G loss: 6.298215]\n",
            "Validating on test set\n",
            "Validation Metrics: 1622 [D loss: 0.055544, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.257804]\n",
            "(1024, 1)\n",
            "Training Metrics: 1623 [D loss: 0.411047, acc.: 99.95%, op_acc: 85.55%] [G loss: 6.325041]\n",
            "Validating on test set\n",
            "Validation Metrics: 1623 [D loss: 0.060833, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.326227]\n",
            "(1024, 1)\n",
            "Training Metrics: 1624 [D loss: 0.426296, acc.: 99.76%, op_acc: 84.86%] [G loss: 6.246435]\n",
            "Validating on test set\n",
            "Validation Metrics: 1624 [D loss: 0.051002, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.259671]\n",
            "(1024, 1)\n",
            "Training Metrics: 1625 [D loss: 0.429151, acc.: 99.71%, op_acc: 85.69%] [G loss: 5.960484]\n",
            "Validating on test set\n",
            "Validation Metrics: 1625 [D loss: 0.067510, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.967848]\n",
            "(1024, 1)\n",
            "Training Metrics: 1626 [D loss: 0.441665, acc.: 99.76%, op_acc: 85.16%] [G loss: 5.955647]\n",
            "Validating on test set\n",
            "Validation Metrics: 1626 [D loss: 0.053471, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.956641]\n",
            "(1024, 1)\n",
            "Training Metrics: 1627 [D loss: 0.425712, acc.: 99.80%, op_acc: 85.21%] [G loss: 5.880470]\n",
            "Validating on test set\n",
            "Validation Metrics: 1627 [D loss: 0.078757, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.877428]\n",
            "(1024, 1)\n",
            "Training Metrics: 1628 [D loss: 0.462242, acc.: 100.00%, op_acc: 84.42%] [G loss: 6.069193]\n",
            "Validating on test set\n",
            "Validation Metrics: 1628 [D loss: 0.047601, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.074436]\n",
            "(1024, 1)\n",
            "Training Metrics: 1629 [D loss: 0.456512, acc.: 99.90%, op_acc: 84.42%] [G loss: 6.472991]\n",
            "Validating on test set\n",
            "Validation Metrics: 1629 [D loss: 0.066376, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.462258]\n",
            "(1024, 1)\n",
            "Training Metrics: 1630 [D loss: 0.450403, acc.: 99.90%, op_acc: 84.33%] [G loss: 6.067898]\n",
            "Validating on test set\n",
            "Validation Metrics: 1630 [D loss: 0.067062, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.058171]\n",
            "(1024, 1)\n",
            "Training Metrics: 1631 [D loss: 0.505871, acc.: 99.95%, op_acc: 82.76%] [G loss: 6.807156]\n",
            "Validating on test set\n",
            "Validation Metrics: 1631 [D loss: 0.046525, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.794234]\n",
            "(1024, 1)\n",
            "Training Metrics: 1632 [D loss: 0.489545, acc.: 99.85%, op_acc: 83.84%] [G loss: 6.469355]\n",
            "Validating on test set\n",
            "Validation Metrics: 1632 [D loss: 0.049374, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.469663]\n",
            "(1024, 1)\n",
            "Training Metrics: 1633 [D loss: 0.457665, acc.: 100.00%, op_acc: 84.86%] [G loss: 6.316456]\n",
            "Validating on test set\n",
            "Validation Metrics: 1633 [D loss: 0.050426, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.326934]\n",
            "(1024, 1)\n",
            "Training Metrics: 1634 [D loss: 0.462557, acc.: 99.90%, op_acc: 85.06%] [G loss: 6.337788]\n",
            "Validating on test set\n",
            "Validation Metrics: 1634 [D loss: 0.061089, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.334979]\n",
            "(1024, 1)\n",
            "Training Metrics: 1635 [D loss: 0.467054, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.470060]\n",
            "Validating on test set\n",
            "Validation Metrics: 1635 [D loss: 0.049512, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.452857]\n",
            "(1024, 1)\n",
            "Training Metrics: 1636 [D loss: 0.429300, acc.: 99.85%, op_acc: 85.40%] [G loss: 6.188287]\n",
            "Validating on test set\n",
            "Validation Metrics: 1636 [D loss: 0.055460, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.171424]\n",
            "(1024, 1)\n",
            "Training Metrics: 1637 [D loss: 0.454634, acc.: 100.00%, op_acc: 85.74%] [G loss: 6.475136]\n",
            "Validating on test set\n",
            "Validation Metrics: 1637 [D loss: 0.052105, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.477554]\n",
            "(1024, 1)\n",
            "Training Metrics: 1638 [D loss: 0.451529, acc.: 99.85%, op_acc: 84.28%] [G loss: 6.140554]\n",
            "Validating on test set\n",
            "Validation Metrics: 1638 [D loss: 0.050526, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.143235]\n",
            "(1024, 1)\n",
            "Training Metrics: 1639 [D loss: 0.435932, acc.: 99.85%, op_acc: 85.40%] [G loss: 6.370767]\n",
            "Validating on test set\n",
            "Validation Metrics: 1639 [D loss: 0.063896, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.377555]\n",
            "(1024, 1)\n",
            "Training Metrics: 1640 [D loss: 0.418116, acc.: 99.80%, op_acc: 85.84%] [G loss: 6.158742]\n",
            "Validating on test set\n",
            "Validation Metrics: 1640 [D loss: 0.046723, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.173063]\n",
            "(1024, 1)\n",
            "Training Metrics: 1641 [D loss: 0.457152, acc.: 99.95%, op_acc: 84.57%] [G loss: 6.244641]\n",
            "Validating on test set\n",
            "Validation Metrics: 1641 [D loss: 0.056513, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.238844]\n",
            "(1024, 1)\n",
            "Training Metrics: 1642 [D loss: 0.484012, acc.: 99.85%, op_acc: 83.40%] [G loss: 5.925054]\n",
            "Validating on test set\n",
            "Validation Metrics: 1642 [D loss: 0.052766, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.912933]\n",
            "(1024, 1)\n",
            "Training Metrics: 1643 [D loss: 0.423244, acc.: 99.80%, op_acc: 84.28%] [G loss: 6.063618]\n",
            "Validating on test set\n",
            "Validation Metrics: 1643 [D loss: 0.052083, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.056747]\n",
            "(1024, 1)\n",
            "Training Metrics: 1644 [D loss: 0.466732, acc.: 100.00%, op_acc: 83.84%] [G loss: 5.926448]\n",
            "Validating on test set\n",
            "Validation Metrics: 1644 [D loss: 0.048032, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.926776]\n",
            "(1024, 1)\n",
            "Training Metrics: 1645 [D loss: 0.434070, acc.: 99.85%, op_acc: 84.47%] [G loss: 6.359684]\n",
            "Validating on test set\n",
            "Validation Metrics: 1645 [D loss: 0.044209, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.365430]\n",
            "(1024, 1)\n",
            "Training Metrics: 1646 [D loss: 0.460766, acc.: 99.80%, op_acc: 84.03%] [G loss: 6.182140]\n",
            "Validating on test set\n",
            "Validation Metrics: 1646 [D loss: 0.048779, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.184838]\n",
            "(1024, 1)\n",
            "Training Metrics: 1647 [D loss: 0.456043, acc.: 99.85%, op_acc: 84.33%] [G loss: 5.784846]\n",
            "Validating on test set\n",
            "Validation Metrics: 1647 [D loss: 0.055901, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.794354]\n",
            "(1024, 1)\n",
            "Training Metrics: 1648 [D loss: 0.482054, acc.: 99.95%, op_acc: 83.40%] [G loss: 6.439381]\n",
            "Validating on test set\n",
            "Validation Metrics: 1648 [D loss: 0.045923, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.435947]\n",
            "(1024, 1)\n",
            "Training Metrics: 1649 [D loss: 0.475760, acc.: 99.95%, op_acc: 83.98%] [G loss: 6.573663]\n",
            "Validating on test set\n",
            "Validation Metrics: 1649 [D loss: 0.050192, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.578155]\n",
            "(1024, 1)\n",
            "Training Metrics: 1650 [D loss: 0.439093, acc.: 99.90%, op_acc: 84.42%] [G loss: 6.292969]\n",
            "Validating on test set\n",
            "Validation Metrics: 1650 [D loss: 0.045583, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.309420]\n",
            "(1024, 1)\n",
            "Training Metrics: 1651 [D loss: 0.450995, acc.: 99.80%, op_acc: 85.30%] [G loss: 6.369244]\n",
            "Validating on test set\n",
            "Validation Metrics: 1651 [D loss: 0.059707, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.359731]\n",
            "(1024, 1)\n",
            "Training Metrics: 1652 [D loss: 0.469625, acc.: 99.95%, op_acc: 83.54%] [G loss: 6.076845]\n",
            "Validating on test set\n",
            "Validation Metrics: 1652 [D loss: 0.046830, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.070179]\n",
            "(1024, 1)\n",
            "Training Metrics: 1653 [D loss: 0.451313, acc.: 99.95%, op_acc: 84.23%] [G loss: 6.429214]\n",
            "Validating on test set\n",
            "Validation Metrics: 1653 [D loss: 0.051035, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.409157]\n",
            "(1024, 1)\n",
            "Training Metrics: 1654 [D loss: 0.457545, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.177305]\n",
            "Validating on test set\n",
            "Validation Metrics: 1654 [D loss: 0.049388, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.173574]\n",
            "(1024, 1)\n",
            "Training Metrics: 1655 [D loss: 0.427046, acc.: 99.90%, op_acc: 86.47%] [G loss: 6.367278]\n",
            "Validating on test set\n",
            "Validation Metrics: 1655 [D loss: 0.051120, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.360958]\n",
            "(1024, 1)\n",
            "Training Metrics: 1656 [D loss: 0.454200, acc.: 99.95%, op_acc: 84.81%] [G loss: 6.510222]\n",
            "Validating on test set\n",
            "Validation Metrics: 1656 [D loss: 0.045706, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.502943]\n",
            "(1024, 1)\n",
            "Training Metrics: 1657 [D loss: 0.460163, acc.: 99.61%, op_acc: 84.62%] [G loss: 6.215156]\n",
            "Validating on test set\n",
            "Validation Metrics: 1657 [D loss: 0.055657, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.207532]\n",
            "(1024, 1)\n",
            "Training Metrics: 1658 [D loss: 0.460433, acc.: 99.85%, op_acc: 84.28%] [G loss: 6.229017]\n",
            "Validating on test set\n",
            "Validation Metrics: 1658 [D loss: 0.053128, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.230072]\n",
            "(1024, 1)\n",
            "Training Metrics: 1659 [D loss: 0.471649, acc.: 99.85%, op_acc: 85.01%] [G loss: 6.063111]\n",
            "Validating on test set\n",
            "Validation Metrics: 1659 [D loss: 0.057876, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.072646]\n",
            "(1024, 1)\n",
            "Training Metrics: 1660 [D loss: 0.426462, acc.: 99.85%, op_acc: 85.35%] [G loss: 6.407145]\n",
            "Validating on test set\n",
            "Validation Metrics: 1660 [D loss: 0.044792, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.417262]\n",
            "(1024, 1)\n",
            "Training Metrics: 1661 [D loss: 0.436951, acc.: 99.95%, op_acc: 83.45%] [G loss: 6.534165]\n",
            "Validating on test set\n",
            "Validation Metrics: 1661 [D loss: 0.061727, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.526950]\n",
            "(1024, 1)\n",
            "Training Metrics: 1662 [D loss: 0.516625, acc.: 99.80%, op_acc: 83.59%] [G loss: 6.108675]\n",
            "Validating on test set\n",
            "Validation Metrics: 1662 [D loss: 0.049507, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.135008]\n",
            "(1024, 1)\n",
            "Training Metrics: 1663 [D loss: 0.470212, acc.: 99.95%, op_acc: 83.06%] [G loss: 6.568163]\n",
            "Validating on test set\n",
            "Validation Metrics: 1663 [D loss: 0.053865, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.544585]\n",
            "(1024, 1)\n",
            "Training Metrics: 1664 [D loss: 0.538991, acc.: 99.80%, op_acc: 83.45%] [G loss: 6.482587]\n",
            "Validating on test set\n",
            "Validation Metrics: 1664 [D loss: 0.048145, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.480752]\n",
            "(1024, 1)\n",
            "Training Metrics: 1665 [D loss: 0.466703, acc.: 99.80%, op_acc: 83.94%] [G loss: 6.269809]\n",
            "Validating on test set\n",
            "Validation Metrics: 1665 [D loss: 0.043762, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.255607]\n",
            "(1024, 1)\n",
            "Training Metrics: 1666 [D loss: 0.460412, acc.: 99.90%, op_acc: 83.64%] [G loss: 6.683274]\n",
            "Validating on test set\n",
            "Validation Metrics: 1666 [D loss: 0.044161, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.670541]\n",
            "(1024, 1)\n",
            "Training Metrics: 1667 [D loss: 0.481821, acc.: 99.76%, op_acc: 83.45%] [G loss: 6.032708]\n",
            "Validating on test set\n",
            "Validation Metrics: 1667 [D loss: 0.043066, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.034101]\n",
            "(1024, 1)\n",
            "Training Metrics: 1668 [D loss: 0.465621, acc.: 99.80%, op_acc: 84.38%] [G loss: 5.896944]\n",
            "Validating on test set\n",
            "Validation Metrics: 1668 [D loss: 0.044479, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.898117]\n",
            "(1024, 1)\n",
            "Training Metrics: 1669 [D loss: 0.477584, acc.: 99.85%, op_acc: 83.35%] [G loss: 6.291157]\n",
            "Validating on test set\n",
            "Validation Metrics: 1669 [D loss: 0.045330, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.287468]\n",
            "(1024, 1)\n",
            "Training Metrics: 1670 [D loss: 0.505578, acc.: 99.90%, op_acc: 83.64%] [G loss: 5.932066]\n",
            "Validating on test set\n",
            "Validation Metrics: 1670 [D loss: 0.040490, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.934690]\n",
            "(1024, 1)\n",
            "Training Metrics: 1671 [D loss: 0.423972, acc.: 99.95%, op_acc: 84.57%] [G loss: 6.267690]\n",
            "Validating on test set\n",
            "Validation Metrics: 1671 [D loss: 0.045633, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.277404]\n",
            "(1024, 1)\n",
            "Training Metrics: 1672 [D loss: 0.473999, acc.: 100.00%, op_acc: 83.89%] [G loss: 6.707285]\n",
            "Validating on test set\n",
            "Validation Metrics: 1672 [D loss: 0.038402, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.696761]\n",
            "(1024, 1)\n",
            "Training Metrics: 1673 [D loss: 0.469296, acc.: 99.90%, op_acc: 83.20%] [G loss: 6.418722]\n",
            "Validating on test set\n",
            "Validation Metrics: 1673 [D loss: 0.048563, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.421082]\n",
            "(1024, 1)\n",
            "Training Metrics: 1674 [D loss: 0.450649, acc.: 99.90%, op_acc: 84.42%] [G loss: 6.414104]\n",
            "Validating on test set\n",
            "Validation Metrics: 1674 [D loss: 0.038681, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.414805]\n",
            "(1024, 1)\n",
            "Training Metrics: 1675 [D loss: 0.448327, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.335815]\n",
            "Validating on test set\n",
            "Validation Metrics: 1675 [D loss: 0.050770, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.336010]\n",
            "(1024, 1)\n",
            "Training Metrics: 1676 [D loss: 0.429849, acc.: 99.90%, op_acc: 84.77%] [G loss: 6.421127]\n",
            "Validating on test set\n",
            "Validation Metrics: 1676 [D loss: 0.043877, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.425886]\n",
            "(1024, 1)\n",
            "Training Metrics: 1677 [D loss: 0.425761, acc.: 99.95%, op_acc: 84.86%] [G loss: 6.916728]\n",
            "Validating on test set\n",
            "Validation Metrics: 1677 [D loss: 0.041304, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.911734]\n",
            "(1024, 1)\n",
            "Training Metrics: 1678 [D loss: 0.436241, acc.: 100.00%, op_acc: 84.96%] [G loss: 6.677162]\n",
            "Validating on test set\n",
            "Validation Metrics: 1678 [D loss: 0.045461, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.676640]\n",
            "(1024, 1)\n",
            "Training Metrics: 1679 [D loss: 0.438812, acc.: 99.90%, op_acc: 86.23%] [G loss: 6.630007]\n",
            "Validating on test set\n",
            "Validation Metrics: 1679 [D loss: 0.041382, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.629344]\n",
            "(1024, 1)\n",
            "Training Metrics: 1680 [D loss: 0.436430, acc.: 99.95%, op_acc: 84.86%] [G loss: 6.597513]\n",
            "Validating on test set\n",
            "Validation Metrics: 1680 [D loss: 0.043826, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.601669]\n",
            "(1024, 1)\n",
            "Training Metrics: 1681 [D loss: 0.499702, acc.: 99.85%, op_acc: 82.08%] [G loss: 6.760463]\n",
            "Validating on test set\n",
            "Validation Metrics: 1681 [D loss: 0.046892, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.764097]\n",
            "(1024, 1)\n",
            "Training Metrics: 1682 [D loss: 0.493905, acc.: 99.90%, op_acc: 85.06%] [G loss: 6.196586]\n",
            "Validating on test set\n",
            "Validation Metrics: 1682 [D loss: 0.044800, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.191304]\n",
            "(1024, 1)\n",
            "Training Metrics: 1683 [D loss: 0.415770, acc.: 99.95%, op_acc: 85.35%] [G loss: 6.377264]\n",
            "Validating on test set\n",
            "Validation Metrics: 1683 [D loss: 0.042983, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.376363]\n",
            "(1024, 1)\n",
            "Training Metrics: 1684 [D loss: 0.448576, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.044054]\n",
            "Validating on test set\n",
            "Validation Metrics: 1684 [D loss: 0.043493, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.038772]\n",
            "(1024, 1)\n",
            "Training Metrics: 1685 [D loss: 0.437810, acc.: 99.90%, op_acc: 83.94%] [G loss: 6.600131]\n",
            "Validating on test set\n",
            "Validation Metrics: 1685 [D loss: 0.043667, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.599141]\n",
            "(1024, 1)\n",
            "Training Metrics: 1686 [D loss: 0.437761, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.375498]\n",
            "Validating on test set\n",
            "Validation Metrics: 1686 [D loss: 0.040107, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.372981]\n",
            "(1024, 1)\n",
            "Training Metrics: 1687 [D loss: 0.499486, acc.: 99.90%, op_acc: 82.32%] [G loss: 6.498186]\n",
            "Validating on test set\n",
            "Validation Metrics: 1687 [D loss: 0.049307, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.482701]\n",
            "(1024, 1)\n",
            "Training Metrics: 1688 [D loss: 0.499959, acc.: 99.80%, op_acc: 84.67%] [G loss: 6.128027]\n",
            "Validating on test set\n",
            "Validation Metrics: 1688 [D loss: 0.050681, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.124470]\n",
            "(1024, 1)\n",
            "Training Metrics: 1689 [D loss: 0.418882, acc.: 99.95%, op_acc: 85.89%] [G loss: 6.376034]\n",
            "Validating on test set\n",
            "Validation Metrics: 1689 [D loss: 0.041719, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.364309]\n",
            "(1024, 1)\n",
            "Training Metrics: 1690 [D loss: 0.399133, acc.: 100.00%, op_acc: 86.04%] [G loss: 6.563484]\n",
            "Validating on test set\n",
            "Validation Metrics: 1690 [D loss: 0.042092, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.562597]\n",
            "(1024, 1)\n",
            "Training Metrics: 1691 [D loss: 0.438100, acc.: 99.90%, op_acc: 84.72%] [G loss: 6.440888]\n",
            "Validating on test set\n",
            "Validation Metrics: 1691 [D loss: 0.044833, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.434092]\n",
            "(1024, 1)\n",
            "Training Metrics: 1692 [D loss: 0.456889, acc.: 99.80%, op_acc: 84.86%] [G loss: 6.217697]\n",
            "Validating on test set\n",
            "Validation Metrics: 1692 [D loss: 0.046212, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.219235]\n",
            "(1024, 1)\n",
            "Training Metrics: 1693 [D loss: 0.432298, acc.: 99.95%, op_acc: 85.16%] [G loss: 6.333165]\n",
            "Validating on test set\n",
            "Validation Metrics: 1693 [D loss: 0.042300, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.335242]\n",
            "(1024, 1)\n",
            "Training Metrics: 1694 [D loss: 0.425051, acc.: 99.80%, op_acc: 85.06%] [G loss: 6.585347]\n",
            "Validating on test set\n",
            "Validation Metrics: 1694 [D loss: 0.046719, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.573743]\n",
            "(1024, 1)\n",
            "Training Metrics: 1695 [D loss: 0.476592, acc.: 99.85%, op_acc: 84.57%] [G loss: 6.284022]\n",
            "Validating on test set\n",
            "Validation Metrics: 1695 [D loss: 0.042224, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.276978]\n",
            "(1024, 1)\n",
            "Training Metrics: 1696 [D loss: 0.397773, acc.: 99.90%, op_acc: 85.79%] [G loss: 6.320787]\n",
            "Validating on test set\n",
            "Validation Metrics: 1696 [D loss: 0.043321, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.332149]\n",
            "(1024, 1)\n",
            "Training Metrics: 1697 [D loss: 0.412252, acc.: 99.80%, op_acc: 85.69%] [G loss: 6.141339]\n",
            "Validating on test set\n",
            "Validation Metrics: 1697 [D loss: 0.043878, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.133808]\n",
            "(1024, 1)\n",
            "Training Metrics: 1698 [D loss: 0.413022, acc.: 99.95%, op_acc: 85.99%] [G loss: 6.437007]\n",
            "Validating on test set\n",
            "Validation Metrics: 1698 [D loss: 0.045629, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.442266]\n",
            "(1024, 1)\n",
            "Training Metrics: 1699 [D loss: 0.409406, acc.: 99.95%, op_acc: 86.47%] [G loss: 6.347145]\n",
            "Validating on test set\n",
            "Validation Metrics: 1699 [D loss: 0.045218, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.365645]\n",
            "(1024, 1)\n",
            "Training Metrics: 1700 [D loss: 0.441369, acc.: 99.80%, op_acc: 85.35%] [G loss: 6.362757]\n",
            "Validating on test set\n",
            "Validation Metrics: 1700 [D loss: 0.048264, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.362242]\n",
            "(1024, 1)\n",
            "Training Metrics: 1701 [D loss: 0.425465, acc.: 99.85%, op_acc: 85.74%] [G loss: 6.105098]\n",
            "Validating on test set\n",
            "Validation Metrics: 1701 [D loss: 0.043597, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.097404]\n",
            "(1024, 1)\n",
            "Training Metrics: 1702 [D loss: 0.442411, acc.: 99.85%, op_acc: 84.23%] [G loss: 6.453673]\n",
            "Validating on test set\n",
            "Validation Metrics: 1702 [D loss: 0.041164, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.440865]\n",
            "(1024, 1)\n",
            "Training Metrics: 1703 [D loss: 0.457084, acc.: 99.71%, op_acc: 84.33%] [G loss: 5.939887]\n",
            "Validating on test set\n",
            "Validation Metrics: 1703 [D loss: 0.048887, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.955462]\n",
            "(1024, 1)\n",
            "Training Metrics: 1704 [D loss: 0.448693, acc.: 99.90%, op_acc: 85.45%] [G loss: 6.159176]\n",
            "Validating on test set\n",
            "Validation Metrics: 1704 [D loss: 0.038563, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.174544]\n",
            "(1024, 1)\n",
            "Training Metrics: 1705 [D loss: 0.413964, acc.: 99.90%, op_acc: 85.30%] [G loss: 6.315140]\n",
            "Validating on test set\n",
            "Validation Metrics: 1705 [D loss: 0.057457, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.316734]\n",
            "(1024, 1)\n",
            "Training Metrics: 1706 [D loss: 0.464344, acc.: 99.85%, op_acc: 84.57%] [G loss: 5.960934]\n",
            "Validating on test set\n",
            "Validation Metrics: 1706 [D loss: 0.045691, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.931697]\n",
            "(1024, 1)\n",
            "Training Metrics: 1707 [D loss: 0.434529, acc.: 99.90%, op_acc: 84.96%] [G loss: 6.328837]\n",
            "Validating on test set\n",
            "Validation Metrics: 1707 [D loss: 0.047439, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.323956]\n",
            "(1024, 1)\n",
            "Training Metrics: 1708 [D loss: 0.460880, acc.: 100.00%, op_acc: 83.74%] [G loss: 6.340178]\n",
            "Validating on test set\n",
            "Validation Metrics: 1708 [D loss: 0.046621, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.349510]\n",
            "(1024, 1)\n",
            "Training Metrics: 1709 [D loss: 0.519667, acc.: 99.85%, op_acc: 82.96%] [G loss: 6.602350]\n",
            "Validating on test set\n",
            "Validation Metrics: 1709 [D loss: 0.039984, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.599964]\n",
            "(1024, 1)\n",
            "Training Metrics: 1710 [D loss: 0.448108, acc.: 99.90%, op_acc: 84.72%] [G loss: 6.427095]\n",
            "Validating on test set\n",
            "Validation Metrics: 1710 [D loss: 0.045684, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.415039]\n",
            "(1024, 1)\n",
            "Training Metrics: 1711 [D loss: 0.437153, acc.: 99.95%, op_acc: 85.50%] [G loss: 6.410182]\n",
            "Validating on test set\n",
            "Validation Metrics: 1711 [D loss: 0.043486, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.404782]\n",
            "(1024, 1)\n",
            "Training Metrics: 1712 [D loss: 0.450529, acc.: 99.90%, op_acc: 84.42%] [G loss: 6.381174]\n",
            "Validating on test set\n",
            "Validation Metrics: 1712 [D loss: 0.044120, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.371317]\n",
            "(1024, 1)\n",
            "Training Metrics: 1713 [D loss: 0.432699, acc.: 100.00%, op_acc: 86.04%] [G loss: 6.405314]\n",
            "Validating on test set\n",
            "Validation Metrics: 1713 [D loss: 0.040697, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.409111]\n",
            "(1024, 1)\n",
            "Training Metrics: 1714 [D loss: 0.435001, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.551417]\n",
            "Validating on test set\n",
            "Validation Metrics: 1714 [D loss: 0.038901, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.543440]\n",
            "(1024, 1)\n",
            "Training Metrics: 1715 [D loss: 0.413209, acc.: 99.95%, op_acc: 86.04%] [G loss: 6.423865]\n",
            "Validating on test set\n",
            "Validation Metrics: 1715 [D loss: 0.041651, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.419199]\n",
            "(1024, 1)\n",
            "Training Metrics: 1716 [D loss: 0.448154, acc.: 99.95%, op_acc: 84.18%] [G loss: 6.858541]\n",
            "Validating on test set\n",
            "Validation Metrics: 1716 [D loss: 0.044859, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.860772]\n",
            "(1024, 1)\n",
            "Training Metrics: 1717 [D loss: 0.444491, acc.: 99.90%, op_acc: 85.30%] [G loss: 6.741022]\n",
            "Validating on test set\n",
            "Validation Metrics: 1717 [D loss: 0.039104, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.734169]\n",
            "(1024, 1)\n",
            "Training Metrics: 1718 [D loss: 0.427587, acc.: 99.85%, op_acc: 84.42%] [G loss: 6.359092]\n",
            "Validating on test set\n",
            "Validation Metrics: 1718 [D loss: 0.038975, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.344814]\n",
            "(1024, 1)\n",
            "Training Metrics: 1719 [D loss: 0.433928, acc.: 99.76%, op_acc: 84.72%] [G loss: 6.312290]\n",
            "Validating on test set\n",
            "Validation Metrics: 1719 [D loss: 0.044222, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.295994]\n",
            "(1024, 1)\n",
            "Training Metrics: 1720 [D loss: 0.448851, acc.: 99.85%, op_acc: 85.21%] [G loss: 6.200842]\n",
            "Validating on test set\n",
            "Validation Metrics: 1720 [D loss: 0.042359, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.197333]\n",
            "(1024, 1)\n",
            "Training Metrics: 1721 [D loss: 0.449684, acc.: 99.80%, op_acc: 83.59%] [G loss: 6.344425]\n",
            "Validating on test set\n",
            "Validation Metrics: 1721 [D loss: 0.049312, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.361509]\n",
            "(1024, 1)\n",
            "Training Metrics: 1722 [D loss: 0.414877, acc.: 99.95%, op_acc: 85.74%] [G loss: 6.231458]\n",
            "Validating on test set\n",
            "Validation Metrics: 1722 [D loss: 0.041650, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.224315]\n",
            "(1024, 1)\n",
            "Training Metrics: 1723 [D loss: 0.449955, acc.: 99.80%, op_acc: 84.91%] [G loss: 6.511371]\n",
            "Validating on test set\n",
            "Validation Metrics: 1723 [D loss: 0.039816, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.487336]\n",
            "(1024, 1)\n",
            "Training Metrics: 1724 [D loss: 0.446586, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.031940]\n",
            "Validating on test set\n",
            "Validation Metrics: 1724 [D loss: 0.049935, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.036180]\n",
            "(1024, 1)\n",
            "Training Metrics: 1725 [D loss: 0.420592, acc.: 100.00%, op_acc: 84.13%] [G loss: 6.559025]\n",
            "Validating on test set\n",
            "Validation Metrics: 1725 [D loss: 0.041165, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.572137]\n",
            "(1024, 1)\n",
            "Training Metrics: 1726 [D loss: 0.429338, acc.: 99.85%, op_acc: 84.23%] [G loss: 6.137582]\n",
            "Validating on test set\n",
            "Validation Metrics: 1726 [D loss: 0.040004, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.133001]\n",
            "(1024, 1)\n",
            "Training Metrics: 1727 [D loss: 0.474758, acc.: 99.95%, op_acc: 85.11%] [G loss: 6.513757]\n",
            "Validating on test set\n",
            "Validation Metrics: 1727 [D loss: 0.041716, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.494599]\n",
            "(1024, 1)\n",
            "Training Metrics: 1728 [D loss: 0.439644, acc.: 100.00%, op_acc: 84.08%] [G loss: 6.668586]\n",
            "Validating on test set\n",
            "Validation Metrics: 1728 [D loss: 0.044999, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.665014]\n",
            "(1024, 1)\n",
            "Training Metrics: 1729 [D loss: 0.442965, acc.: 99.95%, op_acc: 84.72%] [G loss: 6.971157]\n",
            "Validating on test set\n",
            "Validation Metrics: 1729 [D loss: 0.046297, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.977854]\n",
            "(1024, 1)\n",
            "Training Metrics: 1730 [D loss: 0.451753, acc.: 99.85%, op_acc: 84.72%] [G loss: 6.526479]\n",
            "Validating on test set\n",
            "Validation Metrics: 1730 [D loss: 0.047570, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.528053]\n",
            "(1024, 1)\n",
            "Training Metrics: 1731 [D loss: 0.437882, acc.: 99.90%, op_acc: 86.72%] [G loss: 6.551749]\n",
            "Validating on test set\n",
            "Validation Metrics: 1731 [D loss: 0.043178, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.545536]\n",
            "(1024, 1)\n",
            "Training Metrics: 1732 [D loss: 0.443717, acc.: 99.95%, op_acc: 84.18%] [G loss: 6.311772]\n",
            "Validating on test set\n",
            "Validation Metrics: 1732 [D loss: 0.039520, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.308136]\n",
            "(1024, 1)\n",
            "Training Metrics: 1733 [D loss: 0.429289, acc.: 100.00%, op_acc: 85.11%] [G loss: 6.885948]\n",
            "Validating on test set\n",
            "Validation Metrics: 1733 [D loss: 0.038262, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.881742]\n",
            "(1024, 1)\n",
            "Training Metrics: 1734 [D loss: 0.445526, acc.: 100.00%, op_acc: 84.38%] [G loss: 6.846223]\n",
            "Validating on test set\n",
            "Validation Metrics: 1734 [D loss: 0.039215, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.837600]\n",
            "(1024, 1)\n",
            "Training Metrics: 1735 [D loss: 0.440987, acc.: 99.85%, op_acc: 84.08%] [G loss: 6.689863]\n",
            "Validating on test set\n",
            "Validation Metrics: 1735 [D loss: 0.038879, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.685023]\n",
            "(1024, 1)\n",
            "Training Metrics: 1736 [D loss: 0.442873, acc.: 99.90%, op_acc: 84.86%] [G loss: 6.658496]\n",
            "Validating on test set\n",
            "Validation Metrics: 1736 [D loss: 0.041588, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.665177]\n",
            "(1024, 1)\n",
            "Training Metrics: 1737 [D loss: 0.445378, acc.: 99.80%, op_acc: 85.55%] [G loss: 6.090254]\n",
            "Validating on test set\n",
            "Validation Metrics: 1737 [D loss: 0.039723, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.095100]\n",
            "(1024, 1)\n",
            "Training Metrics: 1738 [D loss: 0.444136, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.571622]\n",
            "Validating on test set\n",
            "Validation Metrics: 1738 [D loss: 0.040460, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.568901]\n",
            "(1024, 1)\n",
            "Training Metrics: 1739 [D loss: 0.460822, acc.: 99.90%, op_acc: 84.08%] [G loss: 6.366291]\n",
            "Validating on test set\n",
            "Validation Metrics: 1739 [D loss: 0.038277, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.359047]\n",
            "(1024, 1)\n",
            "Training Metrics: 1740 [D loss: 0.397006, acc.: 99.85%, op_acc: 86.23%] [G loss: 6.199080]\n",
            "Validating on test set\n",
            "Validation Metrics: 1740 [D loss: 0.039120, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.194376]\n",
            "(1024, 1)\n",
            "Training Metrics: 1741 [D loss: 0.437445, acc.: 99.80%, op_acc: 84.03%] [G loss: 6.323024]\n",
            "Validating on test set\n",
            "Validation Metrics: 1741 [D loss: 0.040774, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.313991]\n",
            "(1024, 1)\n",
            "Training Metrics: 1742 [D loss: 0.453599, acc.: 99.90%, op_acc: 83.59%] [G loss: 6.178645]\n",
            "Validating on test set\n",
            "Validation Metrics: 1742 [D loss: 0.040486, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.175683]\n",
            "(1024, 1)\n",
            "Training Metrics: 1743 [D loss: 0.434548, acc.: 100.00%, op_acc: 85.06%] [G loss: 6.405436]\n",
            "Validating on test set\n",
            "Validation Metrics: 1743 [D loss: 0.038074, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.407750]\n",
            "(1024, 1)\n",
            "Training Metrics: 1744 [D loss: 0.414313, acc.: 99.85%, op_acc: 86.04%] [G loss: 6.449178]\n",
            "Validating on test set\n",
            "Validation Metrics: 1744 [D loss: 0.044626, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.445192]\n",
            "(1024, 1)\n",
            "Training Metrics: 1745 [D loss: 0.439952, acc.: 99.95%, op_acc: 85.35%] [G loss: 6.385638]\n",
            "Validating on test set\n",
            "Validation Metrics: 1745 [D loss: 0.041266, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.379806]\n",
            "(1024, 1)\n",
            "Training Metrics: 1746 [D loss: 0.440664, acc.: 99.90%, op_acc: 85.45%] [G loss: 6.692829]\n",
            "Validating on test set\n",
            "Validation Metrics: 1746 [D loss: 0.036321, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.693388]\n",
            "(1024, 1)\n",
            "Training Metrics: 1747 [D loss: 0.448862, acc.: 99.95%, op_acc: 84.13%] [G loss: 5.959252]\n",
            "Validating on test set\n",
            "Validation Metrics: 1747 [D loss: 0.044068, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.944241]\n",
            "(1024, 1)\n",
            "Training Metrics: 1748 [D loss: 0.477015, acc.: 99.95%, op_acc: 83.35%] [G loss: 6.475624]\n",
            "Validating on test set\n",
            "Validation Metrics: 1748 [D loss: 0.038684, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.477069]\n",
            "(1024, 1)\n",
            "Training Metrics: 1749 [D loss: 0.456153, acc.: 99.90%, op_acc: 83.59%] [G loss: 6.442509]\n",
            "Validating on test set\n",
            "Validation Metrics: 1749 [D loss: 0.036805, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.450268]\n",
            "(1024, 1)\n",
            "Training Metrics: 1750 [D loss: 0.425911, acc.: 99.80%, op_acc: 84.13%] [G loss: 6.348581]\n",
            "Validating on test set\n",
            "Validation Metrics: 1750 [D loss: 0.042289, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.357689]\n",
            "(1024, 1)\n",
            "Training Metrics: 1751 [D loss: 0.470451, acc.: 99.85%, op_acc: 84.67%] [G loss: 6.240682]\n",
            "Validating on test set\n",
            "Validation Metrics: 1751 [D loss: 0.043141, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.251215]\n",
            "(1024, 1)\n",
            "Training Metrics: 1752 [D loss: 0.463646, acc.: 99.90%, op_acc: 84.03%] [G loss: 6.567053]\n",
            "Validating on test set\n",
            "Validation Metrics: 1752 [D loss: 0.048398, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.566313]\n",
            "(1024, 1)\n",
            "Training Metrics: 1753 [D loss: 0.441531, acc.: 99.80%, op_acc: 85.79%] [G loss: 6.060114]\n",
            "Validating on test set\n",
            "Validation Metrics: 1753 [D loss: 0.037557, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.057408]\n",
            "(1024, 1)\n",
            "Training Metrics: 1754 [D loss: 0.433046, acc.: 99.76%, op_acc: 84.67%] [G loss: 6.050066]\n",
            "Validating on test set\n",
            "Validation Metrics: 1754 [D loss: 0.039420, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.049284]\n",
            "(1024, 1)\n",
            "Training Metrics: 1755 [D loss: 0.405646, acc.: 100.00%, op_acc: 86.57%] [G loss: 6.462154]\n",
            "Validating on test set\n",
            "Validation Metrics: 1755 [D loss: 0.039982, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.449808]\n",
            "(1024, 1)\n",
            "Training Metrics: 1756 [D loss: 0.473465, acc.: 99.80%, op_acc: 83.84%] [G loss: 5.696646]\n",
            "Validating on test set\n",
            "Validation Metrics: 1756 [D loss: 0.041151, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.695688]\n",
            "(1024, 1)\n",
            "Training Metrics: 1757 [D loss: 0.471078, acc.: 99.85%, op_acc: 83.98%] [G loss: 6.205824]\n",
            "Validating on test set\n",
            "Validation Metrics: 1757 [D loss: 0.036050, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.199022]\n",
            "(1024, 1)\n",
            "Training Metrics: 1758 [D loss: 0.442306, acc.: 100.00%, op_acc: 85.01%] [G loss: 6.496780]\n",
            "Validating on test set\n",
            "Validation Metrics: 1758 [D loss: 0.035580, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.498104]\n",
            "(1024, 1)\n",
            "Training Metrics: 1759 [D loss: 0.422985, acc.: 99.95%, op_acc: 85.35%] [G loss: 6.951446]\n",
            "Validating on test set\n",
            "Validation Metrics: 1759 [D loss: 0.037642, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.949550]\n",
            "(1024, 1)\n",
            "Training Metrics: 1760 [D loss: 0.442572, acc.: 99.85%, op_acc: 84.81%] [G loss: 5.869776]\n",
            "Validating on test set\n",
            "Validation Metrics: 1760 [D loss: 0.040289, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.881660]\n",
            "(1024, 1)\n",
            "Training Metrics: 1761 [D loss: 0.443572, acc.: 100.00%, op_acc: 83.89%] [G loss: 6.171738]\n",
            "Validating on test set\n",
            "Validation Metrics: 1761 [D loss: 0.038335, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.170377]\n",
            "(1024, 1)\n",
            "Training Metrics: 1762 [D loss: 0.451549, acc.: 99.90%, op_acc: 84.28%] [G loss: 6.272180]\n",
            "Validating on test set\n",
            "Validation Metrics: 1762 [D loss: 0.033138, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.274565]\n",
            "(1024, 1)\n",
            "Training Metrics: 1763 [D loss: 0.479145, acc.: 99.80%, op_acc: 82.67%] [G loss: 6.244136]\n",
            "Validating on test set\n",
            "Validation Metrics: 1763 [D loss: 0.039801, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.231198]\n",
            "(1024, 1)\n",
            "Training Metrics: 1764 [D loss: 0.437041, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.394242]\n",
            "Validating on test set\n",
            "Validation Metrics: 1764 [D loss: 0.037062, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.395330]\n",
            "(1024, 1)\n",
            "Training Metrics: 1765 [D loss: 0.437614, acc.: 99.85%, op_acc: 83.89%] [G loss: 6.483750]\n",
            "Validating on test set\n",
            "Validation Metrics: 1765 [D loss: 0.038573, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.483750]\n",
            "(1024, 1)\n",
            "Training Metrics: 1766 [D loss: 0.480098, acc.: 99.90%, op_acc: 83.69%] [G loss: 6.636422]\n",
            "Validating on test set\n",
            "Validation Metrics: 1766 [D loss: 0.039893, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.649645]\n",
            "(1024, 1)\n",
            "Training Metrics: 1767 [D loss: 0.479889, acc.: 99.66%, op_acc: 83.15%] [G loss: 5.951750]\n",
            "Validating on test set\n",
            "Validation Metrics: 1767 [D loss: 0.043480, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.931732]\n",
            "(1024, 1)\n",
            "Training Metrics: 1768 [D loss: 0.399104, acc.: 99.90%, op_acc: 86.13%] [G loss: 6.187492]\n",
            "Validating on test set\n",
            "Validation Metrics: 1768 [D loss: 0.040977, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.185138]\n",
            "(1024, 1)\n",
            "Training Metrics: 1769 [D loss: 0.420336, acc.: 99.95%, op_acc: 84.91%] [G loss: 6.209522]\n",
            "Validating on test set\n",
            "Validation Metrics: 1769 [D loss: 0.039500, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.195261]\n",
            "(1024, 1)\n",
            "Training Metrics: 1770 [D loss: 0.409334, acc.: 99.95%, op_acc: 85.35%] [G loss: 6.471097]\n",
            "Validating on test set\n",
            "Validation Metrics: 1770 [D loss: 0.039090, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.467187]\n",
            "(1024, 1)\n",
            "Training Metrics: 1771 [D loss: 0.419969, acc.: 99.85%, op_acc: 86.18%] [G loss: 6.240134]\n",
            "Validating on test set\n",
            "Validation Metrics: 1771 [D loss: 0.040017, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.247964]\n",
            "(1024, 1)\n",
            "Training Metrics: 1772 [D loss: 0.433434, acc.: 99.90%, op_acc: 84.28%] [G loss: 6.357365]\n",
            "Validating on test set\n",
            "Validation Metrics: 1772 [D loss: 0.037701, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.349129]\n",
            "(1024, 1)\n",
            "Training Metrics: 1773 [D loss: 0.436236, acc.: 99.90%, op_acc: 85.74%] [G loss: 6.519557]\n",
            "Validating on test set\n",
            "Validation Metrics: 1773 [D loss: 0.036051, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.510437]\n",
            "(1024, 1)\n",
            "Training Metrics: 1774 [D loss: 0.446493, acc.: 99.85%, op_acc: 85.25%] [G loss: 6.125685]\n",
            "Validating on test set\n",
            "Validation Metrics: 1774 [D loss: 0.038572, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.133410]\n",
            "(1024, 1)\n",
            "Training Metrics: 1775 [D loss: 0.433432, acc.: 99.95%, op_acc: 84.52%] [G loss: 6.434213]\n",
            "Validating on test set\n",
            "Validation Metrics: 1775 [D loss: 0.038845, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.436527]\n",
            "(1024, 1)\n",
            "Training Metrics: 1776 [D loss: 0.439016, acc.: 99.95%, op_acc: 84.28%] [G loss: 6.473532]\n",
            "Validating on test set\n",
            "Validation Metrics: 1776 [D loss: 0.037859, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.473615]\n",
            "(1024, 1)\n",
            "Training Metrics: 1777 [D loss: 0.444751, acc.: 100.00%, op_acc: 83.69%] [G loss: 6.338940]\n",
            "Validating on test set\n",
            "Validation Metrics: 1777 [D loss: 0.044395, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.336587]\n",
            "(1024, 1)\n",
            "Training Metrics: 1778 [D loss: 0.427808, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.475160]\n",
            "Validating on test set\n",
            "Validation Metrics: 1778 [D loss: 0.035165, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.466445]\n",
            "(1024, 1)\n",
            "Training Metrics: 1779 [D loss: 0.481613, acc.: 99.95%, op_acc: 84.13%] [G loss: 6.585540]\n",
            "Validating on test set\n",
            "Validation Metrics: 1779 [D loss: 0.032668, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.586943]\n",
            "(1024, 1)\n",
            "Training Metrics: 1780 [D loss: 0.466841, acc.: 99.95%, op_acc: 83.94%] [G loss: 6.608146]\n",
            "Validating on test set\n",
            "Validation Metrics: 1780 [D loss: 0.036600, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.596071]\n",
            "(1024, 1)\n",
            "Training Metrics: 1781 [D loss: 0.411727, acc.: 99.90%, op_acc: 86.91%] [G loss: 6.413081]\n",
            "Validating on test set\n",
            "Validation Metrics: 1781 [D loss: 0.036913, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.399529]\n",
            "(1024, 1)\n",
            "Training Metrics: 1782 [D loss: 0.416109, acc.: 100.00%, op_acc: 84.13%] [G loss: 6.777169]\n",
            "Validating on test set\n",
            "Validation Metrics: 1782 [D loss: 0.033023, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.780433]\n",
            "(1024, 1)\n",
            "Training Metrics: 1783 [D loss: 0.429005, acc.: 99.95%, op_acc: 85.16%] [G loss: 6.740306]\n",
            "Validating on test set\n",
            "Validation Metrics: 1783 [D loss: 0.033654, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.739069]\n",
            "(1024, 1)\n",
            "Training Metrics: 1784 [D loss: 0.441435, acc.: 99.76%, op_acc: 84.62%] [G loss: 7.001343]\n",
            "Validating on test set\n",
            "Validation Metrics: 1784 [D loss: 0.033958, acc.: 100.00%, op_acc: 100.00%] [G loss: 7.001429]\n",
            "(1024, 1)\n",
            "Training Metrics: 1785 [D loss: 0.431093, acc.: 99.95%, op_acc: 84.96%] [G loss: 6.365458]\n",
            "Validating on test set\n",
            "Validation Metrics: 1785 [D loss: 0.033020, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.368074]\n",
            "(1024, 1)\n",
            "Training Metrics: 1786 [D loss: 0.422757, acc.: 99.85%, op_acc: 85.06%] [G loss: 6.451362]\n",
            "Validating on test set\n",
            "Validation Metrics: 1786 [D loss: 0.036034, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.460937]\n",
            "(1024, 1)\n",
            "Training Metrics: 1787 [D loss: 0.435888, acc.: 99.90%, op_acc: 84.28%] [G loss: 6.704249]\n",
            "Validating on test set\n",
            "Validation Metrics: 1787 [D loss: 0.034577, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.712033]\n",
            "(1024, 1)\n",
            "Training Metrics: 1788 [D loss: 0.436886, acc.: 99.85%, op_acc: 84.13%] [G loss: 6.054826]\n",
            "Validating on test set\n",
            "Validation Metrics: 1788 [D loss: 0.038399, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.046379]\n",
            "(1024, 1)\n",
            "Training Metrics: 1789 [D loss: 0.443792, acc.: 99.95%, op_acc: 84.28%] [G loss: 6.674312]\n",
            "Validating on test set\n",
            "Validation Metrics: 1789 [D loss: 0.030021, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.668111]\n",
            "(1024, 1)\n",
            "Training Metrics: 1790 [D loss: 0.414949, acc.: 99.95%, op_acc: 85.01%] [G loss: 6.706931]\n",
            "Validating on test set\n",
            "Validation Metrics: 1790 [D loss: 0.030407, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.707860]\n",
            "(1024, 1)\n",
            "Training Metrics: 1791 [D loss: 0.442873, acc.: 99.80%, op_acc: 85.01%] [G loss: 6.466097]\n",
            "Validating on test set\n",
            "Validation Metrics: 1791 [D loss: 0.037348, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.460502]\n",
            "(1024, 1)\n",
            "Training Metrics: 1792 [D loss: 0.403010, acc.: 99.90%, op_acc: 86.43%] [G loss: 6.291746]\n",
            "Validating on test set\n",
            "Validation Metrics: 1792 [D loss: 0.039546, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.283398]\n",
            "(1024, 1)\n",
            "Training Metrics: 1793 [D loss: 0.464472, acc.: 99.95%, op_acc: 84.23%] [G loss: 6.471789]\n",
            "Validating on test set\n",
            "Validation Metrics: 1793 [D loss: 0.032303, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.468321]\n",
            "(1024, 1)\n",
            "Training Metrics: 1794 [D loss: 0.424014, acc.: 99.85%, op_acc: 83.89%] [G loss: 6.330173]\n",
            "Validating on test set\n",
            "Validation Metrics: 1794 [D loss: 0.038352, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.341075]\n",
            "(1024, 1)\n",
            "Training Metrics: 1795 [D loss: 0.438371, acc.: 99.80%, op_acc: 85.64%] [G loss: 6.408854]\n",
            "Validating on test set\n",
            "Validation Metrics: 1795 [D loss: 0.034282, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.410014]\n",
            "(1024, 1)\n",
            "Training Metrics: 1796 [D loss: 0.436295, acc.: 99.71%, op_acc: 85.06%] [G loss: 6.188193]\n",
            "Validating on test set\n",
            "Validation Metrics: 1796 [D loss: 0.033168, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.173069]\n",
            "(1024, 1)\n",
            "Training Metrics: 1797 [D loss: 0.445988, acc.: 99.90%, op_acc: 84.42%] [G loss: 5.896711]\n",
            "Validating on test set\n",
            "Validation Metrics: 1797 [D loss: 0.046539, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.915156]\n",
            "(1024, 1)\n",
            "Training Metrics: 1798 [D loss: 0.396520, acc.: 99.90%, op_acc: 85.45%] [G loss: 6.337935]\n",
            "Validating on test set\n",
            "Validation Metrics: 1798 [D loss: 0.034020, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.318108]\n",
            "(1024, 1)\n",
            "Training Metrics: 1799 [D loss: 0.389285, acc.: 99.80%, op_acc: 85.55%] [G loss: 6.281438]\n",
            "Validating on test set\n",
            "Validation Metrics: 1799 [D loss: 0.034155, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.296490]\n",
            "(1024, 1)\n",
            "Training Metrics: 1800 [D loss: 0.430357, acc.: 99.95%, op_acc: 85.35%] [G loss: 6.234868]\n",
            "Validating on test set\n",
            "Validation Metrics: 1800 [D loss: 0.036646, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.227108]\n",
            "(1024, 1)\n",
            "Training Metrics: 1801 [D loss: 0.410022, acc.: 99.90%, op_acc: 86.38%] [G loss: 6.361528]\n",
            "Validating on test set\n",
            "Validation Metrics: 1801 [D loss: 0.032186, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.342900]\n",
            "(1024, 1)\n",
            "Training Metrics: 1802 [D loss: 0.427171, acc.: 99.76%, op_acc: 85.45%] [G loss: 6.327276]\n",
            "Validating on test set\n",
            "Validation Metrics: 1802 [D loss: 0.033444, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.316276]\n",
            "(1024, 1)\n",
            "Training Metrics: 1803 [D loss: 0.472062, acc.: 99.90%, op_acc: 83.59%] [G loss: 6.353054]\n",
            "Validating on test set\n",
            "Validation Metrics: 1803 [D loss: 0.036509, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.350531]\n",
            "(1024, 1)\n",
            "Training Metrics: 1804 [D loss: 0.433725, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.460307]\n",
            "Validating on test set\n",
            "Validation Metrics: 1804 [D loss: 0.032952, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.470629]\n",
            "(1024, 1)\n",
            "Training Metrics: 1805 [D loss: 0.421775, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.415774]\n",
            "Validating on test set\n",
            "Validation Metrics: 1805 [D loss: 0.034285, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.414899]\n",
            "(1024, 1)\n",
            "Training Metrics: 1806 [D loss: 0.413783, acc.: 99.90%, op_acc: 84.72%] [G loss: 6.305261]\n",
            "Validating on test set\n",
            "Validation Metrics: 1806 [D loss: 0.034797, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.295566]\n",
            "(1024, 1)\n",
            "Training Metrics: 1807 [D loss: 0.430079, acc.: 99.90%, op_acc: 84.96%] [G loss: 6.542769]\n",
            "Validating on test set\n",
            "Validation Metrics: 1807 [D loss: 0.033069, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.528834]\n",
            "(1024, 1)\n",
            "Training Metrics: 1808 [D loss: 0.457644, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.134729]\n",
            "Validating on test set\n",
            "Validation Metrics: 1808 [D loss: 0.033539, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.130226]\n",
            "(1024, 1)\n",
            "Training Metrics: 1809 [D loss: 0.435570, acc.: 99.90%, op_acc: 84.52%] [G loss: 6.299680]\n",
            "Validating on test set\n",
            "Validation Metrics: 1809 [D loss: 0.036369, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.299004]\n",
            "(1024, 1)\n",
            "Training Metrics: 1810 [D loss: 0.438183, acc.: 99.95%, op_acc: 85.06%] [G loss: 6.370750]\n",
            "Validating on test set\n",
            "Validation Metrics: 1810 [D loss: 0.033680, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.372951]\n",
            "(1024, 1)\n",
            "Training Metrics: 1811 [D loss: 0.428766, acc.: 99.95%, op_acc: 85.11%] [G loss: 6.288437]\n",
            "Validating on test set\n",
            "Validation Metrics: 1811 [D loss: 0.037568, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.281711]\n",
            "(1024, 1)\n",
            "Training Metrics: 1812 [D loss: 0.427760, acc.: 99.90%, op_acc: 83.64%] [G loss: 6.888117]\n",
            "Validating on test set\n",
            "Validation Metrics: 1812 [D loss: 0.034004, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.891457]\n",
            "(1024, 1)\n",
            "Training Metrics: 1813 [D loss: 0.513460, acc.: 99.90%, op_acc: 82.52%] [G loss: 6.517231]\n",
            "Validating on test set\n",
            "Validation Metrics: 1813 [D loss: 0.035995, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.496218]\n",
            "(1024, 1)\n",
            "Training Metrics: 1814 [D loss: 0.448864, acc.: 99.85%, op_acc: 84.42%] [G loss: 6.461743]\n",
            "Validating on test set\n",
            "Validation Metrics: 1814 [D loss: 0.034265, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.465233]\n",
            "(1024, 1)\n",
            "Training Metrics: 1815 [D loss: 0.435272, acc.: 100.00%, op_acc: 85.01%] [G loss: 6.671311]\n",
            "Validating on test set\n",
            "Validation Metrics: 1815 [D loss: 0.031904, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.675292]\n",
            "(1024, 1)\n",
            "Training Metrics: 1816 [D loss: 0.444583, acc.: 99.71%, op_acc: 84.33%] [G loss: 6.453060]\n",
            "Validating on test set\n",
            "Validation Metrics: 1816 [D loss: 0.032982, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.456579]\n",
            "(1024, 1)\n",
            "Training Metrics: 1817 [D loss: 0.445362, acc.: 99.90%, op_acc: 84.91%] [G loss: 6.373380]\n",
            "Validating on test set\n",
            "Validation Metrics: 1817 [D loss: 0.035471, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.372509]\n",
            "(1024, 1)\n",
            "Training Metrics: 1818 [D loss: 0.432223, acc.: 99.90%, op_acc: 84.91%] [G loss: 6.292043]\n",
            "Validating on test set\n",
            "Validation Metrics: 1818 [D loss: 0.035199, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.288895]\n",
            "(1024, 1)\n",
            "Training Metrics: 1819 [D loss: 0.436680, acc.: 99.85%, op_acc: 84.62%] [G loss: 6.245403]\n",
            "Validating on test set\n",
            "Validation Metrics: 1819 [D loss: 0.030901, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.249826]\n",
            "(1024, 1)\n",
            "Training Metrics: 1820 [D loss: 0.408638, acc.: 99.85%, op_acc: 85.94%] [G loss: 6.510496]\n",
            "Validating on test set\n",
            "Validation Metrics: 1820 [D loss: 0.033537, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.514958]\n",
            "(1024, 1)\n",
            "Training Metrics: 1821 [D loss: 0.435307, acc.: 100.00%, op_acc: 85.21%] [G loss: 6.614472]\n",
            "Validating on test set\n",
            "Validation Metrics: 1821 [D loss: 0.032424, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.607882]\n",
            "(1024, 1)\n",
            "Training Metrics: 1822 [D loss: 0.440133, acc.: 100.00%, op_acc: 83.84%] [G loss: 6.473386]\n",
            "Validating on test set\n",
            "Validation Metrics: 1822 [D loss: 0.031311, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.466064]\n",
            "(1024, 1)\n",
            "Training Metrics: 1823 [D loss: 0.446126, acc.: 99.95%, op_acc: 83.89%] [G loss: 6.790362]\n",
            "Validating on test set\n",
            "Validation Metrics: 1823 [D loss: 0.031170, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.786714]\n",
            "(1024, 1)\n",
            "Training Metrics: 1824 [D loss: 0.500092, acc.: 99.85%, op_acc: 83.45%] [G loss: 7.418502]\n",
            "Validating on test set\n",
            "Validation Metrics: 1824 [D loss: 0.030671, acc.: 100.00%, op_acc: 100.00%] [G loss: 7.425611]\n",
            "(1024, 1)\n",
            "Training Metrics: 1825 [D loss: 0.491520, acc.: 99.85%, op_acc: 83.35%] [G loss: 6.192610]\n",
            "Validating on test set\n",
            "Validation Metrics: 1825 [D loss: 0.034149, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.173805]\n",
            "(1024, 1)\n",
            "Training Metrics: 1826 [D loss: 0.432428, acc.: 99.85%, op_acc: 83.94%] [G loss: 6.150804]\n",
            "Validating on test set\n",
            "Validation Metrics: 1826 [D loss: 0.041181, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.160417]\n",
            "(1024, 1)\n",
            "Training Metrics: 1827 [D loss: 0.422201, acc.: 99.90%, op_acc: 85.60%] [G loss: 6.329538]\n",
            "Validating on test set\n",
            "Validation Metrics: 1827 [D loss: 0.031641, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.324995]\n",
            "(1024, 1)\n",
            "Training Metrics: 1828 [D loss: 0.430456, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.393555]\n",
            "Validating on test set\n",
            "Validation Metrics: 1828 [D loss: 0.030840, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.374763]\n",
            "(1024, 1)\n",
            "Training Metrics: 1829 [D loss: 0.381044, acc.: 100.00%, op_acc: 86.62%] [G loss: 6.867321]\n",
            "Validating on test set\n",
            "Validation Metrics: 1829 [D loss: 0.031662, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.876746]\n",
            "(1024, 1)\n",
            "Training Metrics: 1830 [D loss: 0.436140, acc.: 99.80%, op_acc: 85.16%] [G loss: 6.309646]\n",
            "Validating on test set\n",
            "Validation Metrics: 1830 [D loss: 0.032809, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.313548]\n",
            "(1024, 1)\n",
            "Training Metrics: 1831 [D loss: 0.447205, acc.: 99.95%, op_acc: 83.84%] [G loss: 6.430043]\n",
            "Validating on test set\n",
            "Validation Metrics: 1831 [D loss: 0.036549, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.443010]\n",
            "(1024, 1)\n",
            "Training Metrics: 1832 [D loss: 0.418334, acc.: 99.95%, op_acc: 86.23%] [G loss: 6.526180]\n",
            "Validating on test set\n",
            "Validation Metrics: 1832 [D loss: 0.034366, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.525848]\n",
            "(1024, 1)\n",
            "Training Metrics: 1833 [D loss: 0.411965, acc.: 99.95%, op_acc: 85.01%] [G loss: 6.528975]\n",
            "Validating on test set\n",
            "Validation Metrics: 1833 [D loss: 0.035176, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.537994]\n",
            "(1024, 1)\n",
            "Training Metrics: 1834 [D loss: 0.443383, acc.: 99.76%, op_acc: 84.08%] [G loss: 6.401014]\n",
            "Validating on test set\n",
            "Validation Metrics: 1834 [D loss: 0.033126, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.397280]\n",
            "(1024, 1)\n",
            "Training Metrics: 1835 [D loss: 0.420587, acc.: 99.80%, op_acc: 85.40%] [G loss: 6.468420]\n",
            "Validating on test set\n",
            "Validation Metrics: 1835 [D loss: 0.035371, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.470527]\n",
            "(1024, 1)\n",
            "Training Metrics: 1836 [D loss: 0.445370, acc.: 99.76%, op_acc: 85.40%] [G loss: 6.178964]\n",
            "Validating on test set\n",
            "Validation Metrics: 1836 [D loss: 0.033952, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.190865]\n",
            "(1024, 1)\n",
            "Training Metrics: 1837 [D loss: 0.425118, acc.: 99.80%, op_acc: 84.62%] [G loss: 5.938049]\n",
            "Validating on test set\n",
            "Validation Metrics: 1837 [D loss: 0.036319, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.941924]\n",
            "(1024, 1)\n",
            "Training Metrics: 1838 [D loss: 0.414217, acc.: 99.95%, op_acc: 85.60%] [G loss: 6.421339]\n",
            "Validating on test set\n",
            "Validation Metrics: 1838 [D loss: 0.032263, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.417936]\n",
            "(1024, 1)\n",
            "Training Metrics: 1839 [D loss: 0.445911, acc.: 99.85%, op_acc: 84.38%] [G loss: 6.031723]\n",
            "Validating on test set\n",
            "Validation Metrics: 1839 [D loss: 0.039041, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.032883]\n",
            "(1024, 1)\n",
            "Training Metrics: 1840 [D loss: 0.421885, acc.: 100.00%, op_acc: 85.11%] [G loss: 6.471536]\n",
            "Validating on test set\n",
            "Validation Metrics: 1840 [D loss: 0.032257, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.468508]\n",
            "(1024, 1)\n",
            "Training Metrics: 1841 [D loss: 0.426889, acc.: 99.95%, op_acc: 84.18%] [G loss: 6.458507]\n",
            "Validating on test set\n",
            "Validation Metrics: 1841 [D loss: 0.028772, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.450464]\n",
            "(1024, 1)\n",
            "Training Metrics: 1842 [D loss: 0.417257, acc.: 99.90%, op_acc: 85.79%] [G loss: 7.008270]\n",
            "Validating on test set\n",
            "Validation Metrics: 1842 [D loss: 0.031074, acc.: 100.00%, op_acc: 100.00%] [G loss: 7.007879]\n",
            "(1024, 1)\n",
            "Training Metrics: 1843 [D loss: 0.421982, acc.: 99.95%, op_acc: 85.21%] [G loss: 6.480075]\n",
            "Validating on test set\n",
            "Validation Metrics: 1843 [D loss: 0.035381, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.475708]\n",
            "(1024, 1)\n",
            "Training Metrics: 1844 [D loss: 0.445861, acc.: 99.76%, op_acc: 84.91%] [G loss: 6.623475]\n",
            "Validating on test set\n",
            "Validation Metrics: 1844 [D loss: 0.034781, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.625973]\n",
            "(1024, 1)\n",
            "Training Metrics: 1845 [D loss: 0.459055, acc.: 99.95%, op_acc: 84.13%] [G loss: 6.673258]\n",
            "Validating on test set\n",
            "Validation Metrics: 1845 [D loss: 0.032780, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.682582]\n",
            "(1024, 1)\n",
            "Training Metrics: 1846 [D loss: 0.413615, acc.: 100.00%, op_acc: 83.98%] [G loss: 6.542995]\n",
            "Validating on test set\n",
            "Validation Metrics: 1846 [D loss: 0.031386, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.539299]\n",
            "(1024, 1)\n",
            "Training Metrics: 1847 [D loss: 0.426109, acc.: 99.95%, op_acc: 85.21%] [G loss: 6.488832]\n",
            "Validating on test set\n",
            "Validation Metrics: 1847 [D loss: 0.037242, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.491256]\n",
            "(1024, 1)\n",
            "Training Metrics: 1848 [D loss: 0.436248, acc.: 99.90%, op_acc: 84.23%] [G loss: 6.756187]\n",
            "Validating on test set\n",
            "Validation Metrics: 1848 [D loss: 0.031955, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.744830]\n",
            "(1024, 1)\n",
            "Training Metrics: 1849 [D loss: 0.439057, acc.: 99.95%, op_acc: 84.86%] [G loss: 6.560845]\n",
            "Validating on test set\n",
            "Validation Metrics: 1849 [D loss: 0.032887, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.561931]\n",
            "(1024, 1)\n",
            "Training Metrics: 1850 [D loss: 0.438507, acc.: 99.95%, op_acc: 84.13%] [G loss: 6.859624]\n",
            "Validating on test set\n",
            "Validation Metrics: 1850 [D loss: 0.033724, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.862156]\n",
            "(1024, 1)\n",
            "Training Metrics: 1851 [D loss: 0.429293, acc.: 99.66%, op_acc: 85.06%] [G loss: 6.132514]\n",
            "Validating on test set\n",
            "Validation Metrics: 1851 [D loss: 0.037102, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.138489]\n",
            "(1024, 1)\n",
            "Training Metrics: 1852 [D loss: 0.431063, acc.: 99.90%, op_acc: 85.06%] [G loss: 5.991474]\n",
            "Validating on test set\n",
            "Validation Metrics: 1852 [D loss: 0.034779, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.992098]\n",
            "(1024, 1)\n",
            "Training Metrics: 1853 [D loss: 0.444645, acc.: 99.90%, op_acc: 85.55%] [G loss: 6.478741]\n",
            "Validating on test set\n",
            "Validation Metrics: 1853 [D loss: 0.031841, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.480681]\n",
            "(1024, 1)\n",
            "Training Metrics: 1854 [D loss: 0.427521, acc.: 99.95%, op_acc: 84.33%] [G loss: 6.765617]\n",
            "Validating on test set\n",
            "Validation Metrics: 1854 [D loss: 0.036901, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.766302]\n",
            "(1024, 1)\n",
            "Training Metrics: 1855 [D loss: 0.452889, acc.: 99.95%, op_acc: 85.11%] [G loss: 6.584601]\n",
            "Validating on test set\n",
            "Validation Metrics: 1855 [D loss: 0.034291, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.568656]\n",
            "(1024, 1)\n",
            "Training Metrics: 1856 [D loss: 0.449296, acc.: 99.95%, op_acc: 83.35%] [G loss: 6.818585]\n",
            "Validating on test set\n",
            "Validation Metrics: 1856 [D loss: 0.033172, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.831125]\n",
            "(1024, 1)\n",
            "Training Metrics: 1857 [D loss: 0.472166, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.715480]\n",
            "Validating on test set\n",
            "Validation Metrics: 1857 [D loss: 0.037471, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.725966]\n",
            "(1024, 1)\n",
            "Training Metrics: 1858 [D loss: 0.466729, acc.: 99.85%, op_acc: 82.91%] [G loss: 6.823779]\n",
            "Validating on test set\n",
            "Validation Metrics: 1858 [D loss: 0.038640, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.826737]\n",
            "(1024, 1)\n",
            "Training Metrics: 1859 [D loss: 0.476765, acc.: 99.80%, op_acc: 83.50%] [G loss: 5.991940]\n",
            "Validating on test set\n",
            "Validation Metrics: 1859 [D loss: 0.035988, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.984164]\n",
            "(1024, 1)\n",
            "Training Metrics: 1860 [D loss: 0.380157, acc.: 99.90%, op_acc: 85.99%] [G loss: 6.411253]\n",
            "Validating on test set\n",
            "Validation Metrics: 1860 [D loss: 0.032864, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.422222]\n",
            "(1024, 1)\n",
            "Training Metrics: 1861 [D loss: 0.422372, acc.: 99.80%, op_acc: 85.50%] [G loss: 6.028438]\n",
            "Validating on test set\n",
            "Validation Metrics: 1861 [D loss: 0.035114, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.023431]\n",
            "(1024, 1)\n",
            "Training Metrics: 1862 [D loss: 0.412646, acc.: 99.85%, op_acc: 85.35%] [G loss: 6.359145]\n",
            "Validating on test set\n",
            "Validation Metrics: 1862 [D loss: 0.036880, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.357082]\n",
            "(1024, 1)\n",
            "Training Metrics: 1863 [D loss: 0.427000, acc.: 99.90%, op_acc: 84.96%] [G loss: 6.292876]\n",
            "Validating on test set\n",
            "Validation Metrics: 1863 [D loss: 0.033242, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.292324]\n",
            "(1024, 1)\n",
            "Training Metrics: 1864 [D loss: 0.399517, acc.: 99.90%, op_acc: 85.60%] [G loss: 6.098353]\n",
            "Validating on test set\n",
            "Validation Metrics: 1864 [D loss: 0.031265, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.097987]\n",
            "(1024, 1)\n",
            "Training Metrics: 1865 [D loss: 0.393824, acc.: 99.90%, op_acc: 85.89%] [G loss: 6.240524]\n",
            "Validating on test set\n",
            "Validation Metrics: 1865 [D loss: 0.508961, acc.: 100.00%, op_acc: 93.46%] [G loss: 6.715371]\n",
            "(1024, 1)\n",
            "Training Metrics: 1866 [D loss: 0.616808, acc.: 99.85%, op_acc: 82.28%] [G loss: 7.101505]\n",
            "Validating on test set\n",
            "Validation Metrics: 1866 [D loss: 4.032833, acc.: 100.00%, op_acc: 55.37%] [G loss: 10.762621]\n",
            "(1024, 1)\n",
            "Training Metrics: 1867 [D loss: 2.589852, acc.: 99.90%, op_acc: 63.33%] [G loss: 6.140835]\n",
            "Validating on test set\n",
            "Validation Metrics: 1867 [D loss: 2.223682, acc.: 100.00%, op_acc: 65.72%] [G loss: 7.557451]\n",
            "(1024, 1)\n",
            "Training Metrics: 1868 [D loss: 1.524411, acc.: 99.95%, op_acc: 64.01%] [G loss: 6.866645]\n",
            "Validating on test set\n",
            "Validation Metrics: 1868 [D loss: 2.990048, acc.: 100.00%, op_acc: 48.14%] [G loss: 7.881680]\n",
            "(1024, 1)\n",
            "Training Metrics: 1869 [D loss: 2.146830, acc.: 99.90%, op_acc: 54.54%] [G loss: 8.649631]\n",
            "Validating on test set\n",
            "Validation Metrics: 1869 [D loss: 1.543347, acc.: 100.00%, op_acc: 67.68%] [G loss: 7.900836]\n",
            "(1024, 1)\n",
            "Training Metrics: 1870 [D loss: 1.304591, acc.: 100.00%, op_acc: 66.36%] [G loss: 9.023354]\n",
            "Validating on test set\n",
            "Validation Metrics: 1870 [D loss: 1.626939, acc.: 100.00%, op_acc: 53.71%] [G loss: 9.126576]\n",
            "(1024, 1)\n",
            "Training Metrics: 1871 [D loss: 1.272953, acc.: 99.85%, op_acc: 62.01%] [G loss: 10.029564]\n",
            "Validating on test set\n",
            "Validation Metrics: 1871 [D loss: 0.587955, acc.: 100.00%, op_acc: 79.98%] [G loss: 9.702392]\n",
            "(1024, 1)\n",
            "Training Metrics: 1872 [D loss: 0.748672, acc.: 99.80%, op_acc: 73.49%] [G loss: 8.869797]\n",
            "Validating on test set\n",
            "Validation Metrics: 1872 [D loss: 0.797508, acc.: 100.00%, op_acc: 76.66%] [G loss: 8.983007]\n",
            "(1024, 1)\n",
            "Training Metrics: 1873 [D loss: 0.820584, acc.: 99.90%, op_acc: 71.19%] [G loss: 8.405430]\n",
            "Validating on test set\n",
            "Validation Metrics: 1873 [D loss: 0.801154, acc.: 100.00%, op_acc: 78.12%] [G loss: 8.620635]\n",
            "(1024, 1)\n",
            "Training Metrics: 1874 [D loss: 0.838190, acc.: 99.95%, op_acc: 73.24%] [G loss: 6.913750]\n",
            "Validating on test set\n",
            "Validation Metrics: 1874 [D loss: 0.551170, acc.: 100.00%, op_acc: 82.81%] [G loss: 6.588027]\n",
            "(1024, 1)\n",
            "Training Metrics: 1875 [D loss: 0.669072, acc.: 99.85%, op_acc: 75.24%] [G loss: 7.293327]\n",
            "Validating on test set\n",
            "Validation Metrics: 1875 [D loss: 2.423446, acc.: 88.48%, op_acc: 55.08%] [G loss: 6.435225]\n",
            "(1024, 1)\n",
            "Training Metrics: 1876 [D loss: 1.636020, acc.: 93.55%, op_acc: 64.65%] [G loss: 9.668872]\n",
            "Validating on test set\n",
            "Validation Metrics: 1876 [D loss: 1.320993, acc.: 100.00%, op_acc: 46.48%] [G loss: 9.235762]\n",
            "(1024, 1)\n",
            "Training Metrics: 1877 [D loss: 1.179595, acc.: 99.56%, op_acc: 54.15%] [G loss: 11.547422]\n",
            "Validating on test set\n",
            "Validation Metrics: 1877 [D loss: 2.497618, acc.: 100.00%, op_acc: 41.02%] [G loss: 10.819662]\n",
            "(1024, 1)\n",
            "Training Metrics: 1878 [D loss: 1.743930, acc.: 99.61%, op_acc: 50.93%] [G loss: 8.922371]\n",
            "Validating on test set\n",
            "Validation Metrics: 1878 [D loss: 2.073338, acc.: 100.00%, op_acc: 43.75%] [G loss: 8.766045]\n",
            "(1024, 1)\n",
            "Training Metrics: 1879 [D loss: 1.521617, acc.: 99.51%, op_acc: 52.59%] [G loss: 8.851873]\n",
            "Validating on test set\n",
            "Validation Metrics: 1879 [D loss: 1.695943, acc.: 99.90%, op_acc: 55.66%] [G loss: 7.826255]\n",
            "(1024, 1)\n",
            "Training Metrics: 1880 [D loss: 1.347331, acc.: 99.51%, op_acc: 57.13%] [G loss: 7.704650]\n",
            "Validating on test set\n",
            "Validation Metrics: 1880 [D loss: 1.633068, acc.: 100.00%, op_acc: 53.12%] [G loss: 7.342652]\n",
            "(1024, 1)\n",
            "Training Metrics: 1881 [D loss: 1.236714, acc.: 99.71%, op_acc: 60.40%] [G loss: 7.465705]\n",
            "Validating on test set\n",
            "Validation Metrics: 1881 [D loss: 2.235637, acc.: 99.90%, op_acc: 34.86%] [G loss: 7.708864]\n",
            "(1024, 1)\n",
            "Training Metrics: 1882 [D loss: 1.629753, acc.: 99.80%, op_acc: 47.46%] [G loss: 10.041641]\n",
            "Validating on test set\n",
            "Validation Metrics: 1882 [D loss: 1.652963, acc.: 100.00%, op_acc: 52.25%] [G loss: 7.546867]\n",
            "(1024, 1)\n",
            "Training Metrics: 1883 [D loss: 1.400615, acc.: 99.17%, op_acc: 54.93%] [G loss: 8.001807]\n",
            "Validating on test set\n",
            "Validation Metrics: 1883 [D loss: 1.262451, acc.: 100.00%, op_acc: 47.07%] [G loss: 8.419514]\n",
            "(1024, 1)\n",
            "Training Metrics: 1884 [D loss: 1.103281, acc.: 99.17%, op_acc: 56.10%] [G loss: 7.607464]\n",
            "Validating on test set\n",
            "Validation Metrics: 1884 [D loss: 0.920215, acc.: 100.00%, op_acc: 64.94%] [G loss: 7.377483]\n",
            "(1024, 1)\n",
            "Training Metrics: 1885 [D loss: 0.972383, acc.: 99.07%, op_acc: 68.16%] [G loss: 6.692981]\n",
            "Validating on test set\n",
            "Validation Metrics: 1885 [D loss: 0.880856, acc.: 100.00%, op_acc: 79.30%] [G loss: 6.534681]\n",
            "(1024, 1)\n",
            "Training Metrics: 1886 [D loss: 0.920946, acc.: 99.56%, op_acc: 71.58%] [G loss: 6.500638]\n",
            "Validating on test set\n",
            "Validation Metrics: 1886 [D loss: 0.704902, acc.: 100.00%, op_acc: 81.15%] [G loss: 6.402207]\n",
            "(1024, 1)\n",
            "Training Metrics: 1887 [D loss: 0.887950, acc.: 99.61%, op_acc: 75.68%] [G loss: 5.959054]\n",
            "Validating on test set\n",
            "Validation Metrics: 1887 [D loss: 0.664717, acc.: 100.00%, op_acc: 82.03%] [G loss: 5.872006]\n",
            "(1024, 1)\n",
            "Training Metrics: 1888 [D loss: 0.805274, acc.: 99.56%, op_acc: 72.61%] [G loss: 6.044413]\n",
            "Validating on test set\n",
            "Validation Metrics: 1888 [D loss: 0.623354, acc.: 100.00%, op_acc: 83.79%] [G loss: 5.917243]\n",
            "(1024, 1)\n",
            "Training Metrics: 1889 [D loss: 0.825654, acc.: 99.80%, op_acc: 74.66%] [G loss: 6.111674]\n",
            "Validating on test set\n",
            "Validation Metrics: 1889 [D loss: 0.782995, acc.: 100.00%, op_acc: 76.76%] [G loss: 6.291087]\n",
            "(1024, 1)\n",
            "Training Metrics: 1890 [D loss: 0.862060, acc.: 99.71%, op_acc: 71.29%] [G loss: 6.376641]\n",
            "Validating on test set\n",
            "Validation Metrics: 1890 [D loss: 0.751352, acc.: 100.00%, op_acc: 71.68%] [G loss: 6.507057]\n",
            "(1024, 1)\n",
            "Training Metrics: 1891 [D loss: 0.853101, acc.: 99.71%, op_acc: 69.97%] [G loss: 6.658594]\n",
            "Validating on test set\n",
            "Validation Metrics: 1891 [D loss: 0.793620, acc.: 100.00%, op_acc: 68.65%] [G loss: 5.680531]\n",
            "(1024, 1)\n",
            "Training Metrics: 1892 [D loss: 0.854370, acc.: 99.76%, op_acc: 68.46%] [G loss: 6.192023]\n",
            "Validating on test set\n",
            "Validation Metrics: 1892 [D loss: 0.653466, acc.: 100.00%, op_acc: 77.83%] [G loss: 6.029322]\n",
            "(1024, 1)\n",
            "Training Metrics: 1893 [D loss: 0.793625, acc.: 99.46%, op_acc: 73.83%] [G loss: 5.808862]\n",
            "Validating on test set\n",
            "Validation Metrics: 1893 [D loss: 0.635734, acc.: 100.00%, op_acc: 82.32%] [G loss: 5.621060]\n",
            "(1024, 1)\n",
            "Training Metrics: 1894 [D loss: 0.783387, acc.: 99.76%, op_acc: 76.81%] [G loss: 6.023530]\n",
            "Validating on test set\n",
            "Validation Metrics: 1894 [D loss: 0.569983, acc.: 100.00%, op_acc: 83.40%] [G loss: 5.951731]\n",
            "(1024, 1)\n",
            "Training Metrics: 1895 [D loss: 0.756491, acc.: 99.61%, op_acc: 75.63%] [G loss: 6.289449]\n",
            "Validating on test set\n",
            "Validation Metrics: 1895 [D loss: 0.541419, acc.: 100.00%, op_acc: 85.64%] [G loss: 6.244983]\n",
            "(1024, 1)\n",
            "Training Metrics: 1896 [D loss: 0.723883, acc.: 99.90%, op_acc: 75.93%] [G loss: 5.993999]\n",
            "Validating on test set\n",
            "Validation Metrics: 1896 [D loss: 0.563384, acc.: 99.22%, op_acc: 82.03%] [G loss: 5.991751]\n",
            "(1024, 1)\n",
            "Training Metrics: 1897 [D loss: 0.805225, acc.: 99.61%, op_acc: 72.02%] [G loss: 6.275002]\n",
            "Validating on test set\n",
            "Validation Metrics: 1897 [D loss: 0.638204, acc.: 93.07%, op_acc: 80.76%] [G loss: 5.898865]\n",
            "(1024, 1)\n",
            "Training Metrics: 1898 [D loss: 0.780249, acc.: 96.44%, op_acc: 72.61%] [G loss: 8.063494]\n",
            "Validating on test set\n",
            "Validation Metrics: 1898 [D loss: 0.593650, acc.: 100.00%, op_acc: 85.25%] [G loss: 7.842531]\n",
            "(1024, 1)\n",
            "Training Metrics: 1899 [D loss: 0.778978, acc.: 99.56%, op_acc: 76.81%] [G loss: 7.636422]\n",
            "Validating on test set\n",
            "Validation Metrics: 1899 [D loss: 0.708177, acc.: 100.00%, op_acc: 75.98%] [G loss: 7.652875]\n",
            "(1024, 1)\n",
            "Training Metrics: 1900 [D loss: 0.818265, acc.: 99.22%, op_acc: 74.17%] [G loss: 6.667789]\n",
            "Validating on test set\n",
            "Validation Metrics: 1900 [D loss: 0.561838, acc.: 100.00%, op_acc: 86.91%] [G loss: 6.315147]\n",
            "(1024, 1)\n",
            "Training Metrics: 1901 [D loss: 0.787317, acc.: 99.41%, op_acc: 73.83%] [G loss: 6.601758]\n",
            "Validating on test set\n",
            "Validation Metrics: 1901 [D loss: 0.990316, acc.: 100.00%, op_acc: 70.41%] [G loss: 7.414880]\n",
            "(1024, 1)\n",
            "Training Metrics: 1902 [D loss: 1.056615, acc.: 99.46%, op_acc: 67.19%] [G loss: 8.006510]\n",
            "Validating on test set\n",
            "Validation Metrics: 1902 [D loss: 0.865603, acc.: 100.00%, op_acc: 64.45%] [G loss: 8.007071]\n",
            "(1024, 1)\n",
            "Training Metrics: 1903 [D loss: 0.975187, acc.: 99.27%, op_acc: 62.89%] [G loss: 7.456906]\n",
            "Validating on test set\n",
            "Validation Metrics: 1903 [D loss: 0.986122, acc.: 100.00%, op_acc: 70.80%] [G loss: 6.169713]\n",
            "(1024, 1)\n",
            "Training Metrics: 1904 [D loss: 1.040690, acc.: 99.37%, op_acc: 66.41%] [G loss: 7.803260]\n",
            "Validating on test set\n",
            "Validation Metrics: 1904 [D loss: 0.700938, acc.: 100.00%, op_acc: 77.25%] [G loss: 7.017293]\n",
            "(1024, 1)\n",
            "Training Metrics: 1905 [D loss: 0.861246, acc.: 99.07%, op_acc: 68.36%] [G loss: 7.280663]\n",
            "Validating on test set\n",
            "Validation Metrics: 1905 [D loss: 0.686755, acc.: 100.00%, op_acc: 77.15%] [G loss: 7.062295]\n",
            "(1024, 1)\n",
            "Training Metrics: 1906 [D loss: 0.818650, acc.: 99.41%, op_acc: 71.92%] [G loss: 6.776797]\n",
            "Validating on test set\n",
            "Validation Metrics: 1906 [D loss: 0.671123, acc.: 100.00%, op_acc: 81.45%] [G loss: 6.766125]\n",
            "(1024, 1)\n",
            "Training Metrics: 1907 [D loss: 0.802320, acc.: 99.71%, op_acc: 73.05%] [G loss: 6.873641]\n",
            "Validating on test set\n",
            "Validation Metrics: 1907 [D loss: 0.596607, acc.: 100.00%, op_acc: 87.30%] [G loss: 6.817468]\n",
            "(1024, 1)\n",
            "Training Metrics: 1908 [D loss: 0.834214, acc.: 99.12%, op_acc: 74.61%] [G loss: 6.003564]\n",
            "Validating on test set\n",
            "Validation Metrics: 1908 [D loss: 0.542401, acc.: 100.00%, op_acc: 88.18%] [G loss: 5.942578]\n",
            "(1024, 1)\n",
            "Training Metrics: 1909 [D loss: 0.777202, acc.: 99.37%, op_acc: 76.66%] [G loss: 5.790105]\n",
            "Validating on test set\n",
            "Validation Metrics: 1909 [D loss: 0.522295, acc.: 100.00%, op_acc: 91.80%] [G loss: 5.777103]\n",
            "(1024, 1)\n",
            "Training Metrics: 1910 [D loss: 0.744462, acc.: 99.51%, op_acc: 77.78%] [G loss: 6.101887]\n",
            "Validating on test set\n",
            "Validation Metrics: 1910 [D loss: 0.464760, acc.: 100.00%, op_acc: 91.89%] [G loss: 6.108825]\n",
            "(1024, 1)\n",
            "Training Metrics: 1911 [D loss: 0.725444, acc.: 99.76%, op_acc: 77.05%] [G loss: 6.025512]\n",
            "Validating on test set\n",
            "Validation Metrics: 1911 [D loss: 0.541508, acc.: 100.00%, op_acc: 84.57%] [G loss: 6.127205]\n",
            "(1024, 1)\n",
            "Training Metrics: 1912 [D loss: 0.782469, acc.: 99.71%, op_acc: 72.71%] [G loss: 6.350463]\n",
            "Validating on test set\n",
            "Validation Metrics: 1912 [D loss: 0.453147, acc.: 100.00%, op_acc: 88.77%] [G loss: 6.240664]\n",
            "(1024, 1)\n",
            "Training Metrics: 1913 [D loss: 0.716797, acc.: 99.46%, op_acc: 76.32%] [G loss: 6.131623]\n",
            "Validating on test set\n",
            "Validation Metrics: 1913 [D loss: 0.361521, acc.: 100.00%, op_acc: 97.27%] [G loss: 6.041842]\n",
            "(1024, 1)\n",
            "Training Metrics: 1914 [D loss: 0.643146, acc.: 99.56%, op_acc: 79.88%] [G loss: 5.582809]\n",
            "Validating on test set\n",
            "Validation Metrics: 1914 [D loss: 0.751053, acc.: 100.00%, op_acc: 81.74%] [G loss: 5.859312]\n",
            "(1024, 1)\n",
            "Training Metrics: 1915 [D loss: 0.876144, acc.: 99.56%, op_acc: 73.24%] [G loss: 6.943426]\n",
            "Validating on test set\n",
            "Validation Metrics: 1915 [D loss: 0.616133, acc.: 100.00%, op_acc: 77.44%] [G loss: 7.094423]\n",
            "(1024, 1)\n",
            "Training Metrics: 1916 [D loss: 0.849321, acc.: 99.46%, op_acc: 69.78%] [G loss: 7.075113]\n",
            "Validating on test set\n",
            "Validation Metrics: 1916 [D loss: 0.602286, acc.: 100.00%, op_acc: 81.64%] [G loss: 7.259154]\n",
            "(1024, 1)\n",
            "Training Metrics: 1917 [D loss: 0.806404, acc.: 99.37%, op_acc: 72.95%] [G loss: 5.849361]\n",
            "Validating on test set\n",
            "Validation Metrics: 1917 [D loss: 0.472245, acc.: 100.00%, op_acc: 91.70%] [G loss: 5.901855]\n",
            "(1024, 1)\n",
            "Training Metrics: 1918 [D loss: 0.758054, acc.: 99.37%, op_acc: 76.71%] [G loss: 5.626340]\n",
            "Validating on test set\n",
            "Validation Metrics: 1918 [D loss: 0.423967, acc.: 100.00%, op_acc: 90.72%] [G loss: 5.608103]\n",
            "(1024, 1)\n",
            "Training Metrics: 1919 [D loss: 0.655392, acc.: 99.66%, op_acc: 79.69%] [G loss: 5.595163]\n",
            "Validating on test set\n",
            "Validation Metrics: 1919 [D loss: 0.314068, acc.: 100.00%, op_acc: 95.51%] [G loss: 5.542327]\n",
            "(1024, 1)\n",
            "Training Metrics: 1920 [D loss: 0.581042, acc.: 99.76%, op_acc: 82.67%] [G loss: 5.307144]\n",
            "Validating on test set\n",
            "Validation Metrics: 1920 [D loss: 0.296436, acc.: 100.00%, op_acc: 97.75%] [G loss: 5.289555]\n",
            "(1024, 1)\n",
            "Training Metrics: 1921 [D loss: 0.656185, acc.: 99.56%, op_acc: 81.15%] [G loss: 5.392969]\n",
            "Validating on test set\n",
            "Validation Metrics: 1921 [D loss: 0.261088, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.348751]\n",
            "(1024, 1)\n",
            "Training Metrics: 1922 [D loss: 0.625181, acc.: 99.32%, op_acc: 83.74%] [G loss: 5.208727]\n",
            "Validating on test set\n",
            "Validation Metrics: 1922 [D loss: 0.262807, acc.: 100.00%, op_acc: 98.24%] [G loss: 5.241112]\n",
            "(1024, 1)\n",
            "Training Metrics: 1923 [D loss: 0.639655, acc.: 99.76%, op_acc: 81.79%] [G loss: 5.950292]\n",
            "Validating on test set\n",
            "Validation Metrics: 1923 [D loss: 0.227812, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.939921]\n",
            "(1024, 1)\n",
            "Training Metrics: 1924 [D loss: 0.608444, acc.: 99.17%, op_acc: 83.74%] [G loss: 5.361837]\n",
            "Validating on test set\n",
            "Validation Metrics: 1924 [D loss: 0.236164, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.365722]\n",
            "(1024, 1)\n",
            "Training Metrics: 1925 [D loss: 0.574702, acc.: 99.66%, op_acc: 83.40%] [G loss: 5.383075]\n",
            "Validating on test set\n",
            "Validation Metrics: 1925 [D loss: 0.231015, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.347399]\n",
            "(1024, 1)\n",
            "Training Metrics: 1926 [D loss: 0.594941, acc.: 99.71%, op_acc: 83.30%] [G loss: 5.364288]\n",
            "Validating on test set\n",
            "Validation Metrics: 1926 [D loss: 0.228198, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.360681]\n",
            "(1024, 1)\n",
            "Training Metrics: 1927 [D loss: 0.587420, acc.: 99.66%, op_acc: 83.40%] [G loss: 5.542540]\n",
            "Validating on test set\n",
            "Validation Metrics: 1927 [D loss: 0.239092, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.490224]\n",
            "(1024, 1)\n",
            "Training Metrics: 1928 [D loss: 0.596659, acc.: 99.71%, op_acc: 82.28%] [G loss: 5.758400]\n",
            "Validating on test set\n",
            "Validation Metrics: 1928 [D loss: 0.227798, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.770492]\n",
            "(1024, 1)\n",
            "Training Metrics: 1929 [D loss: 0.556024, acc.: 99.71%, op_acc: 83.50%] [G loss: 5.809105]\n",
            "Validating on test set\n",
            "Validation Metrics: 1929 [D loss: 0.212460, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.882448]\n",
            "(1024, 1)\n",
            "Training Metrics: 1930 [D loss: 0.567025, acc.: 99.41%, op_acc: 83.01%] [G loss: 5.774053]\n",
            "Validating on test set\n",
            "Validation Metrics: 1930 [D loss: 0.270764, acc.: 100.00%, op_acc: 96.29%] [G loss: 5.807696]\n",
            "(1024, 1)\n",
            "Training Metrics: 1931 [D loss: 0.612379, acc.: 99.37%, op_acc: 82.23%] [G loss: 5.634040]\n",
            "Validating on test set\n",
            "Validation Metrics: 1931 [D loss: 0.269810, acc.: 100.00%, op_acc: 96.19%] [G loss: 5.713118]\n",
            "(1024, 1)\n",
            "Training Metrics: 1932 [D loss: 0.615058, acc.: 99.32%, op_acc: 80.76%] [G loss: 5.028214]\n",
            "Validating on test set\n",
            "Validation Metrics: 1932 [D loss: 0.305124, acc.: 100.00%, op_acc: 94.53%] [G loss: 5.066319]\n",
            "(1024, 1)\n",
            "Training Metrics: 1933 [D loss: 0.618585, acc.: 99.76%, op_acc: 79.79%] [G loss: 5.692677]\n",
            "Validating on test set\n",
            "Validation Metrics: 1933 [D loss: 0.201611, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.624832]\n",
            "(1024, 1)\n",
            "Training Metrics: 1934 [D loss: 0.575152, acc.: 99.71%, op_acc: 82.71%] [G loss: 5.843672]\n",
            "Validating on test set\n",
            "Validation Metrics: 1934 [D loss: 0.187921, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.900991]\n",
            "(1024, 1)\n",
            "Training Metrics: 1935 [D loss: 0.550526, acc.: 99.71%, op_acc: 83.69%] [G loss: 5.972415]\n",
            "Validating on test set\n",
            "Validation Metrics: 1935 [D loss: 0.192039, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.912789]\n",
            "(1024, 1)\n",
            "Training Metrics: 1936 [D loss: 0.549295, acc.: 99.46%, op_acc: 83.89%] [G loss: 5.383200]\n",
            "Validating on test set\n",
            "Validation Metrics: 1936 [D loss: 0.186139, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.424223]\n",
            "(1024, 1)\n",
            "Training Metrics: 1937 [D loss: 0.537177, acc.: 99.71%, op_acc: 84.13%] [G loss: 5.646963]\n",
            "Validating on test set\n",
            "Validation Metrics: 1937 [D loss: 0.178060, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.573354]\n",
            "(1024, 1)\n",
            "Training Metrics: 1938 [D loss: 0.570045, acc.: 99.61%, op_acc: 83.35%] [G loss: 5.418885]\n",
            "Validating on test set\n",
            "Validation Metrics: 1938 [D loss: 0.183886, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.498831]\n",
            "(1024, 1)\n",
            "Training Metrics: 1939 [D loss: 0.531833, acc.: 99.80%, op_acc: 83.45%] [G loss: 5.708550]\n",
            "Validating on test set\n",
            "Validation Metrics: 1939 [D loss: 0.168500, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.706564]\n",
            "(1024, 1)\n",
            "Training Metrics: 1940 [D loss: 0.514206, acc.: 99.76%, op_acc: 84.91%] [G loss: 5.793690]\n",
            "Validating on test set\n",
            "Validation Metrics: 1940 [D loss: 0.179575, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.769597]\n",
            "(1024, 1)\n",
            "Training Metrics: 1941 [D loss: 0.530141, acc.: 99.61%, op_acc: 83.64%] [G loss: 5.709112]\n",
            "Validating on test set\n",
            "Validation Metrics: 1941 [D loss: 0.163264, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.693279]\n",
            "(1024, 1)\n",
            "Training Metrics: 1942 [D loss: 0.579102, acc.: 99.71%, op_acc: 83.11%] [G loss: 5.444837]\n",
            "Validating on test set\n",
            "Validation Metrics: 1942 [D loss: 0.172463, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.442195]\n",
            "(1024, 1)\n",
            "Training Metrics: 1943 [D loss: 0.574991, acc.: 99.46%, op_acc: 83.06%] [G loss: 5.738106]\n",
            "Validating on test set\n",
            "Validation Metrics: 1943 [D loss: 0.178548, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.748675]\n",
            "(1024, 1)\n",
            "Training Metrics: 1944 [D loss: 0.595411, acc.: 99.61%, op_acc: 82.08%] [G loss: 5.734203]\n",
            "Validating on test set\n",
            "Validation Metrics: 1944 [D loss: 0.182664, acc.: 100.00%, op_acc: 98.14%] [G loss: 5.764961]\n",
            "(1024, 1)\n",
            "Training Metrics: 1945 [D loss: 0.594065, acc.: 99.66%, op_acc: 79.64%] [G loss: 5.330400]\n",
            "Validating on test set\n",
            "Validation Metrics: 1945 [D loss: 0.171968, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.336125]\n",
            "(1024, 1)\n",
            "Training Metrics: 1946 [D loss: 0.582198, acc.: 99.66%, op_acc: 81.88%] [G loss: 5.632758]\n",
            "Validating on test set\n",
            "Validation Metrics: 1946 [D loss: 0.160921, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.638456]\n",
            "(1024, 1)\n",
            "Training Metrics: 1947 [D loss: 0.555516, acc.: 99.71%, op_acc: 82.13%] [G loss: 5.644642]\n",
            "Validating on test set\n",
            "Validation Metrics: 1947 [D loss: 0.185033, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.630927]\n",
            "(1024, 1)\n",
            "Training Metrics: 1948 [D loss: 0.565642, acc.: 99.76%, op_acc: 83.64%] [G loss: 6.020390]\n",
            "Validating on test set\n",
            "Validation Metrics: 1948 [D loss: 0.143338, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.015301]\n",
            "(1024, 1)\n",
            "Training Metrics: 1949 [D loss: 0.536044, acc.: 99.71%, op_acc: 84.03%] [G loss: 5.987035]\n",
            "Validating on test set\n",
            "Validation Metrics: 1949 [D loss: 0.147468, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.916987]\n",
            "(1024, 1)\n",
            "Training Metrics: 1950 [D loss: 0.499948, acc.: 99.76%, op_acc: 83.94%] [G loss: 5.655991]\n",
            "Validating on test set\n",
            "Validation Metrics: 1950 [D loss: 0.151687, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.648592]\n",
            "(1024, 1)\n",
            "Training Metrics: 1951 [D loss: 0.558232, acc.: 99.76%, op_acc: 82.81%] [G loss: 6.009489]\n",
            "Validating on test set\n",
            "Validation Metrics: 1951 [D loss: 0.158666, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.032994]\n",
            "(1024, 1)\n",
            "Training Metrics: 1952 [D loss: 0.552089, acc.: 99.76%, op_acc: 82.23%] [G loss: 5.945227]\n",
            "Validating on test set\n",
            "Validation Metrics: 1952 [D loss: 0.154117, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.880574]\n",
            "(1024, 1)\n",
            "Training Metrics: 1953 [D loss: 0.538081, acc.: 99.66%, op_acc: 83.20%] [G loss: 5.961653]\n",
            "Validating on test set\n",
            "Validation Metrics: 1953 [D loss: 0.137867, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.950432]\n",
            "(1024, 1)\n",
            "Training Metrics: 1954 [D loss: 0.475464, acc.: 99.80%, op_acc: 85.11%] [G loss: 5.845819]\n",
            "Validating on test set\n",
            "Validation Metrics: 1954 [D loss: 0.139415, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.822937]\n",
            "(1024, 1)\n",
            "Training Metrics: 1955 [D loss: 0.557010, acc.: 99.51%, op_acc: 83.45%] [G loss: 5.892629]\n",
            "Validating on test set\n",
            "Validation Metrics: 1955 [D loss: 0.139927, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.867400]\n",
            "(1024, 1)\n",
            "Training Metrics: 1956 [D loss: 0.536851, acc.: 99.71%, op_acc: 83.94%] [G loss: 6.045537]\n",
            "Validating on test set\n",
            "Validation Metrics: 1956 [D loss: 0.160751, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.166200]\n",
            "(1024, 1)\n",
            "Training Metrics: 1957 [D loss: 0.551881, acc.: 99.66%, op_acc: 83.30%] [G loss: 5.695903]\n",
            "Validating on test set\n",
            "Validation Metrics: 1957 [D loss: 0.179243, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.732814]\n",
            "(1024, 1)\n",
            "Training Metrics: 1958 [D loss: 0.540957, acc.: 99.61%, op_acc: 83.64%] [G loss: 5.953555]\n",
            "Validating on test set\n",
            "Validation Metrics: 1958 [D loss: 0.168980, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.945539]\n",
            "(1024, 1)\n",
            "Training Metrics: 1959 [D loss: 0.556497, acc.: 99.76%, op_acc: 82.03%] [G loss: 5.144690]\n",
            "Validating on test set\n",
            "Validation Metrics: 1959 [D loss: 0.156698, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.112007]\n",
            "(1024, 1)\n",
            "Training Metrics: 1960 [D loss: 0.531772, acc.: 99.66%, op_acc: 83.74%] [G loss: 5.796092]\n",
            "Validating on test set\n",
            "Validation Metrics: 1960 [D loss: 0.208085, acc.: 100.00%, op_acc: 97.46%] [G loss: 5.753843]\n",
            "(1024, 1)\n",
            "Training Metrics: 1961 [D loss: 0.533631, acc.: 99.56%, op_acc: 83.11%] [G loss: 5.592552]\n",
            "Validating on test set\n",
            "Validation Metrics: 1961 [D loss: 0.127555, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.606321]\n",
            "(1024, 1)\n",
            "Training Metrics: 1962 [D loss: 0.514299, acc.: 99.51%, op_acc: 84.42%] [G loss: 5.426821]\n",
            "Validating on test set\n",
            "Validation Metrics: 1962 [D loss: 0.245431, acc.: 100.00%, op_acc: 98.24%] [G loss: 5.434806]\n",
            "(1024, 1)\n",
            "Training Metrics: 1963 [D loss: 0.613709, acc.: 99.95%, op_acc: 84.08%] [G loss: 5.555225]\n",
            "Validating on test set\n",
            "Validation Metrics: 1963 [D loss: 0.153461, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.535086]\n",
            "(1024, 1)\n",
            "Training Metrics: 1964 [D loss: 0.520066, acc.: 99.56%, op_acc: 84.28%] [G loss: 5.575985]\n",
            "Validating on test set\n",
            "Validation Metrics: 1964 [D loss: 0.290715, acc.: 100.00%, op_acc: 96.88%] [G loss: 5.751961]\n",
            "(1024, 1)\n",
            "Training Metrics: 1965 [D loss: 0.615923, acc.: 99.71%, op_acc: 82.23%] [G loss: 6.009492]\n",
            "Validating on test set\n",
            "Validation Metrics: 1965 [D loss: 0.202739, acc.: 100.00%, op_acc: 97.17%] [G loss: 5.990995]\n",
            "(1024, 1)\n",
            "Training Metrics: 1966 [D loss: 0.568337, acc.: 99.66%, op_acc: 82.32%] [G loss: 6.081553]\n",
            "Validating on test set\n",
            "Validation Metrics: 1966 [D loss: 0.632526, acc.: 100.00%, op_acc: 86.62%] [G loss: 6.340228]\n",
            "(1024, 1)\n",
            "Training Metrics: 1967 [D loss: 0.788373, acc.: 99.66%, op_acc: 77.39%] [G loss: 6.428272]\n",
            "Validating on test set\n",
            "Validation Metrics: 1967 [D loss: 1.082232, acc.: 100.00%, op_acc: 68.95%] [G loss: 7.220750]\n",
            "(1024, 1)\n",
            "Training Metrics: 1968 [D loss: 1.066824, acc.: 99.61%, op_acc: 65.19%] [G loss: 7.090736]\n",
            "Validating on test set\n",
            "Validation Metrics: 1968 [D loss: 0.668556, acc.: 100.00%, op_acc: 84.47%] [G loss: 6.956449]\n",
            "(1024, 1)\n",
            "Training Metrics: 1969 [D loss: 0.881439, acc.: 99.76%, op_acc: 75.10%] [G loss: 5.920539]\n",
            "Validating on test set\n",
            "Validation Metrics: 1969 [D loss: 0.363076, acc.: 100.00%, op_acc: 88.18%] [G loss: 5.650706]\n",
            "(1024, 1)\n",
            "Training Metrics: 1970 [D loss: 0.657797, acc.: 99.66%, op_acc: 78.66%] [G loss: 5.748785]\n",
            "Validating on test set\n",
            "Validation Metrics: 1970 [D loss: 0.234032, acc.: 100.00%, op_acc: 97.46%] [G loss: 5.377480]\n",
            "(1024, 1)\n",
            "Training Metrics: 1971 [D loss: 0.595177, acc.: 99.51%, op_acc: 81.10%] [G loss: 5.407017]\n",
            "Validating on test set\n",
            "Validation Metrics: 1971 [D loss: 0.395473, acc.: 100.00%, op_acc: 89.55%] [G loss: 5.456124]\n",
            "(1024, 1)\n",
            "Training Metrics: 1972 [D loss: 0.670289, acc.: 99.76%, op_acc: 78.42%] [G loss: 6.493040]\n",
            "Validating on test set\n",
            "Validation Metrics: 1972 [D loss: 0.227990, acc.: 100.00%, op_acc: 95.51%] [G loss: 6.318019]\n",
            "(1024, 1)\n",
            "Training Metrics: 1973 [D loss: 0.566976, acc.: 99.76%, op_acc: 81.69%] [G loss: 6.668798]\n",
            "Validating on test set\n",
            "Validation Metrics: 1973 [D loss: 0.199624, acc.: 100.00%, op_acc: 97.85%] [G loss: 6.652514]\n",
            "(1024, 1)\n",
            "Training Metrics: 1974 [D loss: 0.611201, acc.: 99.17%, op_acc: 81.30%] [G loss: 5.780582]\n",
            "Validating on test set\n",
            "Validation Metrics: 1974 [D loss: 0.173097, acc.: 100.00%, op_acc: 98.44%] [G loss: 5.640260]\n",
            "(1024, 1)\n",
            "Training Metrics: 1975 [D loss: 0.545293, acc.: 99.61%, op_acc: 83.84%] [G loss: 5.567763]\n",
            "Validating on test set\n",
            "Validation Metrics: 1975 [D loss: 0.150048, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.409470]\n",
            "(1024, 1)\n",
            "Training Metrics: 1976 [D loss: 0.554329, acc.: 99.71%, op_acc: 83.79%] [G loss: 5.526472]\n",
            "Validating on test set\n",
            "Validation Metrics: 1976 [D loss: 0.155497, acc.: 100.00%, op_acc: 98.54%] [G loss: 5.374526]\n",
            "(1024, 1)\n",
            "Training Metrics: 1977 [D loss: 0.520199, acc.: 99.80%, op_acc: 82.86%] [G loss: 5.854083]\n",
            "Validating on test set\n",
            "Validation Metrics: 1977 [D loss: 0.195260, acc.: 100.00%, op_acc: 97.75%] [G loss: 5.637805]\n",
            "(1024, 1)\n",
            "Training Metrics: 1978 [D loss: 0.551845, acc.: 99.71%, op_acc: 82.76%] [G loss: 5.970565]\n",
            "Validating on test set\n",
            "Validation Metrics: 1978 [D loss: 0.191552, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.883627]\n",
            "(1024, 1)\n",
            "Training Metrics: 1979 [D loss: 0.543469, acc.: 99.85%, op_acc: 83.54%] [G loss: 6.300839]\n",
            "Validating on test set\n",
            "Validation Metrics: 1979 [D loss: 0.183846, acc.: 100.00%, op_acc: 97.75%] [G loss: 6.365398]\n",
            "(1024, 1)\n",
            "Training Metrics: 1980 [D loss: 0.583381, acc.: 99.61%, op_acc: 82.18%] [G loss: 5.663380]\n",
            "Validating on test set\n",
            "Validation Metrics: 1980 [D loss: 0.167583, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.553610]\n",
            "(1024, 1)\n",
            "Training Metrics: 1981 [D loss: 0.531117, acc.: 99.46%, op_acc: 85.55%] [G loss: 5.616602]\n",
            "Validating on test set\n",
            "Validation Metrics: 1981 [D loss: 0.206313, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.686742]\n",
            "(1024, 1)\n",
            "Training Metrics: 1982 [D loss: 0.557797, acc.: 99.66%, op_acc: 83.54%] [G loss: 5.637436]\n",
            "Validating on test set\n",
            "Validation Metrics: 1982 [D loss: 0.199652, acc.: 100.00%, op_acc: 97.27%] [G loss: 5.640097]\n",
            "(1024, 1)\n",
            "Training Metrics: 1983 [D loss: 0.546931, acc.: 99.76%, op_acc: 82.08%] [G loss: 5.760300]\n",
            "Validating on test set\n",
            "Validation Metrics: 1983 [D loss: 0.132695, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.718340]\n",
            "(1024, 1)\n",
            "Training Metrics: 1984 [D loss: 0.534448, acc.: 99.61%, op_acc: 83.40%] [G loss: 5.430302]\n",
            "Validating on test set\n",
            "Validation Metrics: 1984 [D loss: 0.179593, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.378243]\n",
            "(1024, 1)\n",
            "Training Metrics: 1985 [D loss: 0.534204, acc.: 99.95%, op_acc: 83.11%] [G loss: 6.061876]\n",
            "Validating on test set\n",
            "Validation Metrics: 1985 [D loss: 0.166957, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.060063]\n",
            "(1024, 1)\n",
            "Training Metrics: 1986 [D loss: 0.547470, acc.: 99.85%, op_acc: 83.30%] [G loss: 5.827452]\n",
            "Validating on test set\n",
            "Validation Metrics: 1986 [D loss: 0.133211, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.840585]\n",
            "(1024, 1)\n",
            "Training Metrics: 1987 [D loss: 0.488459, acc.: 99.66%, op_acc: 84.77%] [G loss: 5.825250]\n",
            "Validating on test set\n",
            "Validation Metrics: 1987 [D loss: 0.126974, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.801523]\n",
            "(1024, 1)\n",
            "Training Metrics: 1988 [D loss: 0.492755, acc.: 99.80%, op_acc: 85.01%] [G loss: 6.178696]\n",
            "Validating on test set\n",
            "Validation Metrics: 1988 [D loss: 0.121470, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.127667]\n",
            "(1024, 1)\n",
            "Training Metrics: 1989 [D loss: 0.573841, acc.: 99.51%, op_acc: 82.71%] [G loss: 5.430605]\n",
            "Validating on test set\n",
            "Validation Metrics: 1989 [D loss: 0.119454, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.425795]\n",
            "(1024, 1)\n",
            "Training Metrics: 1990 [D loss: 0.535798, acc.: 99.71%, op_acc: 83.11%] [G loss: 6.077209]\n",
            "Validating on test set\n",
            "Validation Metrics: 1990 [D loss: 0.128823, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.086103]\n",
            "(1024, 1)\n",
            "Training Metrics: 1991 [D loss: 0.553301, acc.: 99.66%, op_acc: 82.86%] [G loss: 5.742692]\n",
            "Validating on test set\n",
            "Validation Metrics: 1991 [D loss: 0.134897, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.813909]\n",
            "(1024, 1)\n",
            "Training Metrics: 1992 [D loss: 0.544752, acc.: 99.61%, op_acc: 83.50%] [G loss: 5.684018]\n",
            "Validating on test set\n",
            "Validation Metrics: 1992 [D loss: 0.128110, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.651752]\n",
            "(1024, 1)\n",
            "Training Metrics: 1993 [D loss: 0.515705, acc.: 99.90%, op_acc: 83.89%] [G loss: 5.697558]\n",
            "Validating on test set\n",
            "Validation Metrics: 1993 [D loss: 0.195172, acc.: 100.00%, op_acc: 97.36%] [G loss: 5.763130]\n",
            "(1024, 1)\n",
            "Training Metrics: 1994 [D loss: 0.553615, acc.: 99.56%, op_acc: 83.59%] [G loss: 5.706771]\n",
            "Validating on test set\n",
            "Validation Metrics: 1994 [D loss: 0.146360, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.706633]\n",
            "(1024, 1)\n",
            "Training Metrics: 1995 [D loss: 0.511764, acc.: 99.80%, op_acc: 84.38%] [G loss: 6.126223]\n",
            "Validating on test set\n",
            "Validation Metrics: 1995 [D loss: 0.128333, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.113198]\n",
            "(1024, 1)\n",
            "Training Metrics: 1996 [D loss: 0.551316, acc.: 99.66%, op_acc: 82.23%] [G loss: 6.586533]\n",
            "Validating on test set\n",
            "Validation Metrics: 1996 [D loss: 0.123323, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.702431]\n",
            "(1024, 1)\n",
            "Training Metrics: 1997 [D loss: 0.524290, acc.: 99.66%, op_acc: 83.45%] [G loss: 5.891763]\n",
            "Validating on test set\n",
            "Validation Metrics: 1997 [D loss: 0.181068, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.858102]\n",
            "(1024, 1)\n",
            "Training Metrics: 1998 [D loss: 0.515736, acc.: 99.80%, op_acc: 83.74%] [G loss: 6.167242]\n",
            "Validating on test set\n",
            "Validation Metrics: 1998 [D loss: 0.215889, acc.: 100.00%, op_acc: 96.68%] [G loss: 6.366095]\n",
            "(1024, 1)\n",
            "Training Metrics: 1999 [D loss: 0.569929, acc.: 99.71%, op_acc: 81.49%] [G loss: 6.459722]\n",
            "Validating on test set\n",
            "Validation Metrics: 1999 [D loss: 0.258735, acc.: 100.00%, op_acc: 98.34%] [G loss: 6.584649]\n",
            "(1024, 1)\n",
            "Training Metrics: 2000 [D loss: 0.624704, acc.: 99.76%, op_acc: 81.74%] [G loss: 7.072804]\n",
            "Validating on test set\n",
            "Validation Metrics: 2000 [D loss: 0.160835, acc.: 100.00%, op_acc: 98.93%] [G loss: 7.037219]\n",
            "(1024, 1)\n",
            "Training Metrics: 2001 [D loss: 0.599328, acc.: 99.61%, op_acc: 81.15%] [G loss: 6.111187]\n",
            "Validating on test set\n",
            "Validation Metrics: 2001 [D loss: 0.107166, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.034774]\n",
            "(1024, 1)\n",
            "Training Metrics: 2002 [D loss: 0.570984, acc.: 99.76%, op_acc: 83.30%] [G loss: 6.145624]\n",
            "Validating on test set\n",
            "Validation Metrics: 2002 [D loss: 0.154699, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.176219]\n",
            "(1024, 1)\n",
            "Training Metrics: 2003 [D loss: 0.523689, acc.: 99.76%, op_acc: 83.94%] [G loss: 5.841584]\n",
            "Validating on test set\n",
            "Validation Metrics: 2003 [D loss: 0.108748, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.735417]\n",
            "(1024, 1)\n",
            "Training Metrics: 2004 [D loss: 0.498172, acc.: 99.80%, op_acc: 85.01%] [G loss: 5.747270]\n",
            "Validating on test set\n",
            "Validation Metrics: 2004 [D loss: 0.150424, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.803463]\n",
            "(1024, 1)\n",
            "Training Metrics: 2005 [D loss: 0.552356, acc.: 99.61%, op_acc: 82.57%] [G loss: 5.417633]\n",
            "Validating on test set\n",
            "Validation Metrics: 2005 [D loss: 0.107629, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.334713]\n",
            "(1024, 1)\n",
            "Training Metrics: 2006 [D loss: 0.579392, acc.: 99.51%, op_acc: 81.49%] [G loss: 5.533036]\n",
            "Validating on test set\n",
            "Validation Metrics: 2006 [D loss: 0.109810, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.526694]\n",
            "(1024, 1)\n",
            "Training Metrics: 2007 [D loss: 0.515979, acc.: 99.66%, op_acc: 84.42%] [G loss: 5.182324]\n",
            "Validating on test set\n",
            "Validation Metrics: 2007 [D loss: 0.128918, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.162070]\n",
            "(1024, 1)\n",
            "Training Metrics: 2008 [D loss: 0.461277, acc.: 99.90%, op_acc: 85.21%] [G loss: 5.883138]\n",
            "Validating on test set\n",
            "Validation Metrics: 2008 [D loss: 0.340755, acc.: 100.00%, op_acc: 94.04%] [G loss: 6.300199]\n",
            "(1024, 1)\n",
            "Training Metrics: 2009 [D loss: 0.615976, acc.: 99.76%, op_acc: 80.96%] [G loss: 7.779862]\n",
            "Validating on test set\n",
            "Validation Metrics: 2009 [D loss: 0.145411, acc.: 100.00%, op_acc: 99.51%] [G loss: 7.805578]\n",
            "(1024, 1)\n",
            "Training Metrics: 2010 [D loss: 0.555921, acc.: 99.71%, op_acc: 82.86%] [G loss: 7.263314]\n",
            "Validating on test set\n",
            "Validation Metrics: 2010 [D loss: 0.131918, acc.: 100.00%, op_acc: 99.22%] [G loss: 7.253452]\n",
            "(1024, 1)\n",
            "Training Metrics: 2011 [D loss: 0.532045, acc.: 99.56%, op_acc: 84.13%] [G loss: 6.471062]\n",
            "Validating on test set\n",
            "Validation Metrics: 2011 [D loss: 0.142379, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.298918]\n",
            "(1024, 1)\n",
            "Training Metrics: 2012 [D loss: 0.549177, acc.: 99.51%, op_acc: 83.54%] [G loss: 5.663575]\n",
            "Validating on test set\n",
            "Validation Metrics: 2012 [D loss: 0.103567, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.613161]\n",
            "(1024, 1)\n",
            "Training Metrics: 2013 [D loss: 0.514225, acc.: 99.71%, op_acc: 82.96%] [G loss: 5.970685]\n",
            "Validating on test set\n",
            "Validation Metrics: 2013 [D loss: 0.105163, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.985298]\n",
            "(1024, 1)\n",
            "Training Metrics: 2014 [D loss: 0.534537, acc.: 99.71%, op_acc: 82.03%] [G loss: 5.624148]\n",
            "Validating on test set\n",
            "Validation Metrics: 2014 [D loss: 0.102630, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.513710]\n",
            "(1024, 1)\n",
            "Training Metrics: 2015 [D loss: 0.515928, acc.: 99.66%, op_acc: 83.50%] [G loss: 5.815650]\n",
            "Validating on test set\n",
            "Validation Metrics: 2015 [D loss: 0.109603, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.753671]\n",
            "(1024, 1)\n",
            "Training Metrics: 2016 [D loss: 0.519219, acc.: 99.71%, op_acc: 83.25%] [G loss: 5.447787]\n",
            "Validating on test set\n",
            "Validation Metrics: 2016 [D loss: 0.175834, acc.: 100.00%, op_acc: 96.29%] [G loss: 5.614921]\n",
            "(1024, 1)\n",
            "Training Metrics: 2017 [D loss: 0.555317, acc.: 99.76%, op_acc: 82.18%] [G loss: 6.780170]\n",
            "Validating on test set\n",
            "Validation Metrics: 2017 [D loss: 0.103584, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.662452]\n",
            "(1024, 1)\n",
            "Training Metrics: 2018 [D loss: 0.532313, acc.: 99.41%, op_acc: 83.20%] [G loss: 5.854076]\n",
            "Validating on test set\n",
            "Validation Metrics: 2018 [D loss: 0.146704, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.923960]\n",
            "(1024, 1)\n",
            "Training Metrics: 2019 [D loss: 0.540247, acc.: 99.76%, op_acc: 83.54%] [G loss: 6.644075]\n",
            "Validating on test set\n",
            "Validation Metrics: 2019 [D loss: 0.181880, acc.: 100.00%, op_acc: 97.36%] [G loss: 6.665167]\n",
            "(1024, 1)\n",
            "Training Metrics: 2020 [D loss: 0.597477, acc.: 99.80%, op_acc: 81.49%] [G loss: 6.224632]\n",
            "Validating on test set\n",
            "Validation Metrics: 2020 [D loss: 0.142411, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.203780]\n",
            "(1024, 1)\n",
            "Training Metrics: 2021 [D loss: 0.576797, acc.: 99.71%, op_acc: 82.03%] [G loss: 6.395982]\n",
            "Validating on test set\n",
            "Validation Metrics: 2021 [D loss: 0.144467, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.366396]\n",
            "(1024, 1)\n",
            "Training Metrics: 2022 [D loss: 0.521013, acc.: 99.80%, op_acc: 83.50%] [G loss: 6.107753]\n",
            "Validating on test set\n",
            "Validation Metrics: 2022 [D loss: 0.175717, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.043141]\n",
            "(1024, 1)\n",
            "Training Metrics: 2023 [D loss: 0.545020, acc.: 99.66%, op_acc: 84.47%] [G loss: 6.385515]\n",
            "Validating on test set\n",
            "Validation Metrics: 2023 [D loss: 0.147838, acc.: 100.00%, op_acc: 99.32%] [G loss: 6.259069]\n",
            "(1024, 1)\n",
            "Training Metrics: 2024 [D loss: 0.493383, acc.: 99.90%, op_acc: 84.57%] [G loss: 6.011786]\n",
            "Validating on test set\n",
            "Validation Metrics: 2024 [D loss: 0.162631, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.013377]\n",
            "(1024, 1)\n",
            "Training Metrics: 2025 [D loss: 0.512244, acc.: 99.71%, op_acc: 84.52%] [G loss: 6.171472]\n",
            "Validating on test set\n",
            "Validation Metrics: 2025 [D loss: 0.131270, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.317261]\n",
            "(1024, 1)\n",
            "Training Metrics: 2026 [D loss: 0.493702, acc.: 99.66%, op_acc: 84.28%] [G loss: 6.117849]\n",
            "Validating on test set\n",
            "Validation Metrics: 2026 [D loss: 0.435846, acc.: 100.00%, op_acc: 86.04%] [G loss: 6.429220]\n",
            "(1024, 1)\n",
            "Training Metrics: 2027 [D loss: 0.643323, acc.: 99.56%, op_acc: 76.32%] [G loss: 6.020615]\n",
            "Validating on test set\n",
            "Validation Metrics: 2027 [D loss: 0.278238, acc.: 100.00%, op_acc: 96.58%] [G loss: 6.151464]\n",
            "(1024, 1)\n",
            "Training Metrics: 2028 [D loss: 0.597796, acc.: 99.61%, op_acc: 82.67%] [G loss: 5.824115]\n",
            "Validating on test set\n",
            "Validation Metrics: 2028 [D loss: 0.255843, acc.: 100.00%, op_acc: 99.02%] [G loss: 5.673303]\n",
            "(1024, 1)\n",
            "Training Metrics: 2029 [D loss: 0.571369, acc.: 99.51%, op_acc: 83.79%] [G loss: 5.996783]\n",
            "Validating on test set\n",
            "Validation Metrics: 2029 [D loss: 0.252701, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.988405]\n",
            "(1024, 1)\n",
            "Training Metrics: 2030 [D loss: 0.609108, acc.: 99.61%, op_acc: 82.67%] [G loss: 6.515878]\n",
            "Validating on test set\n",
            "Validation Metrics: 2030 [D loss: 0.165293, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.502440]\n",
            "(1024, 1)\n",
            "Training Metrics: 2031 [D loss: 0.548116, acc.: 99.66%, op_acc: 83.50%] [G loss: 6.438737]\n",
            "Validating on test set\n",
            "Validation Metrics: 2031 [D loss: 0.195623, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.483971]\n",
            "(1024, 1)\n",
            "Training Metrics: 2032 [D loss: 0.557158, acc.: 99.85%, op_acc: 83.40%] [G loss: 6.209704]\n",
            "Validating on test set\n",
            "Validation Metrics: 2032 [D loss: 0.163203, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.166789]\n",
            "(1024, 1)\n",
            "Training Metrics: 2033 [D loss: 0.586494, acc.: 99.71%, op_acc: 83.40%] [G loss: 6.212979]\n",
            "Validating on test set\n",
            "Validation Metrics: 2033 [D loss: 0.159568, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.146307]\n",
            "(1024, 1)\n",
            "Training Metrics: 2034 [D loss: 0.567574, acc.: 99.66%, op_acc: 82.37%] [G loss: 5.839739]\n",
            "Validating on test set\n",
            "Validation Metrics: 2034 [D loss: 0.148171, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.875789]\n",
            "(1024, 1)\n",
            "Training Metrics: 2035 [D loss: 0.526321, acc.: 99.61%, op_acc: 84.42%] [G loss: 5.938884]\n",
            "Validating on test set\n",
            "Validation Metrics: 2035 [D loss: 0.166371, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.878760]\n",
            "(1024, 1)\n",
            "Training Metrics: 2036 [D loss: 0.561413, acc.: 99.76%, op_acc: 81.45%] [G loss: 5.809873]\n",
            "Validating on test set\n",
            "Validation Metrics: 2036 [D loss: 0.143846, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.836592]\n",
            "(1024, 1)\n",
            "Training Metrics: 2037 [D loss: 0.536280, acc.: 99.80%, op_acc: 84.13%] [G loss: 6.300084]\n",
            "Validating on test set\n",
            "Validation Metrics: 2037 [D loss: 0.220186, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.376753]\n",
            "(1024, 1)\n",
            "Training Metrics: 2038 [D loss: 0.586727, acc.: 99.76%, op_acc: 82.67%] [G loss: 6.100753]\n",
            "Validating on test set\n",
            "Validation Metrics: 2038 [D loss: 0.133145, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.119447]\n",
            "(1024, 1)\n",
            "Training Metrics: 2039 [D loss: 0.541921, acc.: 99.90%, op_acc: 82.32%] [G loss: 6.041545]\n",
            "Validating on test set\n",
            "Validation Metrics: 2039 [D loss: 0.130643, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.954718]\n",
            "(1024, 1)\n",
            "Training Metrics: 2040 [D loss: 0.499192, acc.: 99.80%, op_acc: 83.89%] [G loss: 5.843540]\n",
            "Validating on test set\n",
            "Validation Metrics: 2040 [D loss: 0.132112, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.831426]\n",
            "(1024, 1)\n",
            "Training Metrics: 2041 [D loss: 0.490712, acc.: 99.76%, op_acc: 84.86%] [G loss: 5.963623]\n",
            "Validating on test set\n",
            "Validation Metrics: 2041 [D loss: 0.121204, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.965928]\n",
            "(1024, 1)\n",
            "Training Metrics: 2042 [D loss: 0.506451, acc.: 99.90%, op_acc: 83.50%] [G loss: 6.345714]\n",
            "Validating on test set\n",
            "Validation Metrics: 2042 [D loss: 0.119460, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.307623]\n",
            "(1024, 1)\n",
            "Training Metrics: 2043 [D loss: 0.510643, acc.: 99.85%, op_acc: 83.50%] [G loss: 6.260240]\n",
            "Validating on test set\n",
            "Validation Metrics: 2043 [D loss: 0.133132, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.127506]\n",
            "(1024, 1)\n",
            "Training Metrics: 2044 [D loss: 0.529590, acc.: 99.66%, op_acc: 84.13%] [G loss: 6.219238]\n",
            "Validating on test set\n",
            "Validation Metrics: 2044 [D loss: 0.145908, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.120502]\n",
            "(1024, 1)\n",
            "Training Metrics: 2045 [D loss: 0.522189, acc.: 99.80%, op_acc: 82.57%] [G loss: 6.142629]\n",
            "Validating on test set\n",
            "Validation Metrics: 2045 [D loss: 0.098695, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.100185]\n",
            "(1024, 1)\n",
            "Training Metrics: 2046 [D loss: 0.522058, acc.: 99.46%, op_acc: 83.40%] [G loss: 5.605449]\n",
            "Validating on test set\n",
            "Validation Metrics: 2046 [D loss: 0.114920, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.637614]\n",
            "(1024, 1)\n",
            "Training Metrics: 2047 [D loss: 0.495765, acc.: 99.80%, op_acc: 84.08%] [G loss: 5.919885]\n",
            "Validating on test set\n",
            "Validation Metrics: 2047 [D loss: 0.099737, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.895786]\n",
            "(1024, 1)\n",
            "Training Metrics: 2048 [D loss: 0.518959, acc.: 99.61%, op_acc: 83.01%] [G loss: 5.751737]\n",
            "Validating on test set\n",
            "Validation Metrics: 2048 [D loss: 0.105762, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.724338]\n",
            "(1024, 1)\n",
            "Training Metrics: 2049 [D loss: 0.501378, acc.: 99.85%, op_acc: 83.64%] [G loss: 5.674136]\n",
            "Validating on test set\n",
            "Validation Metrics: 2049 [D loss: 0.100127, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.629103]\n",
            "(1024, 1)\n",
            "Training Metrics: 2050 [D loss: 0.532472, acc.: 99.80%, op_acc: 84.23%] [G loss: 5.533133]\n",
            "Validating on test set\n",
            "Validation Metrics: 2050 [D loss: 0.114234, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.549672]\n",
            "(1024, 1)\n",
            "Training Metrics: 2051 [D loss: 0.472093, acc.: 99.95%, op_acc: 85.16%] [G loss: 5.961733]\n",
            "Validating on test set\n",
            "Validation Metrics: 2051 [D loss: 0.110778, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.989137]\n",
            "(1024, 1)\n",
            "Training Metrics: 2052 [D loss: 0.535071, acc.: 99.71%, op_acc: 83.35%] [G loss: 5.645326]\n",
            "Validating on test set\n",
            "Validation Metrics: 2052 [D loss: 0.136220, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.636113]\n",
            "(1024, 1)\n",
            "Training Metrics: 2053 [D loss: 0.539018, acc.: 99.85%, op_acc: 84.33%] [G loss: 5.945840]\n",
            "Validating on test set\n",
            "Validation Metrics: 2053 [D loss: 0.092877, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.903284]\n",
            "(1024, 1)\n",
            "Training Metrics: 2054 [D loss: 0.544347, acc.: 99.76%, op_acc: 82.03%] [G loss: 5.840673]\n",
            "Validating on test set\n",
            "Validation Metrics: 2054 [D loss: 0.081978, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.854392]\n",
            "(1024, 1)\n",
            "Training Metrics: 2055 [D loss: 0.498989, acc.: 99.90%, op_acc: 82.08%] [G loss: 5.769079]\n",
            "Validating on test set\n",
            "Validation Metrics: 2055 [D loss: 0.105067, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.714807]\n",
            "(1024, 1)\n",
            "Training Metrics: 2056 [D loss: 0.522058, acc.: 99.71%, op_acc: 83.79%] [G loss: 5.967967]\n",
            "Validating on test set\n",
            "Validation Metrics: 2056 [D loss: 0.103849, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.936143]\n",
            "(1024, 1)\n",
            "Training Metrics: 2057 [D loss: 0.498424, acc.: 99.76%, op_acc: 82.76%] [G loss: 6.110847]\n",
            "Validating on test set\n",
            "Validation Metrics: 2057 [D loss: 0.097812, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.087960]\n",
            "(1024, 1)\n",
            "Training Metrics: 2058 [D loss: 0.523819, acc.: 99.71%, op_acc: 83.79%] [G loss: 5.778649]\n",
            "Validating on test set\n",
            "Validation Metrics: 2058 [D loss: 0.101173, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.778963]\n",
            "(1024, 1)\n",
            "Training Metrics: 2059 [D loss: 0.564344, acc.: 99.80%, op_acc: 81.64%] [G loss: 6.126211]\n",
            "Validating on test set\n",
            "Validation Metrics: 2059 [D loss: 0.087392, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.146739]\n",
            "(1024, 1)\n",
            "Training Metrics: 2060 [D loss: 0.505108, acc.: 99.61%, op_acc: 83.84%] [G loss: 5.422132]\n",
            "Validating on test set\n",
            "Validation Metrics: 2060 [D loss: 0.156328, acc.: 100.00%, op_acc: 98.54%] [G loss: 5.464298]\n",
            "(1024, 1)\n",
            "Training Metrics: 2061 [D loss: 0.524234, acc.: 99.66%, op_acc: 83.79%] [G loss: 5.946092]\n",
            "Validating on test set\n",
            "Validation Metrics: 2061 [D loss: 0.082287, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.849745]\n",
            "(1024, 1)\n",
            "Training Metrics: 2062 [D loss: 0.515964, acc.: 99.71%, op_acc: 82.81%] [G loss: 5.433959]\n",
            "Validating on test set\n",
            "Validation Metrics: 2062 [D loss: 0.089805, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.429970]\n",
            "(1024, 1)\n",
            "Training Metrics: 2063 [D loss: 0.532003, acc.: 99.66%, op_acc: 83.20%] [G loss: 5.488999]\n",
            "Validating on test set\n",
            "Validation Metrics: 2063 [D loss: 0.171819, acc.: 100.00%, op_acc: 98.44%] [G loss: 5.495026]\n",
            "(1024, 1)\n",
            "Training Metrics: 2064 [D loss: 0.532262, acc.: 99.76%, op_acc: 83.84%] [G loss: 5.738558]\n",
            "Validating on test set\n",
            "Validation Metrics: 2064 [D loss: 0.081556, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.709223]\n",
            "(1024, 1)\n",
            "Training Metrics: 2065 [D loss: 0.513741, acc.: 99.66%, op_acc: 83.25%] [G loss: 5.647186]\n",
            "Validating on test set\n",
            "Validation Metrics: 2065 [D loss: 0.090153, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.662866]\n",
            "(1024, 1)\n",
            "Training Metrics: 2066 [D loss: 0.516588, acc.: 99.76%, op_acc: 83.45%] [G loss: 5.660976]\n",
            "Validating on test set\n",
            "Validation Metrics: 2066 [D loss: 0.091108, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.565858]\n",
            "(1024, 1)\n",
            "Training Metrics: 2067 [D loss: 0.461040, acc.: 99.95%, op_acc: 84.91%] [G loss: 6.364711]\n",
            "Validating on test set\n",
            "Validation Metrics: 2067 [D loss: 0.093780, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.469316]\n",
            "(1024, 1)\n",
            "Training Metrics: 2068 [D loss: 0.510048, acc.: 99.61%, op_acc: 83.50%] [G loss: 5.586217]\n",
            "Validating on test set\n",
            "Validation Metrics: 2068 [D loss: 0.083502, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.451925]\n",
            "(1024, 1)\n",
            "Training Metrics: 2069 [D loss: 0.478055, acc.: 99.76%, op_acc: 85.40%] [G loss: 5.792734]\n",
            "Validating on test set\n",
            "Validation Metrics: 2069 [D loss: 0.088506, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.909049]\n",
            "(1024, 1)\n",
            "Training Metrics: 2070 [D loss: 0.483727, acc.: 99.76%, op_acc: 85.11%] [G loss: 5.901255]\n",
            "Validating on test set\n",
            "Validation Metrics: 2070 [D loss: 0.100730, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.867530]\n",
            "(1024, 1)\n",
            "Training Metrics: 2071 [D loss: 0.478046, acc.: 99.90%, op_acc: 83.79%] [G loss: 6.146384]\n",
            "Validating on test set\n",
            "Validation Metrics: 2071 [D loss: 0.085871, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.183690]\n",
            "(1024, 1)\n",
            "Training Metrics: 2072 [D loss: 0.448350, acc.: 99.85%, op_acc: 85.55%] [G loss: 6.255120]\n",
            "Validating on test set\n",
            "Validation Metrics: 2072 [D loss: 0.077765, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.223990]\n",
            "(1024, 1)\n",
            "Training Metrics: 2073 [D loss: 0.488923, acc.: 99.71%, op_acc: 84.77%] [G loss: 5.925889]\n",
            "Validating on test set\n",
            "Validation Metrics: 2073 [D loss: 0.094618, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.944443]\n",
            "(1024, 1)\n",
            "Training Metrics: 2074 [D loss: 0.442062, acc.: 99.90%, op_acc: 84.52%] [G loss: 6.181165]\n",
            "Validating on test set\n",
            "Validation Metrics: 2074 [D loss: 0.152401, acc.: 100.00%, op_acc: 98.14%] [G loss: 6.265527]\n",
            "(1024, 1)\n",
            "Training Metrics: 2075 [D loss: 0.467120, acc.: 99.76%, op_acc: 85.45%] [G loss: 5.932049]\n",
            "Validating on test set\n",
            "Validation Metrics: 2075 [D loss: 0.093511, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.867463]\n",
            "(1024, 1)\n",
            "Training Metrics: 2076 [D loss: 0.466042, acc.: 99.80%, op_acc: 84.42%] [G loss: 6.007308]\n",
            "Validating on test set\n",
            "Validation Metrics: 2076 [D loss: 0.100380, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.967735]\n",
            "(1024, 1)\n",
            "Training Metrics: 2077 [D loss: 0.479818, acc.: 99.80%, op_acc: 84.18%] [G loss: 6.164384]\n",
            "Validating on test set\n",
            "Validation Metrics: 2077 [D loss: 0.121711, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.107421]\n",
            "(1024, 1)\n",
            "Training Metrics: 2078 [D loss: 0.490924, acc.: 99.76%, op_acc: 84.91%] [G loss: 5.604809]\n",
            "Validating on test set\n",
            "Validation Metrics: 2078 [D loss: 0.081266, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.571383]\n",
            "(1024, 1)\n",
            "Training Metrics: 2079 [D loss: 0.446362, acc.: 99.80%, op_acc: 85.50%] [G loss: 6.152125]\n",
            "Validating on test set\n",
            "Validation Metrics: 2079 [D loss: 0.156455, acc.: 100.00%, op_acc: 97.36%] [G loss: 6.312809]\n",
            "(1024, 1)\n",
            "Training Metrics: 2080 [D loss: 0.502829, acc.: 99.80%, op_acc: 83.69%] [G loss: 5.712209]\n",
            "Validating on test set\n",
            "Validation Metrics: 2080 [D loss: 0.101229, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.720553]\n",
            "(1024, 1)\n",
            "Training Metrics: 2081 [D loss: 0.501101, acc.: 99.76%, op_acc: 83.74%] [G loss: 6.087219]\n",
            "Validating on test set\n",
            "Validation Metrics: 2081 [D loss: 0.076224, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.089071]\n",
            "(1024, 1)\n",
            "Training Metrics: 2082 [D loss: 0.475503, acc.: 99.61%, op_acc: 84.47%] [G loss: 5.398133]\n",
            "Validating on test set\n",
            "Validation Metrics: 2082 [D loss: 0.094845, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.362798]\n",
            "(1024, 1)\n",
            "Training Metrics: 2083 [D loss: 0.474507, acc.: 99.76%, op_acc: 84.18%] [G loss: 5.962530]\n",
            "Validating on test set\n",
            "Validation Metrics: 2083 [D loss: 0.087285, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.949393]\n",
            "(1024, 1)\n",
            "Training Metrics: 2084 [D loss: 0.487896, acc.: 99.85%, op_acc: 83.59%] [G loss: 5.738558]\n",
            "Validating on test set\n",
            "Validation Metrics: 2084 [D loss: 0.130129, acc.: 100.00%, op_acc: 98.24%] [G loss: 5.680344]\n",
            "(1024, 1)\n",
            "Training Metrics: 2085 [D loss: 0.489038, acc.: 99.90%, op_acc: 84.52%] [G loss: 5.835561]\n",
            "Validating on test set\n",
            "Validation Metrics: 2085 [D loss: 0.099712, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.820606]\n",
            "(1024, 1)\n",
            "Training Metrics: 2086 [D loss: 0.478220, acc.: 99.61%, op_acc: 84.96%] [G loss: 5.698067]\n",
            "Validating on test set\n",
            "Validation Metrics: 2086 [D loss: 0.084272, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.683611]\n",
            "(1024, 1)\n",
            "Training Metrics: 2087 [D loss: 0.490997, acc.: 99.76%, op_acc: 84.57%] [G loss: 6.152390]\n",
            "Validating on test set\n",
            "Validation Metrics: 2087 [D loss: 0.074530, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.178929]\n",
            "(1024, 1)\n",
            "Training Metrics: 2088 [D loss: 0.474879, acc.: 99.76%, op_acc: 83.89%] [G loss: 5.900739]\n",
            "Validating on test set\n",
            "Validation Metrics: 2088 [D loss: 0.074452, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.857167]\n",
            "(1024, 1)\n",
            "Training Metrics: 2089 [D loss: 0.450069, acc.: 99.85%, op_acc: 85.06%] [G loss: 5.888803]\n",
            "Validating on test set\n",
            "Validation Metrics: 2089 [D loss: 0.082334, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.883158]\n",
            "(1024, 1)\n",
            "Training Metrics: 2090 [D loss: 0.485331, acc.: 99.85%, op_acc: 82.96%] [G loss: 6.008196]\n",
            "Validating on test set\n",
            "Validation Metrics: 2090 [D loss: 0.099685, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.974038]\n",
            "(1024, 1)\n",
            "Training Metrics: 2091 [D loss: 0.512884, acc.: 99.61%, op_acc: 84.23%] [G loss: 5.511396]\n",
            "Validating on test set\n",
            "Validation Metrics: 2091 [D loss: 0.193566, acc.: 100.00%, op_acc: 96.48%] [G loss: 5.582442]\n",
            "(1024, 1)\n",
            "Training Metrics: 2092 [D loss: 0.579487, acc.: 99.85%, op_acc: 81.10%] [G loss: 6.494052]\n",
            "Validating on test set\n",
            "Validation Metrics: 2092 [D loss: 0.178691, acc.: 100.00%, op_acc: 96.29%] [G loss: 6.642475]\n",
            "(1024, 1)\n",
            "Training Metrics: 2093 [D loss: 0.532929, acc.: 99.95%, op_acc: 82.76%] [G loss: 6.149714]\n",
            "Validating on test set\n",
            "Validation Metrics: 2093 [D loss: 0.083374, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.115739]\n",
            "(1024, 1)\n",
            "Training Metrics: 2094 [D loss: 0.498164, acc.: 99.90%, op_acc: 84.33%] [G loss: 6.609861]\n",
            "Validating on test set\n",
            "Validation Metrics: 2094 [D loss: 0.081861, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.547001]\n",
            "(1024, 1)\n",
            "Training Metrics: 2095 [D loss: 0.480382, acc.: 99.76%, op_acc: 83.64%] [G loss: 6.130939]\n",
            "Validating on test set\n",
            "Validation Metrics: 2095 [D loss: 0.078918, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.096560]\n",
            "(1024, 1)\n",
            "Training Metrics: 2096 [D loss: 0.472174, acc.: 99.71%, op_acc: 84.62%] [G loss: 5.879538]\n",
            "Validating on test set\n",
            "Validation Metrics: 2096 [D loss: 0.091002, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.798345]\n",
            "(1024, 1)\n",
            "Training Metrics: 2097 [D loss: 0.513311, acc.: 99.71%, op_acc: 83.89%] [G loss: 5.946719]\n",
            "Validating on test set\n",
            "Validation Metrics: 2097 [D loss: 0.084438, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.926991]\n",
            "(1024, 1)\n",
            "Training Metrics: 2098 [D loss: 0.492310, acc.: 99.76%, op_acc: 84.28%] [G loss: 5.944158]\n",
            "Validating on test set\n",
            "Validation Metrics: 2098 [D loss: 0.082861, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.919941]\n",
            "(1024, 1)\n",
            "Training Metrics: 2099 [D loss: 0.473729, acc.: 99.90%, op_acc: 84.57%] [G loss: 6.231310]\n",
            "Validating on test set\n",
            "Validation Metrics: 2099 [D loss: 0.120447, acc.: 100.00%, op_acc: 98.44%] [G loss: 6.293877]\n",
            "(1024, 1)\n",
            "Training Metrics: 2100 [D loss: 0.531654, acc.: 99.66%, op_acc: 84.47%] [G loss: 5.764194]\n",
            "Validating on test set\n",
            "Validation Metrics: 2100 [D loss: 0.102851, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.801983]\n",
            "(1024, 1)\n",
            "Training Metrics: 2101 [D loss: 0.471844, acc.: 99.95%, op_acc: 84.13%] [G loss: 6.088368]\n",
            "Validating on test set\n",
            "Validation Metrics: 2101 [D loss: 0.079851, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.004969]\n",
            "(1024, 1)\n",
            "Training Metrics: 2102 [D loss: 0.455145, acc.: 100.00%, op_acc: 85.99%] [G loss: 5.889789]\n",
            "Validating on test set\n",
            "Validation Metrics: 2102 [D loss: 0.176610, acc.: 100.00%, op_acc: 96.68%] [G loss: 5.892936]\n",
            "(1024, 1)\n",
            "Training Metrics: 2103 [D loss: 0.496880, acc.: 99.71%, op_acc: 83.35%] [G loss: 5.981483]\n",
            "Validating on test set\n",
            "Validation Metrics: 2103 [D loss: 0.132586, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.927810]\n",
            "(1024, 1)\n",
            "Training Metrics: 2104 [D loss: 0.511544, acc.: 99.71%, op_acc: 84.33%] [G loss: 5.758697]\n",
            "Validating on test set\n",
            "Validation Metrics: 2104 [D loss: 0.168713, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.862478]\n",
            "(1024, 1)\n",
            "Training Metrics: 2105 [D loss: 0.537296, acc.: 99.80%, op_acc: 84.03%] [G loss: 5.927879]\n",
            "Validating on test set\n",
            "Validation Metrics: 2105 [D loss: 0.091595, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.693049]\n",
            "(1024, 1)\n",
            "Training Metrics: 2106 [D loss: 0.500552, acc.: 99.80%, op_acc: 83.45%] [G loss: 5.933884]\n",
            "Validating on test set\n",
            "Validation Metrics: 2106 [D loss: 0.067772, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.088283]\n",
            "(1024, 1)\n",
            "Training Metrics: 2107 [D loss: 0.439139, acc.: 99.61%, op_acc: 85.55%] [G loss: 5.851641]\n",
            "Validating on test set\n",
            "Validation Metrics: 2107 [D loss: 0.126591, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.796724]\n",
            "(1024, 1)\n",
            "Training Metrics: 2108 [D loss: 0.528974, acc.: 99.85%, op_acc: 82.62%] [G loss: 5.961876]\n",
            "Validating on test set\n",
            "Validation Metrics: 2108 [D loss: 0.106475, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.835685]\n",
            "(1024, 1)\n",
            "Training Metrics: 2109 [D loss: 0.530274, acc.: 99.80%, op_acc: 82.13%] [G loss: 5.705206]\n",
            "Validating on test set\n",
            "Validation Metrics: 2109 [D loss: 0.096854, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.603501]\n",
            "(1024, 1)\n",
            "Training Metrics: 2110 [D loss: 0.470071, acc.: 99.90%, op_acc: 85.06%] [G loss: 5.964136]\n",
            "Validating on test set\n",
            "Validation Metrics: 2110 [D loss: 0.074775, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.940237]\n",
            "(1024, 1)\n",
            "Training Metrics: 2111 [D loss: 0.465293, acc.: 99.90%, op_acc: 84.91%] [G loss: 6.321998]\n",
            "Validating on test set\n",
            "Validation Metrics: 2111 [D loss: 0.089575, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.281972]\n",
            "(1024, 1)\n",
            "Training Metrics: 2112 [D loss: 0.469639, acc.: 99.71%, op_acc: 84.72%] [G loss: 6.212936]\n",
            "Validating on test set\n",
            "Validation Metrics: 2112 [D loss: 0.083208, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.189850]\n",
            "(1024, 1)\n",
            "Training Metrics: 2113 [D loss: 0.477795, acc.: 99.90%, op_acc: 83.94%] [G loss: 5.920446]\n",
            "Validating on test set\n",
            "Validation Metrics: 2113 [D loss: 0.089425, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.024879]\n",
            "(1024, 1)\n",
            "Training Metrics: 2114 [D loss: 0.521916, acc.: 99.76%, op_acc: 83.35%] [G loss: 6.251601]\n",
            "Validating on test set\n",
            "Validation Metrics: 2114 [D loss: 0.111778, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.406012]\n",
            "(1024, 1)\n",
            "Training Metrics: 2115 [D loss: 0.499018, acc.: 99.76%, op_acc: 84.81%] [G loss: 5.973680]\n",
            "Validating on test set\n",
            "Validation Metrics: 2115 [D loss: 0.087865, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.756867]\n",
            "(1024, 1)\n",
            "Training Metrics: 2116 [D loss: 0.465539, acc.: 99.76%, op_acc: 84.96%] [G loss: 5.807596]\n",
            "Validating on test set\n",
            "Validation Metrics: 2116 [D loss: 0.078229, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.038002]\n",
            "(1024, 1)\n",
            "Training Metrics: 2117 [D loss: 0.474455, acc.: 99.76%, op_acc: 84.52%] [G loss: 6.509533]\n",
            "Validating on test set\n",
            "Validation Metrics: 2117 [D loss: 0.082400, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.683395]\n",
            "(1024, 1)\n",
            "Training Metrics: 2118 [D loss: 0.489393, acc.: 99.66%, op_acc: 84.38%] [G loss: 5.861981]\n",
            "Validating on test set\n",
            "Validation Metrics: 2118 [D loss: 0.099115, acc.: 100.00%, op_acc: 99.32%] [G loss: 5.797562]\n",
            "(1024, 1)\n",
            "Training Metrics: 2119 [D loss: 0.497445, acc.: 99.90%, op_acc: 83.50%] [G loss: 5.856383]\n",
            "Validating on test set\n",
            "Validation Metrics: 2119 [D loss: 0.090340, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.621220]\n",
            "(1024, 1)\n",
            "Training Metrics: 2120 [D loss: 0.455633, acc.: 99.80%, op_acc: 84.96%] [G loss: 5.522201]\n",
            "Validating on test set\n",
            "Validation Metrics: 2120 [D loss: 0.101782, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.430672]\n",
            "(1024, 1)\n",
            "Training Metrics: 2121 [D loss: 0.482154, acc.: 99.80%, op_acc: 84.38%] [G loss: 5.827213]\n",
            "Validating on test set\n",
            "Validation Metrics: 2121 [D loss: 0.077657, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.945985]\n",
            "(1024, 1)\n",
            "Training Metrics: 2122 [D loss: 0.474874, acc.: 100.00%, op_acc: 84.52%] [G loss: 6.432868]\n",
            "Validating on test set\n",
            "Validation Metrics: 2122 [D loss: 0.090640, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.355178]\n",
            "(1024, 1)\n",
            "Training Metrics: 2123 [D loss: 0.492667, acc.: 99.66%, op_acc: 84.86%] [G loss: 5.393123]\n",
            "Validating on test set\n",
            "Validation Metrics: 2123 [D loss: 0.100160, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.483110]\n",
            "(1024, 1)\n",
            "Training Metrics: 2124 [D loss: 0.497732, acc.: 99.85%, op_acc: 84.77%] [G loss: 6.279088]\n",
            "Validating on test set\n",
            "Validation Metrics: 2124 [D loss: 0.073657, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.166261]\n",
            "(1024, 1)\n",
            "Training Metrics: 2125 [D loss: 0.488405, acc.: 99.76%, op_acc: 83.50%] [G loss: 5.690598]\n",
            "Validating on test set\n",
            "Validation Metrics: 2125 [D loss: 0.079206, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.720573]\n",
            "(1024, 1)\n",
            "Training Metrics: 2126 [D loss: 0.495790, acc.: 99.76%, op_acc: 84.18%] [G loss: 5.961481]\n",
            "Validating on test set\n",
            "Validation Metrics: 2126 [D loss: 0.081725, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.922428]\n",
            "(1024, 1)\n",
            "Training Metrics: 2127 [D loss: 0.455059, acc.: 99.80%, op_acc: 85.16%] [G loss: 5.934638]\n",
            "Validating on test set\n",
            "Validation Metrics: 2127 [D loss: 0.072006, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.912340]\n",
            "(1024, 1)\n",
            "Training Metrics: 2128 [D loss: 0.463075, acc.: 99.76%, op_acc: 83.74%] [G loss: 6.286765]\n",
            "Validating on test set\n",
            "Validation Metrics: 2128 [D loss: 0.084454, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.410257]\n",
            "(1024, 1)\n",
            "Training Metrics: 2129 [D loss: 0.511236, acc.: 99.85%, op_acc: 83.69%] [G loss: 6.006646]\n",
            "Validating on test set\n",
            "Validation Metrics: 2129 [D loss: 0.081439, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.053482]\n",
            "(1024, 1)\n",
            "Training Metrics: 2130 [D loss: 0.495146, acc.: 99.61%, op_acc: 84.47%] [G loss: 5.982131]\n",
            "Validating on test set\n",
            "Validation Metrics: 2130 [D loss: 0.090038, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.869407]\n",
            "(1024, 1)\n",
            "Training Metrics: 2131 [D loss: 0.469998, acc.: 99.90%, op_acc: 85.25%] [G loss: 6.045409]\n",
            "Validating on test set\n",
            "Validation Metrics: 2131 [D loss: 0.078435, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.914311]\n",
            "(1024, 1)\n",
            "Training Metrics: 2132 [D loss: 0.495434, acc.: 99.56%, op_acc: 85.01%] [G loss: 5.595766]\n",
            "Validating on test set\n",
            "Validation Metrics: 2132 [D loss: 0.090521, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.611249]\n",
            "(1024, 1)\n",
            "Training Metrics: 2133 [D loss: 0.504345, acc.: 99.71%, op_acc: 83.98%] [G loss: 5.901927]\n",
            "Validating on test set\n",
            "Validation Metrics: 2133 [D loss: 0.071473, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.922174]\n",
            "(1024, 1)\n",
            "Training Metrics: 2134 [D loss: 0.498159, acc.: 99.61%, op_acc: 82.96%] [G loss: 5.624181]\n",
            "Validating on test set\n",
            "Validation Metrics: 2134 [D loss: 0.099013, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.606327]\n",
            "(1024, 1)\n",
            "Training Metrics: 2135 [D loss: 0.538090, acc.: 99.85%, op_acc: 83.15%] [G loss: 5.917820]\n",
            "Validating on test set\n",
            "Validation Metrics: 2135 [D loss: 0.104771, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.873221]\n",
            "(1024, 1)\n",
            "Training Metrics: 2136 [D loss: 0.548571, acc.: 99.76%, op_acc: 81.69%] [G loss: 5.783007]\n",
            "Validating on test set\n",
            "Validation Metrics: 2136 [D loss: 0.096039, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.831607]\n",
            "(1024, 1)\n",
            "Training Metrics: 2137 [D loss: 0.505113, acc.: 99.85%, op_acc: 84.72%] [G loss: 5.915652]\n",
            "Validating on test set\n",
            "Validation Metrics: 2137 [D loss: 0.165364, acc.: 100.00%, op_acc: 97.17%] [G loss: 6.136734]\n",
            "(1024, 1)\n",
            "Training Metrics: 2138 [D loss: 0.514256, acc.: 99.80%, op_acc: 83.74%] [G loss: 5.914763]\n",
            "Validating on test set\n",
            "Validation Metrics: 2138 [D loss: 0.122277, acc.: 100.00%, op_acc: 99.22%] [G loss: 6.049186]\n",
            "(1024, 1)\n",
            "Training Metrics: 2139 [D loss: 0.514661, acc.: 99.80%, op_acc: 84.33%] [G loss: 6.005637]\n",
            "Validating on test set\n",
            "Validation Metrics: 2139 [D loss: 0.159077, acc.: 100.00%, op_acc: 97.56%] [G loss: 6.127326]\n",
            "(1024, 1)\n",
            "Training Metrics: 2140 [D loss: 0.517392, acc.: 99.90%, op_acc: 84.33%] [G loss: 7.747548]\n",
            "Validating on test set\n",
            "Validation Metrics: 2140 [D loss: 0.074667, acc.: 100.00%, op_acc: 99.71%] [G loss: 7.484951]\n",
            "(1024, 1)\n",
            "Training Metrics: 2141 [D loss: 0.489081, acc.: 99.76%, op_acc: 83.15%] [G loss: 7.228081]\n",
            "Validating on test set\n",
            "Validation Metrics: 2141 [D loss: 0.134679, acc.: 100.00%, op_acc: 98.05%] [G loss: 7.175918]\n",
            "(1024, 1)\n",
            "Training Metrics: 2142 [D loss: 0.481949, acc.: 99.80%, op_acc: 83.84%] [G loss: 6.912681]\n",
            "Validating on test set\n",
            "Validation Metrics: 2142 [D loss: 0.072223, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.845969]\n",
            "(1024, 1)\n",
            "Training Metrics: 2143 [D loss: 0.496542, acc.: 99.76%, op_acc: 84.42%] [G loss: 6.714695]\n",
            "Validating on test set\n",
            "Validation Metrics: 2143 [D loss: 0.073942, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.659198]\n",
            "(1024, 1)\n",
            "Training Metrics: 2144 [D loss: 0.453508, acc.: 99.80%, op_acc: 84.86%] [G loss: 6.238412]\n",
            "Validating on test set\n",
            "Validation Metrics: 2144 [D loss: 0.076165, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.281683]\n",
            "(1024, 1)\n",
            "Training Metrics: 2145 [D loss: 0.510633, acc.: 99.90%, op_acc: 83.94%] [G loss: 5.906563]\n",
            "Validating on test set\n",
            "Validation Metrics: 2145 [D loss: 0.074656, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.917125]\n",
            "(1024, 1)\n",
            "Training Metrics: 2146 [D loss: 0.524558, acc.: 99.85%, op_acc: 83.98%] [G loss: 6.438390]\n",
            "Validating on test set\n",
            "Validation Metrics: 2146 [D loss: 0.071631, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.313505]\n",
            "(1024, 1)\n",
            "Training Metrics: 2147 [D loss: 0.476761, acc.: 99.76%, op_acc: 84.28%] [G loss: 5.840754]\n",
            "Validating on test set\n",
            "Validation Metrics: 2147 [D loss: 0.086562, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.897245]\n",
            "(1024, 1)\n",
            "Training Metrics: 2148 [D loss: 0.501579, acc.: 99.76%, op_acc: 82.96%] [G loss: 6.080999]\n",
            "Validating on test set\n",
            "Validation Metrics: 2148 [D loss: 0.072852, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.167133]\n",
            "(1024, 1)\n",
            "Training Metrics: 2149 [D loss: 0.495405, acc.: 99.85%, op_acc: 84.62%] [G loss: 6.208670]\n",
            "Validating on test set\n",
            "Validation Metrics: 2149 [D loss: 0.077498, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.020554]\n",
            "(1024, 1)\n",
            "Training Metrics: 2150 [D loss: 0.472010, acc.: 99.95%, op_acc: 84.62%] [G loss: 5.873667]\n",
            "Validating on test set\n",
            "Validation Metrics: 2150 [D loss: 0.069014, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.828322]\n",
            "(1024, 1)\n",
            "Training Metrics: 2151 [D loss: 0.403662, acc.: 99.95%, op_acc: 86.18%] [G loss: 6.200327]\n",
            "Validating on test set\n",
            "Validation Metrics: 2151 [D loss: 0.061364, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.258192]\n",
            "(1024, 1)\n",
            "Training Metrics: 2152 [D loss: 0.483874, acc.: 99.41%, op_acc: 84.81%] [G loss: 5.553463]\n",
            "Validating on test set\n",
            "Validation Metrics: 2152 [D loss: 0.088635, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.734777]\n",
            "(1024, 1)\n",
            "Training Metrics: 2153 [D loss: 0.459200, acc.: 99.80%, op_acc: 85.99%] [G loss: 6.023994]\n",
            "Validating on test set\n",
            "Validation Metrics: 2153 [D loss: 0.071348, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.836472]\n",
            "(1024, 1)\n",
            "Training Metrics: 2154 [D loss: 0.458061, acc.: 99.90%, op_acc: 84.57%] [G loss: 5.995439]\n",
            "Validating on test set\n",
            "Validation Metrics: 2154 [D loss: 0.065393, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.940741]\n",
            "(1024, 1)\n",
            "Training Metrics: 2155 [D loss: 0.438547, acc.: 99.66%, op_acc: 85.25%] [G loss: 5.582918]\n",
            "Validating on test set\n",
            "Validation Metrics: 2155 [D loss: 0.068234, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.599653]\n",
            "(1024, 1)\n",
            "Training Metrics: 2156 [D loss: 0.548567, acc.: 99.66%, op_acc: 82.52%] [G loss: 5.514900]\n",
            "Validating on test set\n",
            "Validation Metrics: 2156 [D loss: 0.069579, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.498508]\n",
            "(1024, 1)\n",
            "Training Metrics: 2157 [D loss: 0.483110, acc.: 99.80%, op_acc: 83.74%] [G loss: 5.679864]\n",
            "Validating on test set\n",
            "Validation Metrics: 2157 [D loss: 0.062900, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.734808]\n",
            "(1024, 1)\n",
            "Training Metrics: 2158 [D loss: 0.502115, acc.: 99.76%, op_acc: 84.38%] [G loss: 5.798965]\n",
            "Validating on test set\n",
            "Validation Metrics: 2158 [D loss: 0.063115, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.763994]\n",
            "(1024, 1)\n",
            "Training Metrics: 2159 [D loss: 0.472438, acc.: 99.95%, op_acc: 84.33%] [G loss: 6.345255]\n",
            "Validating on test set\n",
            "Validation Metrics: 2159 [D loss: 0.057050, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.383232]\n",
            "(1024, 1)\n",
            "Training Metrics: 2160 [D loss: 0.443701, acc.: 99.85%, op_acc: 84.62%] [G loss: 5.843156]\n",
            "Validating on test set\n",
            "Validation Metrics: 2160 [D loss: 0.065059, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.794254]\n",
            "(1024, 1)\n",
            "Training Metrics: 2161 [D loss: 0.450999, acc.: 99.76%, op_acc: 84.72%] [G loss: 5.929156]\n",
            "Validating on test set\n",
            "Validation Metrics: 2161 [D loss: 0.062557, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.927287]\n",
            "(1024, 1)\n",
            "Training Metrics: 2162 [D loss: 0.460056, acc.: 99.95%, op_acc: 83.89%] [G loss: 5.932811]\n",
            "Validating on test set\n",
            "Validation Metrics: 2162 [D loss: 0.066798, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.952947]\n",
            "(1024, 1)\n",
            "Training Metrics: 2163 [D loss: 0.474027, acc.: 99.76%, op_acc: 84.28%] [G loss: 5.856882]\n",
            "Validating on test set\n",
            "Validation Metrics: 2163 [D loss: 0.067066, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.954068]\n",
            "(1024, 1)\n",
            "Training Metrics: 2164 [D loss: 0.504156, acc.: 99.95%, op_acc: 84.57%] [G loss: 6.100686]\n",
            "Validating on test set\n",
            "Validation Metrics: 2164 [D loss: 0.068686, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.049472]\n",
            "(1024, 1)\n",
            "Training Metrics: 2165 [D loss: 0.511962, acc.: 99.61%, op_acc: 82.76%] [G loss: 5.247754]\n",
            "Validating on test set\n",
            "Validation Metrics: 2165 [D loss: 0.069480, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.223851]\n",
            "(1024, 1)\n",
            "Training Metrics: 2166 [D loss: 0.487527, acc.: 99.95%, op_acc: 83.54%] [G loss: 6.160542]\n",
            "Validating on test set\n",
            "Validation Metrics: 2166 [D loss: 0.062800, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.121164]\n",
            "(1024, 1)\n",
            "Training Metrics: 2167 [D loss: 0.527031, acc.: 99.56%, op_acc: 84.42%] [G loss: 5.733471]\n",
            "Validating on test set\n",
            "Validation Metrics: 2167 [D loss: 0.063719, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.756009]\n",
            "(1024, 1)\n",
            "Training Metrics: 2168 [D loss: 0.442884, acc.: 99.95%, op_acc: 84.91%] [G loss: 5.778327]\n",
            "Validating on test set\n",
            "Validation Metrics: 2168 [D loss: 0.072363, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.778742]\n",
            "(1024, 1)\n",
            "Training Metrics: 2169 [D loss: 0.455837, acc.: 99.61%, op_acc: 84.96%] [G loss: 5.980961]\n",
            "Validating on test set\n",
            "Validation Metrics: 2169 [D loss: 0.062094, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.080373]\n",
            "(1024, 1)\n",
            "Training Metrics: 2170 [D loss: 0.420848, acc.: 99.85%, op_acc: 86.52%] [G loss: 5.839357]\n",
            "Validating on test set\n",
            "Validation Metrics: 2170 [D loss: 0.058578, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.716809]\n",
            "(1024, 1)\n",
            "Training Metrics: 2171 [D loss: 0.462955, acc.: 99.95%, op_acc: 84.47%] [G loss: 6.214657]\n",
            "Validating on test set\n",
            "Validation Metrics: 2171 [D loss: 0.076058, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.300126]\n",
            "(1024, 1)\n",
            "Training Metrics: 2172 [D loss: 0.443124, acc.: 99.90%, op_acc: 84.18%] [G loss: 5.745856]\n",
            "Validating on test set\n",
            "Validation Metrics: 2172 [D loss: 0.068468, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.794590]\n",
            "(1024, 1)\n",
            "Training Metrics: 2173 [D loss: 0.511827, acc.: 99.85%, op_acc: 83.30%] [G loss: 6.436347]\n",
            "Validating on test set\n",
            "Validation Metrics: 2173 [D loss: 0.057164, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.296015]\n",
            "(1024, 1)\n",
            "Training Metrics: 2174 [D loss: 0.475162, acc.: 99.80%, op_acc: 84.18%] [G loss: 5.863598]\n",
            "Validating on test set\n",
            "Validation Metrics: 2174 [D loss: 0.069037, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.019367]\n",
            "(1024, 1)\n",
            "Training Metrics: 2175 [D loss: 0.432585, acc.: 99.76%, op_acc: 86.28%] [G loss: 6.108553]\n",
            "Validating on test set\n",
            "Validation Metrics: 2175 [D loss: 0.060647, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.043622]\n",
            "(1024, 1)\n",
            "Training Metrics: 2176 [D loss: 0.462208, acc.: 99.95%, op_acc: 84.57%] [G loss: 6.130314]\n",
            "Validating on test set\n",
            "Validation Metrics: 2176 [D loss: 0.056123, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.069704]\n",
            "(1024, 1)\n",
            "Training Metrics: 2177 [D loss: 0.477034, acc.: 99.66%, op_acc: 84.08%] [G loss: 6.009032]\n",
            "Validating on test set\n",
            "Validation Metrics: 2177 [D loss: 0.066113, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.012798]\n",
            "(1024, 1)\n",
            "Training Metrics: 2178 [D loss: 0.466477, acc.: 99.80%, op_acc: 84.86%] [G loss: 5.426360]\n",
            "Validating on test set\n",
            "Validation Metrics: 2178 [D loss: 0.097573, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.460080]\n",
            "(1024, 1)\n",
            "Training Metrics: 2179 [D loss: 0.508061, acc.: 99.76%, op_acc: 82.81%] [G loss: 5.875744]\n",
            "Validating on test set\n",
            "Validation Metrics: 2179 [D loss: 0.081596, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.925362]\n",
            "(1024, 1)\n",
            "Training Metrics: 2180 [D loss: 0.482117, acc.: 99.80%, op_acc: 84.08%] [G loss: 5.574728]\n",
            "Validating on test set\n",
            "Validation Metrics: 2180 [D loss: 0.058208, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.521448]\n",
            "(1024, 1)\n",
            "Training Metrics: 2181 [D loss: 0.461223, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.140501]\n",
            "Validating on test set\n",
            "Validation Metrics: 2181 [D loss: 0.055608, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.105140]\n",
            "(1024, 1)\n",
            "Training Metrics: 2182 [D loss: 0.423336, acc.: 99.90%, op_acc: 85.16%] [G loss: 6.232400]\n",
            "Validating on test set\n",
            "Validation Metrics: 2182 [D loss: 0.056704, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.195607]\n",
            "(1024, 1)\n",
            "Training Metrics: 2183 [D loss: 0.456792, acc.: 99.76%, op_acc: 84.13%] [G loss: 6.016943]\n",
            "Validating on test set\n",
            "Validation Metrics: 2183 [D loss: 0.059408, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.012464]\n",
            "(1024, 1)\n",
            "Training Metrics: 2184 [D loss: 0.454316, acc.: 99.76%, op_acc: 85.06%] [G loss: 5.877433]\n",
            "Validating on test set\n",
            "Validation Metrics: 2184 [D loss: 0.059593, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.890312]\n",
            "(1024, 1)\n",
            "Training Metrics: 2185 [D loss: 0.460387, acc.: 99.80%, op_acc: 84.72%] [G loss: 5.853499]\n",
            "Validating on test set\n",
            "Validation Metrics: 2185 [D loss: 0.057826, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.838386]\n",
            "(1024, 1)\n",
            "Training Metrics: 2186 [D loss: 0.482614, acc.: 99.76%, op_acc: 84.28%] [G loss: 5.841351]\n",
            "Validating on test set\n",
            "Validation Metrics: 2186 [D loss: 0.062273, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.861038]\n",
            "(1024, 1)\n",
            "Training Metrics: 2187 [D loss: 0.445228, acc.: 99.85%, op_acc: 85.06%] [G loss: 5.831657]\n",
            "Validating on test set\n",
            "Validation Metrics: 2187 [D loss: 0.061134, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.855961]\n",
            "(1024, 1)\n",
            "Training Metrics: 2188 [D loss: 0.425095, acc.: 99.85%, op_acc: 85.45%] [G loss: 5.820515]\n",
            "Validating on test set\n",
            "Validation Metrics: 2188 [D loss: 0.090324, acc.: 100.00%, op_acc: 99.22%] [G loss: 5.874904]\n",
            "(1024, 1)\n",
            "Training Metrics: 2189 [D loss: 0.455886, acc.: 99.85%, op_acc: 85.25%] [G loss: 6.174711]\n",
            "Validating on test set\n",
            "Validation Metrics: 2189 [D loss: 0.066708, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.163578]\n",
            "(1024, 1)\n",
            "Training Metrics: 2190 [D loss: 0.453382, acc.: 99.76%, op_acc: 85.16%] [G loss: 5.882851]\n",
            "Validating on test set\n",
            "Validation Metrics: 2190 [D loss: 0.053872, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.836047]\n",
            "(1024, 1)\n",
            "Training Metrics: 2191 [D loss: 0.407735, acc.: 99.71%, op_acc: 86.38%] [G loss: 5.696820]\n",
            "Validating on test set\n",
            "Validation Metrics: 2191 [D loss: 0.051758, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.660556]\n",
            "(1024, 1)\n",
            "Training Metrics: 2192 [D loss: 0.425761, acc.: 99.85%, op_acc: 85.11%] [G loss: 5.933968]\n",
            "Validating on test set\n",
            "Validation Metrics: 2192 [D loss: 0.053358, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.943564]\n",
            "(1024, 1)\n",
            "Training Metrics: 2193 [D loss: 0.478832, acc.: 99.80%, op_acc: 84.23%] [G loss: 6.347198]\n",
            "Validating on test set\n",
            "Validation Metrics: 2193 [D loss: 0.049370, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.338778]\n",
            "(1024, 1)\n",
            "Training Metrics: 2194 [D loss: 0.459192, acc.: 99.85%, op_acc: 83.45%] [G loss: 5.784039]\n",
            "Validating on test set\n",
            "Validation Metrics: 2194 [D loss: 0.061421, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.769364]\n",
            "(1024, 1)\n",
            "Training Metrics: 2195 [D loss: 0.450056, acc.: 99.71%, op_acc: 84.67%] [G loss: 6.003036]\n",
            "Validating on test set\n",
            "Validation Metrics: 2195 [D loss: 0.093981, acc.: 100.00%, op_acc: 99.02%] [G loss: 6.011486]\n",
            "(1024, 1)\n",
            "Training Metrics: 2196 [D loss: 0.525332, acc.: 99.90%, op_acc: 82.76%] [G loss: 5.999844]\n",
            "Validating on test set\n",
            "Validation Metrics: 2196 [D loss: 0.066531, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.090393]\n",
            "(1024, 1)\n",
            "Training Metrics: 2197 [D loss: 0.485262, acc.: 99.71%, op_acc: 83.30%] [G loss: 6.270853]\n",
            "Validating on test set\n",
            "Validation Metrics: 2197 [D loss: 0.054256, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.208470]\n",
            "(1024, 1)\n",
            "Training Metrics: 2198 [D loss: 0.489311, acc.: 99.80%, op_acc: 84.62%] [G loss: 5.340042]\n",
            "Validating on test set\n",
            "Validation Metrics: 2198 [D loss: 0.053759, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.295054]\n",
            "(1024, 1)\n",
            "Training Metrics: 2199 [D loss: 0.455149, acc.: 99.95%, op_acc: 84.86%] [G loss: 6.104327]\n",
            "Validating on test set\n",
            "Validation Metrics: 2199 [D loss: 0.055075, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.094781]\n",
            "(1024, 1)\n",
            "Training Metrics: 2200 [D loss: 0.487868, acc.: 99.85%, op_acc: 83.69%] [G loss: 6.166024]\n",
            "Validating on test set\n",
            "Validation Metrics: 2200 [D loss: 0.055525, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.154402]\n",
            "(1024, 1)\n",
            "Training Metrics: 2201 [D loss: 0.442475, acc.: 99.85%, op_acc: 85.11%] [G loss: 5.910057]\n",
            "Validating on test set\n",
            "Validation Metrics: 2201 [D loss: 0.056546, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.919488]\n",
            "(1024, 1)\n",
            "Training Metrics: 2202 [D loss: 0.429079, acc.: 99.85%, op_acc: 85.11%] [G loss: 6.301782]\n",
            "Validating on test set\n",
            "Validation Metrics: 2202 [D loss: 0.056218, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.348981]\n",
            "(1024, 1)\n",
            "Training Metrics: 2203 [D loss: 0.428719, acc.: 99.90%, op_acc: 83.98%] [G loss: 6.073440]\n",
            "Validating on test set\n",
            "Validation Metrics: 2203 [D loss: 0.053624, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.035560]\n",
            "(1024, 1)\n",
            "Training Metrics: 2204 [D loss: 0.422661, acc.: 99.85%, op_acc: 85.50%] [G loss: 5.880976]\n",
            "Validating on test set\n",
            "Validation Metrics: 2204 [D loss: 0.049161, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.860374]\n",
            "(1024, 1)\n",
            "Training Metrics: 2205 [D loss: 0.454753, acc.: 99.80%, op_acc: 84.67%] [G loss: 6.251356]\n",
            "Validating on test set\n",
            "Validation Metrics: 2205 [D loss: 0.079034, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.264754]\n",
            "(1024, 1)\n",
            "Training Metrics: 2206 [D loss: 0.473851, acc.: 99.61%, op_acc: 84.77%] [G loss: 5.984957]\n",
            "Validating on test set\n",
            "Validation Metrics: 2206 [D loss: 0.060699, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.037250]\n",
            "(1024, 1)\n",
            "Training Metrics: 2207 [D loss: 0.467874, acc.: 99.80%, op_acc: 84.42%] [G loss: 5.785548]\n",
            "Validating on test set\n",
            "Validation Metrics: 2207 [D loss: 0.052761, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.722277]\n",
            "(1024, 1)\n",
            "Training Metrics: 2208 [D loss: 0.443203, acc.: 99.90%, op_acc: 85.35%] [G loss: 5.990838]\n",
            "Validating on test set\n",
            "Validation Metrics: 2208 [D loss: 0.050552, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.969808]\n",
            "(1024, 1)\n",
            "Training Metrics: 2209 [D loss: 0.434319, acc.: 99.80%, op_acc: 85.06%] [G loss: 5.681728]\n",
            "Validating on test set\n",
            "Validation Metrics: 2209 [D loss: 0.050076, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.648273]\n",
            "(1024, 1)\n",
            "Training Metrics: 2210 [D loss: 0.407444, acc.: 99.90%, op_acc: 85.25%] [G loss: 5.959807]\n",
            "Validating on test set\n",
            "Validation Metrics: 2210 [D loss: 0.055528, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.940157]\n",
            "(1024, 1)\n",
            "Training Metrics: 2211 [D loss: 0.447132, acc.: 99.90%, op_acc: 84.81%] [G loss: 5.962282]\n",
            "Validating on test set\n",
            "Validation Metrics: 2211 [D loss: 0.074865, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.944725]\n",
            "(1024, 1)\n",
            "Training Metrics: 2212 [D loss: 0.474959, acc.: 99.90%, op_acc: 84.28%] [G loss: 6.242290]\n",
            "Validating on test set\n",
            "Validation Metrics: 2212 [D loss: 0.063620, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.291607]\n",
            "(1024, 1)\n",
            "Training Metrics: 2213 [D loss: 0.464662, acc.: 99.90%, op_acc: 83.74%] [G loss: 6.119740]\n",
            "Validating on test set\n",
            "Validation Metrics: 2213 [D loss: 0.065424, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.082736]\n",
            "(1024, 1)\n",
            "Training Metrics: 2214 [D loss: 0.497658, acc.: 99.71%, op_acc: 85.21%] [G loss: 6.208639]\n",
            "Validating on test set\n",
            "Validation Metrics: 2214 [D loss: 0.059904, acc.: 100.00%, op_acc: 99.41%] [G loss: 6.100069]\n",
            "(1024, 1)\n",
            "Training Metrics: 2215 [D loss: 0.464840, acc.: 99.90%, op_acc: 83.74%] [G loss: 6.329434]\n",
            "Validating on test set\n",
            "Validation Metrics: 2215 [D loss: 0.064287, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.264515]\n",
            "(1024, 1)\n",
            "Training Metrics: 2216 [D loss: 0.440093, acc.: 99.90%, op_acc: 84.42%] [G loss: 5.799341]\n",
            "Validating on test set\n",
            "Validation Metrics: 2216 [D loss: 0.109463, acc.: 100.00%, op_acc: 98.54%] [G loss: 5.808531]\n",
            "(1024, 1)\n",
            "Training Metrics: 2217 [D loss: 0.465231, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.016118]\n",
            "Validating on test set\n",
            "Validation Metrics: 2217 [D loss: 0.207435, acc.: 100.00%, op_acc: 95.31%] [G loss: 5.995887]\n",
            "(1024, 1)\n",
            "Training Metrics: 2218 [D loss: 0.492835, acc.: 99.85%, op_acc: 82.42%] [G loss: 5.870540]\n",
            "Validating on test set\n",
            "Validation Metrics: 2218 [D loss: 0.097350, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.810662]\n",
            "(1024, 1)\n",
            "Training Metrics: 2219 [D loss: 0.453673, acc.: 99.85%, op_acc: 84.91%] [G loss: 5.537267]\n",
            "Validating on test set\n",
            "Validation Metrics: 2219 [D loss: 0.279757, acc.: 100.00%, op_acc: 92.09%] [G loss: 5.725657]\n",
            "(1024, 1)\n",
            "Training Metrics: 2220 [D loss: 0.581678, acc.: 99.71%, op_acc: 80.62%] [G loss: 5.736505]\n",
            "Validating on test set\n",
            "Validation Metrics: 2220 [D loss: 0.190383, acc.: 100.00%, op_acc: 93.95%] [G loss: 5.685829]\n",
            "(1024, 1)\n",
            "Training Metrics: 2221 [D loss: 0.535472, acc.: 99.80%, op_acc: 79.54%] [G loss: 5.579584]\n",
            "Validating on test set\n",
            "Validation Metrics: 2221 [D loss: 0.154243, acc.: 100.00%, op_acc: 98.63%] [G loss: 5.455953]\n",
            "(1024, 1)\n",
            "Training Metrics: 2222 [D loss: 0.450989, acc.: 99.80%, op_acc: 85.60%] [G loss: 6.274213]\n",
            "Validating on test set\n",
            "Validation Metrics: 2222 [D loss: 0.114184, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.235676]\n",
            "(1024, 1)\n",
            "Training Metrics: 2223 [D loss: 0.508622, acc.: 99.66%, op_acc: 85.40%] [G loss: 5.964634]\n",
            "Validating on test set\n",
            "Validation Metrics: 2223 [D loss: 0.130763, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.976429]\n",
            "(1024, 1)\n",
            "Training Metrics: 2224 [D loss: 0.510792, acc.: 99.85%, op_acc: 83.11%] [G loss: 5.810054]\n",
            "Validating on test set\n",
            "Validation Metrics: 2224 [D loss: 0.192957, acc.: 100.00%, op_acc: 95.80%] [G loss: 5.617424]\n",
            "(1024, 1)\n",
            "Training Metrics: 2225 [D loss: 0.513428, acc.: 99.90%, op_acc: 82.91%] [G loss: 6.035859]\n",
            "Validating on test set\n",
            "Validation Metrics: 2225 [D loss: 0.361693, acc.: 100.00%, op_acc: 84.86%] [G loss: 6.401405]\n",
            "(1024, 1)\n",
            "Training Metrics: 2226 [D loss: 0.618030, acc.: 99.71%, op_acc: 75.78%] [G loss: 5.616162]\n",
            "Validating on test set\n",
            "Validation Metrics: 2226 [D loss: 0.151978, acc.: 100.00%, op_acc: 99.12%] [G loss: 5.406336]\n",
            "(1024, 1)\n",
            "Training Metrics: 2227 [D loss: 0.492755, acc.: 99.80%, op_acc: 81.79%] [G loss: 6.174543]\n",
            "Validating on test set\n",
            "Validation Metrics: 2227 [D loss: 0.112689, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.109393]\n",
            "(1024, 1)\n",
            "Training Metrics: 2228 [D loss: 0.455347, acc.: 99.80%, op_acc: 85.01%] [G loss: 6.262188]\n",
            "Validating on test set\n",
            "Validation Metrics: 2228 [D loss: 0.095250, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.349071]\n",
            "(1024, 1)\n",
            "Training Metrics: 2229 [D loss: 0.459043, acc.: 99.80%, op_acc: 85.25%] [G loss: 6.214052]\n",
            "Validating on test set\n",
            "Validation Metrics: 2229 [D loss: 0.114277, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.131768]\n",
            "(1024, 1)\n",
            "Training Metrics: 2230 [D loss: 0.428020, acc.: 99.85%, op_acc: 85.79%] [G loss: 6.382336]\n",
            "Validating on test set\n",
            "Validation Metrics: 2230 [D loss: 0.093358, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.413537]\n",
            "(1024, 1)\n",
            "Training Metrics: 2231 [D loss: 0.442566, acc.: 99.95%, op_acc: 85.21%] [G loss: 6.135277]\n",
            "Validating on test set\n",
            "Validation Metrics: 2231 [D loss: 0.065564, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.002523]\n",
            "(1024, 1)\n",
            "Training Metrics: 2232 [D loss: 0.427715, acc.: 99.85%, op_acc: 85.94%] [G loss: 5.960806]\n",
            "Validating on test set\n",
            "Validation Metrics: 2232 [D loss: 0.072381, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.006119]\n",
            "(1024, 1)\n",
            "Training Metrics: 2233 [D loss: 0.452928, acc.: 99.76%, op_acc: 84.67%] [G loss: 5.955916]\n",
            "Validating on test set\n",
            "Validation Metrics: 2233 [D loss: 0.091003, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.064174]\n",
            "(1024, 1)\n",
            "Training Metrics: 2234 [D loss: 0.438920, acc.: 99.80%, op_acc: 86.08%] [G loss: 6.053206]\n",
            "Validating on test set\n",
            "Validation Metrics: 2234 [D loss: 0.073002, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.894021]\n",
            "(1024, 1)\n",
            "Training Metrics: 2235 [D loss: 0.465750, acc.: 99.76%, op_acc: 84.57%] [G loss: 5.770333]\n",
            "Validating on test set\n",
            "Validation Metrics: 2235 [D loss: 0.072363, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.741620]\n",
            "(1024, 1)\n",
            "Training Metrics: 2236 [D loss: 0.444280, acc.: 99.66%, op_acc: 86.18%] [G loss: 5.855544]\n",
            "Validating on test set\n",
            "Validation Metrics: 2236 [D loss: 0.073139, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.921694]\n",
            "(1024, 1)\n",
            "Training Metrics: 2237 [D loss: 0.440629, acc.: 99.66%, op_acc: 85.55%] [G loss: 5.495005]\n",
            "Validating on test set\n",
            "Validation Metrics: 2237 [D loss: 0.090573, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.500022]\n",
            "(1024, 1)\n",
            "Training Metrics: 2238 [D loss: 0.437459, acc.: 99.90%, op_acc: 86.23%] [G loss: 6.156301]\n",
            "Validating on test set\n",
            "Validation Metrics: 2238 [D loss: 0.080587, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.116681]\n",
            "(1024, 1)\n",
            "Training Metrics: 2239 [D loss: 0.512902, acc.: 99.80%, op_acc: 84.08%] [G loss: 5.869759]\n",
            "Validating on test set\n",
            "Validation Metrics: 2239 [D loss: 0.079615, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.751660]\n",
            "(1024, 1)\n",
            "Training Metrics: 2240 [D loss: 0.522468, acc.: 99.61%, op_acc: 82.71%] [G loss: 5.869226]\n",
            "Validating on test set\n",
            "Validation Metrics: 2240 [D loss: 0.070400, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.943388]\n",
            "(1024, 1)\n",
            "Training Metrics: 2241 [D loss: 0.496242, acc.: 99.80%, op_acc: 83.45%] [G loss: 5.617829]\n",
            "Validating on test set\n",
            "Validation Metrics: 2241 [D loss: 0.076160, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.631893]\n",
            "(1024, 1)\n",
            "Training Metrics: 2242 [D loss: 0.480000, acc.: 99.90%, op_acc: 84.57%] [G loss: 6.056885]\n",
            "Validating on test set\n",
            "Validation Metrics: 2242 [D loss: 0.058131, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.967972]\n",
            "(1024, 1)\n",
            "Training Metrics: 2243 [D loss: 0.441237, acc.: 99.80%, op_acc: 85.55%] [G loss: 6.046183]\n",
            "Validating on test set\n",
            "Validation Metrics: 2243 [D loss: 0.062951, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.024550]\n",
            "(1024, 1)\n",
            "Training Metrics: 2244 [D loss: 0.460959, acc.: 99.90%, op_acc: 85.79%] [G loss: 6.185642]\n",
            "Validating on test set\n",
            "Validation Metrics: 2244 [D loss: 0.063360, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.115450]\n",
            "(1024, 1)\n",
            "Training Metrics: 2245 [D loss: 0.479854, acc.: 99.71%, op_acc: 83.98%] [G loss: 5.672887]\n",
            "Validating on test set\n",
            "Validation Metrics: 2245 [D loss: 0.180386, acc.: 100.00%, op_acc: 96.00%] [G loss: 5.609779]\n",
            "(1024, 1)\n",
            "Training Metrics: 2246 [D loss: 0.530874, acc.: 99.80%, op_acc: 80.57%] [G loss: 6.201635]\n",
            "Validating on test set\n",
            "Validation Metrics: 2246 [D loss: 0.085784, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.302415]\n",
            "(1024, 1)\n",
            "Training Metrics: 2247 [D loss: 0.492861, acc.: 99.85%, op_acc: 84.18%] [G loss: 5.744593]\n",
            "Validating on test set\n",
            "Validation Metrics: 2247 [D loss: 0.081004, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.600219]\n",
            "(1024, 1)\n",
            "Training Metrics: 2248 [D loss: 0.471188, acc.: 99.90%, op_acc: 84.57%] [G loss: 5.956578]\n",
            "Validating on test set\n",
            "Validation Metrics: 2248 [D loss: 0.155889, acc.: 100.00%, op_acc: 94.63%] [G loss: 5.998668]\n",
            "(1024, 1)\n",
            "Training Metrics: 2249 [D loss: 0.453788, acc.: 99.71%, op_acc: 83.94%] [G loss: 6.079060]\n",
            "Validating on test set\n",
            "Validation Metrics: 2249 [D loss: 0.080827, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.128097]\n",
            "(1024, 1)\n",
            "Training Metrics: 2250 [D loss: 0.455895, acc.: 99.90%, op_acc: 84.47%] [G loss: 5.939333]\n",
            "Validating on test set\n",
            "Validation Metrics: 2250 [D loss: 0.078260, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.847437]\n",
            "(1024, 1)\n",
            "Training Metrics: 2251 [D loss: 0.468207, acc.: 99.95%, op_acc: 83.74%] [G loss: 6.264420]\n",
            "Validating on test set\n",
            "Validation Metrics: 2251 [D loss: 0.085222, acc.: 100.00%, op_acc: 99.12%] [G loss: 6.171793]\n",
            "(1024, 1)\n",
            "Training Metrics: 2252 [D loss: 0.440046, acc.: 99.85%, op_acc: 85.50%] [G loss: 5.902008]\n",
            "Validating on test set\n",
            "Validation Metrics: 2252 [D loss: 0.087762, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.938048]\n",
            "(1024, 1)\n",
            "Training Metrics: 2253 [D loss: 0.457588, acc.: 99.76%, op_acc: 85.16%] [G loss: 5.802445]\n",
            "Validating on test set\n",
            "Validation Metrics: 2253 [D loss: 0.093087, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.826853]\n",
            "(1024, 1)\n",
            "Training Metrics: 2254 [D loss: 0.454217, acc.: 99.95%, op_acc: 85.35%] [G loss: 5.917827]\n",
            "Validating on test set\n",
            "Validation Metrics: 2254 [D loss: 0.088171, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.937878]\n",
            "(1024, 1)\n",
            "Training Metrics: 2255 [D loss: 0.489574, acc.: 99.85%, op_acc: 83.98%] [G loss: 5.936478]\n",
            "Validating on test set\n",
            "Validation Metrics: 2255 [D loss: 0.123644, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.027902]\n",
            "(1024, 1)\n",
            "Training Metrics: 2256 [D loss: 0.530153, acc.: 99.90%, op_acc: 83.01%] [G loss: 5.911411]\n",
            "Validating on test set\n",
            "Validation Metrics: 2256 [D loss: 0.107441, acc.: 100.00%, op_acc: 99.61%] [G loss: 5.843435]\n",
            "(1024, 1)\n",
            "Training Metrics: 2257 [D loss: 0.503499, acc.: 99.80%, op_acc: 83.64%] [G loss: 6.277088]\n",
            "Validating on test set\n",
            "Validation Metrics: 2257 [D loss: 0.107797, acc.: 100.00%, op_acc: 99.51%] [G loss: 6.203091]\n",
            "(1024, 1)\n",
            "Training Metrics: 2258 [D loss: 0.500310, acc.: 99.80%, op_acc: 83.40%] [G loss: 5.869272]\n",
            "Validating on test set\n",
            "Validation Metrics: 2258 [D loss: 0.089120, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.796119]\n",
            "(1024, 1)\n",
            "Training Metrics: 2259 [D loss: 0.468593, acc.: 100.00%, op_acc: 84.72%] [G loss: 6.182095]\n",
            "Validating on test set\n",
            "Validation Metrics: 2259 [D loss: 0.077942, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.142121]\n",
            "(1024, 1)\n",
            "Training Metrics: 2260 [D loss: 0.507785, acc.: 99.90%, op_acc: 83.74%] [G loss: 5.518309]\n",
            "Validating on test set\n",
            "Validation Metrics: 2260 [D loss: 0.147306, acc.: 100.00%, op_acc: 97.85%] [G loss: 5.583100]\n",
            "(1024, 1)\n",
            "Training Metrics: 2261 [D loss: 0.527613, acc.: 99.80%, op_acc: 82.76%] [G loss: 6.685995]\n",
            "Validating on test set\n",
            "Validation Metrics: 2261 [D loss: 0.123064, acc.: 100.00%, op_acc: 98.93%] [G loss: 6.682571]\n",
            "(1024, 1)\n",
            "Training Metrics: 2262 [D loss: 0.483587, acc.: 99.76%, op_acc: 84.28%] [G loss: 5.763331]\n",
            "Validating on test set\n",
            "Validation Metrics: 2262 [D loss: 0.090121, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.656438]\n",
            "(1024, 1)\n",
            "Training Metrics: 2263 [D loss: 0.467271, acc.: 99.80%, op_acc: 83.98%] [G loss: 5.835948]\n",
            "Validating on test set\n",
            "Validation Metrics: 2263 [D loss: 0.109577, acc.: 100.00%, op_acc: 98.73%] [G loss: 5.813826]\n",
            "(1024, 1)\n",
            "Training Metrics: 2264 [D loss: 0.529746, acc.: 99.85%, op_acc: 81.30%] [G loss: 6.060309]\n",
            "Validating on test set\n",
            "Validation Metrics: 2264 [D loss: 0.090872, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.088706]\n",
            "(1024, 1)\n",
            "Training Metrics: 2265 [D loss: 0.511667, acc.: 99.85%, op_acc: 83.59%] [G loss: 6.485695]\n",
            "Validating on test set\n",
            "Validation Metrics: 2265 [D loss: 0.078178, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.574455]\n",
            "(1024, 1)\n",
            "Training Metrics: 2266 [D loss: 0.495761, acc.: 99.90%, op_acc: 83.35%] [G loss: 5.983112]\n",
            "Validating on test set\n",
            "Validation Metrics: 2266 [D loss: 0.151457, acc.: 100.00%, op_acc: 96.88%] [G loss: 5.989084]\n",
            "(1024, 1)\n",
            "Training Metrics: 2267 [D loss: 0.468147, acc.: 99.85%, op_acc: 83.50%] [G loss: 5.878969]\n",
            "Validating on test set\n",
            "Validation Metrics: 2267 [D loss: 0.105552, acc.: 100.00%, op_acc: 98.83%] [G loss: 5.885674]\n",
            "(1024, 1)\n",
            "Training Metrics: 2268 [D loss: 0.450611, acc.: 99.85%, op_acc: 84.67%] [G loss: 5.975614]\n",
            "Validating on test set\n",
            "Validation Metrics: 2268 [D loss: 0.068348, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.883039]\n",
            "(1024, 1)\n",
            "Training Metrics: 2269 [D loss: 0.484924, acc.: 99.80%, op_acc: 84.42%] [G loss: 5.488240]\n",
            "Validating on test set\n",
            "Validation Metrics: 2269 [D loss: 0.076541, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.441051]\n",
            "(1024, 1)\n",
            "Training Metrics: 2270 [D loss: 0.456059, acc.: 99.85%, op_acc: 84.13%] [G loss: 6.131925]\n",
            "Validating on test set\n",
            "Validation Metrics: 2270 [D loss: 0.067822, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.097646]\n",
            "(1024, 1)\n",
            "Training Metrics: 2271 [D loss: 0.438259, acc.: 99.80%, op_acc: 85.11%] [G loss: 6.073069]\n",
            "Validating on test set\n",
            "Validation Metrics: 2271 [D loss: 0.075451, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.070734]\n",
            "(1024, 1)\n",
            "Training Metrics: 2272 [D loss: 0.424951, acc.: 99.61%, op_acc: 85.25%] [G loss: 5.801646]\n",
            "Validating on test set\n",
            "Validation Metrics: 2272 [D loss: 0.075812, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.788598]\n",
            "(1024, 1)\n",
            "Training Metrics: 2273 [D loss: 0.440865, acc.: 99.90%, op_acc: 85.21%] [G loss: 5.931225]\n",
            "Validating on test set\n",
            "Validation Metrics: 2273 [D loss: 0.075720, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.896175]\n",
            "(1024, 1)\n",
            "Training Metrics: 2274 [D loss: 0.485665, acc.: 99.76%, op_acc: 83.84%] [G loss: 5.676506]\n",
            "Validating on test set\n",
            "Validation Metrics: 2274 [D loss: 0.080205, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.689436]\n",
            "(1024, 1)\n",
            "Training Metrics: 2275 [D loss: 0.464454, acc.: 99.85%, op_acc: 84.72%] [G loss: 5.721117]\n",
            "Validating on test set\n",
            "Validation Metrics: 2275 [D loss: 0.080718, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.763686]\n",
            "(1024, 1)\n",
            "Training Metrics: 2276 [D loss: 0.515291, acc.: 99.85%, op_acc: 83.74%] [G loss: 5.994598]\n",
            "Validating on test set\n",
            "Validation Metrics: 2276 [D loss: 0.077630, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.890958]\n",
            "(1024, 1)\n",
            "Training Metrics: 2277 [D loss: 0.486549, acc.: 99.90%, op_acc: 83.06%] [G loss: 6.184648]\n",
            "Validating on test set\n",
            "Validation Metrics: 2277 [D loss: 0.071805, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.126465]\n",
            "(1024, 1)\n",
            "Training Metrics: 2278 [D loss: 0.468434, acc.: 99.80%, op_acc: 84.57%] [G loss: 6.185753]\n",
            "Validating on test set\n",
            "Validation Metrics: 2278 [D loss: 0.094651, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.201757]\n",
            "(1024, 1)\n",
            "Training Metrics: 2279 [D loss: 0.494294, acc.: 99.90%, op_acc: 83.89%] [G loss: 6.212405]\n",
            "Validating on test set\n",
            "Validation Metrics: 2279 [D loss: 0.064955, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.184937]\n",
            "(1024, 1)\n",
            "Training Metrics: 2280 [D loss: 0.425203, acc.: 99.80%, op_acc: 86.28%] [G loss: 6.038923]\n",
            "Validating on test set\n",
            "Validation Metrics: 2280 [D loss: 0.065998, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.007336]\n",
            "(1024, 1)\n",
            "Training Metrics: 2281 [D loss: 0.461732, acc.: 99.90%, op_acc: 84.47%] [G loss: 6.207466]\n",
            "Validating on test set\n",
            "Validation Metrics: 2281 [D loss: 0.060166, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.214951]\n",
            "(1024, 1)\n",
            "Training Metrics: 2282 [D loss: 0.443019, acc.: 99.95%, op_acc: 85.01%] [G loss: 6.110637]\n",
            "Validating on test set\n",
            "Validation Metrics: 2282 [D loss: 0.062235, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.121253]\n",
            "(1024, 1)\n",
            "Training Metrics: 2283 [D loss: 0.479441, acc.: 99.95%, op_acc: 84.42%] [G loss: 6.288500]\n",
            "Validating on test set\n",
            "Validation Metrics: 2283 [D loss: 0.056437, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.268505]\n",
            "(1024, 1)\n",
            "Training Metrics: 2284 [D loss: 0.479524, acc.: 99.71%, op_acc: 83.69%] [G loss: 6.121802]\n",
            "Validating on test set\n",
            "Validation Metrics: 2284 [D loss: 0.069042, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.094696]\n",
            "(1024, 1)\n",
            "Training Metrics: 2285 [D loss: 0.487674, acc.: 99.80%, op_acc: 84.18%] [G loss: 5.909316]\n",
            "Validating on test set\n",
            "Validation Metrics: 2285 [D loss: 0.061262, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.903162]\n",
            "(1024, 1)\n",
            "Training Metrics: 2286 [D loss: 0.455806, acc.: 99.95%, op_acc: 84.72%] [G loss: 6.151484]\n",
            "Validating on test set\n",
            "Validation Metrics: 2286 [D loss: 0.056790, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.162689]\n",
            "(1024, 1)\n",
            "Training Metrics: 2287 [D loss: 0.448810, acc.: 99.90%, op_acc: 85.21%] [G loss: 6.041784]\n",
            "Validating on test set\n",
            "Validation Metrics: 2287 [D loss: 0.064411, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.038899]\n",
            "(1024, 1)\n",
            "Training Metrics: 2288 [D loss: 0.460185, acc.: 99.80%, op_acc: 85.11%] [G loss: 6.024808]\n",
            "Validating on test set\n",
            "Validation Metrics: 2288 [D loss: 0.053017, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.999278]\n",
            "(1024, 1)\n",
            "Training Metrics: 2289 [D loss: 0.426396, acc.: 99.80%, op_acc: 85.06%] [G loss: 5.815104]\n",
            "Validating on test set\n",
            "Validation Metrics: 2289 [D loss: 0.069724, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.802323]\n",
            "(1024, 1)\n",
            "Training Metrics: 2290 [D loss: 0.466710, acc.: 99.85%, op_acc: 83.01%] [G loss: 6.155403]\n",
            "Validating on test set\n",
            "Validation Metrics: 2290 [D loss: 0.054085, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.178102]\n",
            "(1024, 1)\n",
            "Training Metrics: 2291 [D loss: 0.435969, acc.: 99.76%, op_acc: 84.96%] [G loss: 5.680871]\n",
            "Validating on test set\n",
            "Validation Metrics: 2291 [D loss: 0.060031, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.679385]\n",
            "(1024, 1)\n",
            "Training Metrics: 2292 [D loss: 0.489180, acc.: 99.80%, op_acc: 84.33%] [G loss: 5.842787]\n",
            "Validating on test set\n",
            "Validation Metrics: 2292 [D loss: 0.061956, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.804609]\n",
            "(1024, 1)\n",
            "Training Metrics: 2293 [D loss: 0.457297, acc.: 99.80%, op_acc: 84.23%] [G loss: 5.884789]\n",
            "Validating on test set\n",
            "Validation Metrics: 2293 [D loss: 0.063696, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.878844]\n",
            "(1024, 1)\n",
            "Training Metrics: 2294 [D loss: 0.452898, acc.: 99.85%, op_acc: 85.16%] [G loss: 6.331616]\n",
            "Validating on test set\n",
            "Validation Metrics: 2294 [D loss: 0.062286, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.328722]\n",
            "(1024, 1)\n",
            "Training Metrics: 2295 [D loss: 0.461355, acc.: 99.71%, op_acc: 84.08%] [G loss: 5.832351]\n",
            "Validating on test set\n",
            "Validation Metrics: 2295 [D loss: 0.057522, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.837933]\n",
            "(1024, 1)\n",
            "Training Metrics: 2296 [D loss: 0.424066, acc.: 99.76%, op_acc: 85.50%] [G loss: 5.683568]\n",
            "Validating on test set\n",
            "Validation Metrics: 2296 [D loss: 0.057639, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.670186]\n",
            "(1024, 1)\n",
            "Training Metrics: 2297 [D loss: 0.442638, acc.: 99.85%, op_acc: 85.11%] [G loss: 6.049314]\n",
            "Validating on test set\n",
            "Validation Metrics: 2297 [D loss: 0.066132, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.005488]\n",
            "(1024, 1)\n",
            "Training Metrics: 2298 [D loss: 0.473004, acc.: 99.95%, op_acc: 83.89%] [G loss: 6.234612]\n",
            "Validating on test set\n",
            "Validation Metrics: 2298 [D loss: 0.059787, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.202031]\n",
            "(1024, 1)\n",
            "Training Metrics: 2299 [D loss: 0.429807, acc.: 99.95%, op_acc: 84.72%] [G loss: 5.961518]\n",
            "Validating on test set\n",
            "Validation Metrics: 2299 [D loss: 0.060749, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.969828]\n",
            "(1024, 1)\n",
            "Training Metrics: 2300 [D loss: 0.445135, acc.: 99.80%, op_acc: 84.77%] [G loss: 6.252035]\n",
            "Validating on test set\n",
            "Validation Metrics: 2300 [D loss: 0.050392, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.279477]\n",
            "(1024, 1)\n",
            "Training Metrics: 2301 [D loss: 0.467592, acc.: 99.85%, op_acc: 83.35%] [G loss: 6.344880]\n",
            "Validating on test set\n",
            "Validation Metrics: 2301 [D loss: 0.050842, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.339663]\n",
            "(1024, 1)\n",
            "Training Metrics: 2302 [D loss: 0.490253, acc.: 99.66%, op_acc: 84.67%] [G loss: 6.078302]\n",
            "Validating on test set\n",
            "Validation Metrics: 2302 [D loss: 0.052576, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.053842]\n",
            "(1024, 1)\n",
            "Training Metrics: 2303 [D loss: 0.464250, acc.: 99.85%, op_acc: 84.52%] [G loss: 5.738644]\n",
            "Validating on test set\n",
            "Validation Metrics: 2303 [D loss: 0.055087, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.731396]\n",
            "(1024, 1)\n",
            "Training Metrics: 2304 [D loss: 0.450914, acc.: 99.90%, op_acc: 84.86%] [G loss: 6.497294]\n",
            "Validating on test set\n",
            "Validation Metrics: 2304 [D loss: 0.056433, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.501641]\n",
            "(1024, 1)\n",
            "Training Metrics: 2305 [D loss: 0.441828, acc.: 99.85%, op_acc: 84.91%] [G loss: 5.858641]\n",
            "Validating on test set\n",
            "Validation Metrics: 2305 [D loss: 0.055135, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.872546]\n",
            "(1024, 1)\n",
            "Training Metrics: 2306 [D loss: 0.414678, acc.: 99.80%, op_acc: 86.18%] [G loss: 6.275147]\n",
            "Validating on test set\n",
            "Validation Metrics: 2306 [D loss: 0.047599, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.263868]\n",
            "(1024, 1)\n",
            "Training Metrics: 2307 [D loss: 0.428149, acc.: 99.95%, op_acc: 84.72%] [G loss: 6.060388]\n",
            "Validating on test set\n",
            "Validation Metrics: 2307 [D loss: 0.050402, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.053607]\n",
            "(1024, 1)\n",
            "Training Metrics: 2308 [D loss: 0.466140, acc.: 99.76%, op_acc: 84.86%] [G loss: 5.942800]\n",
            "Validating on test set\n",
            "Validation Metrics: 2308 [D loss: 0.057304, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.916340]\n",
            "(1024, 1)\n",
            "Training Metrics: 2309 [D loss: 0.404801, acc.: 99.95%, op_acc: 85.64%] [G loss: 6.057934]\n",
            "Validating on test set\n",
            "Validation Metrics: 2309 [D loss: 0.051273, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.062251]\n",
            "(1024, 1)\n",
            "Training Metrics: 2310 [D loss: 0.437175, acc.: 99.95%, op_acc: 84.33%] [G loss: 6.573432]\n",
            "Validating on test set\n",
            "Validation Metrics: 2310 [D loss: 0.063843, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.571168]\n",
            "(1024, 1)\n",
            "Training Metrics: 2311 [D loss: 0.486806, acc.: 99.90%, op_acc: 83.74%] [G loss: 5.749360]\n",
            "Validating on test set\n",
            "Validation Metrics: 2311 [D loss: 0.056858, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.763751]\n",
            "(1024, 1)\n",
            "Training Metrics: 2312 [D loss: 0.485930, acc.: 99.71%, op_acc: 83.15%] [G loss: 6.693604]\n",
            "Validating on test set\n",
            "Validation Metrics: 2312 [D loss: 0.047612, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.657421]\n",
            "(1024, 1)\n",
            "Training Metrics: 2313 [D loss: 0.439343, acc.: 99.76%, op_acc: 84.91%] [G loss: 6.131876]\n",
            "Validating on test set\n",
            "Validation Metrics: 2313 [D loss: 0.049958, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.119408]\n",
            "(1024, 1)\n",
            "Training Metrics: 2314 [D loss: 0.444094, acc.: 99.95%, op_acc: 84.91%] [G loss: 5.755336]\n",
            "Validating on test set\n",
            "Validation Metrics: 2314 [D loss: 0.059515, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.770906]\n",
            "(1024, 1)\n",
            "Training Metrics: 2315 [D loss: 0.454744, acc.: 99.90%, op_acc: 85.11%] [G loss: 6.218324]\n",
            "Validating on test set\n",
            "Validation Metrics: 2315 [D loss: 0.055982, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.238650]\n",
            "(1024, 1)\n",
            "Training Metrics: 2316 [D loss: 0.446443, acc.: 99.80%, op_acc: 85.55%] [G loss: 6.392369]\n",
            "Validating on test set\n",
            "Validation Metrics: 2316 [D loss: 0.050105, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.367882]\n",
            "(1024, 1)\n",
            "Training Metrics: 2317 [D loss: 0.438139, acc.: 99.76%, op_acc: 84.96%] [G loss: 6.098546]\n",
            "Validating on test set\n",
            "Validation Metrics: 2317 [D loss: 0.045986, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.066485]\n",
            "(1024, 1)\n",
            "Training Metrics: 2318 [D loss: 0.404346, acc.: 99.95%, op_acc: 86.28%] [G loss: 6.254928]\n",
            "Validating on test set\n",
            "Validation Metrics: 2318 [D loss: 0.047477, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.209248]\n",
            "(1024, 1)\n",
            "Training Metrics: 2319 [D loss: 0.477198, acc.: 99.80%, op_acc: 84.28%] [G loss: 5.816794]\n",
            "Validating on test set\n",
            "Validation Metrics: 2319 [D loss: 0.052777, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.822653]\n",
            "(1024, 1)\n",
            "Training Metrics: 2320 [D loss: 0.441420, acc.: 99.90%, op_acc: 85.01%] [G loss: 6.043104]\n",
            "Validating on test set\n",
            "Validation Metrics: 2320 [D loss: 0.049316, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.016834]\n",
            "(1024, 1)\n",
            "Training Metrics: 2321 [D loss: 0.490270, acc.: 99.71%, op_acc: 84.42%] [G loss: 5.898317]\n",
            "Validating on test set\n",
            "Validation Metrics: 2321 [D loss: 0.049165, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.884890]\n",
            "(1024, 1)\n",
            "Training Metrics: 2322 [D loss: 0.424957, acc.: 99.85%, op_acc: 85.01%] [G loss: 5.976038]\n",
            "Validating on test set\n",
            "Validation Metrics: 2322 [D loss: 0.053671, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.987012]\n",
            "(1024, 1)\n",
            "Training Metrics: 2323 [D loss: 0.441710, acc.: 99.76%, op_acc: 84.52%] [G loss: 6.012732]\n",
            "Validating on test set\n",
            "Validation Metrics: 2323 [D loss: 0.053860, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.001725]\n",
            "(1024, 1)\n",
            "Training Metrics: 2324 [D loss: 0.444767, acc.: 99.56%, op_acc: 84.47%] [G loss: 5.603303]\n",
            "Validating on test set\n",
            "Validation Metrics: 2324 [D loss: 0.055635, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.594264]\n",
            "(1024, 1)\n",
            "Training Metrics: 2325 [D loss: 0.441839, acc.: 99.85%, op_acc: 84.81%] [G loss: 6.185197]\n",
            "Validating on test set\n",
            "Validation Metrics: 2325 [D loss: 0.047072, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.180391]\n",
            "(1024, 1)\n",
            "Training Metrics: 2326 [D loss: 0.478018, acc.: 99.95%, op_acc: 83.84%] [G loss: 5.857533]\n",
            "Validating on test set\n",
            "Validation Metrics: 2326 [D loss: 0.047908, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.851633]\n",
            "(1024, 1)\n",
            "Training Metrics: 2327 [D loss: 0.469427, acc.: 99.80%, op_acc: 83.40%] [G loss: 6.475856]\n",
            "Validating on test set\n",
            "Validation Metrics: 2327 [D loss: 0.053146, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.523561]\n",
            "(1024, 1)\n",
            "Training Metrics: 2328 [D loss: 0.482378, acc.: 99.80%, op_acc: 83.74%] [G loss: 6.095753]\n",
            "Validating on test set\n",
            "Validation Metrics: 2328 [D loss: 0.056396, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.128733]\n",
            "(1024, 1)\n",
            "Training Metrics: 2329 [D loss: 0.455117, acc.: 99.76%, op_acc: 84.81%] [G loss: 5.877257]\n",
            "Validating on test set\n",
            "Validation Metrics: 2329 [D loss: 0.051153, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.844649]\n",
            "(1024, 1)\n",
            "Training Metrics: 2330 [D loss: 0.458603, acc.: 99.90%, op_acc: 85.35%] [G loss: 6.408665]\n",
            "Validating on test set\n",
            "Validation Metrics: 2330 [D loss: 0.043152, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.409414]\n",
            "(1024, 1)\n",
            "Training Metrics: 2331 [D loss: 0.407191, acc.: 99.80%, op_acc: 85.11%] [G loss: 6.246332]\n",
            "Validating on test set\n",
            "Validation Metrics: 2331 [D loss: 0.050900, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.190830]\n",
            "(1024, 1)\n",
            "Training Metrics: 2332 [D loss: 0.423977, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.555575]\n",
            "Validating on test set\n",
            "Validation Metrics: 2332 [D loss: 0.045909, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.524890]\n",
            "(1024, 1)\n",
            "Training Metrics: 2333 [D loss: 0.472790, acc.: 99.71%, op_acc: 84.28%] [G loss: 6.065345]\n",
            "Validating on test set\n",
            "Validation Metrics: 2333 [D loss: 0.047480, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.075013]\n",
            "(1024, 1)\n",
            "Training Metrics: 2334 [D loss: 0.425740, acc.: 99.90%, op_acc: 85.50%] [G loss: 6.065001]\n",
            "Validating on test set\n",
            "Validation Metrics: 2334 [D loss: 0.042201, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.060975]\n",
            "(1024, 1)\n",
            "Training Metrics: 2335 [D loss: 0.436690, acc.: 99.85%, op_acc: 84.96%] [G loss: 6.382111]\n",
            "Validating on test set\n",
            "Validation Metrics: 2335 [D loss: 0.041010, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.381747]\n",
            "(1024, 1)\n",
            "Training Metrics: 2336 [D loss: 0.407686, acc.: 99.95%, op_acc: 85.25%] [G loss: 6.178135]\n",
            "Validating on test set\n",
            "Validation Metrics: 2336 [D loss: 0.049703, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.179168]\n",
            "(1024, 1)\n",
            "Training Metrics: 2337 [D loss: 0.458818, acc.: 99.85%, op_acc: 84.52%] [G loss: 6.606603]\n",
            "Validating on test set\n",
            "Validation Metrics: 2337 [D loss: 0.045913, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.651222]\n",
            "(1024, 1)\n",
            "Training Metrics: 2338 [D loss: 0.439807, acc.: 99.71%, op_acc: 85.79%] [G loss: 5.651612]\n",
            "Validating on test set\n",
            "Validation Metrics: 2338 [D loss: 0.055438, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.654082]\n",
            "(1024, 1)\n",
            "Training Metrics: 2339 [D loss: 0.440510, acc.: 99.80%, op_acc: 85.35%] [G loss: 6.093539]\n",
            "Validating on test set\n",
            "Validation Metrics: 2339 [D loss: 0.045333, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.065378]\n",
            "(1024, 1)\n",
            "Training Metrics: 2340 [D loss: 0.396324, acc.: 99.85%, op_acc: 86.08%] [G loss: 6.151300]\n",
            "Validating on test set\n",
            "Validation Metrics: 2340 [D loss: 0.045228, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.154384]\n",
            "(1024, 1)\n",
            "Training Metrics: 2341 [D loss: 0.437927, acc.: 99.85%, op_acc: 85.84%] [G loss: 5.490466]\n",
            "Validating on test set\n",
            "Validation Metrics: 2341 [D loss: 0.065993, acc.: 100.00%, op_acc: 99.51%] [G loss: 5.490410]\n",
            "(1024, 1)\n",
            "Training Metrics: 2342 [D loss: 0.442732, acc.: 99.76%, op_acc: 84.67%] [G loss: 6.212378]\n",
            "Validating on test set\n",
            "Validation Metrics: 2342 [D loss: 0.041287, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.215060]\n",
            "(1024, 1)\n",
            "Training Metrics: 2343 [D loss: 0.432045, acc.: 99.76%, op_acc: 84.91%] [G loss: 5.851072]\n",
            "Validating on test set\n",
            "Validation Metrics: 2343 [D loss: 0.049583, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.836824]\n",
            "(1024, 1)\n",
            "Training Metrics: 2344 [D loss: 0.454975, acc.: 99.80%, op_acc: 85.06%] [G loss: 6.365838]\n",
            "Validating on test set\n",
            "Validation Metrics: 2344 [D loss: 0.046293, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.354918]\n",
            "(1024, 1)\n",
            "Training Metrics: 2345 [D loss: 0.446186, acc.: 99.80%, op_acc: 84.77%] [G loss: 5.671327]\n",
            "Validating on test set\n",
            "Validation Metrics: 2345 [D loss: 0.048067, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.662521]\n",
            "(1024, 1)\n",
            "Training Metrics: 2346 [D loss: 0.429502, acc.: 99.85%, op_acc: 85.74%] [G loss: 6.211009]\n",
            "Validating on test set\n",
            "Validation Metrics: 2346 [D loss: 0.045495, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.194095]\n",
            "(1024, 1)\n",
            "Training Metrics: 2347 [D loss: 0.408675, acc.: 99.90%, op_acc: 86.23%] [G loss: 6.231216]\n",
            "Validating on test set\n",
            "Validation Metrics: 2347 [D loss: 0.050528, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.225135]\n",
            "(1024, 1)\n",
            "Training Metrics: 2348 [D loss: 0.445088, acc.: 99.90%, op_acc: 84.96%] [G loss: 6.289451]\n",
            "Validating on test set\n",
            "Validation Metrics: 2348 [D loss: 0.048957, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.220821]\n",
            "(1024, 1)\n",
            "Training Metrics: 2349 [D loss: 0.428012, acc.: 99.90%, op_acc: 85.21%] [G loss: 6.077497]\n",
            "Validating on test set\n",
            "Validation Metrics: 2349 [D loss: 0.043138, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.073188]\n",
            "(1024, 1)\n",
            "Training Metrics: 2350 [D loss: 0.465267, acc.: 99.66%, op_acc: 83.01%] [G loss: 6.231668]\n",
            "Validating on test set\n",
            "Validation Metrics: 2350 [D loss: 0.052137, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.248802]\n",
            "(1024, 1)\n",
            "Training Metrics: 2351 [D loss: 0.422584, acc.: 99.66%, op_acc: 86.04%] [G loss: 5.896097]\n",
            "Validating on test set\n",
            "Validation Metrics: 2351 [D loss: 0.045170, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.887298]\n",
            "(1024, 1)\n",
            "Training Metrics: 2352 [D loss: 0.420311, acc.: 99.80%, op_acc: 86.52%] [G loss: 5.994048]\n",
            "Validating on test set\n",
            "Validation Metrics: 2352 [D loss: 0.047429, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.977444]\n",
            "(1024, 1)\n",
            "Training Metrics: 2353 [D loss: 0.440884, acc.: 99.85%, op_acc: 84.28%] [G loss: 6.290691]\n",
            "Validating on test set\n",
            "Validation Metrics: 2353 [D loss: 0.051743, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.305409]\n",
            "(1024, 1)\n",
            "Training Metrics: 2354 [D loss: 0.420314, acc.: 99.85%, op_acc: 85.06%] [G loss: 5.857604]\n",
            "Validating on test set\n",
            "Validation Metrics: 2354 [D loss: 0.044262, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.850761]\n",
            "(1024, 1)\n",
            "Training Metrics: 2355 [D loss: 0.455738, acc.: 99.85%, op_acc: 84.38%] [G loss: 6.567986]\n",
            "Validating on test set\n",
            "Validation Metrics: 2355 [D loss: 0.040426, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.573997]\n",
            "(1024, 1)\n",
            "Training Metrics: 2356 [D loss: 0.419660, acc.: 99.85%, op_acc: 84.86%] [G loss: 5.877796]\n",
            "Validating on test set\n",
            "Validation Metrics: 2356 [D loss: 0.049537, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.863261]\n",
            "(1024, 1)\n",
            "Training Metrics: 2357 [D loss: 0.407944, acc.: 99.80%, op_acc: 86.87%] [G loss: 5.909628]\n",
            "Validating on test set\n",
            "Validation Metrics: 2357 [D loss: 0.045034, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.901686]\n",
            "(1024, 1)\n",
            "Training Metrics: 2358 [D loss: 0.394135, acc.: 99.76%, op_acc: 86.82%] [G loss: 6.448013]\n",
            "Validating on test set\n",
            "Validation Metrics: 2358 [D loss: 0.045539, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.448257]\n",
            "(1024, 1)\n",
            "Training Metrics: 2359 [D loss: 0.409948, acc.: 99.90%, op_acc: 84.86%] [G loss: 6.114954]\n",
            "Validating on test set\n",
            "Validation Metrics: 2359 [D loss: 0.060389, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.128572]\n",
            "(1024, 1)\n",
            "Training Metrics: 2360 [D loss: 0.469886, acc.: 99.85%, op_acc: 83.94%] [G loss: 6.046404]\n",
            "Validating on test set\n",
            "Validation Metrics: 2360 [D loss: 0.050486, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.045796]\n",
            "(1024, 1)\n",
            "Training Metrics: 2361 [D loss: 0.429147, acc.: 99.76%, op_acc: 84.52%] [G loss: 6.044561]\n",
            "Validating on test set\n",
            "Validation Metrics: 2361 [D loss: 0.044185, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.010876]\n",
            "(1024, 1)\n",
            "Training Metrics: 2362 [D loss: 0.439392, acc.: 99.95%, op_acc: 85.16%] [G loss: 6.458846]\n",
            "Validating on test set\n",
            "Validation Metrics: 2362 [D loss: 0.038143, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.450850]\n",
            "(1024, 1)\n",
            "Training Metrics: 2363 [D loss: 0.437604, acc.: 99.71%, op_acc: 84.08%] [G loss: 5.724477]\n",
            "Validating on test set\n",
            "Validation Metrics: 2363 [D loss: 0.039727, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.721265]\n",
            "(1024, 1)\n",
            "Training Metrics: 2364 [D loss: 0.454823, acc.: 99.76%, op_acc: 83.40%] [G loss: 5.862940]\n",
            "Validating on test set\n",
            "Validation Metrics: 2364 [D loss: 0.052862, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.867188]\n",
            "(1024, 1)\n",
            "Training Metrics: 2365 [D loss: 0.427956, acc.: 99.95%, op_acc: 85.01%] [G loss: 6.051763]\n",
            "Validating on test set\n",
            "Validation Metrics: 2365 [D loss: 0.042342, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.072554]\n",
            "(1024, 1)\n",
            "Training Metrics: 2366 [D loss: 0.433007, acc.: 99.80%, op_acc: 84.86%] [G loss: 6.336047]\n",
            "Validating on test set\n",
            "Validation Metrics: 2366 [D loss: 0.054547, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.319510]\n",
            "(1024, 1)\n",
            "Training Metrics: 2367 [D loss: 0.449125, acc.: 99.90%, op_acc: 85.40%] [G loss: 6.015738]\n",
            "Validating on test set\n",
            "Validation Metrics: 2367 [D loss: 0.059718, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.021935]\n",
            "(1024, 1)\n",
            "Training Metrics: 2368 [D loss: 0.456497, acc.: 99.80%, op_acc: 83.64%] [G loss: 6.236551]\n",
            "Validating on test set\n",
            "Validation Metrics: 2368 [D loss: 0.038541, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.200443]\n",
            "(1024, 1)\n",
            "Training Metrics: 2369 [D loss: 0.444934, acc.: 99.61%, op_acc: 84.86%] [G loss: 5.974926]\n",
            "Validating on test set\n",
            "Validation Metrics: 2369 [D loss: 0.042495, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.947442]\n",
            "(1024, 1)\n",
            "Training Metrics: 2370 [D loss: 0.471727, acc.: 99.80%, op_acc: 84.62%] [G loss: 6.180970]\n",
            "Validating on test set\n",
            "Validation Metrics: 2370 [D loss: 0.042062, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.185583]\n",
            "(1024, 1)\n",
            "Training Metrics: 2371 [D loss: 0.433043, acc.: 99.90%, op_acc: 83.45%] [G loss: 6.205760]\n",
            "Validating on test set\n",
            "Validation Metrics: 2371 [D loss: 0.038026, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.204348]\n",
            "(1024, 1)\n",
            "Training Metrics: 2372 [D loss: 0.465724, acc.: 99.95%, op_acc: 85.11%] [G loss: 6.499597]\n",
            "Validating on test set\n",
            "Validation Metrics: 2372 [D loss: 0.034828, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.490782]\n",
            "(1024, 1)\n",
            "Training Metrics: 2373 [D loss: 0.451419, acc.: 99.66%, op_acc: 83.54%] [G loss: 6.195130]\n",
            "Validating on test set\n",
            "Validation Metrics: 2373 [D loss: 0.043055, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.185544]\n",
            "(1024, 1)\n",
            "Training Metrics: 2374 [D loss: 0.386660, acc.: 100.00%, op_acc: 86.52%] [G loss: 6.587296]\n",
            "Validating on test set\n",
            "Validation Metrics: 2374 [D loss: 0.036551, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.585205]\n",
            "(1024, 1)\n",
            "Training Metrics: 2375 [D loss: 0.423875, acc.: 99.76%, op_acc: 85.50%] [G loss: 6.153507]\n",
            "Validating on test set\n",
            "Validation Metrics: 2375 [D loss: 0.038984, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.143047]\n",
            "(1024, 1)\n",
            "Training Metrics: 2376 [D loss: 0.414782, acc.: 99.90%, op_acc: 85.99%] [G loss: 6.010678]\n",
            "Validating on test set\n",
            "Validation Metrics: 2376 [D loss: 0.049803, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.025746]\n",
            "(1024, 1)\n",
            "Training Metrics: 2377 [D loss: 0.423964, acc.: 99.90%, op_acc: 86.04%] [G loss: 6.583854]\n",
            "Validating on test set\n",
            "Validation Metrics: 2377 [D loss: 0.046198, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.568582]\n",
            "(1024, 1)\n",
            "Training Metrics: 2378 [D loss: 0.418602, acc.: 99.85%, op_acc: 85.94%] [G loss: 6.852297]\n",
            "Validating on test set\n",
            "Validation Metrics: 2378 [D loss: 0.036859, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.815160]\n",
            "(1024, 1)\n",
            "Training Metrics: 2379 [D loss: 0.436110, acc.: 99.90%, op_acc: 85.16%] [G loss: 6.716660]\n",
            "Validating on test set\n",
            "Validation Metrics: 2379 [D loss: 0.041489, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.691254]\n",
            "(1024, 1)\n",
            "Training Metrics: 2380 [D loss: 0.419605, acc.: 99.80%, op_acc: 85.94%] [G loss: 6.158799]\n",
            "Validating on test set\n",
            "Validation Metrics: 2380 [D loss: 0.046483, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.152167]\n",
            "(1024, 1)\n",
            "Training Metrics: 2381 [D loss: 0.396618, acc.: 99.80%, op_acc: 87.01%] [G loss: 6.133408]\n",
            "Validating on test set\n",
            "Validation Metrics: 2381 [D loss: 0.044804, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.106190]\n",
            "(1024, 1)\n",
            "Training Metrics: 2382 [D loss: 0.417362, acc.: 99.80%, op_acc: 85.74%] [G loss: 6.082518]\n",
            "Validating on test set\n",
            "Validation Metrics: 2382 [D loss: 0.040314, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.070802]\n",
            "(1024, 1)\n",
            "Training Metrics: 2383 [D loss: 0.406861, acc.: 99.85%, op_acc: 85.94%] [G loss: 6.024579]\n",
            "Validating on test set\n",
            "Validation Metrics: 2383 [D loss: 0.040508, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.033963]\n",
            "(1024, 1)\n",
            "Training Metrics: 2384 [D loss: 0.410939, acc.: 99.76%, op_acc: 85.35%] [G loss: 6.342973]\n",
            "Validating on test set\n",
            "Validation Metrics: 2384 [D loss: 0.046352, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.359554]\n",
            "(1024, 1)\n",
            "Training Metrics: 2385 [D loss: 0.417281, acc.: 99.66%, op_acc: 85.89%] [G loss: 5.475562]\n",
            "Validating on test set\n",
            "Validation Metrics: 2385 [D loss: 0.044993, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.481381]\n",
            "(1024, 1)\n",
            "Training Metrics: 2386 [D loss: 0.445009, acc.: 99.90%, op_acc: 84.67%] [G loss: 6.116517]\n",
            "Validating on test set\n",
            "Validation Metrics: 2386 [D loss: 0.036764, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.094093]\n",
            "(1024, 1)\n",
            "Training Metrics: 2387 [D loss: 0.430066, acc.: 99.85%, op_acc: 85.11%] [G loss: 5.946114]\n",
            "Validating on test set\n",
            "Validation Metrics: 2387 [D loss: 0.041889, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.951688]\n",
            "(1024, 1)\n",
            "Training Metrics: 2388 [D loss: 0.402184, acc.: 99.95%, op_acc: 86.77%] [G loss: 6.171880]\n",
            "Validating on test set\n",
            "Validation Metrics: 2388 [D loss: 0.042020, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.192105]\n",
            "(1024, 1)\n",
            "Training Metrics: 2389 [D loss: 0.413841, acc.: 99.80%, op_acc: 85.35%] [G loss: 6.436724]\n",
            "Validating on test set\n",
            "Validation Metrics: 2389 [D loss: 0.046062, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.455694]\n",
            "(1024, 1)\n",
            "Training Metrics: 2390 [D loss: 0.451504, acc.: 99.76%, op_acc: 84.57%] [G loss: 5.890146]\n",
            "Validating on test set\n",
            "Validation Metrics: 2390 [D loss: 0.042808, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.916498]\n",
            "(1024, 1)\n",
            "Training Metrics: 2391 [D loss: 0.454747, acc.: 99.85%, op_acc: 85.30%] [G loss: 6.036948]\n",
            "Validating on test set\n",
            "Validation Metrics: 2391 [D loss: 0.038483, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.021590]\n",
            "(1024, 1)\n",
            "Training Metrics: 2392 [D loss: 0.423431, acc.: 99.66%, op_acc: 85.94%] [G loss: 5.729288]\n",
            "Validating on test set\n",
            "Validation Metrics: 2392 [D loss: 0.041638, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.731394]\n",
            "(1024, 1)\n",
            "Training Metrics: 2393 [D loss: 0.431344, acc.: 99.85%, op_acc: 85.11%] [G loss: 6.165318]\n",
            "Validating on test set\n",
            "Validation Metrics: 2393 [D loss: 0.039863, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.170101]\n",
            "(1024, 1)\n",
            "Training Metrics: 2394 [D loss: 0.464124, acc.: 99.76%, op_acc: 84.23%] [G loss: 5.689326]\n",
            "Validating on test set\n",
            "Validation Metrics: 2394 [D loss: 0.041095, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.684425]\n",
            "(1024, 1)\n",
            "Training Metrics: 2395 [D loss: 0.445540, acc.: 99.90%, op_acc: 84.57%] [G loss: 6.310053]\n",
            "Validating on test set\n",
            "Validation Metrics: 2395 [D loss: 0.044098, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.307346]\n",
            "(1024, 1)\n",
            "Training Metrics: 2396 [D loss: 0.457456, acc.: 99.85%, op_acc: 84.33%] [G loss: 6.633123]\n",
            "Validating on test set\n",
            "Validation Metrics: 2396 [D loss: 0.045967, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.650617]\n",
            "(1024, 1)\n",
            "Training Metrics: 2397 [D loss: 0.437993, acc.: 99.80%, op_acc: 84.77%] [G loss: 6.062905]\n",
            "Validating on test set\n",
            "Validation Metrics: 2397 [D loss: 0.042716, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.058454]\n",
            "(1024, 1)\n",
            "Training Metrics: 2398 [D loss: 0.424230, acc.: 99.76%, op_acc: 83.94%] [G loss: 5.874394]\n",
            "Validating on test set\n",
            "Validation Metrics: 2398 [D loss: 0.052451, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.859757]\n",
            "(1024, 1)\n",
            "Training Metrics: 2399 [D loss: 0.437703, acc.: 99.85%, op_acc: 85.16%] [G loss: 6.074801]\n",
            "Validating on test set\n",
            "Validation Metrics: 2399 [D loss: 0.052544, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.076222]\n",
            "(1024, 1)\n",
            "Training Metrics: 2400 [D loss: 0.455691, acc.: 99.76%, op_acc: 85.06%] [G loss: 6.390747]\n",
            "Validating on test set\n",
            "Validation Metrics: 2400 [D loss: 0.031956, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.352411]\n",
            "(1024, 1)\n",
            "Training Metrics: 2401 [D loss: 0.427261, acc.: 99.85%, op_acc: 84.18%] [G loss: 5.641592]\n",
            "Validating on test set\n",
            "Validation Metrics: 2401 [D loss: 0.042661, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.660623]\n",
            "(1024, 1)\n",
            "Training Metrics: 2402 [D loss: 0.440472, acc.: 99.61%, op_acc: 84.42%] [G loss: 5.925994]\n",
            "Validating on test set\n",
            "Validation Metrics: 2402 [D loss: 0.038901, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.893445]\n",
            "(1024, 1)\n",
            "Training Metrics: 2403 [D loss: 0.430694, acc.: 99.95%, op_acc: 86.18%] [G loss: 6.151551]\n",
            "Validating on test set\n",
            "Validation Metrics: 2403 [D loss: 0.033737, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.157528]\n",
            "(1024, 1)\n",
            "Training Metrics: 2404 [D loss: 0.408943, acc.: 99.76%, op_acc: 85.84%] [G loss: 6.423924]\n",
            "Validating on test set\n",
            "Validation Metrics: 2404 [D loss: 0.035436, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.427132]\n",
            "(1024, 1)\n",
            "Training Metrics: 2405 [D loss: 0.415357, acc.: 99.85%, op_acc: 86.62%] [G loss: 6.188951]\n",
            "Validating on test set\n",
            "Validation Metrics: 2405 [D loss: 0.037664, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.195906]\n",
            "(1024, 1)\n",
            "Training Metrics: 2406 [D loss: 0.389478, acc.: 99.76%, op_acc: 86.38%] [G loss: 6.206563]\n",
            "Validating on test set\n",
            "Validation Metrics: 2406 [D loss: 0.043703, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.207098]\n",
            "(1024, 1)\n",
            "Training Metrics: 2407 [D loss: 0.407972, acc.: 99.66%, op_acc: 86.33%] [G loss: 5.881217]\n",
            "Validating on test set\n",
            "Validation Metrics: 2407 [D loss: 0.037518, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.845135]\n",
            "(1024, 1)\n",
            "Training Metrics: 2408 [D loss: 0.424575, acc.: 99.85%, op_acc: 84.96%] [G loss: 5.811604]\n",
            "Validating on test set\n",
            "Validation Metrics: 2408 [D loss: 0.039106, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.804973]\n",
            "(1024, 1)\n",
            "Training Metrics: 2409 [D loss: 0.443663, acc.: 99.90%, op_acc: 83.89%] [G loss: 6.068172]\n",
            "Validating on test set\n",
            "Validation Metrics: 2409 [D loss: 0.038285, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.060083]\n",
            "(1024, 1)\n",
            "Training Metrics: 2410 [D loss: 0.425055, acc.: 99.95%, op_acc: 85.40%] [G loss: 6.326708]\n",
            "Validating on test set\n",
            "Validation Metrics: 2410 [D loss: 0.037419, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.336249]\n",
            "(1024, 1)\n",
            "Training Metrics: 2411 [D loss: 0.436190, acc.: 99.85%, op_acc: 84.38%] [G loss: 6.379885]\n",
            "Validating on test set\n",
            "Validation Metrics: 2411 [D loss: 0.037225, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.393576]\n",
            "(1024, 1)\n",
            "Training Metrics: 2412 [D loss: 0.442156, acc.: 99.85%, op_acc: 85.25%] [G loss: 5.882089]\n",
            "Validating on test set\n",
            "Validation Metrics: 2412 [D loss: 0.053197, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.875991]\n",
            "(1024, 1)\n",
            "Training Metrics: 2413 [D loss: 0.454618, acc.: 99.80%, op_acc: 83.94%] [G loss: 6.356941]\n",
            "Validating on test set\n",
            "Validation Metrics: 2413 [D loss: 0.043433, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.345092]\n",
            "(1024, 1)\n",
            "Training Metrics: 2414 [D loss: 0.480566, acc.: 99.61%, op_acc: 85.06%] [G loss: 5.821375]\n",
            "Validating on test set\n",
            "Validation Metrics: 2414 [D loss: 0.041311, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.817307]\n",
            "(1024, 1)\n",
            "Training Metrics: 2415 [D loss: 0.406868, acc.: 99.80%, op_acc: 85.25%] [G loss: 6.125732]\n",
            "Validating on test set\n",
            "Validation Metrics: 2415 [D loss: 0.039747, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.121569]\n",
            "(1024, 1)\n",
            "Training Metrics: 2416 [D loss: 0.423746, acc.: 99.80%, op_acc: 85.69%] [G loss: 5.982219]\n",
            "Validating on test set\n",
            "Validation Metrics: 2416 [D loss: 0.039590, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.979023]\n",
            "(1024, 1)\n",
            "Training Metrics: 2417 [D loss: 0.419160, acc.: 99.95%, op_acc: 85.79%] [G loss: 6.240801]\n",
            "Validating on test set\n",
            "Validation Metrics: 2417 [D loss: 0.039849, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.212594]\n",
            "(1024, 1)\n",
            "Training Metrics: 2418 [D loss: 0.419878, acc.: 99.85%, op_acc: 84.42%] [G loss: 6.845983]\n",
            "Validating on test set\n",
            "Validation Metrics: 2418 [D loss: 0.045579, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.841496]\n",
            "(1024, 1)\n",
            "Training Metrics: 2419 [D loss: 0.421952, acc.: 99.95%, op_acc: 86.04%] [G loss: 6.037416]\n",
            "Validating on test set\n",
            "Validation Metrics: 2419 [D loss: 0.042120, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.058352]\n",
            "(1024, 1)\n",
            "Training Metrics: 2420 [D loss: 0.409175, acc.: 99.90%, op_acc: 86.18%] [G loss: 6.672390]\n",
            "Validating on test set\n",
            "Validation Metrics: 2420 [D loss: 0.035092, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.658969]\n",
            "(1024, 1)\n",
            "Training Metrics: 2421 [D loss: 0.430696, acc.: 99.85%, op_acc: 84.91%] [G loss: 6.381027]\n",
            "Validating on test set\n",
            "Validation Metrics: 2421 [D loss: 0.041615, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.380012]\n",
            "(1024, 1)\n",
            "Training Metrics: 2422 [D loss: 0.386822, acc.: 99.90%, op_acc: 87.65%] [G loss: 6.467074]\n",
            "Validating on test set\n",
            "Validation Metrics: 2422 [D loss: 0.034500, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.483590]\n",
            "(1024, 1)\n",
            "Training Metrics: 2423 [D loss: 0.435871, acc.: 99.80%, op_acc: 84.57%] [G loss: 5.832412]\n",
            "Validating on test set\n",
            "Validation Metrics: 2423 [D loss: 0.041989, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.826234]\n",
            "(1024, 1)\n",
            "Training Metrics: 2424 [D loss: 0.441117, acc.: 99.76%, op_acc: 84.86%] [G loss: 6.290906]\n",
            "Validating on test set\n",
            "Validation Metrics: 2424 [D loss: 0.043849, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.259353]\n",
            "(1024, 1)\n",
            "Training Metrics: 2425 [D loss: 0.457393, acc.: 99.80%, op_acc: 84.38%] [G loss: 5.733939]\n",
            "Validating on test set\n",
            "Validation Metrics: 2425 [D loss: 0.045039, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.755110]\n",
            "(1024, 1)\n",
            "Training Metrics: 2426 [D loss: 0.442448, acc.: 99.90%, op_acc: 84.72%] [G loss: 6.575387]\n",
            "Validating on test set\n",
            "Validation Metrics: 2426 [D loss: 0.039492, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.557379]\n",
            "(1024, 1)\n",
            "Training Metrics: 2427 [D loss: 0.440614, acc.: 99.90%, op_acc: 84.86%] [G loss: 6.232953]\n",
            "Validating on test set\n",
            "Validation Metrics: 2427 [D loss: 0.040020, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.226867]\n",
            "(1024, 1)\n",
            "Training Metrics: 2428 [D loss: 0.415642, acc.: 99.85%, op_acc: 85.69%] [G loss: 6.334075]\n",
            "Validating on test set\n",
            "Validation Metrics: 2428 [D loss: 0.045169, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.335786]\n",
            "(1024, 1)\n",
            "Training Metrics: 2429 [D loss: 0.438759, acc.: 99.90%, op_acc: 84.18%] [G loss: 6.514305]\n",
            "Validating on test set\n",
            "Validation Metrics: 2429 [D loss: 0.036677, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.542577]\n",
            "(1024, 1)\n",
            "Training Metrics: 2430 [D loss: 0.473156, acc.: 99.80%, op_acc: 83.98%] [G loss: 5.974161]\n",
            "Validating on test set\n",
            "Validation Metrics: 2430 [D loss: 0.036870, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.972149]\n",
            "(1024, 1)\n",
            "Training Metrics: 2431 [D loss: 0.411053, acc.: 99.85%, op_acc: 85.69%] [G loss: 6.248240]\n",
            "Validating on test set\n",
            "Validation Metrics: 2431 [D loss: 0.043111, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.241102]\n",
            "(1024, 1)\n",
            "Training Metrics: 2432 [D loss: 0.442492, acc.: 99.85%, op_acc: 86.04%] [G loss: 5.837820]\n",
            "Validating on test set\n",
            "Validation Metrics: 2432 [D loss: 0.042142, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.841533]\n",
            "(1024, 1)\n",
            "Training Metrics: 2433 [D loss: 0.444201, acc.: 99.90%, op_acc: 86.04%] [G loss: 5.870458]\n",
            "Validating on test set\n",
            "Validation Metrics: 2433 [D loss: 0.041224, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.874471]\n",
            "(1024, 1)\n",
            "Training Metrics: 2434 [D loss: 0.416189, acc.: 99.95%, op_acc: 85.84%] [G loss: 6.242798]\n",
            "Validating on test set\n",
            "Validation Metrics: 2434 [D loss: 0.034242, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.240356]\n",
            "(1024, 1)\n",
            "Training Metrics: 2435 [D loss: 0.421437, acc.: 99.80%, op_acc: 85.30%] [G loss: 6.287451]\n",
            "Validating on test set\n",
            "Validation Metrics: 2435 [D loss: 0.034599, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.287482]\n",
            "(1024, 1)\n",
            "Training Metrics: 2436 [D loss: 0.412867, acc.: 99.51%, op_acc: 86.47%] [G loss: 5.458663]\n",
            "Validating on test set\n",
            "Validation Metrics: 2436 [D loss: 0.045194, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.468246]\n",
            "(1024, 1)\n",
            "Training Metrics: 2437 [D loss: 0.435346, acc.: 100.00%, op_acc: 86.08%] [G loss: 6.099541]\n",
            "Validating on test set\n",
            "Validation Metrics: 2437 [D loss: 0.038424, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.086510]\n",
            "(1024, 1)\n",
            "Training Metrics: 2438 [D loss: 0.407952, acc.: 100.00%, op_acc: 86.04%] [G loss: 6.545353]\n",
            "Validating on test set\n",
            "Validation Metrics: 2438 [D loss: 0.032824, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.522378]\n",
            "(1024, 1)\n",
            "Training Metrics: 2439 [D loss: 0.449768, acc.: 99.71%, op_acc: 84.52%] [G loss: 6.211018]\n",
            "Validating on test set\n",
            "Validation Metrics: 2439 [D loss: 0.039377, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.222736]\n",
            "(1024, 1)\n",
            "Training Metrics: 2440 [D loss: 0.440776, acc.: 99.76%, op_acc: 84.52%] [G loss: 6.195770]\n",
            "Validating on test set\n",
            "Validation Metrics: 2440 [D loss: 0.046660, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.204767]\n",
            "(1024, 1)\n",
            "Training Metrics: 2441 [D loss: 0.413570, acc.: 99.95%, op_acc: 85.45%] [G loss: 6.323403]\n",
            "Validating on test set\n",
            "Validation Metrics: 2441 [D loss: 0.032654, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.328517]\n",
            "(1024, 1)\n",
            "Training Metrics: 2442 [D loss: 0.436592, acc.: 99.71%, op_acc: 84.47%] [G loss: 6.163631]\n",
            "Validating on test set\n",
            "Validation Metrics: 2442 [D loss: 0.037351, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.153249]\n",
            "(1024, 1)\n",
            "Training Metrics: 2443 [D loss: 0.420886, acc.: 99.85%, op_acc: 85.40%] [G loss: 5.570994]\n",
            "Validating on test set\n",
            "Validation Metrics: 2443 [D loss: 0.039147, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.559229]\n",
            "(1024, 1)\n",
            "Training Metrics: 2444 [D loss: 0.433831, acc.: 99.85%, op_acc: 84.91%] [G loss: 6.250954]\n",
            "Validating on test set\n",
            "Validation Metrics: 2444 [D loss: 0.040000, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.264493]\n",
            "(1024, 1)\n",
            "Training Metrics: 2445 [D loss: 0.418631, acc.: 99.80%, op_acc: 86.23%] [G loss: 5.881030]\n",
            "Validating on test set\n",
            "Validation Metrics: 2445 [D loss: 0.036471, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.860894]\n",
            "(1024, 1)\n",
            "Training Metrics: 2446 [D loss: 0.461296, acc.: 99.85%, op_acc: 84.57%] [G loss: 5.964303]\n",
            "Validating on test set\n",
            "Validation Metrics: 2446 [D loss: 0.036771, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.978909]\n",
            "(1024, 1)\n",
            "Training Metrics: 2447 [D loss: 0.421201, acc.: 99.76%, op_acc: 85.89%] [G loss: 5.843002]\n",
            "Validating on test set\n",
            "Validation Metrics: 2447 [D loss: 0.037820, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.828368]\n",
            "(1024, 1)\n",
            "Training Metrics: 2448 [D loss: 0.426535, acc.: 99.95%, op_acc: 84.81%] [G loss: 6.467748]\n",
            "Validating on test set\n",
            "Validation Metrics: 2448 [D loss: 0.037227, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.468214]\n",
            "(1024, 1)\n",
            "Training Metrics: 2449 [D loss: 0.438594, acc.: 99.90%, op_acc: 85.16%] [G loss: 6.288888]\n",
            "Validating on test set\n",
            "Validation Metrics: 2449 [D loss: 0.033184, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.300793]\n",
            "(1024, 1)\n",
            "Training Metrics: 2450 [D loss: 0.441868, acc.: 99.90%, op_acc: 85.25%] [G loss: 6.239866]\n",
            "Validating on test set\n",
            "Validation Metrics: 2450 [D loss: 0.034572, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.224665]\n",
            "(1024, 1)\n",
            "Training Metrics: 2451 [D loss: 0.433774, acc.: 99.90%, op_acc: 84.08%] [G loss: 6.552753]\n",
            "Validating on test set\n",
            "Validation Metrics: 2451 [D loss: 0.037617, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.576596]\n",
            "(1024, 1)\n",
            "Training Metrics: 2452 [D loss: 0.410659, acc.: 99.90%, op_acc: 84.23%] [G loss: 6.042484]\n",
            "Validating on test set\n",
            "Validation Metrics: 2452 [D loss: 0.032777, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.032688]\n",
            "(1024, 1)\n",
            "Training Metrics: 2453 [D loss: 0.454209, acc.: 99.90%, op_acc: 84.23%] [G loss: 6.689260]\n",
            "Validating on test set\n",
            "Validation Metrics: 2453 [D loss: 0.034450, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.714625]\n",
            "(1024, 1)\n",
            "Training Metrics: 2454 [D loss: 0.408391, acc.: 99.90%, op_acc: 85.74%] [G loss: 6.507522]\n",
            "Validating on test set\n",
            "Validation Metrics: 2454 [D loss: 0.033950, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.513986]\n",
            "(1024, 1)\n",
            "Training Metrics: 2455 [D loss: 0.426345, acc.: 99.76%, op_acc: 85.64%] [G loss: 6.428857]\n",
            "Validating on test set\n",
            "Validation Metrics: 2455 [D loss: 0.045626, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.403996]\n",
            "(1024, 1)\n",
            "Training Metrics: 2456 [D loss: 0.411796, acc.: 99.90%, op_acc: 86.28%] [G loss: 6.129736]\n",
            "Validating on test set\n",
            "Validation Metrics: 2456 [D loss: 0.036209, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.090455]\n",
            "(1024, 1)\n",
            "Training Metrics: 2457 [D loss: 0.413519, acc.: 99.90%, op_acc: 85.45%] [G loss: 6.261347]\n",
            "Validating on test set\n",
            "Validation Metrics: 2457 [D loss: 0.037987, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.238384]\n",
            "(1024, 1)\n",
            "Training Metrics: 2458 [D loss: 0.407101, acc.: 99.80%, op_acc: 84.67%] [G loss: 6.332771]\n",
            "Validating on test set\n",
            "Validation Metrics: 2458 [D loss: 0.032677, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.342483]\n",
            "(1024, 1)\n",
            "Training Metrics: 2459 [D loss: 0.418232, acc.: 99.90%, op_acc: 86.04%] [G loss: 6.382829]\n",
            "Validating on test set\n",
            "Validation Metrics: 2459 [D loss: 0.042696, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.377745]\n",
            "(1024, 1)\n",
            "Training Metrics: 2460 [D loss: 0.418090, acc.: 99.85%, op_acc: 85.79%] [G loss: 6.466074]\n",
            "Validating on test set\n",
            "Validation Metrics: 2460 [D loss: 0.035110, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.475388]\n",
            "(1024, 1)\n",
            "Training Metrics: 2461 [D loss: 0.434783, acc.: 99.90%, op_acc: 84.38%] [G loss: 6.317688]\n",
            "Validating on test set\n",
            "Validation Metrics: 2461 [D loss: 0.038512, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.306836]\n",
            "(1024, 1)\n",
            "Training Metrics: 2462 [D loss: 0.420337, acc.: 99.95%, op_acc: 85.74%] [G loss: 6.461812]\n",
            "Validating on test set\n",
            "Validation Metrics: 2462 [D loss: 0.030229, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.458738]\n",
            "(1024, 1)\n",
            "Training Metrics: 2463 [D loss: 0.384088, acc.: 99.95%, op_acc: 86.87%] [G loss: 6.257755]\n",
            "Validating on test set\n",
            "Validation Metrics: 2463 [D loss: 0.040475, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.258111]\n",
            "(1024, 1)\n",
            "Training Metrics: 2464 [D loss: 0.464024, acc.: 99.95%, op_acc: 84.57%] [G loss: 6.628257]\n",
            "Validating on test set\n",
            "Validation Metrics: 2464 [D loss: 0.033132, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.610017]\n",
            "(1024, 1)\n",
            "Training Metrics: 2465 [D loss: 0.417903, acc.: 99.66%, op_acc: 84.67%] [G loss: 6.251070]\n",
            "Validating on test set\n",
            "Validation Metrics: 2465 [D loss: 0.037090, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.220891]\n",
            "(1024, 1)\n",
            "Training Metrics: 2466 [D loss: 0.380630, acc.: 99.90%, op_acc: 86.91%] [G loss: 6.090919]\n",
            "Validating on test set\n",
            "Validation Metrics: 2466 [D loss: 0.037311, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.099293]\n",
            "(1024, 1)\n",
            "Training Metrics: 2467 [D loss: 0.433940, acc.: 99.76%, op_acc: 85.64%] [G loss: 6.245670]\n",
            "Validating on test set\n",
            "Validation Metrics: 2467 [D loss: 0.038998, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.284068]\n",
            "(1024, 1)\n",
            "Training Metrics: 2468 [D loss: 0.444395, acc.: 99.80%, op_acc: 84.03%] [G loss: 6.712281]\n",
            "Validating on test set\n",
            "Validation Metrics: 2468 [D loss: 0.032151, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.727393]\n",
            "(1024, 1)\n",
            "Training Metrics: 2469 [D loss: 0.453061, acc.: 99.51%, op_acc: 85.69%] [G loss: 5.913708]\n",
            "Validating on test set\n",
            "Validation Metrics: 2469 [D loss: 0.037026, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.903934]\n",
            "(1024, 1)\n",
            "Training Metrics: 2470 [D loss: 0.417861, acc.: 99.76%, op_acc: 84.96%] [G loss: 5.688772]\n",
            "Validating on test set\n",
            "Validation Metrics: 2470 [D loss: 0.040124, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.679151]\n",
            "(1024, 1)\n",
            "Training Metrics: 2471 [D loss: 0.386635, acc.: 99.90%, op_acc: 86.33%] [G loss: 5.996993]\n",
            "Validating on test set\n",
            "Validation Metrics: 2471 [D loss: 0.033803, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.995090]\n",
            "(1024, 1)\n",
            "Training Metrics: 2472 [D loss: 0.399949, acc.: 99.90%, op_acc: 85.25%] [G loss: 6.222863]\n",
            "Validating on test set\n",
            "Validation Metrics: 2472 [D loss: 0.035477, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.209421]\n",
            "(1024, 1)\n",
            "Training Metrics: 2473 [D loss: 0.412334, acc.: 99.90%, op_acc: 86.18%] [G loss: 5.856622]\n",
            "Validating on test set\n",
            "Validation Metrics: 2473 [D loss: 0.035601, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.859945]\n",
            "(1024, 1)\n",
            "Training Metrics: 2474 [D loss: 0.413423, acc.: 99.85%, op_acc: 86.04%] [G loss: 5.844091]\n",
            "Validating on test set\n",
            "Validation Metrics: 2474 [D loss: 0.038695, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.838031]\n",
            "(1024, 1)\n",
            "Training Metrics: 2475 [D loss: 0.423320, acc.: 99.80%, op_acc: 85.89%] [G loss: 6.342393]\n",
            "Validating on test set\n",
            "Validation Metrics: 2475 [D loss: 0.035403, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.332668]\n",
            "(1024, 1)\n",
            "Training Metrics: 2476 [D loss: 0.430010, acc.: 99.76%, op_acc: 84.91%] [G loss: 5.726778]\n",
            "Validating on test set\n",
            "Validation Metrics: 2476 [D loss: 0.042428, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.702630]\n",
            "(1024, 1)\n",
            "Training Metrics: 2477 [D loss: 0.406525, acc.: 99.90%, op_acc: 85.60%] [G loss: 6.288584]\n",
            "Validating on test set\n",
            "Validation Metrics: 2477 [D loss: 0.034932, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.285255]\n",
            "(1024, 1)\n",
            "Training Metrics: 2478 [D loss: 0.413023, acc.: 99.90%, op_acc: 85.60%] [G loss: 6.369145]\n",
            "Validating on test set\n",
            "Validation Metrics: 2478 [D loss: 0.041187, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.379542]\n",
            "(1024, 1)\n",
            "Training Metrics: 2479 [D loss: 0.404673, acc.: 99.80%, op_acc: 85.25%] [G loss: 5.693963]\n",
            "Validating on test set\n",
            "Validation Metrics: 2479 [D loss: 0.038565, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.675677]\n",
            "(1024, 1)\n",
            "Training Metrics: 2480 [D loss: 0.429259, acc.: 99.95%, op_acc: 84.28%] [G loss: 6.621453]\n",
            "Validating on test set\n",
            "Validation Metrics: 2480 [D loss: 0.035351, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.626876]\n",
            "(1024, 1)\n",
            "Training Metrics: 2481 [D loss: 0.403479, acc.: 99.80%, op_acc: 85.89%] [G loss: 6.282792]\n",
            "Validating on test set\n",
            "Validation Metrics: 2481 [D loss: 0.034186, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.283080]\n",
            "(1024, 1)\n",
            "Training Metrics: 2482 [D loss: 0.397319, acc.: 99.61%, op_acc: 86.13%] [G loss: 5.851846]\n",
            "Validating on test set\n",
            "Validation Metrics: 2482 [D loss: 0.034030, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.869295]\n",
            "(1024, 1)\n",
            "Training Metrics: 2483 [D loss: 0.392031, acc.: 99.95%, op_acc: 85.79%] [G loss: 5.992805]\n",
            "Validating on test set\n",
            "Validation Metrics: 2483 [D loss: 0.037371, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.989162]\n",
            "(1024, 1)\n",
            "Training Metrics: 2484 [D loss: 0.416116, acc.: 99.90%, op_acc: 85.40%] [G loss: 6.547549]\n",
            "Validating on test set\n",
            "Validation Metrics: 2484 [D loss: 0.035223, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.546247]\n",
            "(1024, 1)\n",
            "Training Metrics: 2485 [D loss: 0.404289, acc.: 99.76%, op_acc: 85.60%] [G loss: 5.910132]\n",
            "Validating on test set\n",
            "Validation Metrics: 2485 [D loss: 0.037783, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.908283]\n",
            "(1024, 1)\n",
            "Training Metrics: 2486 [D loss: 0.412343, acc.: 99.90%, op_acc: 85.74%] [G loss: 6.148122]\n",
            "Validating on test set\n",
            "Validation Metrics: 2486 [D loss: 0.038217, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.138894]\n",
            "(1024, 1)\n",
            "Training Metrics: 2487 [D loss: 0.437080, acc.: 99.85%, op_acc: 84.23%] [G loss: 5.972537]\n",
            "Validating on test set\n",
            "Validation Metrics: 2487 [D loss: 0.033806, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.966015]\n",
            "(1024, 1)\n",
            "Training Metrics: 2488 [D loss: 0.410331, acc.: 99.90%, op_acc: 85.45%] [G loss: 6.533610]\n",
            "Validating on test set\n",
            "Validation Metrics: 2488 [D loss: 0.030548, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.543058]\n",
            "(1024, 1)\n",
            "Training Metrics: 2489 [D loss: 0.443819, acc.: 99.85%, op_acc: 85.30%] [G loss: 6.223954]\n",
            "Validating on test set\n",
            "Validation Metrics: 2489 [D loss: 0.043530, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.216828]\n",
            "(1024, 1)\n",
            "Training Metrics: 2490 [D loss: 0.392689, acc.: 99.85%, op_acc: 86.28%] [G loss: 6.123600]\n",
            "Validating on test set\n",
            "Validation Metrics: 2490 [D loss: 0.034895, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.091515]\n",
            "(1024, 1)\n",
            "Training Metrics: 2491 [D loss: 0.415385, acc.: 99.76%, op_acc: 85.60%] [G loss: 6.029924]\n",
            "Validating on test set\n",
            "Validation Metrics: 2491 [D loss: 0.035353, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.020268]\n",
            "(1024, 1)\n",
            "Training Metrics: 2492 [D loss: 0.419311, acc.: 100.00%, op_acc: 85.25%] [G loss: 6.140899]\n",
            "Validating on test set\n",
            "Validation Metrics: 2492 [D loss: 0.035763, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.165331]\n",
            "(1024, 1)\n",
            "Training Metrics: 2493 [D loss: 0.396451, acc.: 99.85%, op_acc: 85.99%] [G loss: 6.653299]\n",
            "Validating on test set\n",
            "Validation Metrics: 2493 [D loss: 0.033990, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.641459]\n",
            "(1024, 1)\n",
            "Training Metrics: 2494 [D loss: 0.392190, acc.: 99.80%, op_acc: 86.82%] [G loss: 5.969727]\n",
            "Validating on test set\n",
            "Validation Metrics: 2494 [D loss: 0.038486, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.984789]\n",
            "(1024, 1)\n",
            "Training Metrics: 2495 [D loss: 0.417230, acc.: 99.76%, op_acc: 86.47%] [G loss: 6.079792]\n",
            "Validating on test set\n",
            "Validation Metrics: 2495 [D loss: 0.034137, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.070521]\n",
            "(1024, 1)\n",
            "Training Metrics: 2496 [D loss: 0.393193, acc.: 99.71%, op_acc: 86.04%] [G loss: 5.845103]\n",
            "Validating on test set\n",
            "Validation Metrics: 2496 [D loss: 0.037012, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.841568]\n",
            "(1024, 1)\n",
            "Training Metrics: 2497 [D loss: 0.379859, acc.: 99.85%, op_acc: 87.35%] [G loss: 6.138742]\n",
            "Validating on test set\n",
            "Validation Metrics: 2497 [D loss: 0.032452, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.151308]\n",
            "(1024, 1)\n",
            "Training Metrics: 2498 [D loss: 0.383887, acc.: 99.80%, op_acc: 86.47%] [G loss: 5.773016]\n",
            "Validating on test set\n",
            "Validation Metrics: 2498 [D loss: 0.033108, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.775805]\n",
            "(1024, 1)\n",
            "Training Metrics: 2499 [D loss: 0.400651, acc.: 99.95%, op_acc: 86.13%] [G loss: 6.766521]\n",
            "Validating on test set\n",
            "Validation Metrics: 2499 [D loss: 0.031433, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.781316]\n",
            "(1024, 1)\n",
            "Training Metrics: 2500 [D loss: 0.399471, acc.: 99.80%, op_acc: 86.52%] [G loss: 6.109846]\n",
            "Validating on test set\n",
            "Validation Metrics: 2500 [D loss: 0.031796, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.060560]\n",
            "(1024, 1)\n",
            "Training Metrics: 2501 [D loss: 0.417220, acc.: 99.85%, op_acc: 86.18%] [G loss: 6.766298]\n",
            "Validating on test set\n",
            "Validation Metrics: 2501 [D loss: 0.030350, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.775378]\n",
            "(1024, 1)\n",
            "Training Metrics: 2502 [D loss: 0.443467, acc.: 99.76%, op_acc: 83.79%] [G loss: 6.053129]\n",
            "Validating on test set\n",
            "Validation Metrics: 2502 [D loss: 0.036123, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.020147]\n",
            "(1024, 1)\n",
            "Training Metrics: 2503 [D loss: 0.408818, acc.: 99.95%, op_acc: 85.50%] [G loss: 6.506790]\n",
            "Validating on test set\n",
            "Validation Metrics: 2503 [D loss: 0.033263, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.486968]\n",
            "(1024, 1)\n",
            "Training Metrics: 2504 [D loss: 0.426476, acc.: 99.85%, op_acc: 85.79%] [G loss: 6.142247]\n",
            "Validating on test set\n",
            "Validation Metrics: 2504 [D loss: 0.032554, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.128414]\n",
            "(1024, 1)\n",
            "Training Metrics: 2505 [D loss: 0.410875, acc.: 99.80%, op_acc: 85.50%] [G loss: 5.688017]\n",
            "Validating on test set\n",
            "Validation Metrics: 2505 [D loss: 0.037711, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.686896]\n",
            "(1024, 1)\n",
            "Training Metrics: 2506 [D loss: 0.401773, acc.: 99.90%, op_acc: 85.89%] [G loss: 6.583272]\n",
            "Validating on test set\n",
            "Validation Metrics: 2506 [D loss: 0.028785, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.595506]\n",
            "(1024, 1)\n",
            "Training Metrics: 2507 [D loss: 0.417735, acc.: 99.76%, op_acc: 84.77%] [G loss: 5.748250]\n",
            "Validating on test set\n",
            "Validation Metrics: 2507 [D loss: 0.033757, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.716035]\n",
            "(1024, 1)\n",
            "Training Metrics: 2508 [D loss: 0.427419, acc.: 99.80%, op_acc: 84.67%] [G loss: 6.644414]\n",
            "Validating on test set\n",
            "Validation Metrics: 2508 [D loss: 0.031946, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.647949]\n",
            "(1024, 1)\n",
            "Training Metrics: 2509 [D loss: 0.394600, acc.: 99.85%, op_acc: 85.35%] [G loss: 5.962253]\n",
            "Validating on test set\n",
            "Validation Metrics: 2509 [D loss: 0.031396, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.989832]\n",
            "(1024, 1)\n",
            "Training Metrics: 2510 [D loss: 0.381651, acc.: 99.95%, op_acc: 86.28%] [G loss: 6.285979]\n",
            "Validating on test set\n",
            "Validation Metrics: 2510 [D loss: 0.033694, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.287883]\n",
            "(1024, 1)\n",
            "Training Metrics: 2511 [D loss: 0.447076, acc.: 99.90%, op_acc: 84.28%] [G loss: 6.747349]\n",
            "Validating on test set\n",
            "Validation Metrics: 2511 [D loss: 0.029307, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.743617]\n",
            "(1024, 1)\n",
            "Training Metrics: 2512 [D loss: 0.387645, acc.: 99.90%, op_acc: 85.64%] [G loss: 6.366568]\n",
            "Validating on test set\n",
            "Validation Metrics: 2512 [D loss: 0.033126, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.366414]\n",
            "(1024, 1)\n",
            "Training Metrics: 2513 [D loss: 0.411118, acc.: 99.90%, op_acc: 86.77%] [G loss: 6.618938]\n",
            "Validating on test set\n",
            "Validation Metrics: 2513 [D loss: 0.028154, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.648098]\n",
            "(1024, 1)\n",
            "Training Metrics: 2514 [D loss: 0.410416, acc.: 99.85%, op_acc: 85.55%] [G loss: 5.949318]\n",
            "Validating on test set\n",
            "Validation Metrics: 2514 [D loss: 0.031960, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.944889]\n",
            "(1024, 1)\n",
            "Training Metrics: 2515 [D loss: 0.442623, acc.: 99.95%, op_acc: 85.25%] [G loss: 6.310543]\n",
            "Validating on test set\n",
            "Validation Metrics: 2515 [D loss: 0.034363, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.299500]\n",
            "(1024, 1)\n",
            "Training Metrics: 2516 [D loss: 0.406682, acc.: 99.85%, op_acc: 85.64%] [G loss: 6.216692]\n",
            "Validating on test set\n",
            "Validation Metrics: 2516 [D loss: 0.037907, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.225105]\n",
            "(1024, 1)\n",
            "Training Metrics: 2517 [D loss: 0.386608, acc.: 99.95%, op_acc: 86.23%] [G loss: 6.359259]\n",
            "Validating on test set\n",
            "Validation Metrics: 2517 [D loss: 0.028371, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.375612]\n",
            "(1024, 1)\n",
            "Training Metrics: 2518 [D loss: 0.392273, acc.: 99.95%, op_acc: 86.33%] [G loss: 6.377108]\n",
            "Validating on test set\n",
            "Validation Metrics: 2518 [D loss: 0.029902, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.389142]\n",
            "(1024, 1)\n",
            "Training Metrics: 2519 [D loss: 0.383176, acc.: 99.90%, op_acc: 86.18%] [G loss: 6.249897]\n",
            "Validating on test set\n",
            "Validation Metrics: 2519 [D loss: 0.034396, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.254104]\n",
            "(1024, 1)\n",
            "Training Metrics: 2520 [D loss: 0.417201, acc.: 99.80%, op_acc: 85.55%] [G loss: 6.188368]\n",
            "Validating on test set\n",
            "Validation Metrics: 2520 [D loss: 0.037570, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.167558]\n",
            "(1024, 1)\n",
            "Training Metrics: 2521 [D loss: 0.378716, acc.: 99.90%, op_acc: 87.30%] [G loss: 6.261407]\n",
            "Validating on test set\n",
            "Validation Metrics: 2521 [D loss: 0.032201, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.278795]\n",
            "(1024, 1)\n",
            "Training Metrics: 2522 [D loss: 0.421905, acc.: 99.95%, op_acc: 84.08%] [G loss: 6.752525]\n",
            "Validating on test set\n",
            "Validation Metrics: 2522 [D loss: 0.027971, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.752171]\n",
            "(1024, 1)\n",
            "Training Metrics: 2523 [D loss: 0.434634, acc.: 99.95%, op_acc: 84.38%] [G loss: 6.584632]\n",
            "Validating on test set\n",
            "Validation Metrics: 2523 [D loss: 0.032654, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.573088]\n",
            "(1024, 1)\n",
            "Training Metrics: 2524 [D loss: 0.473496, acc.: 99.80%, op_acc: 85.16%] [G loss: 5.976821]\n",
            "Validating on test set\n",
            "Validation Metrics: 2524 [D loss: 0.033027, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.966116]\n",
            "(1024, 1)\n",
            "Training Metrics: 2525 [D loss: 0.406791, acc.: 99.90%, op_acc: 85.74%] [G loss: 6.433234]\n",
            "Validating on test set\n",
            "Validation Metrics: 2525 [D loss: 0.036509, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.463826]\n",
            "(1024, 1)\n",
            "Training Metrics: 2526 [D loss: 0.448075, acc.: 99.85%, op_acc: 83.69%] [G loss: 6.274875]\n",
            "Validating on test set\n",
            "Validation Metrics: 2526 [D loss: 0.032676, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.228165]\n",
            "(1024, 1)\n",
            "Training Metrics: 2527 [D loss: 0.432321, acc.: 99.95%, op_acc: 85.79%] [G loss: 6.327388]\n",
            "Validating on test set\n",
            "Validation Metrics: 2527 [D loss: 0.029448, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.339551]\n",
            "(1024, 1)\n",
            "Training Metrics: 2528 [D loss: 0.408349, acc.: 99.90%, op_acc: 84.52%] [G loss: 6.241297]\n",
            "Validating on test set\n",
            "Validation Metrics: 2528 [D loss: 0.029665, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.205551]\n",
            "(1024, 1)\n",
            "Training Metrics: 2529 [D loss: 0.442171, acc.: 99.80%, op_acc: 85.11%] [G loss: 6.274611]\n",
            "Validating on test set\n",
            "Validation Metrics: 2529 [D loss: 0.031635, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.262038]\n",
            "(1024, 1)\n",
            "Training Metrics: 2530 [D loss: 0.445395, acc.: 99.95%, op_acc: 85.11%] [G loss: 6.355613]\n",
            "Validating on test set\n",
            "Validation Metrics: 2530 [D loss: 0.030929, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.354857]\n",
            "(1024, 1)\n",
            "Training Metrics: 2531 [D loss: 0.417968, acc.: 99.85%, op_acc: 86.18%] [G loss: 6.067022]\n",
            "Validating on test set\n",
            "Validation Metrics: 2531 [D loss: 0.028955, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.081025]\n",
            "(1024, 1)\n",
            "Training Metrics: 2532 [D loss: 0.418243, acc.: 99.95%, op_acc: 84.81%] [G loss: 6.631017]\n",
            "Validating on test set\n",
            "Validation Metrics: 2532 [D loss: 0.042995, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.621112]\n",
            "(1024, 1)\n",
            "Training Metrics: 2533 [D loss: 0.399880, acc.: 99.85%, op_acc: 86.87%] [G loss: 6.792594]\n",
            "Validating on test set\n",
            "Validation Metrics: 2533 [D loss: 0.032421, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.817128]\n",
            "(1024, 1)\n",
            "Training Metrics: 2534 [D loss: 0.394904, acc.: 99.95%, op_acc: 85.94%] [G loss: 6.210502]\n",
            "Validating on test set\n",
            "Validation Metrics: 2534 [D loss: 0.030676, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.203606]\n",
            "(1024, 1)\n",
            "Training Metrics: 2535 [D loss: 0.427798, acc.: 99.90%, op_acc: 84.23%] [G loss: 6.642026]\n",
            "Validating on test set\n",
            "Validation Metrics: 2535 [D loss: 0.033043, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.641860]\n",
            "(1024, 1)\n",
            "Training Metrics: 2536 [D loss: 0.427913, acc.: 99.76%, op_acc: 85.21%] [G loss: 5.899520]\n",
            "Validating on test set\n",
            "Validation Metrics: 2536 [D loss: 0.033886, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.908194]\n",
            "(1024, 1)\n",
            "Training Metrics: 2537 [D loss: 0.397413, acc.: 99.90%, op_acc: 85.30%] [G loss: 6.082351]\n",
            "Validating on test set\n",
            "Validation Metrics: 2537 [D loss: 0.032997, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.047918]\n",
            "(1024, 1)\n",
            "Training Metrics: 2538 [D loss: 0.393916, acc.: 99.76%, op_acc: 86.72%] [G loss: 5.484150]\n",
            "Validating on test set\n",
            "Validation Metrics: 2538 [D loss: 0.035159, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.505716]\n",
            "(1024, 1)\n",
            "Training Metrics: 2539 [D loss: 0.391746, acc.: 99.90%, op_acc: 87.30%] [G loss: 5.812708]\n",
            "Validating on test set\n",
            "Validation Metrics: 2539 [D loss: 0.031657, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.805484]\n",
            "(1024, 1)\n",
            "Training Metrics: 2540 [D loss: 0.387244, acc.: 99.95%, op_acc: 86.57%] [G loss: 6.487592]\n",
            "Validating on test set\n",
            "Validation Metrics: 2540 [D loss: 0.030489, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.463161]\n",
            "(1024, 1)\n",
            "Training Metrics: 2541 [D loss: 0.419347, acc.: 99.80%, op_acc: 85.84%] [G loss: 6.069005]\n",
            "Validating on test set\n",
            "Validation Metrics: 2541 [D loss: 0.030886, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.052963]\n",
            "(1024, 1)\n",
            "Training Metrics: 2542 [D loss: 0.379729, acc.: 99.76%, op_acc: 87.06%] [G loss: 6.026528]\n",
            "Validating on test set\n",
            "Validation Metrics: 2542 [D loss: 0.040954, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.027323]\n",
            "(1024, 1)\n",
            "Training Metrics: 2543 [D loss: 0.440839, acc.: 99.80%, op_acc: 85.11%] [G loss: 6.248528]\n",
            "Validating on test set\n",
            "Validation Metrics: 2543 [D loss: 0.028490, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.237743]\n",
            "(1024, 1)\n",
            "Training Metrics: 2544 [D loss: 0.436092, acc.: 100.00%, op_acc: 85.21%] [G loss: 6.331877]\n",
            "Validating on test set\n",
            "Validation Metrics: 2544 [D loss: 0.029095, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.347930]\n",
            "(1024, 1)\n",
            "Training Metrics: 2545 [D loss: 0.423933, acc.: 99.95%, op_acc: 85.21%] [G loss: 6.141328]\n",
            "Validating on test set\n",
            "Validation Metrics: 2545 [D loss: 0.035533, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.136614]\n",
            "(1024, 1)\n",
            "Training Metrics: 2546 [D loss: 0.373607, acc.: 99.85%, op_acc: 86.91%] [G loss: 6.220452]\n",
            "Validating on test set\n",
            "Validation Metrics: 2546 [D loss: 0.030523, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.219181]\n",
            "(1024, 1)\n",
            "Training Metrics: 2547 [D loss: 0.411696, acc.: 99.90%, op_acc: 84.91%] [G loss: 6.718633]\n",
            "Validating on test set\n",
            "Validation Metrics: 2547 [D loss: 0.032891, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.719406]\n",
            "(1024, 1)\n",
            "Training Metrics: 2548 [D loss: 0.381734, acc.: 99.85%, op_acc: 86.04%] [G loss: 6.507467]\n",
            "Validating on test set\n",
            "Validation Metrics: 2548 [D loss: 0.029774, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.491478]\n",
            "(1024, 1)\n",
            "Training Metrics: 2549 [D loss: 0.399099, acc.: 99.80%, op_acc: 85.69%] [G loss: 6.343640]\n",
            "Validating on test set\n",
            "Validation Metrics: 2549 [D loss: 0.030376, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.331022]\n",
            "(1024, 1)\n",
            "Training Metrics: 2550 [D loss: 0.351043, acc.: 99.85%, op_acc: 87.26%] [G loss: 5.887300]\n",
            "Validating on test set\n",
            "Validation Metrics: 2550 [D loss: 0.037049, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.881599]\n",
            "(1024, 1)\n",
            "Training Metrics: 2551 [D loss: 0.409710, acc.: 99.80%, op_acc: 86.38%] [G loss: 5.921782]\n",
            "Validating on test set\n",
            "Validation Metrics: 2551 [D loss: 0.035061, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.929961]\n",
            "(1024, 1)\n",
            "Training Metrics: 2552 [D loss: 0.412754, acc.: 99.85%, op_acc: 86.13%] [G loss: 5.864641]\n",
            "Validating on test set\n",
            "Validation Metrics: 2552 [D loss: 0.034523, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.863240]\n",
            "(1024, 1)\n",
            "Training Metrics: 2553 [D loss: 0.375733, acc.: 99.85%, op_acc: 87.16%] [G loss: 6.374454]\n",
            "Validating on test set\n",
            "Validation Metrics: 2553 [D loss: 0.030788, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.368376]\n",
            "(1024, 1)\n",
            "Training Metrics: 2554 [D loss: 0.394980, acc.: 99.90%, op_acc: 86.72%] [G loss: 6.714098]\n",
            "Validating on test set\n",
            "Validation Metrics: 2554 [D loss: 0.034087, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.743909]\n",
            "(1024, 1)\n",
            "Training Metrics: 2555 [D loss: 0.406279, acc.: 99.85%, op_acc: 85.55%] [G loss: 6.309346]\n",
            "Validating on test set\n",
            "Validation Metrics: 2555 [D loss: 0.029579, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.337793]\n",
            "(1024, 1)\n",
            "Training Metrics: 2556 [D loss: 0.427902, acc.: 99.80%, op_acc: 85.40%] [G loss: 6.287045]\n",
            "Validating on test set\n",
            "Validation Metrics: 2556 [D loss: 0.031496, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.259359]\n",
            "(1024, 1)\n",
            "Training Metrics: 2557 [D loss: 0.453776, acc.: 99.90%, op_acc: 84.77%] [G loss: 6.384093]\n",
            "Validating on test set\n",
            "Validation Metrics: 2557 [D loss: 0.036193, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.357193]\n",
            "(1024, 1)\n",
            "Training Metrics: 2558 [D loss: 0.430923, acc.: 99.80%, op_acc: 85.45%] [G loss: 5.939297]\n",
            "Validating on test set\n",
            "Validation Metrics: 2558 [D loss: 0.037223, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.939979]\n",
            "(1024, 1)\n",
            "Training Metrics: 2559 [D loss: 0.466719, acc.: 99.90%, op_acc: 83.84%] [G loss: 6.362757]\n",
            "Validating on test set\n",
            "Validation Metrics: 2559 [D loss: 0.029730, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.371668]\n",
            "(1024, 1)\n",
            "Training Metrics: 2560 [D loss: 0.478461, acc.: 99.85%, op_acc: 85.84%] [G loss: 5.768579]\n",
            "Validating on test set\n",
            "Validation Metrics: 2560 [D loss: 0.037153, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.777548]\n",
            "(1024, 1)\n",
            "Training Metrics: 2561 [D loss: 0.407591, acc.: 99.95%, op_acc: 85.60%] [G loss: 6.093386]\n",
            "Validating on test set\n",
            "Validation Metrics: 2561 [D loss: 0.036931, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.077853]\n",
            "(1024, 1)\n",
            "Training Metrics: 2562 [D loss: 0.427095, acc.: 99.90%, op_acc: 85.64%] [G loss: 6.678402]\n",
            "Validating on test set\n",
            "Validation Metrics: 2562 [D loss: 0.030849, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.706444]\n",
            "(1024, 1)\n",
            "Training Metrics: 2563 [D loss: 0.402216, acc.: 99.80%, op_acc: 85.11%] [G loss: 6.280496]\n",
            "Validating on test set\n",
            "Validation Metrics: 2563 [D loss: 0.034521, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.268525]\n",
            "(1024, 1)\n",
            "Training Metrics: 2564 [D loss: 0.386164, acc.: 99.90%, op_acc: 86.13%] [G loss: 6.248395]\n",
            "Validating on test set\n",
            "Validation Metrics: 2564 [D loss: 0.035044, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.231210]\n",
            "(1024, 1)\n",
            "Training Metrics: 2565 [D loss: 0.378010, acc.: 99.95%, op_acc: 86.52%] [G loss: 6.529031]\n",
            "Validating on test set\n",
            "Validation Metrics: 2565 [D loss: 0.037451, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.524612]\n",
            "(1024, 1)\n",
            "Training Metrics: 2566 [D loss: 0.397199, acc.: 99.71%, op_acc: 86.08%] [G loss: 5.798237]\n",
            "Validating on test set\n",
            "Validation Metrics: 2566 [D loss: 0.037274, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.806798]\n",
            "(1024, 1)\n",
            "Training Metrics: 2567 [D loss: 0.404414, acc.: 99.90%, op_acc: 85.94%] [G loss: 6.061787]\n",
            "Validating on test set\n",
            "Validation Metrics: 2567 [D loss: 0.034837, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.028520]\n",
            "(1024, 1)\n",
            "Training Metrics: 2568 [D loss: 0.412752, acc.: 99.76%, op_acc: 85.69%] [G loss: 6.196978]\n",
            "Validating on test set\n",
            "Validation Metrics: 2568 [D loss: 0.039468, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.183158]\n",
            "(1024, 1)\n",
            "Training Metrics: 2569 [D loss: 0.416873, acc.: 99.80%, op_acc: 85.50%] [G loss: 5.811330]\n",
            "Validating on test set\n",
            "Validation Metrics: 2569 [D loss: 0.033538, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.818150]\n",
            "(1024, 1)\n",
            "Training Metrics: 2570 [D loss: 0.385715, acc.: 99.76%, op_acc: 85.89%] [G loss: 6.060019]\n",
            "Validating on test set\n",
            "Validation Metrics: 2570 [D loss: 0.030864, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.045725]\n",
            "(1024, 1)\n",
            "Training Metrics: 2571 [D loss: 0.446357, acc.: 99.85%, op_acc: 83.89%] [G loss: 5.699572]\n",
            "Validating on test set\n",
            "Validation Metrics: 2571 [D loss: 0.038228, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.677369]\n",
            "(1024, 1)\n",
            "Training Metrics: 2572 [D loss: 0.405642, acc.: 99.95%, op_acc: 85.06%] [G loss: 6.559884]\n",
            "Validating on test set\n",
            "Validation Metrics: 2572 [D loss: 0.039640, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.550280]\n",
            "(1024, 1)\n",
            "Training Metrics: 2573 [D loss: 0.410600, acc.: 99.76%, op_acc: 85.35%] [G loss: 5.861755]\n",
            "Validating on test set\n",
            "Validation Metrics: 2573 [D loss: 0.034291, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.830308]\n",
            "(1024, 1)\n",
            "Training Metrics: 2574 [D loss: 0.382254, acc.: 99.85%, op_acc: 86.87%] [G loss: 5.725754]\n",
            "Validating on test set\n",
            "Validation Metrics: 2574 [D loss: 0.035895, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.744081]\n",
            "(1024, 1)\n",
            "Training Metrics: 2575 [D loss: 0.409209, acc.: 99.95%, op_acc: 85.16%] [G loss: 6.427521]\n",
            "Validating on test set\n",
            "Validation Metrics: 2575 [D loss: 0.033858, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.420727]\n",
            "(1024, 1)\n",
            "Training Metrics: 2576 [D loss: 0.359284, acc.: 99.90%, op_acc: 87.79%] [G loss: 6.509231]\n",
            "Validating on test set\n",
            "Validation Metrics: 2576 [D loss: 0.029409, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.522409]\n",
            "(1024, 1)\n",
            "Training Metrics: 2577 [D loss: 0.418593, acc.: 100.00%, op_acc: 85.45%] [G loss: 6.851327]\n",
            "Validating on test set\n",
            "Validation Metrics: 2577 [D loss: 0.034920, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.823386]\n",
            "(1024, 1)\n",
            "Training Metrics: 2578 [D loss: 0.419677, acc.: 99.85%, op_acc: 85.35%] [G loss: 6.722102]\n",
            "Validating on test set\n",
            "Validation Metrics: 2578 [D loss: 0.030968, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.722466]\n",
            "(1024, 1)\n",
            "Training Metrics: 2579 [D loss: 0.406100, acc.: 99.85%, op_acc: 85.69%] [G loss: 6.960749]\n",
            "Validating on test set\n",
            "Validation Metrics: 2579 [D loss: 0.035998, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.980820]\n",
            "(1024, 1)\n",
            "Training Metrics: 2580 [D loss: 0.429344, acc.: 99.76%, op_acc: 86.04%] [G loss: 6.540276]\n",
            "Validating on test set\n",
            "Validation Metrics: 2580 [D loss: 0.034158, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.532683]\n",
            "(1024, 1)\n",
            "Training Metrics: 2581 [D loss: 0.360173, acc.: 99.85%, op_acc: 87.06%] [G loss: 5.992828]\n",
            "Validating on test set\n",
            "Validation Metrics: 2581 [D loss: 0.036171, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.999257]\n",
            "(1024, 1)\n",
            "Training Metrics: 2582 [D loss: 0.397096, acc.: 100.00%, op_acc: 86.91%] [G loss: 6.643404]\n",
            "Validating on test set\n",
            "Validation Metrics: 2582 [D loss: 0.033070, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.652126]\n",
            "(1024, 1)\n",
            "Training Metrics: 2583 [D loss: 0.406771, acc.: 99.90%, op_acc: 86.62%] [G loss: 6.269968]\n",
            "Validating on test set\n",
            "Validation Metrics: 2583 [D loss: 0.034931, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.243263]\n",
            "(1024, 1)\n",
            "Training Metrics: 2584 [D loss: 0.372549, acc.: 99.90%, op_acc: 86.77%] [G loss: 6.740590]\n",
            "Validating on test set\n",
            "Validation Metrics: 2584 [D loss: 0.034963, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.729047]\n",
            "(1024, 1)\n",
            "Training Metrics: 2585 [D loss: 0.393141, acc.: 99.80%, op_acc: 86.77%] [G loss: 6.597695]\n",
            "Validating on test set\n",
            "Validation Metrics: 2585 [D loss: 0.032926, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.611160]\n",
            "(1024, 1)\n",
            "Training Metrics: 2586 [D loss: 0.383862, acc.: 99.95%, op_acc: 86.33%] [G loss: 6.640841]\n",
            "Validating on test set\n",
            "Validation Metrics: 2586 [D loss: 0.034461, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.614868]\n",
            "(1024, 1)\n",
            "Training Metrics: 2587 [D loss: 0.420948, acc.: 99.90%, op_acc: 85.11%] [G loss: 6.454570]\n",
            "Validating on test set\n",
            "Validation Metrics: 2587 [D loss: 0.033670, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.458612]\n",
            "(1024, 1)\n",
            "Training Metrics: 2588 [D loss: 0.450719, acc.: 99.95%, op_acc: 84.52%] [G loss: 6.425413]\n",
            "Validating on test set\n",
            "Validation Metrics: 2588 [D loss: 0.032600, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.420763]\n",
            "(1024, 1)\n",
            "Training Metrics: 2589 [D loss: 0.389261, acc.: 99.90%, op_acc: 85.94%] [G loss: 6.118154]\n",
            "Validating on test set\n",
            "Validation Metrics: 2589 [D loss: 0.038219, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.121562]\n",
            "(1024, 1)\n",
            "Training Metrics: 2590 [D loss: 0.382538, acc.: 99.80%, op_acc: 87.35%] [G loss: 6.054723]\n",
            "Validating on test set\n",
            "Validation Metrics: 2590 [D loss: 0.040683, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.068325]\n",
            "(1024, 1)\n",
            "Training Metrics: 2591 [D loss: 0.416940, acc.: 99.85%, op_acc: 86.38%] [G loss: 6.092860]\n",
            "Validating on test set\n",
            "Validation Metrics: 2591 [D loss: 0.034823, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.122716]\n",
            "(1024, 1)\n",
            "Training Metrics: 2592 [D loss: 0.399078, acc.: 100.00%, op_acc: 85.30%] [G loss: 6.696305]\n",
            "Validating on test set\n",
            "Validation Metrics: 2592 [D loss: 0.035676, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.664926]\n",
            "(1024, 1)\n",
            "Training Metrics: 2593 [D loss: 0.424283, acc.: 99.90%, op_acc: 85.30%] [G loss: 6.592010]\n",
            "Validating on test set\n",
            "Validation Metrics: 2593 [D loss: 0.035510, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.567457]\n",
            "(1024, 1)\n",
            "Training Metrics: 2594 [D loss: 0.394430, acc.: 99.85%, op_acc: 85.74%] [G loss: 6.754025]\n",
            "Validating on test set\n",
            "Validation Metrics: 2594 [D loss: 0.038997, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.728690]\n",
            "(1024, 1)\n",
            "Training Metrics: 2595 [D loss: 0.413012, acc.: 99.95%, op_acc: 85.16%] [G loss: 5.973994]\n",
            "Validating on test set\n",
            "Validation Metrics: 2595 [D loss: 0.039809, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.971610]\n",
            "(1024, 1)\n",
            "Training Metrics: 2596 [D loss: 0.456195, acc.: 99.80%, op_acc: 84.03%] [G loss: 6.621577]\n",
            "Validating on test set\n",
            "Validation Metrics: 2596 [D loss: 0.033935, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.617984]\n",
            "(1024, 1)\n",
            "Training Metrics: 2597 [D loss: 0.397438, acc.: 99.90%, op_acc: 85.55%] [G loss: 6.051516]\n",
            "Validating on test set\n",
            "Validation Metrics: 2597 [D loss: 0.038388, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.047286]\n",
            "(1024, 1)\n",
            "Training Metrics: 2598 [D loss: 0.415381, acc.: 99.76%, op_acc: 85.50%] [G loss: 5.760819]\n",
            "Validating on test set\n",
            "Validation Metrics: 2598 [D loss: 0.039779, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.768181]\n",
            "(1024, 1)\n",
            "Training Metrics: 2599 [D loss: 0.430563, acc.: 99.85%, op_acc: 84.62%] [G loss: 6.152813]\n",
            "Validating on test set\n",
            "Validation Metrics: 2599 [D loss: 0.032665, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.107132]\n",
            "(1024, 1)\n",
            "Training Metrics: 2600 [D loss: 0.466050, acc.: 99.90%, op_acc: 85.11%] [G loss: 6.681775]\n",
            "Validating on test set\n",
            "Validation Metrics: 2600 [D loss: 0.032940, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.696021]\n",
            "(1024, 1)\n",
            "Training Metrics: 2601 [D loss: 0.409446, acc.: 99.80%, op_acc: 85.94%] [G loss: 6.378226]\n",
            "Validating on test set\n",
            "Validation Metrics: 2601 [D loss: 0.029486, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.376746]\n",
            "(1024, 1)\n",
            "Training Metrics: 2602 [D loss: 0.446939, acc.: 99.85%, op_acc: 84.23%] [G loss: 5.966772]\n",
            "Validating on test set\n",
            "Validation Metrics: 2602 [D loss: 0.038444, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.969654]\n",
            "(1024, 1)\n",
            "Training Metrics: 2603 [D loss: 0.376163, acc.: 99.80%, op_acc: 87.01%] [G loss: 6.489546]\n",
            "Validating on test set\n",
            "Validation Metrics: 2603 [D loss: 0.034016, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.498864]\n",
            "(1024, 1)\n",
            "Training Metrics: 2604 [D loss: 0.397870, acc.: 99.90%, op_acc: 86.47%] [G loss: 6.142964]\n",
            "Validating on test set\n",
            "Validation Metrics: 2604 [D loss: 0.030636, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.090054]\n",
            "(1024, 1)\n",
            "Training Metrics: 2605 [D loss: 0.381766, acc.: 99.80%, op_acc: 85.99%] [G loss: 6.183372]\n",
            "Validating on test set\n",
            "Validation Metrics: 2605 [D loss: 0.032381, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.178818]\n",
            "(1024, 1)\n",
            "Training Metrics: 2606 [D loss: 0.366002, acc.: 99.95%, op_acc: 87.26%] [G loss: 6.219316]\n",
            "Validating on test set\n",
            "Validation Metrics: 2606 [D loss: 0.031299, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.244519]\n",
            "(1024, 1)\n",
            "Training Metrics: 2607 [D loss: 0.404593, acc.: 99.90%, op_acc: 84.57%] [G loss: 6.611052]\n",
            "Validating on test set\n",
            "Validation Metrics: 2607 [D loss: 0.028878, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.601406]\n",
            "(1024, 1)\n",
            "Training Metrics: 2608 [D loss: 0.368027, acc.: 99.95%, op_acc: 87.01%] [G loss: 6.320380]\n",
            "Validating on test set\n",
            "Validation Metrics: 2608 [D loss: 0.033591, acc.: 100.00%, op_acc: 99.71%] [G loss: 6.304987]\n",
            "(1024, 1)\n",
            "Training Metrics: 2609 [D loss: 0.378287, acc.: 99.85%, op_acc: 87.89%] [G loss: 6.900529]\n",
            "Validating on test set\n",
            "Validation Metrics: 2609 [D loss: 0.036098, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.893878]\n",
            "(1024, 1)\n",
            "Training Metrics: 2610 [D loss: 0.422306, acc.: 99.66%, op_acc: 84.81%] [G loss: 5.875794]\n",
            "Validating on test set\n",
            "Validation Metrics: 2610 [D loss: 0.051600, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.833453]\n",
            "(1024, 1)\n",
            "Training Metrics: 2611 [D loss: 0.441129, acc.: 99.76%, op_acc: 84.72%] [G loss: 6.361744]\n",
            "Validating on test set\n",
            "Validation Metrics: 2611 [D loss: 0.090742, acc.: 100.00%, op_acc: 98.63%] [G loss: 6.218210]\n",
            "(1024, 1)\n",
            "Training Metrics: 2612 [D loss: 0.422130, acc.: 99.90%, op_acc: 85.11%] [G loss: 7.824061]\n",
            "Validating on test set\n",
            "Validation Metrics: 2612 [D loss: 0.063706, acc.: 100.00%, op_acc: 99.90%] [G loss: 7.776057]\n",
            "(1024, 1)\n",
            "Training Metrics: 2613 [D loss: 0.441534, acc.: 99.71%, op_acc: 85.11%] [G loss: 7.623817]\n",
            "Validating on test set\n",
            "Validation Metrics: 2613 [D loss: 0.045831, acc.: 100.00%, op_acc: 100.00%] [G loss: 7.585546]\n",
            "(1024, 1)\n",
            "Training Metrics: 2614 [D loss: 0.425624, acc.: 99.76%, op_acc: 84.91%] [G loss: 6.432734]\n",
            "Validating on test set\n",
            "Validation Metrics: 2614 [D loss: 0.039645, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.425944]\n",
            "(1024, 1)\n",
            "Training Metrics: 2615 [D loss: 0.402602, acc.: 99.66%, op_acc: 86.08%] [G loss: 6.073107]\n",
            "Validating on test set\n",
            "Validation Metrics: 2615 [D loss: 0.050641, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.116249]\n",
            "(1024, 1)\n",
            "Training Metrics: 2616 [D loss: 0.451161, acc.: 99.80%, op_acc: 84.33%] [G loss: 5.877300]\n",
            "Validating on test set\n",
            "Validation Metrics: 2616 [D loss: 0.050664, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.880672]\n",
            "(1024, 1)\n",
            "Training Metrics: 2617 [D loss: 0.442158, acc.: 99.85%, op_acc: 84.08%] [G loss: 6.563202]\n",
            "Validating on test set\n",
            "Validation Metrics: 2617 [D loss: 0.136738, acc.: 100.00%, op_acc: 96.48%] [G loss: 6.615031]\n",
            "(1024, 1)\n",
            "Training Metrics: 2618 [D loss: 0.497394, acc.: 99.85%, op_acc: 83.54%] [G loss: 5.899322]\n",
            "Validating on test set\n",
            "Validation Metrics: 2618 [D loss: 0.091061, acc.: 100.00%, op_acc: 98.24%] [G loss: 5.935143]\n",
            "(1024, 1)\n",
            "Training Metrics: 2619 [D loss: 0.436311, acc.: 99.85%, op_acc: 84.03%] [G loss: 5.963904]\n",
            "Validating on test set\n",
            "Validation Metrics: 2619 [D loss: 0.249426, acc.: 100.00%, op_acc: 92.97%] [G loss: 6.145071]\n",
            "(1024, 1)\n",
            "Training Metrics: 2620 [D loss: 0.534925, acc.: 99.80%, op_acc: 82.52%] [G loss: 5.612341]\n",
            "Validating on test set\n",
            "Validation Metrics: 2620 [D loss: 0.106163, acc.: 100.00%, op_acc: 97.66%] [G loss: 5.639764]\n",
            "(1024, 1)\n",
            "Training Metrics: 2621 [D loss: 0.491768, acc.: 99.71%, op_acc: 82.23%] [G loss: 6.006618]\n",
            "Validating on test set\n",
            "Validation Metrics: 2621 [D loss: 0.064692, acc.: 100.00%, op_acc: 99.61%] [G loss: 6.043030]\n",
            "(1024, 1)\n",
            "Training Metrics: 2622 [D loss: 0.421985, acc.: 100.00%, op_acc: 85.06%] [G loss: 6.116531]\n",
            "Validating on test set\n",
            "Validation Metrics: 2622 [D loss: 0.255403, acc.: 100.00%, op_acc: 95.80%] [G loss: 6.186958]\n",
            "(1024, 1)\n",
            "Training Metrics: 2623 [D loss: 0.532864, acc.: 99.85%, op_acc: 82.67%] [G loss: 6.730691]\n",
            "Validating on test set\n",
            "Validation Metrics: 2623 [D loss: 0.173566, acc.: 100.00%, op_acc: 95.61%] [G loss: 6.764100]\n",
            "(1024, 1)\n",
            "Training Metrics: 2624 [D loss: 0.497875, acc.: 99.66%, op_acc: 82.71%] [G loss: 5.400348]\n",
            "Validating on test set\n",
            "Validation Metrics: 2624 [D loss: 0.086605, acc.: 100.00%, op_acc: 98.93%] [G loss: 5.274408]\n",
            "(1024, 1)\n",
            "Training Metrics: 2625 [D loss: 0.463385, acc.: 99.85%, op_acc: 83.69%] [G loss: 6.069722]\n",
            "Validating on test set\n",
            "Validation Metrics: 2625 [D loss: 0.095072, acc.: 100.00%, op_acc: 99.41%] [G loss: 5.749962]\n",
            "(1024, 1)\n",
            "Training Metrics: 2626 [D loss: 0.440581, acc.: 99.85%, op_acc: 84.91%] [G loss: 6.473269]\n",
            "Validating on test set\n",
            "Validation Metrics: 2626 [D loss: 0.161874, acc.: 100.00%, op_acc: 96.39%] [G loss: 5.992716]\n",
            "(1024, 1)\n",
            "Training Metrics: 2627 [D loss: 0.504651, acc.: 99.80%, op_acc: 83.15%] [G loss: 6.122704]\n",
            "Validating on test set\n",
            "Validation Metrics: 2627 [D loss: 0.155725, acc.: 100.00%, op_acc: 96.00%] [G loss: 5.799345]\n",
            "(1024, 1)\n",
            "Training Metrics: 2628 [D loss: 0.513337, acc.: 99.76%, op_acc: 81.49%] [G loss: 6.451427]\n",
            "Validating on test set\n",
            "Validation Metrics: 2628 [D loss: 0.174326, acc.: 100.00%, op_acc: 96.97%] [G loss: 6.524012]\n",
            "(1024, 1)\n",
            "Training Metrics: 2629 [D loss: 0.533728, acc.: 99.90%, op_acc: 82.91%] [G loss: 5.941071]\n",
            "Validating on test set\n",
            "Validation Metrics: 2629 [D loss: 0.140734, acc.: 100.00%, op_acc: 96.48%] [G loss: 5.730306]\n",
            "(1024, 1)\n",
            "Training Metrics: 2630 [D loss: 0.493160, acc.: 99.80%, op_acc: 82.28%] [G loss: 6.387565]\n",
            "Validating on test set\n",
            "Validation Metrics: 2630 [D loss: 0.115254, acc.: 100.00%, op_acc: 97.56%] [G loss: 6.533116]\n",
            "(1024, 1)\n",
            "Training Metrics: 2631 [D loss: 0.438378, acc.: 99.76%, op_acc: 84.47%] [G loss: 7.453625]\n",
            "Validating on test set\n",
            "Validation Metrics: 2631 [D loss: 0.334315, acc.: 100.00%, op_acc: 92.77%] [G loss: 7.583730]\n",
            "(1024, 1)\n",
            "Training Metrics: 2632 [D loss: 0.496096, acc.: 99.61%, op_acc: 82.37%] [G loss: 5.890509]\n",
            "Validating on test set\n",
            "Validation Metrics: 2632 [D loss: 0.092836, acc.: 100.00%, op_acc: 96.97%] [G loss: 5.708147]\n",
            "(1024, 1)\n",
            "Training Metrics: 2633 [D loss: 0.427584, acc.: 99.76%, op_acc: 83.84%] [G loss: 6.172979]\n",
            "Validating on test set\n",
            "Validation Metrics: 2633 [D loss: 0.046818, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.130670]\n",
            "(1024, 1)\n",
            "Training Metrics: 2634 [D loss: 0.434282, acc.: 99.80%, op_acc: 84.81%] [G loss: 6.019093]\n",
            "Validating on test set\n",
            "Validation Metrics: 2634 [D loss: 0.040962, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.928417]\n",
            "(1024, 1)\n",
            "Training Metrics: 2635 [D loss: 0.430031, acc.: 99.80%, op_acc: 84.47%] [G loss: 6.121696]\n",
            "Validating on test set\n",
            "Validation Metrics: 2635 [D loss: 0.041346, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.064492]\n",
            "(1024, 1)\n",
            "Training Metrics: 2636 [D loss: 0.409554, acc.: 99.95%, op_acc: 85.01%] [G loss: 5.661201]\n",
            "Validating on test set\n",
            "Validation Metrics: 2636 [D loss: 0.055991, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.672011]\n",
            "(1024, 1)\n",
            "Training Metrics: 2637 [D loss: 0.405838, acc.: 99.90%, op_acc: 85.89%] [G loss: 6.285595]\n",
            "Validating on test set\n",
            "Validation Metrics: 2637 [D loss: 0.046098, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.255294]\n",
            "(1024, 1)\n",
            "Training Metrics: 2638 [D loss: 0.419292, acc.: 99.80%, op_acc: 85.79%] [G loss: 6.274602]\n",
            "Validating on test set\n",
            "Validation Metrics: 2638 [D loss: 0.046613, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.245822]\n",
            "(1024, 1)\n",
            "Training Metrics: 2639 [D loss: 0.438831, acc.: 99.80%, op_acc: 85.06%] [G loss: 5.721398]\n",
            "Validating on test set\n",
            "Validation Metrics: 2639 [D loss: 0.047984, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.760633]\n",
            "(1024, 1)\n",
            "Training Metrics: 2640 [D loss: 0.431972, acc.: 99.85%, op_acc: 85.79%] [G loss: 6.302259]\n",
            "Validating on test set\n",
            "Validation Metrics: 2640 [D loss: 0.048150, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.304594]\n",
            "(1024, 1)\n",
            "Training Metrics: 2641 [D loss: 0.447176, acc.: 99.90%, op_acc: 83.74%] [G loss: 5.852982]\n",
            "Validating on test set\n",
            "Validation Metrics: 2641 [D loss: 0.051038, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.898099]\n",
            "(1024, 1)\n",
            "Training Metrics: 2642 [D loss: 0.457014, acc.: 99.76%, op_acc: 85.06%] [G loss: 5.978720]\n",
            "Validating on test set\n",
            "Validation Metrics: 2642 [D loss: 0.047345, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.981139]\n",
            "(1024, 1)\n",
            "Training Metrics: 2643 [D loss: 0.437744, acc.: 99.80%, op_acc: 84.52%] [G loss: 5.712863]\n",
            "Validating on test set\n",
            "Validation Metrics: 2643 [D loss: 0.045693, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.713924]\n",
            "(1024, 1)\n",
            "Training Metrics: 2644 [D loss: 0.403219, acc.: 99.90%, op_acc: 86.96%] [G loss: 6.397079]\n",
            "Validating on test set\n",
            "Validation Metrics: 2644 [D loss: 0.042968, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.426589]\n",
            "(1024, 1)\n",
            "Training Metrics: 2645 [D loss: 0.426822, acc.: 99.61%, op_acc: 85.45%] [G loss: 5.797578]\n",
            "Validating on test set\n",
            "Validation Metrics: 2645 [D loss: 0.054859, acc.: 100.00%, op_acc: 99.71%] [G loss: 5.819913]\n",
            "(1024, 1)\n",
            "Training Metrics: 2646 [D loss: 0.417246, acc.: 99.80%, op_acc: 85.50%] [G loss: 5.598407]\n",
            "Validating on test set\n",
            "Validation Metrics: 2646 [D loss: 0.052112, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.640828]\n",
            "(1024, 1)\n",
            "Training Metrics: 2647 [D loss: 0.396684, acc.: 99.90%, op_acc: 85.30%] [G loss: 5.937294]\n",
            "Validating on test set\n",
            "Validation Metrics: 2647 [D loss: 0.045960, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.900409]\n",
            "(1024, 1)\n",
            "Training Metrics: 2648 [D loss: 0.408219, acc.: 99.76%, op_acc: 85.25%] [G loss: 6.323596]\n",
            "Validating on test set\n",
            "Validation Metrics: 2648 [D loss: 0.041096, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.317822]\n",
            "(1024, 1)\n",
            "Training Metrics: 2649 [D loss: 0.421012, acc.: 99.61%, op_acc: 85.79%] [G loss: 5.666141]\n",
            "Validating on test set\n",
            "Validation Metrics: 2649 [D loss: 0.042945, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.691577]\n",
            "(1024, 1)\n",
            "Training Metrics: 2650 [D loss: 0.425050, acc.: 99.85%, op_acc: 85.16%] [G loss: 6.303593]\n",
            "Validating on test set\n",
            "Validation Metrics: 2650 [D loss: 0.050383, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.323078]\n",
            "(1024, 1)\n",
            "Training Metrics: 2651 [D loss: 0.468756, acc.: 99.56%, op_acc: 83.01%] [G loss: 5.729859]\n",
            "Validating on test set\n",
            "Validation Metrics: 2651 [D loss: 0.044053, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.683648]\n",
            "(1024, 1)\n",
            "Training Metrics: 2652 [D loss: 0.421368, acc.: 99.95%, op_acc: 84.81%] [G loss: 6.191577]\n",
            "Validating on test set\n",
            "Validation Metrics: 2652 [D loss: 0.045423, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.198508]\n",
            "(1024, 1)\n",
            "Training Metrics: 2653 [D loss: 0.408297, acc.: 99.85%, op_acc: 86.13%] [G loss: 6.422328]\n",
            "Validating on test set\n",
            "Validation Metrics: 2653 [D loss: 0.038685, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.390628]\n",
            "(1024, 1)\n",
            "Training Metrics: 2654 [D loss: 0.442593, acc.: 99.71%, op_acc: 83.98%] [G loss: 5.759922]\n",
            "Validating on test set\n",
            "Validation Metrics: 2654 [D loss: 0.042258, acc.: 100.00%, op_acc: 99.80%] [G loss: 5.768844]\n",
            "(1024, 1)\n",
            "Training Metrics: 2655 [D loss: 0.423685, acc.: 99.71%, op_acc: 84.86%] [G loss: 5.868880]\n",
            "Validating on test set\n",
            "Validation Metrics: 2655 [D loss: 0.041063, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.818742]\n",
            "(1024, 1)\n",
            "Training Metrics: 2656 [D loss: 0.434516, acc.: 100.00%, op_acc: 84.86%] [G loss: 6.441531]\n",
            "Validating on test set\n",
            "Validation Metrics: 2656 [D loss: 0.038745, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.423293]\n",
            "(1024, 1)\n",
            "Training Metrics: 2657 [D loss: 0.441002, acc.: 99.80%, op_acc: 85.79%] [G loss: 5.916525]\n",
            "Validating on test set\n",
            "Validation Metrics: 2657 [D loss: 0.041804, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.914086]\n",
            "(1024, 1)\n",
            "Training Metrics: 2658 [D loss: 0.392458, acc.: 99.85%, op_acc: 85.94%] [G loss: 6.206901]\n",
            "Validating on test set\n",
            "Validation Metrics: 2658 [D loss: 0.041753, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.153108]\n",
            "(1024, 1)\n",
            "Training Metrics: 2659 [D loss: 0.392926, acc.: 99.90%, op_acc: 86.08%] [G loss: 6.458572]\n",
            "Validating on test set\n",
            "Validation Metrics: 2659 [D loss: 0.039047, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.446307]\n",
            "(1024, 1)\n",
            "Training Metrics: 2660 [D loss: 0.448100, acc.: 99.80%, op_acc: 84.23%] [G loss: 6.386926]\n",
            "Validating on test set\n",
            "Validation Metrics: 2660 [D loss: 0.038375, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.391579]\n",
            "(1024, 1)\n",
            "Training Metrics: 2661 [D loss: 0.451752, acc.: 99.80%, op_acc: 84.57%] [G loss: 5.911460]\n",
            "Validating on test set\n",
            "Validation Metrics: 2661 [D loss: 0.043354, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.905071]\n",
            "(1024, 1)\n",
            "Training Metrics: 2662 [D loss: 0.444219, acc.: 99.95%, op_acc: 84.67%] [G loss: 6.282075]\n",
            "Validating on test set\n",
            "Validation Metrics: 2662 [D loss: 0.043093, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.277775]\n",
            "(1024, 1)\n",
            "Training Metrics: 2663 [D loss: 0.455009, acc.: 99.71%, op_acc: 85.16%] [G loss: 5.981583]\n",
            "Validating on test set\n",
            "Validation Metrics: 2663 [D loss: 0.043691, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.961549]\n",
            "(1024, 1)\n",
            "Training Metrics: 2664 [D loss: 0.419523, acc.: 99.85%, op_acc: 85.06%] [G loss: 5.644528]\n",
            "Validating on test set\n",
            "Validation Metrics: 2664 [D loss: 0.041576, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.646138]\n",
            "(1024, 1)\n",
            "Training Metrics: 2665 [D loss: 0.434267, acc.: 99.85%, op_acc: 85.21%] [G loss: 6.376056]\n",
            "Validating on test set\n",
            "Validation Metrics: 2665 [D loss: 0.045511, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.371190]\n",
            "(1024, 1)\n",
            "Training Metrics: 2666 [D loss: 0.429072, acc.: 99.71%, op_acc: 86.18%] [G loss: 5.936129]\n",
            "Validating on test set\n",
            "Validation Metrics: 2666 [D loss: 0.044404, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.913160]\n",
            "(1024, 1)\n",
            "Training Metrics: 2667 [D loss: 0.429647, acc.: 99.85%, op_acc: 84.86%] [G loss: 6.058784]\n",
            "Validating on test set\n",
            "Validation Metrics: 2667 [D loss: 0.036707, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.040837]\n",
            "(1024, 1)\n",
            "Training Metrics: 2668 [D loss: 0.411735, acc.: 99.90%, op_acc: 84.77%] [G loss: 5.883731]\n",
            "Validating on test set\n",
            "Validation Metrics: 2668 [D loss: 0.035606, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.869926]\n",
            "(1024, 1)\n",
            "Training Metrics: 2669 [D loss: 0.423248, acc.: 99.80%, op_acc: 85.55%] [G loss: 6.482172]\n",
            "Validating on test set\n",
            "Validation Metrics: 2669 [D loss: 0.036138, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.477145]\n",
            "(1024, 1)\n",
            "Training Metrics: 2670 [D loss: 0.407608, acc.: 99.95%, op_acc: 86.47%] [G loss: 5.829553]\n",
            "Validating on test set\n",
            "Validation Metrics: 2670 [D loss: 0.044995, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.807194]\n",
            "(1024, 1)\n",
            "Training Metrics: 2671 [D loss: 0.427201, acc.: 99.80%, op_acc: 84.47%] [G loss: 6.567628]\n",
            "Validating on test set\n",
            "Validation Metrics: 2671 [D loss: 0.036104, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.583826]\n",
            "(1024, 1)\n",
            "Training Metrics: 2672 [D loss: 0.406053, acc.: 99.76%, op_acc: 85.89%] [G loss: 5.561073]\n",
            "Validating on test set\n",
            "Validation Metrics: 2672 [D loss: 0.042950, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.544378]\n",
            "(1024, 1)\n",
            "Training Metrics: 2673 [D loss: 0.403699, acc.: 99.90%, op_acc: 85.40%] [G loss: 6.545732]\n",
            "Validating on test set\n",
            "Validation Metrics: 2673 [D loss: 0.036945, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.533685]\n",
            "(1024, 1)\n",
            "Training Metrics: 2674 [D loss: 0.417361, acc.: 99.85%, op_acc: 84.23%] [G loss: 6.358378]\n",
            "Validating on test set\n",
            "Validation Metrics: 2674 [D loss: 0.035339, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.323565]\n",
            "(1024, 1)\n",
            "Training Metrics: 2675 [D loss: 0.408561, acc.: 99.80%, op_acc: 86.33%] [G loss: 6.015581]\n",
            "Validating on test set\n",
            "Validation Metrics: 2675 [D loss: 0.036586, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.003137]\n",
            "(1024, 1)\n",
            "Training Metrics: 2676 [D loss: 0.416776, acc.: 100.00%, op_acc: 85.94%] [G loss: 6.211985]\n",
            "Validating on test set\n",
            "Validation Metrics: 2676 [D loss: 0.035215, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.224136]\n",
            "(1024, 1)\n",
            "Training Metrics: 2677 [D loss: 0.389892, acc.: 99.90%, op_acc: 85.99%] [G loss: 6.359697]\n",
            "Validating on test set\n",
            "Validation Metrics: 2677 [D loss: 0.043622, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.350549]\n",
            "(1024, 1)\n",
            "Training Metrics: 2678 [D loss: 0.402681, acc.: 99.80%, op_acc: 86.62%] [G loss: 6.400321]\n",
            "Validating on test set\n",
            "Validation Metrics: 2678 [D loss: 0.037003, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.389787]\n",
            "(1024, 1)\n",
            "Training Metrics: 2679 [D loss: 0.399615, acc.: 99.95%, op_acc: 86.67%] [G loss: 6.130921]\n",
            "Validating on test set\n",
            "Validation Metrics: 2679 [D loss: 0.036946, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.109984]\n",
            "(1024, 1)\n",
            "Training Metrics: 2680 [D loss: 0.407578, acc.: 99.80%, op_acc: 85.30%] [G loss: 6.093825]\n",
            "Validating on test set\n",
            "Validation Metrics: 2680 [D loss: 0.035994, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.102843]\n",
            "(1024, 1)\n",
            "Training Metrics: 2681 [D loss: 0.387576, acc.: 99.71%, op_acc: 86.57%] [G loss: 5.884620]\n",
            "Validating on test set\n",
            "Validation Metrics: 2681 [D loss: 0.034057, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.891870]\n",
            "(1024, 1)\n",
            "Training Metrics: 2682 [D loss: 0.402867, acc.: 99.85%, op_acc: 85.84%] [G loss: 6.241139]\n",
            "Validating on test set\n",
            "Validation Metrics: 2682 [D loss: 0.034103, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.237494]\n",
            "(1024, 1)\n",
            "Training Metrics: 2683 [D loss: 0.444914, acc.: 99.76%, op_acc: 84.42%] [G loss: 5.802309]\n",
            "Validating on test set\n",
            "Validation Metrics: 2683 [D loss: 0.035859, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.787014]\n",
            "(1024, 1)\n",
            "Training Metrics: 2684 [D loss: 0.412818, acc.: 99.76%, op_acc: 85.16%] [G loss: 6.084495]\n",
            "Validating on test set\n",
            "Validation Metrics: 2684 [D loss: 0.034134, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.091282]\n",
            "(1024, 1)\n",
            "Training Metrics: 2685 [D loss: 0.430531, acc.: 99.90%, op_acc: 84.52%] [G loss: 5.964259]\n",
            "Validating on test set\n",
            "Validation Metrics: 2685 [D loss: 0.033201, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.957921]\n",
            "(1024, 1)\n",
            "Training Metrics: 2686 [D loss: 0.449486, acc.: 99.76%, op_acc: 84.81%] [G loss: 5.922788]\n",
            "Validating on test set\n",
            "Validation Metrics: 2686 [D loss: 0.034166, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.955568]\n",
            "(1024, 1)\n",
            "Training Metrics: 2687 [D loss: 0.409009, acc.: 99.80%, op_acc: 85.94%] [G loss: 5.991636]\n",
            "Validating on test set\n",
            "Validation Metrics: 2687 [D loss: 0.034630, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.013259]\n",
            "(1024, 1)\n",
            "Training Metrics: 2688 [D loss: 0.361687, acc.: 99.90%, op_acc: 86.57%] [G loss: 6.330535]\n",
            "Validating on test set\n",
            "Validation Metrics: 2688 [D loss: 0.032566, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.318616]\n",
            "(1024, 1)\n",
            "Training Metrics: 2689 [D loss: 0.398780, acc.: 99.90%, op_acc: 86.04%] [G loss: 6.178030]\n",
            "Validating on test set\n",
            "Validation Metrics: 2689 [D loss: 0.037495, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.167984]\n",
            "(1024, 1)\n",
            "Training Metrics: 2690 [D loss: 0.450564, acc.: 99.90%, op_acc: 84.23%] [G loss: 6.206420]\n",
            "Validating on test set\n",
            "Validation Metrics: 2690 [D loss: 0.037733, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.194236]\n",
            "(1024, 1)\n",
            "Training Metrics: 2691 [D loss: 0.414848, acc.: 99.71%, op_acc: 85.89%] [G loss: 5.874665]\n",
            "Validating on test set\n",
            "Validation Metrics: 2691 [D loss: 0.032492, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.890277]\n",
            "(1024, 1)\n",
            "Training Metrics: 2692 [D loss: 0.408799, acc.: 99.85%, op_acc: 84.52%] [G loss: 5.811992]\n",
            "Validating on test set\n",
            "Validation Metrics: 2692 [D loss: 0.034065, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.824946]\n",
            "(1024, 1)\n",
            "Training Metrics: 2693 [D loss: 0.408729, acc.: 99.80%, op_acc: 84.81%] [G loss: 5.522127]\n",
            "Validating on test set\n",
            "Validation Metrics: 2693 [D loss: 0.034683, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.513428]\n",
            "(1024, 1)\n",
            "Training Metrics: 2694 [D loss: 0.403662, acc.: 99.85%, op_acc: 85.84%] [G loss: 6.224702]\n",
            "Validating on test set\n",
            "Validation Metrics: 2694 [D loss: 0.037272, acc.: 100.00%, op_acc: 99.80%] [G loss: 6.233726]\n",
            "(1024, 1)\n",
            "Training Metrics: 2695 [D loss: 0.435301, acc.: 100.00%, op_acc: 83.94%] [G loss: 6.425806]\n",
            "Validating on test set\n",
            "Validation Metrics: 2695 [D loss: 0.033434, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.429931]\n",
            "(1024, 1)\n",
            "Training Metrics: 2696 [D loss: 0.416798, acc.: 99.85%, op_acc: 85.55%] [G loss: 6.716985]\n",
            "Validating on test set\n",
            "Validation Metrics: 2696 [D loss: 0.031671, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.702731]\n",
            "(1024, 1)\n",
            "Training Metrics: 2697 [D loss: 0.406155, acc.: 99.85%, op_acc: 84.86%] [G loss: 5.786239]\n",
            "Validating on test set\n",
            "Validation Metrics: 2697 [D loss: 0.033286, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.781479]\n",
            "(1024, 1)\n",
            "Training Metrics: 2698 [D loss: 0.398265, acc.: 100.00%, op_acc: 86.23%] [G loss: 6.775196]\n",
            "Validating on test set\n",
            "Validation Metrics: 2698 [D loss: 0.033103, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.781086]\n",
            "(1024, 1)\n",
            "Training Metrics: 2699 [D loss: 0.386100, acc.: 99.61%, op_acc: 86.96%] [G loss: 6.007997]\n",
            "Validating on test set\n",
            "Validation Metrics: 2699 [D loss: 0.036221, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.013384]\n",
            "(1024, 1)\n",
            "Training Metrics: 2700 [D loss: 0.362347, acc.: 100.00%, op_acc: 86.67%] [G loss: 6.244243]\n",
            "Validating on test set\n",
            "Validation Metrics: 2700 [D loss: 0.031234, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.246264]\n",
            "(1024, 1)\n",
            "Training Metrics: 2701 [D loss: 0.401217, acc.: 99.85%, op_acc: 86.47%] [G loss: 6.278293]\n",
            "Validating on test set\n",
            "Validation Metrics: 2701 [D loss: 0.030083, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.279668]\n",
            "(1024, 1)\n",
            "Training Metrics: 2702 [D loss: 0.365918, acc.: 99.71%, op_acc: 86.38%] [G loss: 5.791483]\n",
            "Validating on test set\n",
            "Validation Metrics: 2702 [D loss: 0.031732, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.794682]\n",
            "(1024, 1)\n",
            "Training Metrics: 2703 [D loss: 0.392270, acc.: 100.00%, op_acc: 86.13%] [G loss: 6.557044]\n",
            "Validating on test set\n",
            "Validation Metrics: 2703 [D loss: 0.031573, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.575285]\n",
            "(1024, 1)\n",
            "Training Metrics: 2704 [D loss: 0.412303, acc.: 99.85%, op_acc: 86.91%] [G loss: 6.513611]\n",
            "Validating on test set\n",
            "Validation Metrics: 2704 [D loss: 0.034378, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.490879]\n",
            "(1024, 1)\n",
            "Training Metrics: 2705 [D loss: 0.365815, acc.: 99.90%, op_acc: 86.77%] [G loss: 6.634907]\n",
            "Validating on test set\n",
            "Validation Metrics: 2705 [D loss: 0.031719, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.613129]\n",
            "(1024, 1)\n",
            "Training Metrics: 2706 [D loss: 0.409567, acc.: 99.95%, op_acc: 85.25%] [G loss: 6.136696]\n",
            "Validating on test set\n",
            "Validation Metrics: 2706 [D loss: 0.029395, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.131502]\n",
            "(1024, 1)\n",
            "Training Metrics: 2707 [D loss: 0.406345, acc.: 99.85%, op_acc: 85.25%] [G loss: 6.143846]\n",
            "Validating on test set\n",
            "Validation Metrics: 2707 [D loss: 0.032962, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.150850]\n",
            "(1024, 1)\n",
            "Training Metrics: 2708 [D loss: 0.439485, acc.: 99.95%, op_acc: 85.06%] [G loss: 6.815911]\n",
            "Validating on test set\n",
            "Validation Metrics: 2708 [D loss: 0.033139, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.826152]\n",
            "(1024, 1)\n",
            "Training Metrics: 2709 [D loss: 0.397237, acc.: 99.85%, op_acc: 85.35%] [G loss: 6.017994]\n",
            "Validating on test set\n",
            "Validation Metrics: 2709 [D loss: 0.031480, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.040822]\n",
            "(1024, 1)\n",
            "Training Metrics: 2710 [D loss: 0.416422, acc.: 100.00%, op_acc: 85.30%] [G loss: 6.280394]\n",
            "Validating on test set\n",
            "Validation Metrics: 2710 [D loss: 0.029808, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.266569]\n",
            "(1024, 1)\n",
            "Training Metrics: 2711 [D loss: 0.414969, acc.: 99.71%, op_acc: 85.35%] [G loss: 6.500538]\n",
            "Validating on test set\n",
            "Validation Metrics: 2711 [D loss: 0.033762, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.502062]\n",
            "(1024, 1)\n",
            "Training Metrics: 2712 [D loss: 0.432415, acc.: 99.85%, op_acc: 85.21%] [G loss: 6.070756]\n",
            "Validating on test set\n",
            "Validation Metrics: 2712 [D loss: 0.032739, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.067563]\n",
            "(1024, 1)\n",
            "Training Metrics: 2713 [D loss: 0.427327, acc.: 99.80%, op_acc: 84.81%] [G loss: 6.345653]\n",
            "Validating on test set\n",
            "Validation Metrics: 2713 [D loss: 0.030454, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.365539]\n",
            "(1024, 1)\n",
            "Training Metrics: 2714 [D loss: 0.365842, acc.: 99.90%, op_acc: 87.21%] [G loss: 5.852660]\n",
            "Validating on test set\n",
            "Validation Metrics: 2714 [D loss: 0.033513, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.851772]\n",
            "(1024, 1)\n",
            "Training Metrics: 2715 [D loss: 0.374299, acc.: 99.95%, op_acc: 86.28%] [G loss: 6.628150]\n",
            "Validating on test set\n",
            "Validation Metrics: 2715 [D loss: 0.030657, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.644557]\n",
            "(1024, 1)\n",
            "Training Metrics: 2716 [D loss: 0.390053, acc.: 99.76%, op_acc: 85.74%] [G loss: 6.391163]\n",
            "Validating on test set\n",
            "Validation Metrics: 2716 [D loss: 0.029927, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.369476]\n",
            "(1024, 1)\n",
            "Training Metrics: 2717 [D loss: 0.417423, acc.: 99.71%, op_acc: 85.69%] [G loss: 6.040248]\n",
            "Validating on test set\n",
            "Validation Metrics: 2717 [D loss: 0.033093, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.067569]\n",
            "(1024, 1)\n",
            "Training Metrics: 2718 [D loss: 0.403668, acc.: 99.95%, op_acc: 84.77%] [G loss: 6.173778]\n",
            "Validating on test set\n",
            "Validation Metrics: 2718 [D loss: 0.030080, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.174584]\n",
            "(1024, 1)\n",
            "Training Metrics: 2719 [D loss: 0.459413, acc.: 99.76%, op_acc: 84.28%] [G loss: 5.995591]\n",
            "Validating on test set\n",
            "Validation Metrics: 2719 [D loss: 0.031452, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.990255]\n",
            "(1024, 1)\n",
            "Training Metrics: 2720 [D loss: 0.417448, acc.: 99.80%, op_acc: 84.33%] [G loss: 6.096589]\n",
            "Validating on test set\n",
            "Validation Metrics: 2720 [D loss: 0.034662, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.091255]\n",
            "(1024, 1)\n",
            "Training Metrics: 2721 [D loss: 0.453391, acc.: 99.85%, op_acc: 83.40%] [G loss: 5.937714]\n",
            "Validating on test set\n",
            "Validation Metrics: 2721 [D loss: 0.031664, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.924514]\n",
            "(1024, 1)\n",
            "Training Metrics: 2722 [D loss: 0.444644, acc.: 99.76%, op_acc: 84.28%] [G loss: 5.906936]\n",
            "Validating on test set\n",
            "Validation Metrics: 2722 [D loss: 0.031933, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.902030]\n",
            "(1024, 1)\n",
            "Training Metrics: 2723 [D loss: 0.408146, acc.: 99.80%, op_acc: 85.99%] [G loss: 5.900174]\n",
            "Validating on test set\n",
            "Validation Metrics: 2723 [D loss: 0.034088, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.915677]\n",
            "(1024, 1)\n",
            "Training Metrics: 2724 [D loss: 0.400767, acc.: 99.95%, op_acc: 84.96%] [G loss: 6.390959]\n",
            "Validating on test set\n",
            "Validation Metrics: 2724 [D loss: 0.031294, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.389827]\n",
            "(1024, 1)\n",
            "Training Metrics: 2725 [D loss: 0.397544, acc.: 99.76%, op_acc: 85.25%] [G loss: 5.937943]\n",
            "Validating on test set\n",
            "Validation Metrics: 2725 [D loss: 0.031397, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.922647]\n",
            "(1024, 1)\n",
            "Training Metrics: 2726 [D loss: 0.421422, acc.: 99.80%, op_acc: 84.77%] [G loss: 5.864600]\n",
            "Validating on test set\n",
            "Validation Metrics: 2726 [D loss: 0.036637, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.941873]\n",
            "(1024, 1)\n",
            "Training Metrics: 2727 [D loss: 0.440123, acc.: 99.80%, op_acc: 85.11%] [G loss: 5.818781]\n",
            "Validating on test set\n",
            "Validation Metrics: 2727 [D loss: 0.036865, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.787750]\n",
            "(1024, 1)\n",
            "Training Metrics: 2728 [D loss: 0.421287, acc.: 99.90%, op_acc: 85.35%] [G loss: 6.412990]\n",
            "Validating on test set\n",
            "Validation Metrics: 2728 [D loss: 0.034570, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.408127]\n",
            "(1024, 1)\n",
            "Training Metrics: 2729 [D loss: 0.427964, acc.: 99.85%, op_acc: 84.13%] [G loss: 6.054812]\n",
            "Validating on test set\n",
            "Validation Metrics: 2729 [D loss: 0.043713, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.992171]\n",
            "(1024, 1)\n",
            "Training Metrics: 2730 [D loss: 0.423275, acc.: 99.90%, op_acc: 86.28%] [G loss: 6.239106]\n",
            "Validating on test set\n",
            "Validation Metrics: 2730 [D loss: 0.035141, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.194743]\n",
            "(1024, 1)\n",
            "Training Metrics: 2731 [D loss: 0.392809, acc.: 99.95%, op_acc: 85.40%] [G loss: 6.398694]\n",
            "Validating on test set\n",
            "Validation Metrics: 2731 [D loss: 0.031401, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.389725]\n",
            "(1024, 1)\n",
            "Training Metrics: 2732 [D loss: 0.473109, acc.: 99.95%, op_acc: 83.40%] [G loss: 6.466826]\n",
            "Validating on test set\n",
            "Validation Metrics: 2732 [D loss: 0.026540, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.450106]\n",
            "(1024, 1)\n",
            "Training Metrics: 2733 [D loss: 0.446189, acc.: 99.95%, op_acc: 84.03%] [G loss: 6.474231]\n",
            "Validating on test set\n",
            "Validation Metrics: 2733 [D loss: 0.028457, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.468301]\n",
            "(1024, 1)\n",
            "Training Metrics: 2734 [D loss: 0.431576, acc.: 99.80%, op_acc: 85.21%] [G loss: 6.594336]\n",
            "Validating on test set\n",
            "Validation Metrics: 2734 [D loss: 0.027479, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.592537]\n",
            "(1024, 1)\n",
            "Training Metrics: 2735 [D loss: 0.386863, acc.: 99.85%, op_acc: 85.69%] [G loss: 5.774201]\n",
            "Validating on test set\n",
            "Validation Metrics: 2735 [D loss: 0.029805, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.780569]\n",
            "(1024, 1)\n",
            "Training Metrics: 2736 [D loss: 0.429504, acc.: 99.71%, op_acc: 84.62%] [G loss: 6.504931]\n",
            "Validating on test set\n",
            "Validation Metrics: 2736 [D loss: 0.028234, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.481718]\n",
            "(1024, 1)\n",
            "Training Metrics: 2737 [D loss: 0.414925, acc.: 99.76%, op_acc: 85.84%] [G loss: 5.662570]\n",
            "Validating on test set\n",
            "Validation Metrics: 2737 [D loss: 0.032908, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.678870]\n",
            "(1024, 1)\n",
            "Training Metrics: 2738 [D loss: 0.384905, acc.: 100.00%, op_acc: 86.47%] [G loss: 6.295769]\n",
            "Validating on test set\n",
            "Validation Metrics: 2738 [D loss: 0.028754, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.291934]\n",
            "(1024, 1)\n",
            "Training Metrics: 2739 [D loss: 0.404039, acc.: 99.71%, op_acc: 85.64%] [G loss: 5.773678]\n",
            "Validating on test set\n",
            "Validation Metrics: 2739 [D loss: 0.033421, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.736862]\n",
            "(1024, 1)\n",
            "Training Metrics: 2740 [D loss: 0.378827, acc.: 99.90%, op_acc: 86.96%] [G loss: 5.964861]\n",
            "Validating on test set\n",
            "Validation Metrics: 2740 [D loss: 0.030631, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.975945]\n",
            "(1024, 1)\n",
            "Training Metrics: 2741 [D loss: 0.406479, acc.: 99.80%, op_acc: 85.30%] [G loss: 6.813808]\n",
            "Validating on test set\n",
            "Validation Metrics: 2741 [D loss: 0.028186, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.804630]\n",
            "(1024, 1)\n",
            "Training Metrics: 2742 [D loss: 0.444138, acc.: 100.00%, op_acc: 83.79%] [G loss: 6.051277]\n",
            "Validating on test set\n",
            "Validation Metrics: 2742 [D loss: 0.033149, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.049502]\n",
            "(1024, 1)\n",
            "Training Metrics: 2743 [D loss: 0.410760, acc.: 99.85%, op_acc: 85.99%] [G loss: 6.463511]\n",
            "Validating on test set\n",
            "Validation Metrics: 2743 [D loss: 0.028818, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.456626]\n",
            "(1024, 1)\n",
            "Training Metrics: 2744 [D loss: 0.418947, acc.: 99.61%, op_acc: 85.30%] [G loss: 5.645338]\n",
            "Validating on test set\n",
            "Validation Metrics: 2744 [D loss: 0.035972, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.678883]\n",
            "(1024, 1)\n",
            "Training Metrics: 2745 [D loss: 0.395463, acc.: 99.80%, op_acc: 85.74%] [G loss: 5.810506]\n",
            "Validating on test set\n",
            "Validation Metrics: 2745 [D loss: 0.032662, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.814447]\n",
            "(1024, 1)\n",
            "Training Metrics: 2746 [D loss: 0.405480, acc.: 99.90%, op_acc: 86.33%] [G loss: 6.477286]\n",
            "Validating on test set\n",
            "Validation Metrics: 2746 [D loss: 0.026383, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.463140]\n",
            "(1024, 1)\n",
            "Training Metrics: 2747 [D loss: 0.395315, acc.: 99.71%, op_acc: 86.13%] [G loss: 5.934167]\n",
            "Validating on test set\n",
            "Validation Metrics: 2747 [D loss: 0.030728, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.929990]\n",
            "(1024, 1)\n",
            "Training Metrics: 2748 [D loss: 0.388248, acc.: 99.90%, op_acc: 86.57%] [G loss: 6.272361]\n",
            "Validating on test set\n",
            "Validation Metrics: 2748 [D loss: 0.026967, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.290669]\n",
            "(1024, 1)\n",
            "Training Metrics: 2749 [D loss: 0.415921, acc.: 99.95%, op_acc: 85.11%] [G loss: 6.190329]\n",
            "Validating on test set\n",
            "Validation Metrics: 2749 [D loss: 0.030604, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.188572]\n",
            "(1024, 1)\n",
            "Training Metrics: 2750 [D loss: 0.391868, acc.: 99.85%, op_acc: 86.08%] [G loss: 6.454898]\n",
            "Validating on test set\n",
            "Validation Metrics: 2750 [D loss: 0.030305, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.447778]\n",
            "(1024, 1)\n",
            "Training Metrics: 2751 [D loss: 0.378157, acc.: 99.90%, op_acc: 86.52%] [G loss: 6.477676]\n",
            "Validating on test set\n",
            "Validation Metrics: 2751 [D loss: 0.028972, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.490809]\n",
            "(1024, 1)\n",
            "Training Metrics: 2752 [D loss: 0.402555, acc.: 99.76%, op_acc: 86.91%] [G loss: 5.868652]\n",
            "Validating on test set\n",
            "Validation Metrics: 2752 [D loss: 0.028687, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.869690]\n",
            "(1024, 1)\n",
            "Training Metrics: 2753 [D loss: 0.364902, acc.: 99.90%, op_acc: 87.30%] [G loss: 6.134429]\n",
            "Validating on test set\n",
            "Validation Metrics: 2753 [D loss: 0.026367, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.144315]\n",
            "(1024, 1)\n",
            "Training Metrics: 2754 [D loss: 0.398443, acc.: 99.95%, op_acc: 86.38%] [G loss: 6.229634]\n",
            "Validating on test set\n",
            "Validation Metrics: 2754 [D loss: 0.030165, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.224039]\n",
            "(1024, 1)\n",
            "Training Metrics: 2755 [D loss: 0.371821, acc.: 99.80%, op_acc: 86.62%] [G loss: 6.261420]\n",
            "Validating on test set\n",
            "Validation Metrics: 2755 [D loss: 0.035174, acc.: 100.00%, op_acc: 99.90%] [G loss: 6.240846]\n",
            "(1024, 1)\n",
            "Training Metrics: 2756 [D loss: 0.414843, acc.: 99.71%, op_acc: 86.28%] [G loss: 5.950409]\n",
            "Validating on test set\n",
            "Validation Metrics: 2756 [D loss: 0.028369, acc.: 100.00%, op_acc: 99.90%] [G loss: 5.950667]\n",
            "(1024, 1)\n",
            "Training Metrics: 2757 [D loss: 0.356882, acc.: 99.90%, op_acc: 87.94%] [G loss: 6.075563]\n",
            "Validating on test set\n",
            "Validation Metrics: 2757 [D loss: 0.028974, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.077645]\n",
            "(1024, 1)\n",
            "Training Metrics: 2758 [D loss: 0.418063, acc.: 99.95%, op_acc: 84.96%] [G loss: 5.923512]\n",
            "Validating on test set\n",
            "Validation Metrics: 2758 [D loss: 0.028857, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.909320]\n",
            "(1024, 1)\n",
            "Training Metrics: 2759 [D loss: 0.424540, acc.: 99.80%, op_acc: 84.23%] [G loss: 6.000277]\n",
            "Validating on test set\n",
            "Validation Metrics: 2759 [D loss: 0.032468, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.001684]\n",
            "(1024, 1)\n",
            "Training Metrics: 2760 [D loss: 0.413081, acc.: 99.95%, op_acc: 86.18%] [G loss: 6.149829]\n",
            "Validating on test set\n",
            "Validation Metrics: 2760 [D loss: 0.029234, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.142267]\n",
            "(1024, 1)\n",
            "Training Metrics: 2761 [D loss: 0.436812, acc.: 99.76%, op_acc: 84.57%] [G loss: 6.517107]\n",
            "Validating on test set\n",
            "Validation Metrics: 2761 [D loss: 0.027188, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.514770]\n",
            "(1024, 1)\n",
            "Training Metrics: 2762 [D loss: 0.400987, acc.: 99.85%, op_acc: 85.74%] [G loss: 6.045943]\n",
            "Validating on test set\n",
            "Validation Metrics: 2762 [D loss: 0.028357, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.048942]\n",
            "(1024, 1)\n",
            "Training Metrics: 2763 [D loss: 0.360056, acc.: 99.80%, op_acc: 87.65%] [G loss: 5.990661]\n",
            "Validating on test set\n",
            "Validation Metrics: 2763 [D loss: 0.028730, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.998544]\n",
            "(1024, 1)\n",
            "Training Metrics: 2764 [D loss: 0.380198, acc.: 99.85%, op_acc: 85.89%] [G loss: 6.619686]\n",
            "Validating on test set\n",
            "Validation Metrics: 2764 [D loss: 0.025637, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.617282]\n",
            "(1024, 1)\n",
            "Training Metrics: 2765 [D loss: 0.358064, acc.: 100.00%, op_acc: 87.45%] [G loss: 6.361090]\n",
            "Validating on test set\n",
            "Validation Metrics: 2765 [D loss: 0.027709, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.363823]\n",
            "(1024, 1)\n",
            "Training Metrics: 2766 [D loss: 0.430155, acc.: 99.85%, op_acc: 85.45%] [G loss: 6.667988]\n",
            "Validating on test set\n",
            "Validation Metrics: 2766 [D loss: 0.029091, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.654339]\n",
            "(1024, 1)\n",
            "Training Metrics: 2767 [D loss: 0.403510, acc.: 99.85%, op_acc: 85.16%] [G loss: 6.232118]\n",
            "Validating on test set\n",
            "Validation Metrics: 2767 [D loss: 0.029514, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.233803]\n",
            "(1024, 1)\n",
            "Training Metrics: 2768 [D loss: 0.389726, acc.: 99.95%, op_acc: 85.35%] [G loss: 6.801268]\n",
            "Validating on test set\n",
            "Validation Metrics: 2768 [D loss: 0.027372, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.793797]\n",
            "(1024, 1)\n",
            "Training Metrics: 2769 [D loss: 0.413177, acc.: 99.90%, op_acc: 84.86%] [G loss: 6.666966]\n",
            "Validating on test set\n",
            "Validation Metrics: 2769 [D loss: 0.027706, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.677685]\n",
            "(1024, 1)\n",
            "Training Metrics: 2770 [D loss: 0.425645, acc.: 99.90%, op_acc: 84.62%] [G loss: 6.600413]\n",
            "Validating on test set\n",
            "Validation Metrics: 2770 [D loss: 0.026772, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.592958]\n",
            "(1024, 1)\n",
            "Training Metrics: 2771 [D loss: 0.409356, acc.: 99.95%, op_acc: 84.62%] [G loss: 6.595914]\n",
            "Validating on test set\n",
            "Validation Metrics: 2771 [D loss: 0.030550, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.571807]\n",
            "(1024, 1)\n",
            "Training Metrics: 2772 [D loss: 0.398775, acc.: 99.95%, op_acc: 85.55%] [G loss: 6.748039]\n",
            "Validating on test set\n",
            "Validation Metrics: 2772 [D loss: 0.030326, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.777014]\n",
            "(1024, 1)\n",
            "Training Metrics: 2773 [D loss: 0.390017, acc.: 99.80%, op_acc: 85.64%] [G loss: 6.169400]\n",
            "Validating on test set\n",
            "Validation Metrics: 2773 [D loss: 0.032297, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.190617]\n",
            "(1024, 1)\n",
            "Training Metrics: 2774 [D loss: 0.433158, acc.: 99.80%, op_acc: 84.86%] [G loss: 6.046798]\n",
            "Validating on test set\n",
            "Validation Metrics: 2774 [D loss: 0.031650, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.043877]\n",
            "(1024, 1)\n",
            "Training Metrics: 2775 [D loss: 0.431846, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.375494]\n",
            "Validating on test set\n",
            "Validation Metrics: 2775 [D loss: 0.031836, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.375354]\n",
            "(1024, 1)\n",
            "Training Metrics: 2776 [D loss: 0.395232, acc.: 99.90%, op_acc: 86.28%] [G loss: 6.713589]\n",
            "Validating on test set\n",
            "Validation Metrics: 2776 [D loss: 0.025511, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.712458]\n",
            "(1024, 1)\n",
            "Training Metrics: 2777 [D loss: 0.387952, acc.: 99.85%, op_acc: 85.79%] [G loss: 6.435356]\n",
            "Validating on test set\n",
            "Validation Metrics: 2777 [D loss: 0.025645, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.413256]\n",
            "(1024, 1)\n",
            "Training Metrics: 2778 [D loss: 0.419308, acc.: 99.80%, op_acc: 83.98%] [G loss: 6.591067]\n",
            "Validating on test set\n",
            "Validation Metrics: 2778 [D loss: 0.023828, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.556767]\n",
            "(1024, 1)\n",
            "Training Metrics: 2779 [D loss: 0.409242, acc.: 99.85%, op_acc: 84.72%] [G loss: 5.814772]\n",
            "Validating on test set\n",
            "Validation Metrics: 2779 [D loss: 0.030682, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.822568]\n",
            "(1024, 1)\n",
            "Training Metrics: 2780 [D loss: 0.399104, acc.: 99.80%, op_acc: 86.62%] [G loss: 6.014043]\n",
            "Validating on test set\n",
            "Validation Metrics: 2780 [D loss: 0.027283, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.006854]\n",
            "(1024, 1)\n",
            "Training Metrics: 2781 [D loss: 0.396995, acc.: 99.90%, op_acc: 85.69%] [G loss: 6.091779]\n",
            "Validating on test set\n",
            "Validation Metrics: 2781 [D loss: 0.026074, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.093925]\n",
            "(1024, 1)\n",
            "Training Metrics: 2782 [D loss: 0.403856, acc.: 99.80%, op_acc: 85.45%] [G loss: 6.348271]\n",
            "Validating on test set\n",
            "Validation Metrics: 2782 [D loss: 0.024784, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.359079]\n",
            "(1024, 1)\n",
            "Training Metrics: 2783 [D loss: 0.374479, acc.: 99.85%, op_acc: 87.40%] [G loss: 6.212309]\n",
            "Validating on test set\n",
            "Validation Metrics: 2783 [D loss: 0.026816, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.230092]\n",
            "(1024, 1)\n",
            "Training Metrics: 2784 [D loss: 0.394400, acc.: 99.90%, op_acc: 85.16%] [G loss: 6.071296]\n",
            "Validating on test set\n",
            "Validation Metrics: 2784 [D loss: 0.029353, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.074972]\n",
            "(1024, 1)\n",
            "Training Metrics: 2785 [D loss: 0.402653, acc.: 100.00%, op_acc: 85.16%] [G loss: 6.877293]\n",
            "Validating on test set\n",
            "Validation Metrics: 2785 [D loss: 0.026945, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.878153]\n",
            "(1024, 1)\n",
            "Training Metrics: 2786 [D loss: 0.395504, acc.: 99.85%, op_acc: 86.04%] [G loss: 6.389488]\n",
            "Validating on test set\n",
            "Validation Metrics: 2786 [D loss: 0.028123, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.389993]\n",
            "(1024, 1)\n",
            "Training Metrics: 2787 [D loss: 0.428814, acc.: 99.85%, op_acc: 84.62%] [G loss: 6.669394]\n",
            "Validating on test set\n",
            "Validation Metrics: 2787 [D loss: 0.026137, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.660599]\n",
            "(1024, 1)\n",
            "Training Metrics: 2788 [D loss: 0.402967, acc.: 99.95%, op_acc: 85.69%] [G loss: 6.256967]\n",
            "Validating on test set\n",
            "Validation Metrics: 2788 [D loss: 0.033674, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.256651]\n",
            "(1024, 1)\n",
            "Training Metrics: 2789 [D loss: 0.407733, acc.: 99.90%, op_acc: 84.81%] [G loss: 6.576129]\n",
            "Validating on test set\n",
            "Validation Metrics: 2789 [D loss: 0.027677, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.576673]\n",
            "(1024, 1)\n",
            "Training Metrics: 2790 [D loss: 0.434951, acc.: 99.90%, op_acc: 84.03%] [G loss: 6.554473]\n",
            "Validating on test set\n",
            "Validation Metrics: 2790 [D loss: 0.026129, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.553732]\n",
            "(1024, 1)\n",
            "Training Metrics: 2791 [D loss: 0.421432, acc.: 99.90%, op_acc: 85.35%] [G loss: 6.567168]\n",
            "Validating on test set\n",
            "Validation Metrics: 2791 [D loss: 0.028152, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.571351]\n",
            "(1024, 1)\n",
            "Training Metrics: 2792 [D loss: 0.426973, acc.: 99.95%, op_acc: 84.47%] [G loss: 6.547031]\n",
            "Validating on test set\n",
            "Validation Metrics: 2792 [D loss: 0.029356, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.527774]\n",
            "(1024, 1)\n",
            "Training Metrics: 2793 [D loss: 0.373049, acc.: 99.80%, op_acc: 86.52%] [G loss: 6.043685]\n",
            "Validating on test set\n",
            "Validation Metrics: 2793 [D loss: 0.028571, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.032221]\n",
            "(1024, 1)\n",
            "Training Metrics: 2794 [D loss: 0.380671, acc.: 99.95%, op_acc: 85.45%] [G loss: 6.479534]\n",
            "Validating on test set\n",
            "Validation Metrics: 2794 [D loss: 0.027005, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.469005]\n",
            "(1024, 1)\n",
            "Training Metrics: 2795 [D loss: 0.391971, acc.: 99.85%, op_acc: 85.74%] [G loss: 5.648456]\n",
            "Validating on test set\n",
            "Validation Metrics: 2795 [D loss: 0.030738, acc.: 100.00%, op_acc: 100.00%] [G loss: 5.635049]\n",
            "(1024, 1)\n",
            "Training Metrics: 2796 [D loss: 0.369112, acc.: 99.95%, op_acc: 86.82%] [G loss: 7.030326]\n",
            "Validating on test set\n",
            "Validation Metrics: 2796 [D loss: 0.029032, acc.: 100.00%, op_acc: 99.90%] [G loss: 7.047925]\n",
            "(1024, 1)\n",
            "Training Metrics: 2797 [D loss: 0.370107, acc.: 99.85%, op_acc: 86.33%] [G loss: 6.572421]\n",
            "Validating on test set\n",
            "Validation Metrics: 2797 [D loss: 0.026902, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.592842]\n",
            "(1024, 1)\n",
            "Training Metrics: 2798 [D loss: 0.392575, acc.: 99.90%, op_acc: 85.60%] [G loss: 6.590532]\n",
            "Validating on test set\n",
            "Validation Metrics: 2798 [D loss: 0.025027, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.573014]\n",
            "(1024, 1)\n",
            "Training Metrics: 2799 [D loss: 0.393461, acc.: 99.85%, op_acc: 86.04%] [G loss: 6.140999]\n",
            "Validating on test set\n",
            "Validation Metrics: 2799 [D loss: 0.027801, acc.: 100.00%, op_acc: 100.00%] [G loss: 6.122840]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcHxsCQORRFA",
        "colab_type": "code",
        "outputId": "32501ab0-7cfc-4e7d-defe-e4373e905960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "GAN = define_discriminator()\n",
        "GAN.load_weights(\"model_0698.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 10, 256)           1280      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 10, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 10, 512)           524800    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "frozen_batch_normalization_1 (None, 10, 512)           2048      \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 10, 128)           262272    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1280)              0         \n",
            "=================================================================\n",
            "Total params: 790,400\n",
            "Trainable params: 789,376\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 10, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 1280)         790400      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1281        sequential_1[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 17)           21777       sequential_1[1][0]               \n",
            "==================================================================================================\n",
            "Total params: 813,458\n",
            "Trainable params: 812,434\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9eUwIAYNmzh",
        "colab_type": "code",
        "outputId": "1bf7d06b-11f2-49f3-db42-48f0631f7ee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "\n",
        "\n",
        "label_image = GAN.predict( fullDataX.to_numpy().reshape(145*145,10,1) )\n",
        "label_image = np.array(label_image[1])\n",
        "y = []\n",
        "for t in label_image:\n",
        "  y.append(np.argmax(t))\n",
        "label_image = np.array(y).reshape(145,145)\n",
        "image_label_overlay = label2rgb(label_image)\n",
        "fig, (ax1, ax2, ax3)  = plt.subplots(3,figsize=(10, 10))\n",
        "\n",
        "ax1.imshow(image_label_overlay)\n",
        "image_label_overlay = label2rgb(fullDataY.to_numpy().reshape(145,145))\n",
        "ax2.imshow(image_label_overlay)\n",
        "image_label_overlay = label2rgb(clf.predict(fullDataX.to_numpy()).reshape(145,145)  )\n",
        "ax3.imshow(image_label_overlay)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff4d66a6978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMsAAAJCCAYAAABu2zMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNUOm6H_VS99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyVYKhL1VNv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}